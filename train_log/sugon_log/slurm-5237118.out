+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/cvs.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/cvs.sh
++++ export CVS_RSH=ssh
++++ CVS_RSH=ssh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/gnome-ssh-askpass.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/gnome-ssh-askpass.sh
++++ SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
++++ export SSH_ASKPASS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mc.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mc.sh
++++ '[' -n '4.2.46(2)-release' ']'
++++ alias 'mc=. /usr/libexec/mc/mc-wrapper.sh'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 57947 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_2='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_2='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3
++++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3
++++ export CONDA_SHLVL=3
++++ CONDA_SHLVL=3
++++ export CONDA_DEFAULT_ENV=base
++++ CONDA_DEFAULT_ENV=base
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ export CONDA_PREFIX_2=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++++ CONDA_PREFIX_2=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++++ export _CE_M=
++++ _CE_M=
++++ export _CE_CONDA=
++++ _CE_CONDA=
++++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_3='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_3='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_3=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_3=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ TEST_DIR=./test_script
+ exp=exp15
+ echo exp15
exp15
+ cat
不同的op_per_job+MAML
试验步骤：用常规办法DAN.py训练op_per_job_options中的每个，得到几个模型,作为baseline
常规方法得到的模型进行迁移学习 从第一个问题模型迁移到其他，以及从最后一个问题的模型迁移到其他问题。
MAML训练
MAML迁移
对比试验结果
+ op_per_job_options='4 6 8 10 12'
+ logdir=./runs/exp15
+ hidden_dim_actor=64
+ hidden_dim_critic=64
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ n_j=15
+ n_m=5
+ data_source=SD2
+ logdir_dan=exp15/DAN
+ options=($op_per_job_options)
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN.py --n_j 15 --n_m 5 --data_source SD2 --model_suffix SD2_operjob4 --logdir exp15/DAN/train_model/4 --op_per_job 4 --max_updates 20
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_operjob4
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_operjob4
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/20 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.91	 makespan: 683.80	 Mean_loss: 4.67763901,  training time: 4.00
progress:   0%|[34m          [0m| 0/20 [00:03<?, ?it/s]progress:   5%|[34m▌         [0m| 1/20 [00:04<01:16,  4.00s/it]                                                        Episode 2	 reward: -7.18	 makespan: 710.75	 Mean_loss: 5.56926870,  training time: 1.29
progress:   5%|[34m▌         [0m| 1/20 [00:05<01:16,  4.00s/it]progress:  10%|[34m█         [0m| 2/20 [00:05<00:43,  2.41s/it]                                                        Episode 3	 reward: -7.12	 makespan: 705.05	 Mean_loss: 4.33746910,  training time: 1.22
progress:  10%|[34m█         [0m| 2/20 [00:06<00:43,  2.41s/it]progress:  15%|[34m█▌        [0m| 3/20 [00:06<00:31,  1.87s/it]                                                        Episode 4	 reward: -7.31	 makespan: 723.45	 Mean_loss: 4.15510321,  training time: 1.28
progress:  15%|[34m█▌        [0m| 3/20 [00:07<00:31,  1.87s/it]progress:  20%|[34m██        [0m| 4/20 [00:07<00:26,  1.64s/it]                                                        Episode 5	 reward: -7.02	 makespan: 694.90	 Mean_loss: 4.12584925,  training time: 1.27
progress:  20%|[34m██        [0m| 4/20 [00:09<00:26,  1.64s/it]progress:  25%|[34m██▌       [0m| 5/20 [00:09<00:22,  1.51s/it]                                                        Episode 6	 reward: -7.12	 makespan: 705.10	 Mean_loss: 2.82301402,  training time: 1.27
progress:  25%|[34m██▌       [0m| 5/20 [00:10<00:22,  1.51s/it]progress:  30%|[34m███       [0m| 6/20 [00:10<00:19,  1.43s/it]                                                        Episode 7	 reward: -6.87	 makespan: 680.45	 Mean_loss: 2.07966900,  training time: 1.27
progress:  30%|[34m███       [0m| 6/20 [00:11<00:19,  1.43s/it]progress:  35%|[34m███▌      [0m| 7/20 [00:11<00:17,  1.38s/it]                                                        Episode 8	 reward: -6.94	 makespan: 686.90	 Mean_loss: 1.46125376,  training time: 1.27
progress:  35%|[34m███▌      [0m| 7/20 [00:12<00:17,  1.38s/it]progress:  40%|[34m████      [0m| 8/20 [00:12<00:16,  1.34s/it]                                                        Episode 9	 reward: -6.85	 makespan: 678.10	 Mean_loss: 1.43748152,  training time: 1.26
progress:  40%|[34m████      [0m| 8/20 [00:14<00:16,  1.34s/it]progress:  45%|[34m████▌     [0m| 9/20 [00:14<00:14,  1.32s/it]                                                        Episode 10	 reward: -6.93	 makespan: 685.60	 Mean_loss: 1.45981240,  training time: 1.28
progress:  45%|[34m████▌     [0m| 9/20 [00:15<00:14,  1.32s/it]progress:  50%|[34m█████     [0m| 10/20 [00:15<00:13,  1.31s/it]                                                         Episode 11	 reward: -6.93	 makespan: 686.05	 Mean_loss: 1.37004006,  training time: 1.30
progress:  50%|[34m█████     [0m| 10/20 [00:16<00:13,  1.31s/it]progress:  55%|[34m█████▌    [0m| 11/20 [00:16<00:11,  1.31s/it]                                                         Episode 12	 reward: -6.89	 makespan: 682.45	 Mean_loss: 1.36105585,  training time: 1.27
progress:  55%|[34m█████▌    [0m| 11/20 [00:18<00:11,  1.31s/it]progress:  60%|[34m██████    [0m| 12/20 [00:18<00:10,  1.30s/it]                                                         Episode 13	 reward: -6.84	 makespan: 677.10	 Mean_loss: 1.47982454,  training time: 1.27
progress:  60%|[34m██████    [0m| 12/20 [00:19<00:10,  1.30s/it]progress:  65%|[34m██████▌   [0m| 13/20 [00:19<00:09,  1.29s/it]                                                         Episode 14	 reward: -6.83	 makespan: 676.15	 Mean_loss: 1.20331275,  training time: 1.27
progress:  65%|[34m██████▌   [0m| 13/20 [00:20<00:09,  1.29s/it]progress:  70%|[34m███████   [0m| 14/20 [00:20<00:07,  1.28s/it]                                                         Episode 15	 reward: -6.65	 makespan: 658.65	 Mean_loss: 0.99917805,  training time: 1.23
progress:  70%|[34m███████   [0m| 14/20 [00:21<00:07,  1.28s/it]progress:  75%|[34m███████▌  [0m| 15/20 [00:21<00:06,  1.27s/it]                                                         Episode 16	 reward: -6.77	 makespan: 670.60	 Mean_loss: 0.93986118,  training time: 1.24
progress:  75%|[34m███████▌  [0m| 15/20 [00:23<00:06,  1.27s/it]progress:  80%|[34m████████  [0m| 16/20 [00:23<00:05,  1.26s/it]                                                         Episode 17	 reward: -6.94	 makespan: 687.55	 Mean_loss: 0.92174208,  training time: 1.21
progress:  80%|[34m████████  [0m| 16/20 [00:24<00:05,  1.26s/it]progress:  85%|[34m████████▌ [0m| 17/20 [00:24<00:03,  1.25s/it]                                                         Episode 18	 reward: -6.74	 makespan: 666.85	 Mean_loss: 0.91857213,  training time: 1.26
progress:  85%|[34m████████▌ [0m| 17/20 [00:25<00:03,  1.25s/it]progress:  90%|[34m█████████ [0m| 18/20 [00:25<00:02,  1.25s/it]                                                         Episode 19	 reward: -6.68	 makespan: 660.95	 Mean_loss: 0.70889664,  training time: 1.27
progress:  90%|[34m█████████ [0m| 18/20 [00:26<00:02,  1.25s/it]progress:  95%|[34m█████████▌[0m| 19/20 [00:26<00:01,  1.26s/it]                                                         Episode 20	 reward: -6.44	 makespan: 637.55	 Mean_loss: 0.69198513,  training time: 1.27
progress:  95%|[34m█████████▌[0m| 19/20 [00:28<00:01,  1.26s/it]progress: 100%|[34m██████████[0m| 20/20 [00:28<00:00,  1.26s/it]progress: 100%|[34m██████████[0m| 20/20 [00:28<00:00,  1.40s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN.py --n_j 15 --n_m 5 --data_source SD2 --model_suffix SD2_operjob6 --logdir exp15/DAN/train_model/6 --op_per_job 6 --max_updates 20
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_operjob6
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_operjob6
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/20 [00:00<?, ?it/s]                                                Episode 1	 reward: -10.33	 makespan: 1023.00	 Mean_loss: 6.83565998,  training time: 2.88
progress:   0%|[34m          [0m| 0/20 [00:02<?, ?it/s]progress:   5%|[34m▌         [0m| 1/20 [00:02<00:54,  2.88s/it]                                                        Episode 2	 reward: -10.27	 makespan: 1017.10	 Mean_loss: 6.73180485,  training time: 1.79
progress:   5%|[34m▌         [0m| 1/20 [00:04<00:54,  2.88s/it]progress:  10%|[34m█         [0m| 2/20 [00:04<00:40,  2.24s/it]                                                        Episode 3	 reward: -9.91	 makespan: 980.90	 Mean_loss: 5.96374941,  training time: 1.80
progress:  10%|[34m█         [0m| 2/20 [00:06<00:40,  2.24s/it]progress:  15%|[34m█▌        [0m| 3/20 [00:06<00:34,  2.04s/it]                                                        Episode 4	 reward: -9.93	 makespan: 982.65	 Mean_loss: 5.48780823,  training time: 1.81
progress:  15%|[34m█▌        [0m| 3/20 [00:08<00:34,  2.04s/it]progress:  20%|[34m██        [0m| 4/20 [00:08<00:31,  1.95s/it]                                                        Episode 5	 reward: -10.15	 makespan: 1004.75	 Mean_loss: 5.20213556,  training time: 1.81
progress:  20%|[34m██        [0m| 4/20 [00:10<00:31,  1.95s/it]progress:  25%|[34m██▌       [0m| 5/20 [00:10<00:28,  1.90s/it]                                                        Episode 6	 reward: -10.14	 makespan: 1003.40	 Mean_loss: 4.58393335,  training time: 1.81
progress:  25%|[34m██▌       [0m| 5/20 [00:11<00:28,  1.90s/it]progress:  30%|[34m███       [0m| 6/20 [00:11<00:26,  1.87s/it]                                                        Episode 7	 reward: -10.20	 makespan: 1010.10	 Mean_loss: 4.15934372,  training time: 1.81
progress:  30%|[34m███       [0m| 6/20 [00:13<00:26,  1.87s/it]progress:  35%|[34m███▌      [0m| 7/20 [00:13<00:24,  1.85s/it]                                                        Episode 8	 reward: -10.07	 makespan: 997.00	 Mean_loss: 3.20348144,  training time: 1.82
progress:  35%|[34m███▌      [0m| 7/20 [00:15<00:24,  1.85s/it]progress:  40%|[34m████      [0m| 8/20 [00:15<00:22,  1.84s/it]                                                        Episode 9	 reward: -9.49	 makespan: 939.80	 Mean_loss: 2.49046230,  training time: 1.81
progress:  40%|[34m████      [0m| 8/20 [00:17<00:22,  1.84s/it]progress:  45%|[34m████▌     [0m| 9/20 [00:17<00:20,  1.83s/it]                                                        Episode 10	 reward: -9.88	 makespan: 978.25	 Mean_loss: 2.70065165,  training time: 1.81
progress:  45%|[34m████▌     [0m| 9/20 [00:19<00:20,  1.83s/it]progress:  50%|[34m█████     [0m| 10/20 [00:19<00:18,  1.82s/it]                                                         Episode 11	 reward: -9.76	 makespan: 966.25	 Mean_loss: 2.76794839,  training time: 1.79
progress:  50%|[34m█████     [0m| 10/20 [00:20<00:18,  1.82s/it]progress:  55%|[34m█████▌    [0m| 11/20 [00:20<00:16,  1.82s/it]                                                         Episode 12	 reward: -9.70	 makespan: 960.05	 Mean_loss: 3.01188278,  training time: 1.80
progress:  55%|[34m█████▌    [0m| 11/20 [00:22<00:16,  1.82s/it]progress:  60%|[34m██████    [0m| 12/20 [00:22<00:14,  1.81s/it]                                                         Episode 13	 reward: -9.74	 makespan: 964.50	 Mean_loss: 3.07882619,  training time: 1.83
progress:  60%|[34m██████    [0m| 12/20 [00:24<00:14,  1.81s/it]progress:  65%|[34m██████▌   [0m| 13/20 [00:24<00:12,  1.82s/it]                                                         Episode 14	 reward: -9.59	 makespan: 949.60	 Mean_loss: 2.78824329,  training time: 1.80
progress:  65%|[34m██████▌   [0m| 13/20 [00:26<00:12,  1.82s/it]progress:  70%|[34m███████   [0m| 14/20 [00:26<00:10,  1.81s/it]                                                         Episode 15	 reward: -9.96	 makespan: 985.90	 Mean_loss: 2.68715620,  training time: 1.79
progress:  70%|[34m███████   [0m| 14/20 [00:28<00:10,  1.81s/it]progress:  75%|[34m███████▌  [0m| 15/20 [00:28<00:09,  1.81s/it]                                                         Episode 16	 reward: -9.43	 makespan: 933.20	 Mean_loss: 2.76189756,  training time: 1.81
progress:  75%|[34m███████▌  [0m| 15/20 [00:29<00:09,  1.81s/it]progress:  80%|[34m████████  [0m| 16/20 [00:29<00:07,  1.81s/it]                                                         Episode 17	 reward: -9.63	 makespan: 953.80	 Mean_loss: 2.45739079,  training time: 1.83
progress:  80%|[34m████████  [0m| 16/20 [00:31<00:07,  1.81s/it]progress:  85%|[34m████████▌ [0m| 17/20 [00:31<00:05,  1.81s/it]                                                         Episode 18	 reward: -9.48	 makespan: 938.10	 Mean_loss: 2.22801638,  training time: 1.89
progress:  85%|[34m████████▌ [0m| 17/20 [00:33<00:05,  1.81s/it]progress:  90%|[34m█████████ [0m| 18/20 [00:33<00:03,  1.84s/it]                                                         Episode 19	 reward: -9.67	 makespan: 957.50	 Mean_loss: 1.91241801,  training time: 1.79
progress:  90%|[34m█████████ [0m| 18/20 [00:35<00:03,  1.84s/it]progress:  95%|[34m█████████▌[0m| 19/20 [00:35<00:01,  1.82s/it]                                                         Episode 20	 reward: -9.54	 makespan: 944.65	 Mean_loss: 1.75556087,  training time: 1.82
progress:  95%|[34m█████████▌[0m| 19/20 [00:37<00:01,  1.82s/it]progress: 100%|[34m██████████[0m| 20/20 [00:37<00:00,  1.82s/it]progress: 100%|[34m██████████[0m| 20/20 [00:37<00:00,  1.87s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN.py --n_j 15 --n_m 5 --data_source SD2 --model_suffix SD2_operjob8 --logdir exp15/DAN/train_model/8 --op_per_job 8 --max_updates 20
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_operjob8
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_operjob8
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/20 [00:00<?, ?it/s]                                                Episode 1	 reward: -13.33	 makespan: 1319.35	 Mean_loss: 11.89170170,  training time: 3.63
progress:   0%|[34m          [0m| 0/20 [00:03<?, ?it/s]progress:   5%|[34m▌         [0m| 1/20 [00:03<01:08,  3.63s/it]                                                        Episode 2	 reward: -13.46	 makespan: 1332.15	 Mean_loss: 11.93201065,  training time: 2.48
progress:   5%|[34m▌         [0m| 1/20 [00:06<01:08,  3.63s/it]progress:  10%|[34m█         [0m| 2/20 [00:06<00:53,  2.95s/it]                                                        Episode 3	 reward: -13.26	 makespan: 1312.55	 Mean_loss: 10.20423889,  training time: 2.56
progress:  10%|[34m█         [0m| 2/20 [00:08<00:53,  2.95s/it]progress:  15%|[34m█▌        [0m| 3/20 [00:08<00:47,  2.77s/it]                                                        Episode 4	 reward: -12.94	 makespan: 1281.05	 Mean_loss: 8.26996613,  training time: 2.45
progress:  15%|[34m█▌        [0m| 3/20 [00:11<00:47,  2.77s/it]progress:  20%|[34m██        [0m| 4/20 [00:11<00:42,  2.65s/it]                                                        Episode 5	 reward: -12.71	 makespan: 1257.80	 Mean_loss: 6.88114452,  training time: 2.47
progress:  20%|[34m██        [0m| 4/20 [00:13<00:42,  2.65s/it]progress:  25%|[34m██▌       [0m| 5/20 [00:13<00:38,  2.58s/it]                                                        Episode 6	 reward: -13.11	 makespan: 1297.45	 Mean_loss: 6.13510036,  training time: 2.40
progress:  25%|[34m██▌       [0m| 5/20 [00:15<00:38,  2.58s/it]progress:  30%|[34m███       [0m| 6/20 [00:15<00:35,  2.52s/it]                                                        Episode 7	 reward: -13.05	 makespan: 1292.05	 Mean_loss: 6.01012182,  training time: 2.45
progress:  30%|[34m███       [0m| 6/20 [00:18<00:35,  2.52s/it]progress:  35%|[34m███▌      [0m| 7/20 [00:18<00:32,  2.50s/it]                                                        Episode 8	 reward: -12.84	 makespan: 1270.80	 Mean_loss: 6.02054739,  training time: 2.46
progress:  35%|[34m███▌      [0m| 7/20 [00:20<00:32,  2.50s/it]progress:  40%|[34m████      [0m| 8/20 [00:20<00:29,  2.49s/it]                                                        Episode 9	 reward: -13.00	 makespan: 1286.75	 Mean_loss: 6.69446898,  training time: 2.54
progress:  40%|[34m████      [0m| 8/20 [00:23<00:29,  2.49s/it]progress:  45%|[34m████▌     [0m| 9/20 [00:23<00:27,  2.50s/it]                                                        Episode 10	 reward: -12.45	 makespan: 1232.45	 Mean_loss: 7.29403639,  training time: 2.48
progress:  45%|[34m████▌     [0m| 9/20 [00:25<00:27,  2.50s/it]progress:  50%|[34m█████     [0m| 10/20 [00:25<00:24,  2.49s/it]                                                         Episode 11	 reward: -12.36	 makespan: 1223.20	 Mean_loss: 7.03046608,  training time: 2.46
progress:  50%|[34m█████     [0m| 10/20 [00:28<00:24,  2.49s/it]progress:  55%|[34m█████▌    [0m| 11/20 [00:28<00:22,  2.49s/it]                                                         Episode 12	 reward: -12.00	 makespan: 1188.15	 Mean_loss: 7.02474689,  training time: 2.47
progress:  55%|[34m█████▌    [0m| 11/20 [00:30<00:22,  2.49s/it]progress:  60%|[34m██████    [0m| 12/20 [00:30<00:19,  2.48s/it]                                                         Episode 13	 reward: -12.23	 makespan: 1210.30	 Mean_loss: 6.51465559,  training time: 2.46
progress:  60%|[34m██████    [0m| 12/20 [00:33<00:19,  2.48s/it]progress:  65%|[34m██████▌   [0m| 13/20 [00:33<00:17,  2.48s/it]                                                         Episode 14	 reward: -12.14	 makespan: 1201.90	 Mean_loss: 5.41429186,  training time: 2.45
progress:  65%|[34m██████▌   [0m| 13/20 [00:35<00:17,  2.48s/it]progress:  70%|[34m███████   [0m| 14/20 [00:35<00:14,  2.47s/it]                                                         Episode 15	 reward: -12.22	 makespan: 1210.05	 Mean_loss: 4.91370773,  training time: 2.40
progress:  70%|[34m███████   [0m| 14/20 [00:38<00:14,  2.47s/it]progress:  75%|[34m███████▌  [0m| 15/20 [00:38<00:12,  2.45s/it]                                                         Episode 16	 reward: -11.96	 makespan: 1184.40	 Mean_loss: 4.20316076,  training time: 2.43
progress:  75%|[34m███████▌  [0m| 15/20 [00:40<00:12,  2.45s/it]progress:  80%|[34m████████  [0m| 16/20 [00:40<00:09,  2.44s/it]                                                         Episode 17	 reward: -11.87	 makespan: 1175.15	 Mean_loss: 3.71675897,  training time: 2.54
progress:  80%|[34m████████  [0m| 16/20 [00:43<00:09,  2.44s/it]progress:  85%|[34m████████▌ [0m| 17/20 [00:43<00:07,  2.47s/it]                                                         Episode 18	 reward: -12.45	 makespan: 1233.00	 Mean_loss: 2.89842200,  training time: 2.57
progress:  85%|[34m████████▌ [0m| 17/20 [00:45<00:07,  2.47s/it]progress:  90%|[34m█████████ [0m| 18/20 [00:45<00:05,  2.50s/it]                                                         Episode 19	 reward: -12.43	 makespan: 1230.15	 Mean_loss: 3.45468688,  training time: 2.43
progress:  90%|[34m█████████ [0m| 18/20 [00:48<00:05,  2.50s/it]progress:  95%|[34m█████████▌[0m| 19/20 [00:48<00:02,  2.48s/it]                                                         Episode 20	 reward: -12.43	 makespan: 1230.75	 Mean_loss: 3.45589209,  training time: 2.47
progress:  95%|[34m█████████▌[0m| 19/20 [00:50<00:02,  2.48s/it]progress: 100%|[34m██████████[0m| 20/20 [00:50<00:00,  2.48s/it]progress: 100%|[34m██████████[0m| 20/20 [00:50<00:00,  2.53s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN.py --n_j 15 --n_m 5 --data_source SD2 --model_suffix SD2_operjob10 --logdir exp15/DAN/train_model/10 --op_per_job 10 --max_updates 20
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_operjob10
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_operjob10
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/20 [00:00<?, ?it/s]                                                Episode 1	 reward: -16.76	 makespan: 1659.15	 Mean_loss: 14.83499908,  training time: 4.18
progress:   0%|[34m          [0m| 0/20 [00:04<?, ?it/s]progress:   5%|[34m▌         [0m| 1/20 [00:04<01:19,  4.19s/it]                                                        Episode 2	 reward: -15.96	 makespan: 1579.60	 Mean_loss: 12.63767624,  training time: 3.09
progress:   5%|[34m▌         [0m| 1/20 [00:07<01:19,  4.19s/it]progress:  10%|[34m█         [0m| 2/20 [00:07<01:03,  3.54s/it]                                                        Episode 3	 reward: -15.89	 makespan: 1573.20	 Mean_loss: 11.49868011,  training time: 3.08
progress:  10%|[34m█         [0m| 2/20 [00:10<01:03,  3.54s/it]progress:  15%|[34m█▌        [0m| 3/20 [00:10<00:56,  3.33s/it]                                                        Episode 4	 reward: -15.83	 makespan: 1567.50	 Mean_loss: 9.98457718,  training time: 3.04
progress:  15%|[34m█▌        [0m| 3/20 [00:13<00:56,  3.33s/it]progress:  20%|[34m██        [0m| 4/20 [00:13<00:51,  3.22s/it]                                                        Episode 5	 reward: -15.85	 makespan: 1569.10	 Mean_loss: 8.65267658,  training time: 3.07
progress:  20%|[34m██        [0m| 4/20 [00:16<00:51,  3.22s/it]progress:  25%|[34m██▌       [0m| 5/20 [00:16<00:47,  3.17s/it]                                                        Episode 6	 reward: -15.65	 makespan: 1549.35	 Mean_loss: 7.11559582,  training time: 3.05
progress:  25%|[34m██▌       [0m| 5/20 [00:19<00:47,  3.17s/it]progress:  30%|[34m███       [0m| 6/20 [00:19<00:43,  3.13s/it]                                                        Episode 7	 reward: -15.91	 makespan: 1575.15	 Mean_loss: 7.23695755,  training time: 3.17
progress:  30%|[34m███       [0m| 6/20 [00:22<00:43,  3.13s/it]progress:  35%|[34m███▌      [0m| 7/20 [00:22<00:40,  3.14s/it]                                                        Episode 8	 reward: -15.94	 makespan: 1578.05	 Mean_loss: 8.17576599,  training time: 3.05
progress:  35%|[34m███▌      [0m| 7/20 [00:25<00:40,  3.14s/it]progress:  40%|[34m████      [0m| 8/20 [00:25<00:37,  3.11s/it]                                                        Episode 9	 reward: -15.94	 makespan: 1578.30	 Mean_loss: 8.61864948,  training time: 3.05
progress:  40%|[34m████      [0m| 8/20 [00:28<00:37,  3.11s/it]progress:  45%|[34m████▌     [0m| 9/20 [00:28<00:34,  3.09s/it]                                                        Episode 10	 reward: -15.83	 makespan: 1566.70	 Mean_loss: 9.06381989,  training time: 3.07
progress:  45%|[34m████▌     [0m| 9/20 [00:31<00:34,  3.09s/it]progress:  50%|[34m█████     [0m| 10/20 [00:31<00:30,  3.09s/it]                                                         Episode 11	 reward: -16.28	 makespan: 1611.25	 Mean_loss: 10.41670322,  training time: 3.07
progress:  50%|[34m█████     [0m| 10/20 [00:34<00:30,  3.09s/it]progress:  55%|[34m█████▌    [0m| 11/20 [00:34<00:27,  3.08s/it]                                                         Episode 12	 reward: -16.30	 makespan: 1613.75	 Mean_loss: 10.59910870,  training time: 3.07
progress:  55%|[34m█████▌    [0m| 11/20 [00:38<00:27,  3.08s/it]progress:  60%|[34m██████    [0m| 12/20 [00:38<00:24,  3.08s/it]                                                         Episode 13	 reward: -16.21	 makespan: 1604.30	 Mean_loss: 10.20063305,  training time: 3.07
progress:  60%|[34m██████    [0m| 12/20 [00:41<00:24,  3.08s/it]progress:  65%|[34m██████▌   [0m| 13/20 [00:41<00:21,  3.08s/it]                                                         Episode 14	 reward: -16.23	 makespan: 1606.70	 Mean_loss: 10.36065865,  training time: 3.05
progress:  65%|[34m██████▌   [0m| 13/20 [00:44<00:21,  3.08s/it]progress:  70%|[34m███████   [0m| 14/20 [00:44<00:18,  3.07s/it]                                                         Episode 15	 reward: -16.22	 makespan: 1606.10	 Mean_loss: 9.01762199,  training time: 3.02
progress:  70%|[34m███████   [0m| 14/20 [00:47<00:18,  3.07s/it]progress:  75%|[34m███████▌  [0m| 15/20 [00:47<00:15,  3.06s/it]                                                         Episode 16	 reward: -16.45	 makespan: 1628.90	 Mean_loss: 8.10642242,  training time: 3.06
progress:  75%|[34m███████▌  [0m| 15/20 [00:50<00:15,  3.06s/it]progress:  80%|[34m████████  [0m| 16/20 [00:50<00:12,  3.06s/it]                                                         Episode 17	 reward: -16.12	 makespan: 1596.20	 Mean_loss: 8.53792191,  training time: 3.06
progress:  80%|[34m████████  [0m| 16/20 [00:53<00:12,  3.06s/it]progress:  85%|[34m████████▌ [0m| 17/20 [00:53<00:09,  3.06s/it]                                                         Episode 18	 reward: -16.27	 makespan: 1610.60	 Mean_loss: 7.47415876,  training time: 3.06
progress:  85%|[34m████████▌ [0m| 17/20 [00:56<00:09,  3.06s/it]progress:  90%|[34m█████████ [0m| 18/20 [00:56<00:06,  3.06s/it]                                                         Episode 19	 reward: -16.21	 makespan: 1604.60	 Mean_loss: 7.47172880,  training time: 3.04
progress:  90%|[34m█████████ [0m| 18/20 [00:59<00:06,  3.06s/it]progress:  95%|[34m█████████▌[0m| 19/20 [00:59<00:03,  3.06s/it]                                                         Episode 20	 reward: -16.71	 makespan: 1653.85	 Mean_loss: 6.51805592,  training time: 3.07
progress:  95%|[34m█████████▌[0m| 19/20 [01:02<00:03,  3.06s/it]progress: 100%|[34m██████████[0m| 20/20 [01:02<00:00,  3.06s/it]progress: 100%|[34m██████████[0m| 20/20 [01:02<00:00,  3.12s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN.py --n_j 15 --n_m 5 --data_source SD2 --model_suffix SD2_operjob12 --logdir exp15/DAN/train_model/12 --op_per_job 12 --max_updates 20
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_operjob12
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_operjob12
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/20 [00:00<?, ?it/s]                                                Episode 1	 reward: -20.43	 makespan: 2022.80	 Mean_loss: 22.64959717,  training time: 5.08
progress:   0%|[34m          [0m| 0/20 [00:05<?, ?it/s]progress:   5%|[34m▌         [0m| 1/20 [00:05<01:36,  5.08s/it]                                                        Episode 2	 reward: -19.52	 makespan: 1932.20	 Mean_loss: 18.76117897,  training time: 3.83
progress:   5%|[34m▌         [0m| 1/20 [00:08<01:36,  5.08s/it]progress:  10%|[34m█         [0m| 2/20 [00:08<01:18,  4.34s/it]                                                        Episode 3	 reward: -19.07	 makespan: 1887.65	 Mean_loss: 15.47761917,  training time: 3.84
progress:  10%|[34m█         [0m| 2/20 [00:12<01:18,  4.34s/it]progress:  15%|[34m█▌        [0m| 3/20 [00:12<01:09,  4.12s/it]                                                        Episode 4	 reward: -18.78	 makespan: 1858.95	 Mean_loss: 11.35195351,  training time: 3.85
progress:  15%|[34m█▌        [0m| 3/20 [00:16<01:09,  4.12s/it]progress:  20%|[34m██        [0m| 4/20 [00:16<01:04,  4.01s/it]                                                        Episode 5	 reward: -19.17	 makespan: 1897.80	 Mean_loss: 10.63013554,  training time: 3.92
progress:  20%|[34m██        [0m| 4/20 [00:20<01:04,  4.01s/it]progress:  25%|[34m██▌       [0m| 5/20 [00:20<00:59,  3.98s/it]                                                        Episode 6	 reward: -20.00	 makespan: 1980.15	 Mean_loss: 12.30818462,  training time: 3.81
progress:  25%|[34m██▌       [0m| 5/20 [00:24<00:59,  3.98s/it]progress:  30%|[34m███       [0m| 6/20 [00:24<00:54,  3.92s/it]                                                        Episode 7	 reward: -19.46	 makespan: 1926.85	 Mean_loss: 14.01500511,  training time: 3.78
progress:  30%|[34m███       [0m| 6/20 [00:28<00:54,  3.92s/it]progress:  35%|[34m███▌      [0m| 7/20 [00:28<00:50,  3.88s/it]                                                        Episode 8	 reward: -19.45	 makespan: 1925.50	 Mean_loss: 14.72734642,  training time: 3.83
progress:  35%|[34m███▌      [0m| 7/20 [00:31<00:50,  3.88s/it]progress:  40%|[34m████      [0m| 8/20 [00:31<00:46,  3.86s/it]                                                        Episode 9	 reward: -20.14	 makespan: 1993.65	 Mean_loss: 15.80562878,  training time: 3.88
progress:  40%|[34m████      [0m| 8/20 [00:35<00:46,  3.86s/it]progress:  45%|[34m████▌     [0m| 9/20 [00:35<00:42,  3.87s/it]                                                        Episode 10	 reward: -20.25	 makespan: 2004.90	 Mean_loss: 16.86549377,  training time: 3.77
progress:  45%|[34m████▌     [0m| 9/20 [00:39<00:42,  3.87s/it]progress:  50%|[34m█████     [0m| 10/20 [00:39<00:38,  3.84s/it]                                                         Episode 11	 reward: -19.97	 makespan: 1976.55	 Mean_loss: 17.59708023,  training time: 3.81
progress:  50%|[34m█████     [0m| 10/20 [00:43<00:38,  3.84s/it]progress:  55%|[34m█████▌    [0m| 11/20 [00:43<00:34,  3.83s/it]                                                         Episode 12	 reward: -20.10	 makespan: 1989.70	 Mean_loss: 17.98911858,  training time: 3.76
progress:  55%|[34m█████▌    [0m| 11/20 [00:47<00:34,  3.83s/it]progress:  60%|[34m██████    [0m| 12/20 [00:47<00:30,  3.81s/it]                                                         Episode 13	 reward: -20.55	 makespan: 2034.85	 Mean_loss: 17.08071518,  training time: 3.73
progress:  60%|[34m██████    [0m| 12/20 [00:50<00:30,  3.81s/it]progress:  65%|[34m██████▌   [0m| 13/20 [00:50<00:26,  3.78s/it]                                                         Episode 14	 reward: -19.92	 makespan: 1972.50	 Mean_loss: 14.38840008,  training time: 3.74
progress:  65%|[34m██████▌   [0m| 13/20 [00:54<00:26,  3.78s/it]progress:  70%|[34m███████   [0m| 14/20 [00:54<00:22,  3.77s/it]                                                         Episode 15	 reward: -20.33	 makespan: 2012.60	 Mean_loss: 13.88965702,  training time: 3.77
progress:  70%|[34m███████   [0m| 14/20 [00:58<00:22,  3.77s/it]progress:  75%|[34m███████▌  [0m| 15/20 [00:58<00:18,  3.77s/it]                                                         Episode 16	 reward: -20.38	 makespan: 2017.55	 Mean_loss: 14.04613113,  training time: 3.75
progress:  75%|[34m███████▌  [0m| 15/20 [01:02<00:18,  3.77s/it]progress:  80%|[34m████████  [0m| 16/20 [01:02<00:15,  3.77s/it]                                                         Episode 17	 reward: -20.38	 makespan: 2017.70	 Mean_loss: 14.73794270,  training time: 3.92
progress:  80%|[34m████████  [0m| 16/20 [01:06<00:15,  3.77s/it]progress:  85%|[34m████████▌ [0m| 17/20 [01:06<00:11,  3.81s/it]                                                         Episode 18	 reward: -19.95	 makespan: 1975.10	 Mean_loss: 12.93645954,  training time: 3.81
progress:  85%|[34m████████▌ [0m| 17/20 [01:09<00:11,  3.81s/it]progress:  90%|[34m█████████ [0m| 18/20 [01:09<00:07,  3.81s/it]                                                         Episode 19	 reward: -20.07	 makespan: 1987.25	 Mean_loss: 12.98776627,  training time: 3.77
progress:  90%|[34m█████████ [0m| 18/20 [01:13<00:07,  3.81s/it]progress:  95%|[34m█████████▌[0m| 19/20 [01:13<00:03,  3.80s/it]                                                         Episode 20	 reward: -19.84	 makespan: 1964.55	 Mean_loss: 12.62973022,  training time: 3.94
progress:  95%|[34m█████████▌[0m| 19/20 [01:17<00:03,  3.80s/it]progress: 100%|[34m██████████[0m| 20/20 [01:17<00:00,  3.84s/it]progress: 100%|[34m██████████[0m| 20/20 [01:17<00:00,  3.88s/it]
+ max_updates_finetune=50
+ lr=0.003
+ first_model_name=15x5+mix+SD2_operjob4
+ last_model_name=15x5+mix+SD2_operjob12
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.43047988,  training time: 2.33
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:54,  2.33s/it]                                                        Episode 2	 reward: -8.14	 makespan: 805.75	 Mean_loss: 0.53252107,  training time: 1.27
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:54,  2.33s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:21,  1.71s/it]                                                        Episode 3	 reward: -7.96	 makespan: 788.25	 Mean_loss: 0.39635828,  training time: 1.27
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:21,  1.71s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.51s/it]                                                        Episode 4	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.33946377,  training time: 1.29
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.51s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:05,  1.42s/it]                                                        Episode 5	 reward: -8.24	 makespan: 816.00	 Mean_loss: 0.28909802,  training time: 1.20
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:05,  1.42s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.34s/it]                                                        Episode 6	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.43609515,  training time: 1.23
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.34s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:57,  1.31s/it]                                                        Episode 7	 reward: -7.77	 makespan: 769.25	 Mean_loss: 0.28454506,  training time: 1.25
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:57,  1.31s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.29s/it]                                                        Episode 8	 reward: -7.38	 makespan: 730.75	 Mean_loss: 0.25318855,  training time: 1.20
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.29s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:52,  1.26s/it]                                                        Episode 9	 reward: -7.28	 makespan: 721.00	 Mean_loss: 0.20344794,  training time: 1.19
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:52,  1.26s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:50,  1.24s/it]                                                        Episode 10	 reward: -7.30	 makespan: 723.00	 Mean_loss: 0.24684963,  training time: 1.25
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:50,  1.24s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:49,  1.24s/it]                                                         Episode 11	 reward: -7.10	 makespan: 703.00	 Mean_loss: 0.25078565,  training time: 1.19
progress:  20%|[34m██        [0m| 10/50 [00:14<00:49,  1.24s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:47,  1.23s/it]                                                         Episode 12	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.17545092,  training time: 1.31
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:47,  1.23s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:47,  1.25s/it]                                                         Episode 13	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.17924093,  training time: 1.19
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:47,  1.25s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:45,  1.24s/it]                                                         Episode 14	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.21355137,  training time: 1.19
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:45,  1.24s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:44,  1.22s/it]                                                         Episode 15	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.17769992,  training time: 1.22
progress:  28%|[34m██▊       [0m| 14/50 [00:19<00:44,  1.22s/it]progress:  30%|[34m███       [0m| 15/50 [00:19<00:42,  1.22s/it]                                                         Episode 16	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.08528283,  training time: 1.18
progress:  30%|[34m███       [0m| 15/50 [00:20<00:42,  1.22s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:20<00:41,  1.21s/it]                                                         Episode 17	 reward: -6.54	 makespan: 647.25	 Mean_loss: 0.10442920,  training time: 1.21
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:41,  1.21s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:39,  1.21s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.75	 Mean_loss: 0.17336684,  training time: 1.19
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:39,  1.21s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:38,  1.21s/it]                                                         Episode 19	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08907536,  training time: 1.18
progress:  36%|[34m███▌      [0m| 18/50 [00:24<00:38,  1.21s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:24<00:37,  1.20s/it]                                                         Episode 20	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.07613036,  training time: 1.19
progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:37,  1.20s/it]progress:  40%|[34m████      [0m| 20/50 [00:25<00:35,  1.20s/it]                                                         Episode 21	 reward: -5.97	 makespan: 591.00	 Mean_loss: 0.07923748,  training time: 1.19
progress:  40%|[34m████      [0m| 20/50 [00:26<00:35,  1.20s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:26<00:34,  1.20s/it]                                                         Episode 22	 reward: -6.32	 makespan: 625.25	 Mean_loss: 0.04873575,  training time: 1.18
progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:34,  1.20s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:27<00:33,  1.19s/it]                                                         Episode 23	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.06564324,  training time: 1.19
progress:  44%|[34m████▍     [0m| 22/50 [00:29<00:33,  1.19s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:29<00:32,  1.19s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.07317406,  training time: 1.22
progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:32,  1.19s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:30<00:31,  1.20s/it]                                                         Episode 25	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.06566608,  training time: 1.18
progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:31,  1.20s/it]progress:  50%|[34m█████     [0m| 25/50 [00:31<00:29,  1.20s/it]                                                         Episode 26	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.06757811,  training time: 1.19
progress:  50%|[34m█████     [0m| 25/50 [00:32<00:29,  1.20s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:32<00:28,  1.19s/it]                                                         Episode 27	 reward: -5.74	 makespan: 568.50	 Mean_loss: 0.04555443,  training time: 1.24
progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:28,  1.19s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:33<00:27,  1.21s/it]                                                         Episode 28	 reward: -5.67	 makespan: 561.00	 Mean_loss: 0.03131913,  training time: 1.20
progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:27,  1.21s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:35<00:26,  1.21s/it]                                                         Episode 29	 reward: -5.35	 makespan: 529.25	 Mean_loss: 0.05986745,  training time: 1.22
progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:26,  1.21s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:36<00:25,  1.21s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.09671779,  training time: 1.19
progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:25,  1.21s/it]progress:  60%|[34m██████    [0m| 30/50 [00:37<00:24,  1.21s/it]                                                         Episode 31	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.05455026,  training time: 1.21
progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.21s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:38<00:22,  1.21s/it]                                                         Episode 32	 reward: -5.56	 makespan: 550.75	 Mean_loss: 0.03890508,  training time: 1.19
progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:22,  1.21s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:40<00:21,  1.20s/it]                                                         Episode 33	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.04827370,  training time: 1.20
progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:21,  1.20s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:41<00:20,  1.20s/it]                                                         Episode 34	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.02542099,  training time: 1.21
progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:20,  1.20s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:42<00:19,  1.20s/it]                                                         Episode 35	 reward: -5.31	 makespan: 525.75	 Mean_loss: 0.05752164,  training time: 1.19
progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.20s/it]progress:  70%|[34m███████   [0m| 35/50 [00:43<00:17,  1.20s/it]                                                         Episode 36	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.06172506,  training time: 1.21
progress:  70%|[34m███████   [0m| 35/50 [00:44<00:17,  1.20s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:44<00:16,  1.20s/it]                                                         Episode 37	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.05981886,  training time: 1.19
progress:  72%|[34m███████▏  [0m| 36/50 [00:45<00:16,  1.20s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:45<00:15,  1.20s/it]                                                         Episode 38	 reward: -5.92	 makespan: 586.25	 Mean_loss: 0.04371587,  training time: 1.19
progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:15,  1.20s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:47<00:14,  1.20s/it]                                                         Episode 39	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.06650192,  training time: 1.26
progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:14,  1.20s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:48<00:13,  1.22s/it]                                                         Episode 40	 reward: -5.95	 makespan: 588.75	 Mean_loss: 0.06599416,  training time: 1.20
progress:  78%|[34m███████▊  [0m| 39/50 [00:49<00:13,  1.22s/it]progress:  80%|[34m████████  [0m| 40/50 [00:49<00:12,  1.21s/it]                                                         Episode 41	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.02862106,  training time: 1.21
progress:  80%|[34m████████  [0m| 40/50 [00:50<00:12,  1.21s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:50<00:10,  1.21s/it]                                                         Episode 42	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.02969238,  training time: 1.18
progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:10,  1.21s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:52<00:09,  1.20s/it]                                                         Episode 43	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.03002254,  training time: 1.20
progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:09,  1.20s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:53<00:08,  1.20s/it]                                                         Episode 44	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.04049779,  training time: 1.20
progress:  86%|[34m████████▌ [0m| 43/50 [00:54<00:08,  1.20s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:54<00:07,  1.20s/it]                                                         Episode 45	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.03323376,  training time: 1.17
progress:  88%|[34m████████▊ [0m| 44/50 [00:55<00:07,  1.20s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:55<00:05,  1.19s/it]                                                         Episode 46	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.06915612,  training time: 1.18
progress:  90%|[34m█████████ [0m| 45/50 [00:56<00:05,  1.19s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:56<00:04,  1.19s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.03915487,  training time: 1.21
progress:  92%|[34m█████████▏[0m| 46/50 [00:58<00:04,  1.19s/it]progress:  94%|[34m█████████▍[0m| 47/50 [00:58<00:03,  1.20s/it]                                                         Episode 48	 reward: -5.80	 makespan: 574.25	 Mean_loss: 0.02318419,  training time: 1.20
progress:  94%|[34m█████████▍[0m| 47/50 [00:59<00:03,  1.20s/it]progress:  96%|[34m█████████▌[0m| 48/50 [00:59<00:02,  1.20s/it]                                                         Episode 49	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.03192383,  training time: 1.18
progress:  96%|[34m█████████▌[0m| 48/50 [01:00<00:02,  1.20s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:00<00:01,  1.19s/it]                                                         Episode 50	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.09658686,  training time: 1.20
progress:  98%|[34m█████████▊[0m| 49/50 [01:01<00:01,  1.19s/it]progress: 100%|[34m██████████[0m| 50/50 [01:01<00:00,  1.19s/it]progress: 100%|[34m██████████[0m| 50/50 [01:01<00:00,  1.23s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.43047988,  training time: 2.41
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:58,  2.41s/it]                                                        Episode 2	 reward: -8.14	 makespan: 805.75	 Mean_loss: 0.53252107,  training time: 1.25
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:58,  2.41s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:22,  1.73s/it]                                                        Episode 3	 reward: -7.96	 makespan: 788.25	 Mean_loss: 0.39635828,  training time: 1.24
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:22,  1.73s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.51s/it]                                                        Episode 4	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.33946377,  training time: 1.28
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.51s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:05,  1.42s/it]                                                        Episode 5	 reward: -8.24	 makespan: 816.00	 Mean_loss: 0.28909802,  training time: 1.22
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:05,  1.42s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.35s/it]                                                        Episode 6	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.43609515,  training time: 1.24
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.35s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:57,  1.31s/it]                                                        Episode 7	 reward: -7.77	 makespan: 769.25	 Mean_loss: 0.28454506,  training time: 1.26
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:57,  1.31s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.30s/it]                                                        Episode 8	 reward: -7.38	 makespan: 730.75	 Mean_loss: 0.25318855,  training time: 1.22
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.30s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.27s/it]                                                        Episode 9	 reward: -7.28	 makespan: 721.00	 Mean_loss: 0.20344794,  training time: 1.26
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.27s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:52,  1.27s/it]                                                        Episode 10	 reward: -7.30	 makespan: 723.00	 Mean_loss: 0.24684963,  training time: 1.22
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:52,  1.27s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:50,  1.25s/it]                                                         Episode 11	 reward: -7.10	 makespan: 703.00	 Mean_loss: 0.25078565,  training time: 1.24
progress:  20%|[34m██        [0m| 10/50 [00:14<00:50,  1.25s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:48,  1.25s/it]                                                         Episode 12	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.17545092,  training time: 1.40
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:48,  1.25s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:49,  1.30s/it]                                                         Episode 13	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.17924093,  training time: 1.30
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:49,  1.30s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:48,  1.30s/it]                                                         Episode 14	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.21355137,  training time: 1.26
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:48,  1.30s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:46,  1.29s/it]                                                         Episode 15	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.17769992,  training time: 1.24
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:46,  1.29s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.27s/it]                                                         Episode 16	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.08528283,  training time: 1.25
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.27s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.27s/it]                                                         Episode 17	 reward: -6.54	 makespan: 647.25	 Mean_loss: 0.10442920,  training time: 1.27
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.27s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.27s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.75	 Mean_loss: 0.17336684,  training time: 1.22
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:41,  1.27s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:40,  1.25s/it]                                                         Episode 19	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08907536,  training time: 1.23
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:40,  1.25s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.25s/it]                                                         Episode 20	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.07613036,  training time: 1.24
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.25s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.25s/it]                                                         Episode 21	 reward: -5.97	 makespan: 591.00	 Mean_loss: 0.07923748,  training time: 1.26
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.25s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.25s/it]                                                         Episode 22	 reward: -6.32	 makespan: 625.25	 Mean_loss: 0.04873575,  training time: 1.26
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.25s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:35,  1.25s/it]                                                         Episode 23	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.06564324,  training time: 1.26
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:35,  1.25s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.26s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.07317406,  training time: 1.27
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.26s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.26s/it]                                                         Episode 25	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.06566608,  training time: 1.27
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.26s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:31,  1.26s/it]                                                         Episode 26	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.06757811,  training time: 1.26
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:31,  1.26s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:30,  1.26s/it]                                                         Episode 27	 reward: -5.74	 makespan: 568.50	 Mean_loss: 0.04555443,  training time: 1.25
progress:  52%|[34m█████▏    [0m| 26/50 [00:35<00:30,  1.26s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.26s/it]                                                         Episode 28	 reward: -5.67	 makespan: 561.00	 Mean_loss: 0.03131913,  training time: 1.26
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.26s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.26s/it]                                                         Episode 29	 reward: -5.35	 makespan: 529.25	 Mean_loss: 0.05986745,  training time: 1.27
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.26s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.26s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.09671779,  training time: 1.26
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:26,  1.26s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:25,  1.26s/it]                                                         Episode 31	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.05455026,  training time: 1.26
progress:  60%|[34m██████    [0m| 30/50 [00:40<00:25,  1.26s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.26s/it]                                                         Episode 32	 reward: -5.56	 makespan: 550.75	 Mean_loss: 0.03890508,  training time: 1.27
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.26s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.26s/it]                                                         Episode 33	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.04827370,  training time: 1.22
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.26s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:21,  1.25s/it]                                                         Episode 34	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.02542099,  training time: 1.26
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:21,  1.25s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:20,  1.25s/it]                                                         Episode 35	 reward: -5.31	 makespan: 525.75	 Mean_loss: 0.05752164,  training time: 1.27
progress:  68%|[34m██████▊   [0m| 34/50 [00:45<00:20,  1.25s/it]progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.26s/it]                                                         Episode 36	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.06172506,  training time: 1.25
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.26s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.26s/it]                                                         Episode 37	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.05981886,  training time: 1.26
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.26s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:16,  1.26s/it]                                                         Episode 38	 reward: -5.92	 makespan: 586.25	 Mean_loss: 0.04371587,  training time: 1.27
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:16,  1.26s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:15,  1.26s/it]                                                         Episode 39	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.06650192,  training time: 1.26
progress:  76%|[34m███████▌  [0m| 38/50 [00:50<00:15,  1.26s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.26s/it]                                                         Episode 40	 reward: -5.95	 makespan: 588.75	 Mean_loss: 0.06599416,  training time: 1.25
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.26s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.26s/it]                                                         Episode 41	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.02862106,  training time: 1.20
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.26s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.24s/it]                                                         Episode 42	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.02969238,  training time: 1.29
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.24s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:10,  1.26s/it]                                                         Episode 43	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.03002254,  training time: 1.27
progress:  84%|[34m████████▍ [0m| 42/50 [00:55<00:10,  1.26s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.26s/it]                                                         Episode 44	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.04049779,  training time: 1.25
progress:  86%|[34m████████▌ [0m| 43/50 [00:56<00:08,  1.26s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.26s/it]                                                         Episode 45	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.03323376,  training time: 1.27
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.26s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.26s/it]                                                         Episode 46	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.06915612,  training time: 1.23
progress:  90%|[34m█████████ [0m| 45/50 [00:59<00:06,  1.26s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:05,  1.25s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.03915487,  training time: 1.26
progress:  92%|[34m█████████▏[0m| 46/50 [01:00<00:05,  1.25s/it]progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.26s/it]                                                         Episode 48	 reward: -5.80	 makespan: 574.25	 Mean_loss: 0.02318419,  training time: 1.26
progress:  94%|[34m█████████▍[0m| 47/50 [01:01<00:03,  1.26s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.26s/it]                                                         Episode 49	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.03192383,  training time: 1.22
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.26s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.25s/it]                                                         Episode 50	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.09658686,  training time: 1.23
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.25s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.28s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.43047988,  training time: 2.44
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:59,  2.45s/it]                                                        Episode 2	 reward: -8.14	 makespan: 805.75	 Mean_loss: 0.53252107,  training time: 1.23
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:59,  2.45s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:23,  1.73s/it]                                                        Episode 3	 reward: -7.96	 makespan: 788.25	 Mean_loss: 0.39635828,  training time: 1.25
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:23,  1.73s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:11,  1.51s/it]                                                        Episode 4	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.33946377,  training time: 1.23
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:11,  1.51s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.40s/it]                                                        Episode 5	 reward: -8.24	 makespan: 816.00	 Mean_loss: 0.28909802,  training time: 1.23
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.40s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.34s/it]                                                        Episode 6	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.43609515,  training time: 1.22
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.34s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:57,  1.30s/it]                                                        Episode 7	 reward: -7.77	 makespan: 769.25	 Mean_loss: 0.28454506,  training time: 1.27
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:57,  1.30s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.29s/it]                                                        Episode 8	 reward: -7.38	 makespan: 730.75	 Mean_loss: 0.25318855,  training time: 1.22
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.29s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.27s/it]                                                        Episode 9	 reward: -7.28	 makespan: 721.00	 Mean_loss: 0.20344794,  training time: 1.22
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.27s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:51,  1.25s/it]                                                        Episode 10	 reward: -7.30	 makespan: 723.00	 Mean_loss: 0.24684963,  training time: 1.25
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:51,  1.25s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:50,  1.25s/it]                                                         Episode 11	 reward: -7.10	 makespan: 703.00	 Mean_loss: 0.25078565,  training time: 1.27
progress:  20%|[34m██        [0m| 10/50 [00:14<00:50,  1.25s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:49,  1.26s/it]                                                         Episode 12	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.17545092,  training time: 1.34
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:49,  1.26s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:48,  1.28s/it]                                                         Episode 13	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.17924093,  training time: 1.23
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:48,  1.28s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:46,  1.27s/it]                                                         Episode 14	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.21355137,  training time: 1.27
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:46,  1.27s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:45,  1.27s/it]                                                         Episode 15	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.17769992,  training time: 1.22
progress:  28%|[34m██▊       [0m| 14/50 [00:19<00:45,  1.27s/it]progress:  30%|[34m███       [0m| 15/50 [00:19<00:43,  1.25s/it]                                                         Episode 16	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.08528283,  training time: 1.23
progress:  30%|[34m███       [0m| 15/50 [00:21<00:43,  1.25s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:42,  1.25s/it]                                                         Episode 17	 reward: -6.54	 makespan: 647.25	 Mean_loss: 0.10442920,  training time: 1.24
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:42,  1.25s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.25s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.75	 Mean_loss: 0.17336684,  training time: 1.22
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:41,  1.25s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:39,  1.24s/it]                                                         Episode 19	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08907536,  training time: 1.21
progress:  36%|[34m███▌      [0m| 18/50 [00:24<00:39,  1.24s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:24<00:38,  1.23s/it]                                                         Episode 20	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.07613036,  training time: 1.26
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.23s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.24s/it]                                                         Episode 21	 reward: -5.97	 makespan: 591.00	 Mean_loss: 0.07923748,  training time: 1.23
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.24s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:35,  1.24s/it]                                                         Episode 22	 reward: -6.32	 makespan: 625.25	 Mean_loss: 0.04873575,  training time: 1.22
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:35,  1.24s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.23s/it]                                                         Episode 23	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.06564324,  training time: 1.22
progress:  44%|[34m████▍     [0m| 22/50 [00:29<00:34,  1.23s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:29<00:33,  1.23s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.07317406,  training time: 1.21
progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.23s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:30<00:31,  1.22s/it]                                                         Episode 25	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.06566608,  training time: 1.20
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:31,  1.22s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:30,  1.22s/it]                                                         Episode 26	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.06757811,  training time: 1.24
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:30,  1.22s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:29,  1.23s/it]                                                         Episode 27	 reward: -5.74	 makespan: 568.50	 Mean_loss: 0.04555443,  training time: 1.21
progress:  52%|[34m█████▏    [0m| 26/50 [00:34<00:29,  1.23s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:34<00:28,  1.22s/it]                                                         Episode 28	 reward: -5.67	 makespan: 561.00	 Mean_loss: 0.03131913,  training time: 1.21
progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.22s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:35<00:26,  1.22s/it]                                                         Episode 29	 reward: -5.35	 makespan: 529.25	 Mean_loss: 0.05986745,  training time: 1.20
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:26,  1.22s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:25,  1.21s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.09671779,  training time: 1.27
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:25,  1.21s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.23s/it]                                                         Episode 31	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.05455026,  training time: 1.20
progress:  60%|[34m██████    [0m| 30/50 [00:39<00:24,  1.23s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:39<00:23,  1.22s/it]                                                         Episode 32	 reward: -5.56	 makespan: 550.75	 Mean_loss: 0.03890508,  training time: 1.21
progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.22s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:40<00:21,  1.22s/it]                                                         Episode 33	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.04827370,  training time: 1.24
progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:21,  1.22s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:41<00:20,  1.22s/it]                                                         Episode 34	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.02542099,  training time: 1.22
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:20,  1.22s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.22s/it]                                                         Episode 35	 reward: -5.31	 makespan: 525.75	 Mean_loss: 0.05752164,  training time: 1.23
progress:  68%|[34m██████▊   [0m| 34/50 [00:44<00:19,  1.22s/it]progress:  70%|[34m███████   [0m| 35/50 [00:44<00:18,  1.22s/it]                                                         Episode 36	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.06172506,  training time: 1.20
progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.22s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:45<00:17,  1.22s/it]                                                         Episode 37	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.05981886,  training time: 1.22
progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.22s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:46<00:15,  1.22s/it]                                                         Episode 38	 reward: -5.92	 makespan: 586.25	 Mean_loss: 0.04371587,  training time: 1.24
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:15,  1.22s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:14,  1.22s/it]                                                         Episode 39	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.06650192,  training time: 1.20
progress:  76%|[34m███████▌  [0m| 38/50 [00:49<00:14,  1.22s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:49<00:13,  1.22s/it]                                                         Episode 40	 reward: -5.95	 makespan: 588.75	 Mean_loss: 0.06599416,  training time: 1.27
progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.22s/it]progress:  80%|[34m████████  [0m| 40/50 [00:50<00:12,  1.23s/it]                                                         Episode 41	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.02862106,  training time: 1.27
progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.23s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:51<00:11,  1.24s/it]                                                         Episode 42	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.02969238,  training time: 1.23
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.24s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:09,  1.24s/it]                                                         Episode 43	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.03002254,  training time: 1.24
progress:  84%|[34m████████▍ [0m| 42/50 [00:54<00:09,  1.24s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:54<00:08,  1.24s/it]                                                         Episode 44	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.04049779,  training time: 1.23
progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.24s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:55<00:07,  1.24s/it]                                                         Episode 45	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.03323376,  training time: 1.21
progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.24s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:56<00:06,  1.23s/it]                                                         Episode 46	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.06915612,  training time: 1.25
progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.23s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:57<00:04,  1.24s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.03915487,  training time: 1.23
progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:04,  1.24s/it]progress:  94%|[34m█████████▍[0m| 47/50 [00:59<00:03,  1.24s/it]                                                         Episode 48	 reward: -5.80	 makespan: 574.25	 Mean_loss: 0.02318419,  training time: 1.22
progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.24s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:00<00:02,  1.23s/it]                                                         Episode 49	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.03192383,  training time: 1.24
progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.23s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:01<00:01,  1.23s/it]                                                         Episode 50	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.09658686,  training time: 1.23
progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.23s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.23s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.26s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.43047988,  training time: 2.33
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:54,  2.34s/it]                                                        Episode 2	 reward: -8.14	 makespan: 805.75	 Mean_loss: 0.53252107,  training time: 1.26
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:54,  2.34s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:21,  1.70s/it]                                                        Episode 3	 reward: -7.96	 makespan: 788.25	 Mean_loss: 0.39635828,  training time: 1.24
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:21,  1.70s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.49s/it]                                                        Episode 4	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.33946377,  training time: 1.27
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.49s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.41s/it]                                                        Episode 5	 reward: -8.24	 makespan: 816.00	 Mean_loss: 0.28909802,  training time: 1.27
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.41s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.36s/it]                                                        Episode 6	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.43609515,  training time: 1.26
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.36s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:58,  1.32s/it]                                                        Episode 7	 reward: -7.77	 makespan: 769.25	 Mean_loss: 0.28454506,  training time: 1.26
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:58,  1.32s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:56,  1.30s/it]                                                        Episode 8	 reward: -7.38	 makespan: 730.75	 Mean_loss: 0.25318855,  training time: 1.23
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:56,  1.30s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.28s/it]                                                        Episode 9	 reward: -7.28	 makespan: 721.00	 Mean_loss: 0.20344794,  training time: 1.19
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.28s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:51,  1.25s/it]                                                        Episode 10	 reward: -7.30	 makespan: 723.00	 Mean_loss: 0.24684963,  training time: 1.22
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:51,  1.25s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:49,  1.24s/it]                                                         Episode 11	 reward: -7.10	 makespan: 703.00	 Mean_loss: 0.25078565,  training time: 1.27
progress:  20%|[34m██        [0m| 10/50 [00:14<00:49,  1.24s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:48,  1.25s/it]                                                         Episode 12	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.17545092,  training time: 1.41
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:48,  1.25s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:49,  1.30s/it]                                                         Episode 13	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.17924093,  training time: 1.25
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:49,  1.30s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.29s/it]                                                         Episode 14	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.21355137,  training time: 1.27
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:47,  1.29s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:46,  1.28s/it]                                                         Episode 15	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.17769992,  training time: 1.26
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:46,  1.28s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.27s/it]                                                         Episode 16	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.08528283,  training time: 1.31
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.27s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.28s/it]                                                         Episode 17	 reward: -6.54	 makespan: 647.25	 Mean_loss: 0.10442920,  training time: 1.27
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.28s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:42,  1.28s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.75	 Mean_loss: 0.17336684,  training time: 1.26
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:42,  1.28s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:40,  1.28s/it]                                                         Episode 19	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08907536,  training time: 1.26
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:40,  1.28s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:39,  1.27s/it]                                                         Episode 20	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.07613036,  training time: 1.27
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:39,  1.27s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:38,  1.27s/it]                                                         Episode 21	 reward: -5.97	 makespan: 591.00	 Mean_loss: 0.07923748,  training time: 1.20
progress:  40%|[34m████      [0m| 20/50 [00:27<00:38,  1.27s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.25s/it]                                                         Episode 22	 reward: -6.32	 makespan: 625.25	 Mean_loss: 0.04873575,  training time: 1.26
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.25s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:35,  1.25s/it]                                                         Episode 23	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.06564324,  training time: 1.26
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:35,  1.25s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.26s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.07317406,  training time: 1.26
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.26s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.26s/it]                                                         Episode 25	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.06566608,  training time: 1.26
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.26s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:31,  1.26s/it]                                                         Episode 26	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.06757811,  training time: 1.26
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:31,  1.26s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:30,  1.26s/it]                                                         Episode 27	 reward: -5.74	 makespan: 568.50	 Mean_loss: 0.04555443,  training time: 1.32
progress:  52%|[34m█████▏    [0m| 26/50 [00:35<00:30,  1.26s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:29,  1.28s/it]                                                         Episode 28	 reward: -5.67	 makespan: 561.00	 Mean_loss: 0.03131913,  training time: 1.21
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:29,  1.28s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.26s/it]                                                         Episode 29	 reward: -5.35	 makespan: 529.25	 Mean_loss: 0.05986745,  training time: 1.23
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.26s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.25s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.09671779,  training time: 1.25
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:26,  1.25s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:25,  1.25s/it]                                                         Episode 31	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.05455026,  training time: 1.24
progress:  60%|[34m██████    [0m| 30/50 [00:40<00:25,  1.25s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.25s/it]                                                         Episode 32	 reward: -5.56	 makespan: 550.75	 Mean_loss: 0.03890508,  training time: 1.26
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.25s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.25s/it]                                                         Episode 33	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.04827370,  training time: 1.20
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.25s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:21,  1.24s/it]                                                         Episode 34	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.02542099,  training time: 1.25
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:21,  1.24s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.24s/it]                                                         Episode 35	 reward: -5.31	 makespan: 525.75	 Mean_loss: 0.05752164,  training time: 1.25
progress:  68%|[34m██████▊   [0m| 34/50 [00:45<00:19,  1.24s/it]progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.24s/it]                                                         Episode 36	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.06172506,  training time: 1.22
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.24s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.24s/it]                                                         Episode 37	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.05981886,  training time: 1.33
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.24s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:16,  1.26s/it]                                                         Episode 38	 reward: -5.92	 makespan: 586.25	 Mean_loss: 0.04371587,  training time: 1.25
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:16,  1.26s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:15,  1.26s/it]                                                         Episode 39	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.06650192,  training time: 1.27
progress:  76%|[34m███████▌  [0m| 38/50 [00:50<00:15,  1.26s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.26s/it]                                                         Episode 40	 reward: -5.95	 makespan: 588.75	 Mean_loss: 0.06599416,  training time: 1.29
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.26s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.27s/it]                                                         Episode 41	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.02862106,  training time: 1.29
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.27s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.28s/it]                                                         Episode 42	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.02969238,  training time: 1.20
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.28s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:10,  1.26s/it]                                                         Episode 43	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.03002254,  training time: 1.24
progress:  84%|[34m████████▍ [0m| 42/50 [00:55<00:10,  1.26s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.25s/it]                                                         Episode 44	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.04049779,  training time: 1.25
progress:  86%|[34m████████▌ [0m| 43/50 [00:56<00:08,  1.25s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.25s/it]                                                         Episode 45	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.03323376,  training time: 1.20
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.25s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.24s/it]                                                         Episode 46	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.06915612,  training time: 1.25
progress:  90%|[34m█████████ [0m| 45/50 [00:58<00:06,  1.24s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:58<00:04,  1.24s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.03915487,  training time: 1.21
progress:  92%|[34m█████████▏[0m| 46/50 [01:00<00:04,  1.24s/it]progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.23s/it]                                                         Episode 48	 reward: -5.80	 makespan: 574.25	 Mean_loss: 0.02318419,  training time: 1.25
progress:  94%|[34m█████████▍[0m| 47/50 [01:01<00:03,  1.23s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.24s/it]                                                         Episode 49	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.03192383,  training time: 1.27
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.24s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.24s/it]                                                         Episode 50	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.09658686,  training time: 1.17
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.22s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.28s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.43047988,  training time: 2.35
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:54,  2.35s/it]                                                        Episode 2	 reward: -8.14	 makespan: 805.75	 Mean_loss: 0.53252107,  training time: 1.27
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:54,  2.35s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:22,  1.71s/it]                                                        Episode 3	 reward: -7.96	 makespan: 788.25	 Mean_loss: 0.39635828,  training time: 1.25
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:22,  1.71s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.50s/it]                                                        Episode 4	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.33946377,  training time: 1.26
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.50s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.41s/it]                                                        Episode 5	 reward: -8.24	 makespan: 816.00	 Mean_loss: 0.28909802,  training time: 1.25
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.41s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.35s/it]                                                        Episode 6	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.43609515,  training time: 1.26
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.35s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:58,  1.32s/it]                                                        Episode 7	 reward: -7.77	 makespan: 769.25	 Mean_loss: 0.28454506,  training time: 1.26
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:58,  1.32s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.30s/it]                                                        Episode 8	 reward: -7.38	 makespan: 730.75	 Mean_loss: 0.25318855,  training time: 1.26
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.30s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:54,  1.29s/it]                                                        Episode 9	 reward: -7.28	 makespan: 721.00	 Mean_loss: 0.20344794,  training time: 1.27
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:54,  1.29s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:52,  1.28s/it]                                                        Episode 10	 reward: -7.30	 makespan: 723.00	 Mean_loss: 0.24684963,  training time: 1.27
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:52,  1.28s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:51,  1.28s/it]                                                         Episode 11	 reward: -7.10	 makespan: 703.00	 Mean_loss: 0.25078565,  training time: 1.26
progress:  20%|[34m██        [0m| 10/50 [00:14<00:51,  1.28s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:49,  1.27s/it]                                                         Episode 12	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.17545092,  training time: 1.40
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:49,  1.27s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:49,  1.31s/it]                                                         Episode 13	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.17924093,  training time: 1.26
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:49,  1.31s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.30s/it]                                                         Episode 14	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.21355137,  training time: 1.27
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:47,  1.30s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:46,  1.29s/it]                                                         Episode 15	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.17769992,  training time: 1.27
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:46,  1.29s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.28s/it]                                                         Episode 16	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.08528283,  training time: 1.27
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.28s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.28s/it]                                                         Episode 17	 reward: -6.54	 makespan: 647.25	 Mean_loss: 0.10442920,  training time: 1.25
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.28s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.27s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.75	 Mean_loss: 0.17336684,  training time: 1.26
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:41,  1.27s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:40,  1.27s/it]                                                         Episode 19	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08907536,  training time: 1.27
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:40,  1.27s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:39,  1.27s/it]                                                         Episode 20	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.07613036,  training time: 1.26
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:39,  1.27s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.27s/it]                                                         Episode 21	 reward: -5.97	 makespan: 591.00	 Mean_loss: 0.07923748,  training time: 1.27
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.27s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.27s/it]                                                         Episode 22	 reward: -6.32	 makespan: 625.25	 Mean_loss: 0.04873575,  training time: 1.26
progress:  42%|[34m████▏     [0m| 21/50 [00:29<00:36,  1.27s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:29<00:35,  1.27s/it]                                                         Episode 23	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.06564324,  training time: 1.26
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:35,  1.27s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:34,  1.27s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.07317406,  training time: 1.24
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:34,  1.27s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.26s/it]                                                         Episode 25	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.06566608,  training time: 1.25
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.26s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:31,  1.26s/it]                                                         Episode 26	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.06757811,  training time: 1.25
progress:  50%|[34m█████     [0m| 25/50 [00:34<00:31,  1.26s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:34<00:30,  1.26s/it]                                                         Episode 27	 reward: -5.74	 makespan: 568.50	 Mean_loss: 0.04555443,  training time: 1.27
progress:  52%|[34m█████▏    [0m| 26/50 [00:35<00:30,  1.26s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.26s/it]                                                         Episode 28	 reward: -5.67	 makespan: 561.00	 Mean_loss: 0.03131913,  training time: 1.25
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.26s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.26s/it]                                                         Episode 29	 reward: -5.35	 makespan: 529.25	 Mean_loss: 0.05986745,  training time: 1.28
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.26s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.26s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.09671779,  training time: 1.25
progress:  58%|[34m█████▊    [0m| 29/50 [00:39<00:26,  1.26s/it]progress:  60%|[34m██████    [0m| 30/50 [00:39<00:25,  1.26s/it]                                                         Episode 31	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.05455026,  training time: 1.26
progress:  60%|[34m██████    [0m| 30/50 [00:40<00:25,  1.26s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.26s/it]                                                         Episode 32	 reward: -5.56	 makespan: 550.75	 Mean_loss: 0.03890508,  training time: 1.24
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.26s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.26s/it]                                                         Episode 33	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.04827370,  training time: 1.25
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.26s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:21,  1.26s/it]                                                         Episode 34	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.02542099,  training time: 1.24
progress:  66%|[34m██████▌   [0m| 33/50 [00:44<00:21,  1.26s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:44<00:20,  1.25s/it]                                                         Episode 35	 reward: -5.31	 makespan: 525.75	 Mean_loss: 0.05752164,  training time: 1.25
progress:  68%|[34m██████▊   [0m| 34/50 [00:45<00:20,  1.25s/it]progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.25s/it]                                                         Episode 36	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.06172506,  training time: 1.26
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.25s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.25s/it]                                                         Episode 37	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.05981886,  training time: 1.26
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.25s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:16,  1.26s/it]                                                         Episode 38	 reward: -5.92	 makespan: 586.25	 Mean_loss: 0.04371587,  training time: 1.26
progress:  74%|[34m███████▍  [0m| 37/50 [00:49<00:16,  1.26s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:49<00:15,  1.26s/it]                                                         Episode 39	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.06650192,  training time: 1.24
progress:  76%|[34m███████▌  [0m| 38/50 [00:50<00:15,  1.26s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.25s/it]                                                         Episode 40	 reward: -5.95	 makespan: 588.75	 Mean_loss: 0.06599416,  training time: 1.26
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.25s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.25s/it]                                                         Episode 41	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.02862106,  training time: 1.24
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.25s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.25s/it]                                                         Episode 42	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.02969238,  training time: 1.24
progress:  82%|[34m████████▏ [0m| 41/50 [00:54<00:11,  1.25s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:54<00:09,  1.25s/it]                                                         Episode 43	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.03002254,  training time: 1.20
progress:  84%|[34m████████▍ [0m| 42/50 [00:55<00:09,  1.25s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.23s/it]                                                         Episode 44	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.04049779,  training time: 1.25
progress:  86%|[34m████████▌ [0m| 43/50 [00:56<00:08,  1.23s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.24s/it]                                                         Episode 45	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.03323376,  training time: 1.26
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.24s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.25s/it]                                                         Episode 46	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.06915612,  training time: 1.24
progress:  90%|[34m█████████ [0m| 45/50 [00:59<00:06,  1.25s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:04,  1.25s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.03915487,  training time: 1.21
progress:  92%|[34m█████████▏[0m| 46/50 [01:00<00:04,  1.25s/it]progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.23s/it]                                                         Episode 48	 reward: -5.80	 makespan: 574.25	 Mean_loss: 0.02318419,  training time: 1.25
progress:  94%|[34m█████████▍[0m| 47/50 [01:01<00:03,  1.23s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.24s/it]                                                         Episode 49	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.03192383,  training time: 1.26
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.24s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.25s/it]                                                         Episode 50	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.09658686,  training time: 1.21
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.25s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.23s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.28s/it]
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.02	 makespan: 794.25	 Mean_loss: 3.21101403,  training time: 2.46
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<02:00,  2.46s/it]                                                        Episode 2	 reward: -8.01	 makespan: 792.75	 Mean_loss: 1.27297485,  training time: 1.28
progress:   2%|[34m▏         [0m| 1/50 [00:03<02:00,  2.46s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:24,  1.77s/it]                                                        Episode 3	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.71829706,  training time: 1.28
progress:   4%|[34m▍         [0m| 2/50 [00:05<01:24,  1.77s/it]progress:   6%|[34m▌         [0m| 3/50 [00:05<01:12,  1.55s/it]                                                        Episode 4	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.47944695,  training time: 1.26
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:12,  1.55s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:06,  1.43s/it]                                                        Episode 5	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.65117538,  training time: 1.23
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:06,  1.43s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:01,  1.36s/it]                                                        Episode 6	 reward: -8.09	 makespan: 801.00	 Mean_loss: 0.57020319,  training time: 1.25
progress:  10%|[34m█         [0m| 5/50 [00:08<01:01,  1.36s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:58,  1.32s/it]                                                        Episode 7	 reward: -7.78	 makespan: 770.50	 Mean_loss: 0.41050962,  training time: 1.22
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:58,  1.32s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.29s/it]                                                        Episode 8	 reward: -6.88	 makespan: 681.00	 Mean_loss: 0.41756612,  training time: 1.21
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.29s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.27s/it]                                                        Episode 9	 reward: -7.63	 makespan: 755.00	 Mean_loss: 0.57507598,  training time: 1.28
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.27s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:52,  1.27s/it]                                                        Episode 10	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.27850029,  training time: 1.24
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:52,  1.27s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:50,  1.26s/it]                                                         Episode 11	 reward: -7.12	 makespan: 704.50	 Mean_loss: 0.37990975,  training time: 1.27
progress:  20%|[34m██        [0m| 10/50 [00:14<00:50,  1.26s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:49,  1.26s/it]                                                         Episode 12	 reward: -7.12	 makespan: 705.00	 Mean_loss: 0.24205419,  training time: 1.33
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:49,  1.26s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:48,  1.28s/it]                                                         Episode 13	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.26883006,  training time: 1.26
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:48,  1.28s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.28s/it]                                                         Episode 14	 reward: -6.91	 makespan: 684.00	 Mean_loss: 0.22321047,  training time: 1.28
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:47,  1.28s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:45,  1.28s/it]                                                         Episode 15	 reward: -6.87	 makespan: 680.00	 Mean_loss: 0.23601755,  training time: 1.26
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:45,  1.28s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.27s/it]                                                         Episode 16	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.21802236,  training time: 1.29
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.27s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.28s/it]                                                         Episode 17	 reward: -6.48	 makespan: 642.00	 Mean_loss: 0.17190768,  training time: 1.27
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.28s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:42,  1.28s/it]                                                         Episode 18	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.10819272,  training time: 1.23
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:42,  1.28s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:40,  1.26s/it]                                                         Episode 19	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.11288698,  training time: 1.23
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:40,  1.26s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.25s/it]                                                         Episode 20	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.07991631,  training time: 1.24
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.25s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.25s/it]                                                         Episode 21	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.06988034,  training time: 1.23
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.25s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.24s/it]                                                         Episode 22	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.10889138,  training time: 1.22
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.24s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.24s/it]                                                         Episode 23	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.05701911,  training time: 1.22
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:34,  1.24s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.23s/it]                                                         Episode 24	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.10097367,  training time: 1.24
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.23s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.24s/it]                                                         Episode 25	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.07842380,  training time: 1.21
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.24s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:30,  1.23s/it]                                                         Episode 26	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07951394,  training time: 1.22
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:30,  1.23s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:29,  1.23s/it]                                                         Episode 27	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.08025291,  training time: 1.25
progress:  52%|[34m█████▏    [0m| 26/50 [00:34<00:29,  1.23s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:34<00:28,  1.23s/it]                                                         Episode 28	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06642981,  training time: 1.22
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.23s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.23s/it]                                                         Episode 29	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.15515080,  training time: 1.23
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.23s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:25,  1.23s/it]                                                         Episode 30	 reward: -6.28	 makespan: 621.25	 Mean_loss: 0.06181020,  training time: 1.27
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:25,  1.23s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.24s/it]                                                         Episode 31	 reward: -6.62	 makespan: 655.75	 Mean_loss: 0.07743054,  training time: 1.19
progress:  60%|[34m██████    [0m| 30/50 [00:39<00:24,  1.24s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:39<00:23,  1.23s/it]                                                         Episode 32	 reward: -6.53	 makespan: 646.00	 Mean_loss: 0.05874833,  training time: 1.21
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.23s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.22s/it]                                                         Episode 33	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.07964465,  training time: 1.20
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.22s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:20,  1.22s/it]                                                         Episode 34	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.08120796,  training time: 1.20
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:20,  1.22s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.21s/it]                                                         Episode 35	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.12908915,  training time: 1.21
progress:  68%|[34m██████▊   [0m| 34/50 [00:44<00:19,  1.21s/it]progress:  70%|[34m███████   [0m| 35/50 [00:44<00:18,  1.21s/it]                                                         Episode 36	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.08053461,  training time: 1.20
progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.21s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:45<00:16,  1.21s/it]                                                         Episode 37	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10462729,  training time: 1.20
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:16,  1.21s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:15,  1.21s/it]                                                         Episode 38	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.06759962,  training time: 1.20
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:15,  1.21s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:14,  1.20s/it]                                                         Episode 39	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.08021324,  training time: 1.19
progress:  76%|[34m███████▌  [0m| 38/50 [00:49<00:14,  1.20s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:49<00:13,  1.20s/it]                                                         Episode 40	 reward: -6.19	 makespan: 613.25	 Mean_loss: 0.06176097,  training time: 1.21
progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.20s/it]progress:  80%|[34m████████  [0m| 40/50 [00:50<00:12,  1.20s/it]                                                         Episode 41	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14815387,  training time: 1.19
progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.20s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:51<00:10,  1.20s/it]                                                         Episode 42	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.05613716,  training time: 1.20
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:10,  1.20s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:09,  1.20s/it]                                                         Episode 43	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.10037018,  training time: 1.19
progress:  84%|[34m████████▍ [0m| 42/50 [00:54<00:09,  1.20s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:54<00:08,  1.20s/it]                                                         Episode 44	 reward: -6.06	 makespan: 599.50	 Mean_loss: 0.03694038,  training time: 1.25
progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.20s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:55<00:07,  1.21s/it]                                                         Episode 45	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.06969463,  training time: 1.20
progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.21s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:56<00:06,  1.21s/it]                                                         Episode 46	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.06036489,  training time: 1.19
progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.21s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:57<00:04,  1.20s/it]                                                         Episode 47	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.03793489,  training time: 1.24
progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:04,  1.20s/it]progress:  94%|[34m█████████▍[0m| 47/50 [00:59<00:03,  1.21s/it]                                                         Episode 48	 reward: -5.99	 makespan: 592.75	 Mean_loss: 0.06755880,  training time: 1.19
progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.21s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:00<00:02,  1.21s/it]                                                         Episode 49	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.04995026,  training time: 1.19
progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.21s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:01<00:01,  1.20s/it]                                                         Episode 50	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.04884755,  training time: 1.22
progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.20s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.21s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.26s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.02	 makespan: 794.25	 Mean_loss: 3.21101403,  training time: 2.32
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:53,  2.32s/it]                                                        Episode 2	 reward: -8.01	 makespan: 792.75	 Mean_loss: 1.27297485,  training time: 1.24
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:53,  2.32s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:20,  1.69s/it]                                                        Episode 3	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.71829706,  training time: 1.24
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:20,  1.69s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:09,  1.48s/it]                                                        Episode 4	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.47944695,  training time: 1.27
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:09,  1.48s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.40s/it]                                                        Episode 5	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.65117538,  training time: 1.23
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.40s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.34s/it]                                                        Episode 6	 reward: -8.09	 makespan: 801.00	 Mean_loss: 0.57020319,  training time: 1.35
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.34s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:59,  1.34s/it]                                                        Episode 7	 reward: -7.78	 makespan: 770.50	 Mean_loss: 0.41050962,  training time: 1.26
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:59,  1.34s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:56,  1.32s/it]                                                        Episode 8	 reward: -6.88	 makespan: 681.00	 Mean_loss: 0.41756612,  training time: 1.26
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:56,  1.32s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:54,  1.30s/it]                                                        Episode 9	 reward: -7.63	 makespan: 755.00	 Mean_loss: 0.57507598,  training time: 1.27
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:54,  1.30s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:52,  1.29s/it]                                                        Episode 10	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.27850029,  training time: 1.22
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:52,  1.29s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:50,  1.27s/it]                                                         Episode 11	 reward: -7.12	 makespan: 704.50	 Mean_loss: 0.37990975,  training time: 1.27
progress:  20%|[34m██        [0m| 10/50 [00:14<00:50,  1.27s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:49,  1.27s/it]                                                         Episode 12	 reward: -7.12	 makespan: 705.00	 Mean_loss: 0.24205419,  training time: 1.35
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:49,  1.27s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:49,  1.30s/it]                                                         Episode 13	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.26883006,  training time: 1.26
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:49,  1.30s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.29s/it]                                                         Episode 14	 reward: -6.91	 makespan: 684.00	 Mean_loss: 0.22321047,  training time: 1.26
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:47,  1.29s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:46,  1.28s/it]                                                         Episode 15	 reward: -6.87	 makespan: 680.00	 Mean_loss: 0.23601755,  training time: 1.26
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:46,  1.28s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.27s/it]                                                         Episode 16	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.21802236,  training time: 1.26
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.27s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.27s/it]                                                         Episode 17	 reward: -6.48	 makespan: 642.00	 Mean_loss: 0.17190768,  training time: 1.21
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.27s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.25s/it]                                                         Episode 18	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.10819272,  training time: 1.22
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:41,  1.25s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:39,  1.24s/it]                                                         Episode 19	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.11288698,  training time: 1.26
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:39,  1.24s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.25s/it]                                                         Episode 20	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.07991631,  training time: 1.26
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.25s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.25s/it]                                                         Episode 21	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.06988034,  training time: 1.26
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.25s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.25s/it]                                                         Episode 22	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.10889138,  training time: 1.22
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.25s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.25s/it]                                                         Episode 23	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.05701911,  training time: 1.25
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:34,  1.25s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.25s/it]                                                         Episode 24	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.10097367,  training time: 1.27
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.25s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.26s/it]                                                         Episode 25	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.07842380,  training time: 1.26
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.26s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:31,  1.26s/it]                                                         Episode 26	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07951394,  training time: 1.23
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:31,  1.26s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:30,  1.25s/it]                                                         Episode 27	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.08025291,  training time: 1.25
progress:  52%|[34m█████▏    [0m| 26/50 [00:35<00:30,  1.25s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.25s/it]                                                         Episode 28	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06642981,  training time: 1.26
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.25s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.25s/it]                                                         Episode 29	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.15515080,  training time: 1.22
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.25s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.24s/it]                                                         Episode 30	 reward: -6.28	 makespan: 621.25	 Mean_loss: 0.06181020,  training time: 1.24
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:26,  1.24s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.24s/it]                                                         Episode 31	 reward: -6.62	 makespan: 655.75	 Mean_loss: 0.07743054,  training time: 1.26
progress:  60%|[34m██████    [0m| 30/50 [00:40<00:24,  1.24s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.25s/it]                                                         Episode 32	 reward: -6.53	 makespan: 646.00	 Mean_loss: 0.05874833,  training time: 1.27
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.25s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.25s/it]                                                         Episode 33	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.07964465,  training time: 1.25
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.25s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:21,  1.25s/it]                                                         Episode 34	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.08120796,  training time: 1.28
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:21,  1.25s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:20,  1.26s/it]                                                         Episode 35	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.12908915,  training time: 1.26
progress:  68%|[34m██████▊   [0m| 34/50 [00:45<00:20,  1.26s/it]progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.26s/it]                                                         Episode 36	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.08053461,  training time: 1.27
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.26s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.26s/it]                                                         Episode 37	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10462729,  training time: 1.22
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.26s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:16,  1.25s/it]                                                         Episode 38	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.06759962,  training time: 1.26
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:16,  1.25s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:15,  1.25s/it]                                                         Episode 39	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.08021324,  training time: 1.26
progress:  76%|[34m███████▌  [0m| 38/50 [00:50<00:15,  1.25s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.26s/it]                                                         Episode 40	 reward: -6.19	 makespan: 613.25	 Mean_loss: 0.06176097,  training time: 1.24
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.26s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.25s/it]                                                         Episode 41	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14815387,  training time: 1.26
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.25s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.25s/it]                                                         Episode 42	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.05613716,  training time: 1.26
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.25s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:10,  1.26s/it]                                                         Episode 43	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.10037018,  training time: 1.27
progress:  84%|[34m████████▍ [0m| 42/50 [00:55<00:10,  1.26s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.26s/it]                                                         Episode 44	 reward: -6.06	 makespan: 599.50	 Mean_loss: 0.03694038,  training time: 1.33
progress:  86%|[34m████████▌ [0m| 43/50 [00:56<00:08,  1.26s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.28s/it]                                                         Episode 45	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.06969463,  training time: 1.26
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.28s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.27s/it]                                                         Episode 46	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.06036489,  training time: 1.22
progress:  90%|[34m█████████ [0m| 45/50 [00:58<00:06,  1.27s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:58<00:05,  1.26s/it]                                                         Episode 47	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.03793489,  training time: 1.24
progress:  92%|[34m█████████▏[0m| 46/50 [01:00<00:05,  1.26s/it]progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.25s/it]                                                         Episode 48	 reward: -5.99	 makespan: 592.75	 Mean_loss: 0.06755880,  training time: 1.25
progress:  94%|[34m█████████▍[0m| 47/50 [01:01<00:03,  1.25s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.25s/it]                                                         Episode 49	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.04995026,  training time: 1.24
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.25s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.25s/it]                                                         Episode 50	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.04884755,  training time: 1.26
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.25s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.25s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.28s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.02	 makespan: 794.25	 Mean_loss: 3.21101403,  training time: 2.33
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:54,  2.34s/it]                                                        Episode 2	 reward: -8.01	 makespan: 792.75	 Mean_loss: 1.27297485,  training time: 1.31
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:54,  2.34s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:23,  1.73s/it]                                                        Episode 3	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.71829706,  training time: 1.30
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:23,  1.73s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:12,  1.54s/it]                                                        Episode 4	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.47944695,  training time: 1.26
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:12,  1.54s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:05,  1.43s/it]                                                        Episode 5	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.65117538,  training time: 1.26
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:05,  1.43s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:01,  1.37s/it]                                                        Episode 6	 reward: -8.09	 makespan: 801.00	 Mean_loss: 0.57020319,  training time: 1.26
progress:  10%|[34m█         [0m| 5/50 [00:08<01:01,  1.37s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:58,  1.33s/it]                                                        Episode 7	 reward: -7.78	 makespan: 770.50	 Mean_loss: 0.41050962,  training time: 1.35
progress:  12%|[34m█▏        [0m| 6/50 [00:10<00:58,  1.33s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:10<00:57,  1.34s/it]                                                        Episode 8	 reward: -6.88	 makespan: 681.00	 Mean_loss: 0.41756612,  training time: 1.28
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:57,  1.34s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:55,  1.32s/it]                                                        Episode 9	 reward: -7.63	 makespan: 755.00	 Mean_loss: 0.57507598,  training time: 1.27
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:55,  1.32s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:53,  1.30s/it]                                                        Episode 10	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.27850029,  training time: 1.26
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:53,  1.30s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:51,  1.29s/it]                                                         Episode 11	 reward: -7.12	 makespan: 704.50	 Mean_loss: 0.37990975,  training time: 1.28
progress:  20%|[34m██        [0m| 10/50 [00:15<00:51,  1.29s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:15<00:50,  1.29s/it]                                                         Episode 12	 reward: -7.12	 makespan: 705.00	 Mean_loss: 0.24205419,  training time: 1.41
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:50,  1.29s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:50,  1.32s/it]                                                         Episode 13	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.26883006,  training time: 1.23
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:50,  1.32s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.30s/it]                                                         Episode 14	 reward: -6.91	 makespan: 684.00	 Mean_loss: 0.22321047,  training time: 1.25
progress:  26%|[34m██▌       [0m| 13/50 [00:19<00:47,  1.30s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:19<00:46,  1.28s/it]                                                         Episode 15	 reward: -6.87	 makespan: 680.00	 Mean_loss: 0.23601755,  training time: 1.23
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:46,  1.28s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.27s/it]                                                         Episode 16	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.21802236,  training time: 1.27
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.27s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.27s/it]                                                         Episode 17	 reward: -6.48	 makespan: 642.00	 Mean_loss: 0.17190768,  training time: 1.24
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.27s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.26s/it]                                                         Episode 18	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.10819272,  training time: 1.21
progress:  34%|[34m███▍      [0m| 17/50 [00:24<00:41,  1.26s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:24<00:39,  1.25s/it]                                                         Episode 19	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.11288698,  training time: 1.28
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:39,  1.25s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.26s/it]                                                         Episode 20	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.07991631,  training time: 1.21
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.26s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.24s/it]                                                         Episode 21	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.06988034,  training time: 1.25
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.24s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.24s/it]                                                         Episode 22	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.10889138,  training time: 1.20
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.24s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.23s/it]                                                         Episode 23	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.05701911,  training time: 1.23
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:34,  1.23s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.23s/it]                                                         Episode 24	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.10097367,  training time: 1.26
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.23s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.24s/it]                                                         Episode 25	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.07842380,  training time: 1.22
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.24s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:30,  1.24s/it]                                                         Episode 26	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07951394,  training time: 1.25
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:30,  1.24s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:29,  1.24s/it]                                                         Episode 27	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.08025291,  training time: 1.26
progress:  52%|[34m█████▏    [0m| 26/50 [00:35<00:29,  1.24s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.25s/it]                                                         Episode 28	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06642981,  training time: 1.24
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.25s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.25s/it]                                                         Episode 29	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.15515080,  training time: 1.24
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.25s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.24s/it]                                                         Episode 30	 reward: -6.28	 makespan: 621.25	 Mean_loss: 0.06181020,  training time: 1.25
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:26,  1.24s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.25s/it]                                                         Episode 31	 reward: -6.62	 makespan: 655.75	 Mean_loss: 0.07743054,  training time: 1.23
progress:  60%|[34m██████    [0m| 30/50 [00:40<00:24,  1.25s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.24s/it]                                                         Episode 32	 reward: -6.53	 makespan: 646.00	 Mean_loss: 0.05874833,  training time: 1.26
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.24s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.25s/it]                                                         Episode 33	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.07964465,  training time: 1.25
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.25s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:21,  1.25s/it]                                                         Episode 34	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.08120796,  training time: 1.25
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:21,  1.25s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:20,  1.25s/it]                                                         Episode 35	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.12908915,  training time: 1.27
progress:  68%|[34m██████▊   [0m| 34/50 [00:45<00:20,  1.25s/it]progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.26s/it]                                                         Episode 36	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.08053461,  training time: 1.27
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.26s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.26s/it]                                                         Episode 37	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10462729,  training time: 1.22
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.26s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:16,  1.25s/it]                                                         Episode 38	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.06759962,  training time: 1.22
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:16,  1.25s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:14,  1.24s/it]                                                         Episode 39	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.08021324,  training time: 1.24
progress:  76%|[34m███████▌  [0m| 38/50 [00:50<00:14,  1.24s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.24s/it]                                                         Episode 40	 reward: -6.19	 makespan: 613.25	 Mean_loss: 0.06176097,  training time: 1.24
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.24s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.24s/it]                                                         Episode 41	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14815387,  training time: 1.23
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.24s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.24s/it]                                                         Episode 42	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.05613716,  training time: 1.23
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.24s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:09,  1.23s/it]                                                         Episode 43	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.10037018,  training time: 1.24
progress:  84%|[34m████████▍ [0m| 42/50 [00:55<00:09,  1.23s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.24s/it]                                                         Episode 44	 reward: -6.06	 makespan: 599.50	 Mean_loss: 0.03694038,  training time: 1.24
progress:  86%|[34m████████▌ [0m| 43/50 [00:56<00:08,  1.24s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.24s/it]                                                         Episode 45	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.06969463,  training time: 1.24
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.24s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.24s/it]                                                         Episode 46	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.06036489,  training time: 1.23
progress:  90%|[34m█████████ [0m| 45/50 [00:58<00:06,  1.24s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:58<00:04,  1.24s/it]                                                         Episode 47	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.03793489,  training time: 1.22
progress:  92%|[34m█████████▏[0m| 46/50 [01:00<00:04,  1.24s/it]progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.23s/it]                                                         Episode 48	 reward: -5.99	 makespan: 592.75	 Mean_loss: 0.06755880,  training time: 1.22
progress:  94%|[34m█████████▍[0m| 47/50 [01:01<00:03,  1.23s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.23s/it]                                                         Episode 49	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.04995026,  training time: 1.25
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.23s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.24s/it]                                                         Episode 50	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.04884755,  training time: 1.31
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.26s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.28s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.02	 makespan: 794.25	 Mean_loss: 3.21101403,  training time: 2.39
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:57,  2.39s/it]                                                        Episode 2	 reward: -8.01	 makespan: 792.75	 Mean_loss: 1.27297485,  training time: 1.26
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:57,  2.39s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:22,  1.73s/it]                                                        Episode 3	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.71829706,  training time: 1.25
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:22,  1.73s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.51s/it]                                                        Episode 4	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.47944695,  training time: 1.26
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.51s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.41s/it]                                                        Episode 5	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.65117538,  training time: 1.21
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.41s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.34s/it]                                                        Episode 6	 reward: -8.09	 makespan: 801.00	 Mean_loss: 0.57020319,  training time: 1.27
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.34s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:57,  1.32s/it]                                                        Episode 7	 reward: -7.78	 makespan: 770.50	 Mean_loss: 0.41050962,  training time: 1.23
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:57,  1.32s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.29s/it]                                                        Episode 8	 reward: -6.88	 makespan: 681.00	 Mean_loss: 0.41756612,  training time: 1.24
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.29s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.27s/it]                                                        Episode 9	 reward: -7.63	 makespan: 755.00	 Mean_loss: 0.57507598,  training time: 1.24
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.27s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:51,  1.26s/it]                                                        Episode 10	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.27850029,  training time: 1.21
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:51,  1.26s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:49,  1.25s/it]                                                         Episode 11	 reward: -7.12	 makespan: 704.50	 Mean_loss: 0.37990975,  training time: 1.24
progress:  20%|[34m██        [0m| 10/50 [00:14<00:49,  1.25s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:14<00:48,  1.25s/it]                                                         Episode 12	 reward: -7.12	 makespan: 705.00	 Mean_loss: 0.24205419,  training time: 1.32
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:48,  1.25s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:48,  1.27s/it]                                                         Episode 13	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.26883006,  training time: 1.24
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:48,  1.27s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:46,  1.26s/it]                                                         Episode 14	 reward: -6.91	 makespan: 684.00	 Mean_loss: 0.22321047,  training time: 1.24
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:46,  1.26s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:45,  1.25s/it]                                                         Episode 15	 reward: -6.87	 makespan: 680.00	 Mean_loss: 0.23601755,  training time: 1.24
progress:  28%|[34m██▊       [0m| 14/50 [00:19<00:45,  1.25s/it]progress:  30%|[34m███       [0m| 15/50 [00:19<00:43,  1.25s/it]                                                         Episode 16	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.21802236,  training time: 1.23
progress:  30%|[34m███       [0m| 15/50 [00:21<00:43,  1.25s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:42,  1.25s/it]                                                         Episode 17	 reward: -6.48	 makespan: 642.00	 Mean_loss: 0.17190768,  training time: 1.22
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:42,  1.25s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:40,  1.24s/it]                                                         Episode 18	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.10819272,  training time: 1.22
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:40,  1.24s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:39,  1.23s/it]                                                         Episode 19	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.11288698,  training time: 1.22
progress:  36%|[34m███▌      [0m| 18/50 [00:24<00:39,  1.23s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:24<00:38,  1.23s/it]                                                         Episode 20	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.07991631,  training time: 1.22
progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.23s/it]progress:  40%|[34m████      [0m| 20/50 [00:25<00:36,  1.23s/it]                                                         Episode 21	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.06988034,  training time: 1.22
progress:  40%|[34m████      [0m| 20/50 [00:27<00:36,  1.23s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:35,  1.23s/it]                                                         Episode 22	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.10889138,  training time: 1.19
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:35,  1.23s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.22s/it]                                                         Episode 23	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.05701911,  training time: 1.21
progress:  44%|[34m████▍     [0m| 22/50 [00:29<00:34,  1.22s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:29<00:32,  1.22s/it]                                                         Episode 24	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.10097367,  training time: 1.23
progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:32,  1.22s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:30<00:31,  1.22s/it]                                                         Episode 25	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.07842380,  training time: 1.22
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:31,  1.22s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:30,  1.22s/it]                                                         Episode 26	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07951394,  training time: 1.22
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:30,  1.22s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:29,  1.22s/it]                                                         Episode 27	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.08025291,  training time: 1.22
progress:  52%|[34m█████▏    [0m| 26/50 [00:34<00:29,  1.22s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:34<00:28,  1.22s/it]                                                         Episode 28	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06642981,  training time: 1.23
progress:  54%|[34m█████▍    [0m| 27/50 [00:35<00:28,  1.22s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:35<00:26,  1.22s/it]                                                         Episode 29	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.15515080,  training time: 1.22
progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:26,  1.22s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:36<00:25,  1.22s/it]                                                         Episode 30	 reward: -6.28	 makespan: 621.25	 Mean_loss: 0.06181020,  training time: 1.22
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:25,  1.22s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.22s/it]                                                         Episode 31	 reward: -6.62	 makespan: 655.75	 Mean_loss: 0.07743054,  training time: 1.23
progress:  60%|[34m██████    [0m| 30/50 [00:39<00:24,  1.22s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:39<00:23,  1.22s/it]                                                         Episode 32	 reward: -6.53	 makespan: 646.00	 Mean_loss: 0.05874833,  training time: 1.22
progress:  62%|[34m██████▏   [0m| 31/50 [00:40<00:23,  1.22s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:40<00:22,  1.22s/it]                                                         Episode 33	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.07964465,  training time: 1.20
progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.22s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:41<00:20,  1.22s/it]                                                         Episode 34	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.08120796,  training time: 1.23
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:20,  1.22s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.22s/it]                                                         Episode 35	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.12908915,  training time: 1.23
progress:  68%|[34m██████▊   [0m| 34/50 [00:44<00:19,  1.22s/it]progress:  70%|[34m███████   [0m| 35/50 [00:44<00:18,  1.22s/it]                                                         Episode 36	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.08053461,  training time: 1.22
progress:  70%|[34m███████   [0m| 35/50 [00:45<00:18,  1.22s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:45<00:17,  1.22s/it]                                                         Episode 37	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10462729,  training time: 1.21
progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.22s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:46<00:15,  1.22s/it]                                                         Episode 38	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.06759962,  training time: 1.20
progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:15,  1.22s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:47<00:14,  1.21s/it]                                                         Episode 39	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.08021324,  training time: 1.23
progress:  76%|[34m███████▌  [0m| 38/50 [00:49<00:14,  1.21s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:49<00:13,  1.22s/it]                                                         Episode 40	 reward: -6.19	 makespan: 613.25	 Mean_loss: 0.06176097,  training time: 1.30
progress:  78%|[34m███████▊  [0m| 39/50 [00:50<00:13,  1.22s/it]progress:  80%|[34m████████  [0m| 40/50 [00:50<00:12,  1.24s/it]                                                         Episode 41	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14815387,  training time: 1.23
progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.24s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:51<00:11,  1.24s/it]                                                         Episode 42	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.05613716,  training time: 1.19
progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.24s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:52<00:09,  1.23s/it]                                                         Episode 43	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.10037018,  training time: 1.22
progress:  84%|[34m████████▍ [0m| 42/50 [00:54<00:09,  1.23s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:54<00:08,  1.22s/it]                                                         Episode 44	 reward: -6.06	 makespan: 599.50	 Mean_loss: 0.03694038,  training time: 1.26
progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.22s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:55<00:07,  1.24s/it]                                                         Episode 45	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.06969463,  training time: 1.23
progress:  88%|[34m████████▊ [0m| 44/50 [00:56<00:07,  1.24s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:56<00:06,  1.23s/it]                                                         Episode 46	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.06036489,  training time: 1.19
progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.23s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:57<00:04,  1.22s/it]                                                         Episode 47	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.03793489,  training time: 1.30
progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:04,  1.22s/it]progress:  94%|[34m█████████▍[0m| 47/50 [00:59<00:03,  1.25s/it]                                                         Episode 48	 reward: -5.99	 makespan: 592.75	 Mean_loss: 0.06755880,  training time: 1.24
progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.25s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:00<00:02,  1.24s/it]                                                         Episode 49	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.04995026,  training time: 1.23
progress:  96%|[34m█████████▌[0m| 48/50 [01:01<00:02,  1.24s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:01<00:01,  1.24s/it]                                                         Episode 50	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.04884755,  training time: 1.24
progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:02<00:00,  1.26s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.02	 makespan: 794.25	 Mean_loss: 3.21101403,  training time: 2.32
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:53,  2.32s/it]                                                        Episode 2	 reward: -8.01	 makespan: 792.75	 Mean_loss: 1.27297485,  training time: 1.26
progress:   2%|[34m▏         [0m| 1/50 [00:03<01:53,  2.32s/it]progress:   4%|[34m▍         [0m| 2/50 [00:03<01:21,  1.70s/it]                                                        Episode 3	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.71829706,  training time: 1.25
progress:   4%|[34m▍         [0m| 2/50 [00:04<01:21,  1.70s/it]progress:   6%|[34m▌         [0m| 3/50 [00:04<01:10,  1.50s/it]                                                        Episode 4	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.47944695,  training time: 1.26
progress:   6%|[34m▌         [0m| 3/50 [00:06<01:10,  1.50s/it]progress:   8%|[34m▊         [0m| 4/50 [00:06<01:04,  1.41s/it]                                                        Episode 5	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.65117538,  training time: 1.26
progress:   8%|[34m▊         [0m| 4/50 [00:07<01:04,  1.41s/it]progress:  10%|[34m█         [0m| 5/50 [00:07<01:00,  1.35s/it]                                                        Episode 6	 reward: -8.09	 makespan: 801.00	 Mean_loss: 0.57020319,  training time: 1.26
progress:  10%|[34m█         [0m| 5/50 [00:08<01:00,  1.35s/it]progress:  12%|[34m█▏        [0m| 6/50 [00:08<00:58,  1.32s/it]                                                        Episode 7	 reward: -7.78	 makespan: 770.50	 Mean_loss: 0.41050962,  training time: 1.26
progress:  12%|[34m█▏        [0m| 6/50 [00:09<00:58,  1.32s/it]progress:  14%|[34m█▍        [0m| 7/50 [00:09<00:55,  1.30s/it]                                                        Episode 8	 reward: -6.88	 makespan: 681.00	 Mean_loss: 0.41756612,  training time: 1.25
progress:  14%|[34m█▍        [0m| 7/50 [00:11<00:55,  1.30s/it]progress:  16%|[34m█▌        [0m| 8/50 [00:11<00:53,  1.28s/it]                                                        Episode 9	 reward: -7.63	 makespan: 755.00	 Mean_loss: 0.57507598,  training time: 1.27
progress:  16%|[34m█▌        [0m| 8/50 [00:12<00:53,  1.28s/it]progress:  18%|[34m█▊        [0m| 9/50 [00:12<00:52,  1.28s/it]                                                        Episode 10	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.27850029,  training time: 1.31
progress:  18%|[34m█▊        [0m| 9/50 [00:13<00:52,  1.28s/it]progress:  20%|[34m██        [0m| 10/50 [00:13<00:51,  1.29s/it]                                                         Episode 11	 reward: -7.12	 makespan: 704.50	 Mean_loss: 0.37990975,  training time: 1.28
progress:  20%|[34m██        [0m| 10/50 [00:15<00:51,  1.29s/it]progress:  22%|[34m██▏       [0m| 11/50 [00:15<00:50,  1.29s/it]                                                         Episode 12	 reward: -7.12	 makespan: 705.00	 Mean_loss: 0.24205419,  training time: 1.34
progress:  22%|[34m██▏       [0m| 11/50 [00:16<00:50,  1.29s/it]progress:  24%|[34m██▍       [0m| 12/50 [00:16<00:49,  1.31s/it]                                                         Episode 13	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.26883006,  training time: 1.25
progress:  24%|[34m██▍       [0m| 12/50 [00:17<00:49,  1.31s/it]progress:  26%|[34m██▌       [0m| 13/50 [00:17<00:47,  1.29s/it]                                                         Episode 14	 reward: -6.91	 makespan: 684.00	 Mean_loss: 0.22321047,  training time: 1.24
progress:  26%|[34m██▌       [0m| 13/50 [00:18<00:47,  1.29s/it]progress:  28%|[34m██▊       [0m| 14/50 [00:18<00:45,  1.27s/it]                                                         Episode 15	 reward: -6.87	 makespan: 680.00	 Mean_loss: 0.23601755,  training time: 1.28
progress:  28%|[34m██▊       [0m| 14/50 [00:20<00:45,  1.27s/it]progress:  30%|[34m███       [0m| 15/50 [00:20<00:44,  1.28s/it]                                                         Episode 16	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.21802236,  training time: 1.24
progress:  30%|[34m███       [0m| 15/50 [00:21<00:44,  1.28s/it]progress:  32%|[34m███▏      [0m| 16/50 [00:21<00:43,  1.27s/it]                                                         Episode 17	 reward: -6.48	 makespan: 642.00	 Mean_loss: 0.17190768,  training time: 1.24
progress:  32%|[34m███▏      [0m| 16/50 [00:22<00:43,  1.27s/it]progress:  34%|[34m███▍      [0m| 17/50 [00:22<00:41,  1.26s/it]                                                         Episode 18	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.10819272,  training time: 1.24
progress:  34%|[34m███▍      [0m| 17/50 [00:23<00:41,  1.26s/it]progress:  36%|[34m███▌      [0m| 18/50 [00:23<00:40,  1.25s/it]                                                         Episode 19	 reward: -6.51	 makespan: 644.00	 Mean_loss: 0.11288698,  training time: 1.24
progress:  36%|[34m███▌      [0m| 18/50 [00:25<00:40,  1.25s/it]progress:  38%|[34m███▊      [0m| 19/50 [00:25<00:38,  1.25s/it]                                                         Episode 20	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.07991631,  training time: 1.25
progress:  38%|[34m███▊      [0m| 19/50 [00:26<00:38,  1.25s/it]progress:  40%|[34m████      [0m| 20/50 [00:26<00:37,  1.25s/it]                                                         Episode 21	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.06988034,  training time: 1.23
progress:  40%|[34m████      [0m| 20/50 [00:27<00:37,  1.25s/it]progress:  42%|[34m████▏     [0m| 21/50 [00:27<00:36,  1.24s/it]                                                         Episode 22	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.10889138,  training time: 1.24
progress:  42%|[34m████▏     [0m| 21/50 [00:28<00:36,  1.24s/it]progress:  44%|[34m████▍     [0m| 22/50 [00:28<00:34,  1.24s/it]                                                         Episode 23	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.05701911,  training time: 1.21
progress:  44%|[34m████▍     [0m| 22/50 [00:30<00:34,  1.24s/it]progress:  46%|[34m████▌     [0m| 23/50 [00:30<00:33,  1.24s/it]                                                         Episode 24	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.10097367,  training time: 1.24
progress:  46%|[34m████▌     [0m| 23/50 [00:31<00:33,  1.24s/it]progress:  48%|[34m████▊     [0m| 24/50 [00:31<00:32,  1.24s/it]                                                         Episode 25	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.07842380,  training time: 1.23
progress:  48%|[34m████▊     [0m| 24/50 [00:32<00:32,  1.24s/it]progress:  50%|[34m█████     [0m| 25/50 [00:32<00:30,  1.24s/it]                                                         Episode 26	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07951394,  training time: 1.23
progress:  50%|[34m█████     [0m| 25/50 [00:33<00:30,  1.24s/it]progress:  52%|[34m█████▏    [0m| 26/50 [00:33<00:29,  1.24s/it]                                                         Episode 27	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.08025291,  training time: 1.25
progress:  52%|[34m█████▏    [0m| 26/50 [00:34<00:29,  1.24s/it]progress:  54%|[34m█████▍    [0m| 27/50 [00:34<00:28,  1.24s/it]                                                         Episode 28	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06642981,  training time: 1.23
progress:  54%|[34m█████▍    [0m| 27/50 [00:36<00:28,  1.24s/it]progress:  56%|[34m█████▌    [0m| 28/50 [00:36<00:27,  1.24s/it]                                                         Episode 29	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.15515080,  training time: 1.27
progress:  56%|[34m█████▌    [0m| 28/50 [00:37<00:27,  1.24s/it]progress:  58%|[34m█████▊    [0m| 29/50 [00:37<00:26,  1.25s/it]                                                         Episode 30	 reward: -6.28	 makespan: 621.25	 Mean_loss: 0.06181020,  training time: 1.22
progress:  58%|[34m█████▊    [0m| 29/50 [00:38<00:26,  1.25s/it]progress:  60%|[34m██████    [0m| 30/50 [00:38<00:24,  1.24s/it]                                                         Episode 31	 reward: -6.62	 makespan: 655.75	 Mean_loss: 0.07743054,  training time: 1.24
progress:  60%|[34m██████    [0m| 30/50 [00:39<00:24,  1.24s/it]progress:  62%|[34m██████▏   [0m| 31/50 [00:39<00:23,  1.24s/it]                                                         Episode 32	 reward: -6.53	 makespan: 646.00	 Mean_loss: 0.05874833,  training time: 1.24
progress:  62%|[34m██████▏   [0m| 31/50 [00:41<00:23,  1.24s/it]progress:  64%|[34m██████▍   [0m| 32/50 [00:41<00:22,  1.24s/it]                                                         Episode 33	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.07964465,  training time: 1.21
progress:  64%|[34m██████▍   [0m| 32/50 [00:42<00:22,  1.24s/it]progress:  66%|[34m██████▌   [0m| 33/50 [00:42<00:20,  1.23s/it]                                                         Episode 34	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.08120796,  training time: 1.23
progress:  66%|[34m██████▌   [0m| 33/50 [00:43<00:20,  1.23s/it]progress:  68%|[34m██████▊   [0m| 34/50 [00:43<00:19,  1.23s/it]                                                         Episode 35	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.12908915,  training time: 1.23
progress:  68%|[34m██████▊   [0m| 34/50 [00:44<00:19,  1.23s/it]progress:  70%|[34m███████   [0m| 35/50 [00:44<00:18,  1.23s/it]                                                         Episode 36	 reward: -6.63	 makespan: 656.00	 Mean_loss: 0.08053461,  training time: 1.24
progress:  70%|[34m███████   [0m| 35/50 [00:46<00:18,  1.23s/it]progress:  72%|[34m███████▏  [0m| 36/50 [00:46<00:17,  1.24s/it]                                                         Episode 37	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10462729,  training time: 1.20
progress:  72%|[34m███████▏  [0m| 36/50 [00:47<00:17,  1.24s/it]progress:  74%|[34m███████▍  [0m| 37/50 [00:47<00:15,  1.22s/it]                                                         Episode 38	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.06759962,  training time: 1.24
progress:  74%|[34m███████▍  [0m| 37/50 [00:48<00:15,  1.22s/it]progress:  76%|[34m███████▌  [0m| 38/50 [00:48<00:14,  1.23s/it]                                                         Episode 39	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.08021324,  training time: 1.23
progress:  76%|[34m███████▌  [0m| 38/50 [00:49<00:14,  1.23s/it]progress:  78%|[34m███████▊  [0m| 39/50 [00:49<00:13,  1.23s/it]                                                         Episode 40	 reward: -6.19	 makespan: 613.25	 Mean_loss: 0.06176097,  training time: 1.24
progress:  78%|[34m███████▊  [0m| 39/50 [00:51<00:13,  1.23s/it]progress:  80%|[34m████████  [0m| 40/50 [00:51<00:12,  1.23s/it]                                                         Episode 41	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14815387,  training time: 1.25
progress:  80%|[34m████████  [0m| 40/50 [00:52<00:12,  1.23s/it]progress:  82%|[34m████████▏ [0m| 41/50 [00:52<00:11,  1.24s/it]                                                         Episode 42	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.05613716,  training time: 1.20
progress:  82%|[34m████████▏ [0m| 41/50 [00:53<00:11,  1.24s/it]progress:  84%|[34m████████▍ [0m| 42/50 [00:53<00:09,  1.23s/it]                                                         Episode 43	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.10037018,  training time: 1.25
progress:  84%|[34m████████▍ [0m| 42/50 [00:54<00:09,  1.23s/it]progress:  86%|[34m████████▌ [0m| 43/50 [00:54<00:08,  1.23s/it]                                                         Episode 44	 reward: -6.06	 makespan: 599.50	 Mean_loss: 0.03694038,  training time: 1.23
progress:  86%|[34m████████▌ [0m| 43/50 [00:55<00:08,  1.23s/it]progress:  88%|[34m████████▊ [0m| 44/50 [00:55<00:07,  1.23s/it]                                                         Episode 45	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.06969463,  training time: 1.24
progress:  88%|[34m████████▊ [0m| 44/50 [00:57<00:07,  1.23s/it]progress:  90%|[34m█████████ [0m| 45/50 [00:57<00:06,  1.24s/it]                                                         Episode 46	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.06036489,  training time: 1.20
progress:  90%|[34m█████████ [0m| 45/50 [00:58<00:06,  1.24s/it]progress:  92%|[34m█████████▏[0m| 46/50 [00:58<00:04,  1.22s/it]                                                         Episode 47	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.03793489,  training time: 1.31
progress:  92%|[34m█████████▏[0m| 46/50 [00:59<00:04,  1.22s/it]progress:  94%|[34m█████████▍[0m| 47/50 [00:59<00:03,  1.25s/it]                                                         Episode 48	 reward: -5.99	 makespan: 592.75	 Mean_loss: 0.06755880,  training time: 1.23
progress:  94%|[34m█████████▍[0m| 47/50 [01:00<00:03,  1.25s/it]progress:  96%|[34m█████████▌[0m| 48/50 [01:00<00:02,  1.24s/it]                                                         Episode 49	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.04995026,  training time: 1.21
progress:  96%|[34m█████████▌[0m| 48/50 [01:02<00:02,  1.24s/it]progress:  98%|[34m█████████▊[0m| 49/50 [01:02<00:01,  1.24s/it]                                                         Episode 50	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.04884755,  training time: 1.20
progress:  98%|[34m█████████▊[0m| 49/50 [01:03<00:01,  1.24s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.23s/it]progress: 100%|[34m██████████[0m| 50/50 [01:03<00:00,  1.27s/it]
+ meta_iterations=1000
+ max_updates_maml=1000
+ model_suffix=exp15_1000_64_3
+ num_tasks=4
+ logdir_maml=exp15/maml
+ python train/multi_task_maml_exp15.py --logdir exp15/maml --model_suffix exp15_1000_64_3 --maml_model True --meta_iterations 1000 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --op_per_job_options 4 6 8 10 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  maml+exp15_1000_64_3
self.op_per_job_options [4, 6, 8, 10, 12]
[484.5, 694.0, 915.75, 1143.25, 1407.75]
Episode 1	 reward: -13.73	 Mean_loss: 4.09039497,  training time: 12.85
[497.5, 759.75, 926.25, 1177.75, 1366.5]
Episode 2	 reward: -12.95	 Mean_loss: 3.60044312,  training time: 11.87
[467.75, 714.25, 938.75, 1139.5, 1289.5]
Episode 3	 reward: -14.36	 Mean_loss: 3.15213037,  training time: 11.75
[478.0, 762.0, 920.75, 1171.25, 1312.75]
Episode 4	 reward: -13.45	 Mean_loss: 3.18093228,  training time: 11.68
[469.5, 747.5, 905.5, 1195.0, 1349.25]
Episode 5	 reward: -13.74	 Mean_loss: 3.32943940,  training time: 11.64
[465.25, 706.5, 913.75, 1256.5, 1423.0]
Episode 6	 reward: -13.69	 Mean_loss: 4.18012142,  training time: 11.54
[473.5, 743.25, 922.5, 1160.0, 1313.75]
Episode 7	 reward: -13.44	 Mean_loss: 3.09386253,  training time: 11.53
[497.5, 709.25, 929.5, 1132.0, 1351.5]
Episode 8	 reward: -13.44	 Mean_loss: 3.29218197,  training time: 11.53
[485.5, 755.0, 918.5, 1200.75, 1390.5]
Episode 9	 reward: -14.34	 Mean_loss: 3.92076421,  training time: 11.54
[461.5, 786.5, 912.5, 1240.75, 1334.75]
Episode 10	 reward: -13.57	 Mean_loss: 3.22211170,  training time: 11.52
[483.0, 720.0, 889.25, 1175.75, 1293.5]
Episode 11	 reward: -14.37	 Mean_loss: 2.98532224,  training time: 11.54
[492.75, 723.0, 854.5, 1232.5, 1355.25]
Episode 12	 reward: -13.98	 Mean_loss: 3.43281126,  training time: 11.53
[420.75, 728.75, 901.25, 1228.0, 1396.0]
Episode 13	 reward: -13.15	 Mean_loss: 3.68879652,  training time: 11.54
[464.75, 712.75, 927.75, 1162.25, 1320.25]
Episode 14	 reward: -13.16	 Mean_loss: 3.16826344,  training time: 11.52
[474.5, 660.5, 907.75, 1226.75, 1370.0]
Episode 15	 reward: -14.78	 Mean_loss: 3.62929511,  training time: 11.53
[526.5, 761.25, 923.5, 1192.25, 1366.0]
Episode 16	 reward: -13.36	 Mean_loss: 3.37331915,  training time: 11.48
[456.25, 780.0, 969.75, 1238.25, 1300.75]
Episode 17	 reward: -12.68	 Mean_loss: 3.04072380,  training time: 11.45
[519.75, 691.0, 900.0, 1267.75, 1382.0]
Episode 18	 reward: -14.28	 Mean_loss: 3.52534962,  training time: 11.42
[471.0, 748.0, 899.75, 1135.5, 1339.25]
Episode 19	 reward: -14.17	 Mean_loss: 3.29685736,  training time: 11.45
[492.75, 681.75, 955.0, 1163.0, 1362.0]
Episode 20	 reward: -14.29	 Mean_loss: 3.32945704,  training time: 11.45
[509.0, 821.25, 995.5, 1267.25, 1426.75]
Episode 21	 reward: -14.07	 Mean_loss: 3.85511422,  training time: 11.50
[465.0, 735.25, 942.75, 1189.5, 1371.75]
Episode 22	 reward: -13.12	 Mean_loss: 3.38576841,  training time: 11.48
[458.25, 764.25, 944.5, 1142.75, 1386.0]
Episode 23	 reward: -14.19	 Mean_loss: 3.40297008,  training time: 11.48
[457.25, 739.5, 977.75, 1088.25, 1350.25]
Episode 24	 reward: -14.02	 Mean_loss: 3.23981357,  training time: 11.53
[482.25, 688.5, 986.5, 1145.25, 1470.5]
Episode 25	 reward: -14.10	 Mean_loss: 4.24629736,  training time: 11.47
[436.25, 721.75, 986.0, 1156.0, 1343.0]
Episode 26	 reward: -13.62	 Mean_loss: 3.08502412,  training time: 11.49
[457.5, 777.0, 955.75, 1139.0, 1398.75]
Episode 27	 reward: -13.65	 Mean_loss: 3.78120947,  training time: 11.48
[455.0, 783.5, 967.5, 1184.5, 1333.5]
Episode 28	 reward: -13.32	 Mean_loss: 3.16025758,  training time: 11.48
[458.5, 823.5, 947.75, 1091.75, 1381.5]
Episode 29	 reward: -13.29	 Mean_loss: 3.48611283,  training time: 11.60
[515.25, 741.25, 960.75, 1162.0, 1329.25]
Episode 30	 reward: -13.62	 Mean_loss: 3.15717459,  training time: 11.51
[525.0, 764.5, 967.75, 1144.5, 1324.75]
Episode 31	 reward: -13.76	 Mean_loss: 2.99575520,  training time: 11.50
[449.0, 766.25, 1028.5, 1128.0, 1323.75]
Episode 32	 reward: -14.30	 Mean_loss: 3.26628542,  training time: 11.52
[522.75, 778.5, 994.25, 1125.0, 1378.5]
Episode 33	 reward: -13.16	 Mean_loss: 3.38159442,  training time: 11.51
[534.0, 689.75, 971.75, 1125.5, 1433.25]
Episode 34	 reward: -13.33	 Mean_loss: 3.88626480,  training time: 11.50
[463.0, 753.25, 958.75, 1124.5, 1334.25]
Episode 35	 reward: -13.00	 Mean_loss: 3.05319238,  training time: 11.51
[488.25, 787.0, 962.5, 1113.25, 1369.75]
Episode 36	 reward: -14.25	 Mean_loss: 3.27527785,  training time: 11.48
[471.75, 808.25, 1002.25, 1085.0, 1394.75]
Episode 37	 reward: -13.23	 Mean_loss: 3.62599754,  training time: 11.51
[453.25, 772.0, 946.25, 1115.75, 1369.75]
Episode 38	 reward: -14.09	 Mean_loss: 3.16584516,  training time: 11.48
[498.75, 751.0, 1059.0, 1118.25, 1284.5]
Episode 39	 reward: -14.21	 Mean_loss: 2.52738905,  training time: 11.49
[514.25, 764.0, 930.75, 1191.0, 1345.0]
Episode 40	 reward: -13.48	 Mean_loss: 3.10792375,  training time: 11.52
[502.5, 745.0, 928.25, 1215.5, 1337.0]
Episode 41	 reward: -12.99	 Mean_loss: 3.24582195,  training time: 11.56
[523.25, 731.25, 951.5, 1175.0, 1247.25]
Episode 42	 reward: -13.03	 Mean_loss: 2.46412921,  training time: 11.54
[493.5, 700.0, 963.0, 1182.75, 1350.75]
Episode 43	 reward: -13.42	 Mean_loss: 3.22260690,  training time: 11.53
[517.5, 681.5, 904.0, 1163.5, 1371.0]
Episode 44	 reward: -14.09	 Mean_loss: 3.31244731,  training time: 11.51
[511.25, 719.0, 909.5, 1168.25, 1386.25]
Episode 45	 reward: -13.17	 Mean_loss: 3.50970602,  training time: 11.53
[462.0, 713.75, 956.75, 1156.25, 1288.25]
Episode 46	 reward: -13.17	 Mean_loss: 2.79076886,  training time: 11.51
[530.0, 708.0, 899.25, 1201.5, 1376.5]
Episode 47	 reward: -13.51	 Mean_loss: 3.43782783,  training time: 11.56
[473.25, 734.5, 888.75, 1142.25, 1338.25]
Episode 48	 reward: -13.62	 Mean_loss: 3.22249818,  training time: 11.63
[514.25, 784.0, 925.5, 1139.0, 1314.25]
Episode 49	 reward: -13.40	 Mean_loss: 2.85609651,  training time: 11.55
[481.0, 738.5, 928.5, 1153.25, 1257.0]
Episode 50	 reward: -13.56	 Mean_loss: 2.44667339,  training time: 11.54
[481.5, 737.0, 927.75, 1204.0, 1272.75]
Episode 51	 reward: -13.29	 Mean_loss: 2.62281060,  training time: 11.56
[462.75, 753.25, 912.5, 1109.25, 1266.75]
Episode 52	 reward: -13.48	 Mean_loss: 2.68029237,  training time: 11.56
[494.5, 780.5, 913.0, 1060.0, 1321.5]
Episode 53	 reward: -13.30	 Mean_loss: 2.88612223,  training time: 11.53
[534.75, 735.25, 888.75, 1187.5, 1322.0]
Episode 54	 reward: -13.21	 Mean_loss: 3.05748606,  training time: 11.55
[497.25, 748.0, 882.75, 1108.25, 1289.0]
Episode 55	 reward: -12.92	 Mean_loss: 2.60049152,  training time: 11.52
[547.5, 710.0, 916.0, 1196.75, 1291.5]
Episode 56	 reward: -13.42	 Mean_loss: 2.79106951,  training time: 11.56
[448.25, 694.75, 890.25, 1075.5, 1318.5]
Episode 57	 reward: -13.20	 Mean_loss: 2.77138376,  training time: 11.54
[436.75, 725.75, 930.75, 1127.75, 1325.75]
Episode 58	 reward: -13.05	 Mean_loss: 2.87096715,  training time: 11.59
[477.0, 699.0, 924.0, 1164.5, 1318.75]
Episode 59	 reward: -13.23	 Mean_loss: 2.93675351,  training time: 11.39
[534.75, 773.5, 854.75, 1129.25, 1317.25]
Episode 60	 reward: -14.09	 Mean_loss: 2.88446379,  training time: 11.45
[479.75, 712.25, 897.0, 1152.5, 1417.0]
Episode 61	 reward: -13.71	 Mean_loss: 3.02429509,  training time: 11.52
[485.5, 746.0, 905.0, 1188.0, 1459.75]
Episode 62	 reward: -14.44	 Mean_loss: 3.36144829,  training time: 11.42
[523.75, 681.0, 799.5, 1199.5, 1418.0]
Episode 63	 reward: -14.72	 Mean_loss: 2.88910937,  training time: 11.47
[459.5, 785.0, 872.5, 1202.0, 1382.75]
Episode 64	 reward: -14.52	 Mean_loss: 2.79497528,  training time: 11.45
[484.0, 710.75, 855.0, 1209.75, 1369.25]
Episode 65	 reward: -14.85	 Mean_loss: 2.60956788,  training time: 11.43
[480.5, 686.5, 876.25, 1130.0, 1340.75]
Episode 66	 reward: -14.30	 Mean_loss: 2.52767611,  training time: 11.43
[464.0, 713.25, 950.25, 1193.75, 1420.0]
Episode 67	 reward: -14.96	 Mean_loss: 2.96820569,  training time: 11.44
[510.5, 719.75, 866.5, 1177.25, 1357.25]
Episode 68	 reward: -14.35	 Mean_loss: 2.63584018,  training time: 11.46
[467.25, 736.25, 865.0, 1167.0, 1320.0]
Episode 69	 reward: -13.70	 Mean_loss: 2.20319891,  training time: 11.45
[442.0, 731.5, 835.25, 1147.75, 1403.75]
Episode 70	 reward: -14.59	 Mean_loss: 2.82912207,  training time: 11.74
[462.75, 707.5, 821.25, 1172.75, 1405.75]
Episode 71	 reward: -13.99	 Mean_loss: 2.94023418,  training time: 11.63
[474.5, 787.75, 830.25, 1139.75, 1328.5]
Episode 72	 reward: -14.04	 Mean_loss: 2.36779642,  training time: 11.65
[456.0, 795.75, 813.5, 1137.75, 1377.5]
Episode 73	 reward: -14.86	 Mean_loss: 2.62656593,  training time: 11.72
[450.25, 727.25, 878.0, 1229.0, 1432.75]
Episode 74	 reward: -14.14	 Mean_loss: 3.08769011,  training time: 11.60
[473.75, 763.5, 875.25, 1250.75, 1434.25]
Episode 75	 reward: -13.92	 Mean_loss: 3.04321766,  training time: 11.60
[487.5, 758.75, 883.75, 1161.5, 1474.5]
Episode 76	 reward: -13.87	 Mean_loss: 3.07490039,  training time: 11.61
[435.75, 703.0, 863.0, 1158.75, 1388.0]
Episode 77	 reward: -14.11	 Mean_loss: 2.82316709,  training time: 11.62
[464.5, 740.25, 857.75, 1157.0, 1356.25]
Episode 78	 reward: -14.15	 Mean_loss: 2.64367795,  training time: 11.61
[455.5, 663.5, 881.0, 1198.75, 1444.75]
Episode 79	 reward: -13.88	 Mean_loss: 3.01653457,  training time: 11.63
[506.75, 685.0, 857.5, 1268.75, 1368.25]
Episode 80	 reward: -14.26	 Mean_loss: 2.45059991,  training time: 11.65
[465.0, 693.5, 908.25, 1107.0, 1240.75]
Episode 81	 reward: -13.61	 Mean_loss: 2.04985690,  training time: 11.65
[437.0, 653.25, 908.0, 1126.5, 1397.5]
Episode 82	 reward: -14.21	 Mean_loss: 3.10235667,  training time: 11.61
[482.5, 699.0, 898.0, 1179.5, 1387.25]
Episode 83	 reward: -13.58	 Mean_loss: 2.86002779,  training time: 11.66
[445.75, 672.5, 865.5, 1259.75, 1291.5]
Episode 84	 reward: -13.82	 Mean_loss: 2.30461907,  training time: 11.66
[460.0, 692.5, 947.0, 1150.75, 1284.0]
Episode 85	 reward: -14.08	 Mean_loss: 2.16292119,  training time: 11.64
[484.0, 644.5, 866.75, 1129.5, 1368.5]
Episode 86	 reward: -13.64	 Mean_loss: 2.67175698,  training time: 11.62
[429.0, 679.25, 878.5, 1176.25, 1296.25]
Episode 87	 reward: -13.52	 Mean_loss: 2.27481174,  training time: 11.64
[481.75, 732.5, 931.25, 1102.25, 1422.5]
Episode 88	 reward: -13.48	 Mean_loss: 2.96792841,  training time: 11.68
[468.5, 645.5, 959.75, 1176.5, 1278.25]
Episode 89	 reward: -14.30	 Mean_loss: 2.06430292,  training time: 11.64
[454.75, 640.5, 890.25, 1027.0, 1314.25]
Episode 90	 reward: -14.18	 Mean_loss: 2.28205538,  training time: 11.64
[468.5, 686.75, 869.5, 1161.5, 1372.0]
Episode 91	 reward: -14.15	 Mean_loss: 2.80381465,  training time: 11.67
[453.0, 635.5, 928.75, 1121.5, 1387.25]
Episode 92	 reward: -13.37	 Mean_loss: 2.76067305,  training time: 11.62
[475.5, 624.0, 885.75, 1201.5, 1376.25]
Episode 93	 reward: -13.96	 Mean_loss: 2.59698009,  training time: 11.67
[448.5, 682.75, 891.25, 1151.0, 1361.75]
Episode 94	 reward: -13.95	 Mean_loss: 2.38961601,  training time: 11.64
[476.5, 645.75, 902.0, 1077.75, 1367.0]
Episode 95	 reward: -13.99	 Mean_loss: 2.72823477,  training time: 11.71
[485.75, 653.25, 963.75, 1174.25, 1327.0]
Episode 96	 reward: -14.22	 Mean_loss: 2.14376211,  training time: 11.70
[452.75, 689.5, 943.0, 1240.25, 1366.5]
Episode 97	 reward: -14.41	 Mean_loss: 2.55680060,  training time: 11.75
[467.25, 653.75, 896.75, 1127.75, 1375.75]
Episode 98	 reward: -13.66	 Mean_loss: 2.51290870,  training time: 11.72
[534.0, 669.0, 886.75, 1139.0, 1336.0]
Episode 99	 reward: -13.21	 Mean_loss: 2.10854006,  training time: 11.69
[454.5, 623.25, 906.75, 1178.0, 1374.0]
Episode 100	 reward: -13.81	 Mean_loss: 2.30515718,  training time: 11.71
[549.5, 729.5, 923.75, 1100.25, 1371.0]
Episode 101	 reward: -14.00	 Mean_loss: 2.26051307,  training time: 11.77
[543.0, 706.75, 947.0, 1179.0, 1383.25]
Episode 102	 reward: -13.90	 Mean_loss: 2.28363252,  training time: 11.68
[497.75, 680.75, 887.5, 1058.0, 1374.75]
Episode 103	 reward: -14.02	 Mean_loss: 1.99155986,  training time: 11.62
[511.5, 690.0, 976.5, 1162.0, 1350.5]
Episode 104	 reward: -13.47	 Mean_loss: 1.83350658,  training time: 11.66
[498.5, 691.5, 878.75, 1102.5, 1378.75]
Episode 105	 reward: -14.09	 Mean_loss: 2.13098025,  training time: 11.76
[517.0, 730.5, 906.5, 1026.0, 1422.5]
Episode 106	 reward: -13.98	 Mean_loss: 2.33716083,  training time: 11.62
[505.75, 709.0, 1021.5, 1145.0, 1376.25]
Episode 107	 reward: -13.48	 Mean_loss: 1.98460293,  training time: 11.65
[480.5, 776.75, 927.75, 1067.25, 1282.25]
Episode 108	 reward: -13.83	 Mean_loss: 1.53187895,  training time: 11.67
[495.5, 670.0, 922.75, 1113.5, 1360.25]
Episode 109	 reward: -14.35	 Mean_loss: 1.78262544,  training time: 11.64
[536.25, 735.75, 966.25, 1098.25, 1380.5]
Episode 110	 reward: -14.51	 Mean_loss: 2.12850738,  training time: 11.65
[524.5, 714.0, 974.5, 1105.5, 1359.25]
Episode 111	 reward: -13.66	 Mean_loss: 1.79117751,  training time: 11.65
[579.75, 689.5, 907.5, 1131.0, 1315.5]
Episode 112	 reward: -14.32	 Mean_loss: 1.61639774,  training time: 11.62
[543.0, 712.0, 941.5, 1107.25, 1427.0]
Episode 113	 reward: -14.31	 Mean_loss: 2.15478969,  training time: 11.61
[523.0, 743.5, 1052.5, 1162.0, 1337.5]
Episode 114	 reward: -14.53	 Mean_loss: 1.63739657,  training time: 11.67
[514.0, 655.75, 895.25, 1109.0, 1412.75]
Episode 115	 reward: -14.15	 Mean_loss: 1.96740043,  training time: 11.62
[504.0, 685.75, 880.75, 1124.0, 1474.0]
Episode 116	 reward: -14.11	 Mean_loss: 2.78861904,  training time: 11.67
[480.75, 740.0, 941.25, 1088.75, 1307.5]
Episode 117	 reward: -13.75	 Mean_loss: 1.33816171,  training time: 11.75
[563.25, 744.0, 919.5, 1110.5, 1387.0]
Episode 118	 reward: -13.46	 Mean_loss: 1.67539215,  training time: 11.63
[482.5, 630.0, 967.25, 1115.25, 1355.5]
Episode 119	 reward: -13.81	 Mean_loss: 1.68217123,  training time: 11.63
[515.5, 704.25, 939.0, 1087.0, 1383.0]
Episode 120	 reward: -13.81	 Mean_loss: 1.66742444,  training time: 11.65
[448.75, 741.25, 893.0, 1121.25, 1250.0]
Episode 121	 reward: -13.53	 Mean_loss: 1.05516005,  training time: 11.68
[406.25, 702.0, 930.0, 1115.25, 1263.25]
Episode 122	 reward: -13.20	 Mean_loss: 1.07900846,  training time: 11.66
[438.75, 682.0, 911.25, 1061.25, 1373.25]
Episode 123	 reward: -13.87	 Mean_loss: 1.53083789,  training time: 11.65
[458.0, 693.25, 883.75, 1130.75, 1230.5]
Episode 124	 reward: -13.41	 Mean_loss: 0.89388800,  training time: 11.62
[440.75, 692.75, 875.5, 1154.5, 1262.5]
Episode 125	 reward: -13.12	 Mean_loss: 0.96392334,  training time: 11.69
[444.5, 695.75, 962.0, 1059.75, 1229.5]
Episode 126	 reward: -13.58	 Mean_loss: 0.81430292,  training time: 11.67
[450.75, 694.25, 938.0, 1170.75, 1220.0]
Episode 127	 reward: -13.48	 Mean_loss: 0.87693942,  training time: 11.63
[442.0, 685.25, 930.0, 1094.0, 1285.5]
Episode 128	 reward: -13.31	 Mean_loss: 1.00158644,  training time: 11.63
[443.0, 650.5, 828.5, 1110.0, 1223.5]
Episode 129	 reward: -13.32	 Mean_loss: 0.78829336,  training time: 11.67
[443.75, 690.25, 898.5, 1106.75, 1310.25]
Episode 130	 reward: -13.64	 Mean_loss: 1.02982581,  training time: 11.63
[412.25, 676.25, 883.75, 1154.5, 1289.75]
Episode 131	 reward: -13.69	 Mean_loss: 1.00345016,  training time: 11.66
[438.25, 695.0, 962.5, 1160.5, 1256.5]
Episode 132	 reward: -13.22	 Mean_loss: 0.86652178,  training time: 11.65
[428.0, 645.0, 943.25, 1161.5, 1218.5]
Episode 133	 reward: -12.74	 Mean_loss: 0.73652887,  training time: 11.63
[456.75, 678.75, 870.5, 1126.5, 1317.25]
Episode 134	 reward: -13.47	 Mean_loss: 0.99022144,  training time: 11.67
[457.25, 729.75, 912.0, 1091.75, 1299.5]
Episode 135	 reward: -13.79	 Mean_loss: 0.91471726,  training time: 11.67
[453.0, 661.75, 944.25, 1115.75, 1271.0]
Episode 136	 reward: -13.11	 Mean_loss: 0.83707964,  training time: 11.65
[410.0, 714.75, 968.75, 1120.25, 1290.5]
Episode 137	 reward: -13.47	 Mean_loss: 0.93591392,  training time: 11.63
[432.25, 674.5, 933.25, 1140.0, 1254.5]
Episode 138	 reward: -12.90	 Mean_loss: 0.64923275,  training time: 11.63
[418.75, 640.75, 937.25, 1127.0, 1210.75]
Episode 139	 reward: -13.03	 Mean_loss: 0.62058818,  training time: 11.64
[451.75, 693.5, 977.25, 1139.5, 1370.0]
Episode 140	 reward: -13.46	 Mean_loss: 1.24071229,  training time: 11.66
[513.25, 724.25, 886.75, 1070.0, 1270.75]
Episode 141	 reward: -13.36	 Mean_loss: 0.86434042,  training time: 11.70
[519.0, 695.0, 876.5, 1104.5, 1237.75]
Episode 142	 reward: -13.55	 Mean_loss: 0.73658085,  training time: 11.68
[505.75, 745.75, 900.75, 1047.25, 1321.75]
Episode 143	 reward: -13.70	 Mean_loss: 1.01017165,  training time: 11.64
[504.5, 720.75, 873.0, 1109.0, 1332.25]
Episode 144	 reward: -13.73	 Mean_loss: 1.02893448,  training time: 11.63
[459.25, 662.25, 882.25, 1048.5, 1273.75]
Episode 145	 reward: -13.86	 Mean_loss: 0.79323059,  training time: 11.58
[477.5, 697.5, 920.5, 1082.75, 1327.0]
Episode 146	 reward: -12.79	 Mean_loss: 1.04039955,  training time: 11.59
[485.0, 677.25, 954.75, 1088.0, 1238.0]
Episode 147	 reward: -14.04	 Mean_loss: 0.72251356,  training time: 11.60
[460.75, 733.25, 868.75, 1116.0, 1255.5]
Episode 148	 reward: -12.99	 Mean_loss: 0.65384233,  training time: 11.59
[485.75, 716.75, 875.5, 1081.5, 1299.5]
Episode 149	 reward: -13.88	 Mean_loss: 0.82254529,  training time: 11.60
[473.5, 701.5, 859.25, 1040.5, 1323.75]
Episode 150	 reward: -13.05	 Mean_loss: 0.98615384,  training time: 11.67
[503.25, 707.25, 855.75, 1120.0, 1267.75]
Episode 151	 reward: -13.48	 Mean_loss: 0.68158662,  training time: 11.56
[475.75, 689.25, 840.0, 1044.25, 1263.75]
Episode 152	 reward: -13.65	 Mean_loss: 0.86990601,  training time: 11.58
[503.5, 659.5, 877.5, 1086.25, 1258.0]
Episode 153	 reward: -13.52	 Mean_loss: 0.63679832,  training time: 11.55
[484.25, 686.25, 857.75, 1079.5, 1255.0]
Episode 154	 reward: -13.29	 Mean_loss: 0.71787935,  training time: 11.58
[517.0, 705.75, 936.5, 1085.5, 1239.5]
Episode 155	 reward: -12.93	 Mean_loss: 0.52805567,  training time: 11.59
[481.5, 735.75, 908.75, 1036.5, 1319.5]
Episode 156	 reward: -14.60	 Mean_loss: 0.72836494,  training time: 11.63
[496.75, 704.0, 882.75, 1091.0, 1258.25]
Episode 157	 reward: -13.79	 Mean_loss: 0.58560991,  training time: 11.60
[464.75, 683.75, 864.75, 1060.5, 1279.75]
Episode 158	 reward: -13.74	 Mean_loss: 0.61538661,  training time: 11.60
[481.5, 707.5, 871.5, 1126.25, 1303.5]
Episode 159	 reward: -13.53	 Mean_loss: 0.75563532,  training time: 11.61
[490.5, 694.0, 904.0, 1053.25, 1261.75]
Episode 160	 reward: -14.26	 Mean_loss: 0.57254654,  training time: 11.56
[480.5, 655.25, 919.75, 1056.5, 1420.75]
Episode 161	 reward: -14.87	 Mean_loss: 1.08115768,  training time: 11.62
[478.25, 661.75, 896.0, 1054.5, 1330.25]
Episode 162	 reward: -14.31	 Mean_loss: 0.56586885,  training time: 11.58
[439.75, 639.25, 849.0, 1145.25, 1330.25]
Episode 163	 reward: -13.64	 Mean_loss: 0.71521509,  training time: 11.58
[494.5, 712.0, 907.25, 1045.75, 1382.5]
Episode 164	 reward: -14.44	 Mean_loss: 0.81497908,  training time: 11.57
[484.25, 647.25, 871.0, 1084.5, 1376.25]
Episode 165	 reward: -14.61	 Mean_loss: 0.79833734,  training time: 11.57
[458.5, 620.5, 842.5, 1092.5, 1427.25]
Episode 166	 reward: -14.18	 Mean_loss: 0.84111130,  training time: 11.58
[520.75, 631.0, 953.5, 1018.75, 1380.75]
Episode 167	 reward: -13.95	 Mean_loss: 0.77848685,  training time: 11.56
[450.75, 701.75, 900.75, 1100.0, 1435.75]
Episode 168	 reward: -15.03	 Mean_loss: 1.34434569,  training time: 11.57
[445.25, 678.0, 883.25, 1019.75, 1341.5]
Episode 169	 reward: -13.47	 Mean_loss: 0.59020108,  training time: 11.61
[501.0, 680.25, 887.75, 1059.0, 1367.75]
Episode 170	 reward: -14.68	 Mean_loss: 0.63883907,  training time: 11.62
[520.0, 640.0, 850.5, 1062.75, 1351.0]
Episode 171	 reward: -14.30	 Mean_loss: 0.80382097,  training time: 11.60
[480.25, 656.25, 895.25, 1096.75, 1340.25]
Episode 172	 reward: -14.08	 Mean_loss: 0.73581618,  training time: 11.65
[468.25, 642.0, 872.5, 1038.5, 1353.75]
Episode 173	 reward: -14.66	 Mean_loss: 0.65679741,  training time: 11.67
[476.25, 677.5, 908.5, 1066.75, 1328.25]
Episode 174	 reward: -14.20	 Mean_loss: 0.50480318,  training time: 11.63
[466.0, 633.75, 883.25, 1078.0, 1409.25]
Episode 175	 reward: -14.26	 Mean_loss: 0.81919688,  training time: 11.69
[442.5, 773.25, 892.5, 989.5, 1454.75]
Episode 176	 reward: -14.05	 Mean_loss: 0.73409760,  training time: 11.64
[445.75, 672.0, 925.75, 1053.75, 1411.5]
Episode 177	 reward: -14.98	 Mean_loss: 0.87171358,  training time: 11.63
[454.0, 706.5, 900.25, 1047.5, 1304.25]
Episode 178	 reward: -14.51	 Mean_loss: 0.63354760,  training time: 11.71
[416.5, 691.0, 891.25, 1020.75, 1328.25]
Episode 179	 reward: -14.31	 Mean_loss: 0.59073228,  training time: 11.63
[455.25, 686.5, 850.5, 969.0, 1362.5]
Episode 180	 reward: -14.38	 Mean_loss: 0.68451935,  training time: 11.66
[437.0, 654.75, 886.5, 1060.75, 1169.25]
Episode 181	 reward: -12.87	 Mean_loss: 0.40220645,  training time: 11.63
[486.5, 758.5, 849.5, 1112.25, 1275.5]
Episode 182	 reward: -13.20	 Mean_loss: 0.52227193,  training time: 11.63
[451.5, 745.0, 837.25, 1163.5, 1272.25]
Episode 183	 reward: -13.26	 Mean_loss: 0.51472682,  training time: 11.59
[421.25, 655.75, 890.25, 1128.5, 1249.75]
Episode 184	 reward: -13.31	 Mean_loss: 0.52913356,  training time: 11.57
[459.25, 673.75, 890.0, 1106.75, 1212.75]
Episode 185	 reward: -13.27	 Mean_loss: 0.42262051,  training time: 11.55
[464.25, 642.75, 843.0, 1152.75, 1266.25]
Episode 186	 reward: -13.30	 Mean_loss: 0.42049181,  training time: 11.57
[444.25, 689.75, 858.75, 1084.25, 1147.0]
Episode 187	 reward: -13.93	 Mean_loss: 0.26462609,  training time: 11.59
[480.0, 723.5, 842.5, 1106.75, 1224.25]
Episode 188	 reward: -13.36	 Mean_loss: 0.46588483,  training time: 11.59
[452.0, 683.75, 910.5, 1064.75, 1249.75]
Episode 189	 reward: -13.27	 Mean_loss: 0.57518899,  training time: 11.59
[478.5, 664.5, 843.25, 1056.25, 1196.75]
Episode 190	 reward: -13.81	 Mean_loss: 0.49929482,  training time: 11.57
[480.5, 694.75, 862.75, 1062.5, 1224.25]
Episode 191	 reward: -13.81	 Mean_loss: 0.56681776,  training time: 11.67
[465.75, 681.75, 815.0, 1106.25, 1310.25]
Episode 192	 reward: -13.21	 Mean_loss: 0.62328821,  training time: 11.66
[434.0, 630.75, 810.0, 1158.75, 1185.5]
Episode 193	 reward: -13.51	 Mean_loss: 0.45284158,  training time: 11.69
[445.5, 707.25, 797.0, 1133.25, 1270.25]
Episode 194	 reward: -12.87	 Mean_loss: 0.44511634,  training time: 11.64
[476.25, 759.0, 863.5, 1069.0, 1217.75]
Episode 195	 reward: -14.04	 Mean_loss: 0.42967266,  training time: 11.60
[450.75, 710.25, 794.75, 1147.75, 1256.5]
Episode 196	 reward: -12.44	 Mean_loss: 0.52281708,  training time: 11.60
[410.5, 739.75, 831.5, 1072.5, 1232.25]
Episode 197	 reward: -13.33	 Mean_loss: 0.63171077,  training time: 11.67
[478.75, 709.5, 908.25, 1068.0, 1262.25]
Episode 198	 reward: -13.40	 Mean_loss: 0.48566669,  training time: 11.55
[427.25, 629.75, 875.0, 1122.25, 1310.5]
Episode 199	 reward: -12.87	 Mean_loss: 0.70950115,  training time: 11.61
[432.5, 670.75, 866.75, 1129.0, 1214.25]
Episode 200	 reward: -12.56	 Mean_loss: 0.40006670,  training time: 11.59
[464.0, 684.5, 914.75, 1072.75, 1338.75]
Episode 201	 reward: -13.62	 Mean_loss: 0.58011478,  training time: 11.61
[444.0, 655.5, 887.0, 1084.5, 1302.5]
Episode 202	 reward: -13.45	 Mean_loss: 0.55674982,  training time: 11.59
[511.5, 663.75, 919.75, 1059.5, 1342.75]
Episode 203	 reward: -13.90	 Mean_loss: 0.54635394,  training time: 11.58
[458.25, 666.25, 870.25, 1015.25, 1308.25]
Episode 204	 reward: -13.80	 Mean_loss: 0.54512829,  training time: 11.59
[540.75, 751.25, 937.25, 1067.0, 1323.5]
Episode 205	 reward: -14.14	 Mean_loss: 0.56225187,  training time: 11.62
[493.5, 666.25, 913.25, 1063.75, 1326.5]
Episode 206	 reward: -13.40	 Mean_loss: 0.49963510,  training time: 11.62
[490.75, 688.25, 906.0, 1063.0, 1340.5]
Episode 207	 reward: -13.99	 Mean_loss: 0.48150495,  training time: 11.58
[512.75, 735.0, 853.0, 1109.0, 1372.5]
Episode 208	 reward: -13.56	 Mean_loss: 0.69272149,  training time: 11.59
[461.75, 703.5, 850.75, 1054.5, 1329.5]
Episode 209	 reward: -14.44	 Mean_loss: 0.61588526,  training time: 11.69
[490.75, 692.0, 892.25, 1034.75, 1307.75]
Episode 210	 reward: -13.63	 Mean_loss: 0.51759350,  training time: 11.66
[453.0, 681.0, 920.25, 1069.75, 1261.0]
Episode 211	 reward: -13.91	 Mean_loss: 0.44743553,  training time: 11.59
[458.25, 660.0, 859.5, 1070.25, 1343.5]
Episode 212	 reward: -13.89	 Mean_loss: 0.55528527,  training time: 11.54
[454.25, 652.75, 976.75, 999.25, 1310.5]
Episode 213	 reward: -13.74	 Mean_loss: 0.47508433,  training time: 11.55
[502.5, 676.5, 908.25, 997.5, 1348.0]
Episode 214	 reward: -13.77	 Mean_loss: 0.67007196,  training time: 11.56
[475.75, 715.0, 894.75, 1081.75, 1345.0]
Episode 215	 reward: -14.54	 Mean_loss: 0.60227048,  training time: 11.54
[478.75, 706.75, 864.5, 1075.75, 1320.5]
Episode 216	 reward: -14.26	 Mean_loss: 0.54044902,  training time: 11.56
[457.25, 702.5, 921.25, 1076.5, 1276.5]
Episode 217	 reward: -14.70	 Mean_loss: 0.55892295,  training time: 11.58
[466.75, 665.75, 897.25, 1049.0, 1277.25]
Episode 218	 reward: -14.87	 Mean_loss: 0.33379143,  training time: 11.52
[489.5, 803.75, 878.25, 1025.0, 1313.0]
Episode 219	 reward: -14.02	 Mean_loss: 0.61456501,  training time: 11.58
[520.0, 627.0, 910.25, 1075.5, 1301.25]
Episode 220	 reward: -14.19	 Mean_loss: 0.52876532,  training time: 11.61
[485.5, 694.5, 924.0, 973.0, 1296.5]
Episode 221	 reward: -13.30	 Mean_loss: 0.41244063,  training time: 11.66
[511.75, 671.25, 903.75, 1051.0, 1227.25]
Episode 222	 reward: -13.11	 Mean_loss: 0.41351628,  training time: 11.66
[484.75, 688.25, 857.0, 1128.5, 1316.5]
Episode 223	 reward: -12.80	 Mean_loss: 0.60795861,  training time: 11.54
[479.25, 718.75, 843.75, 1025.75, 1174.5]
Episode 224	 reward: -13.19	 Mean_loss: 0.31327620,  training time: 11.55
[534.5, 759.75, 926.0, 1049.5, 1243.25]
Episode 225	 reward: -13.04	 Mean_loss: 0.49597728,  training time: 11.56
[459.5, 703.5, 892.75, 1142.25, 1230.75]
Episode 226	 reward: -13.27	 Mean_loss: 0.43957034,  training time: 11.59
[441.5, 692.75, 923.75, 1095.25, 1177.0]
Episode 227	 reward: -14.00	 Mean_loss: 0.41188121,  training time: 11.53
[495.0, 705.0, 908.5, 1070.75, 1239.75]
Episode 228	 reward: -14.02	 Mean_loss: 0.33877647,  training time: 11.55
[476.75, 684.75, 967.0, 1131.25, 1211.5]
Episode 229	 reward: -12.77	 Mean_loss: 0.35238388,  training time: 11.56
[479.5, 698.0, 854.5, 1087.25, 1246.5]
Episode 230	 reward: -12.91	 Mean_loss: 0.48751828,  training time: 11.58
[529.75, 734.0, 914.75, 992.75, 1228.5]
Episode 231	 reward: -13.40	 Mean_loss: 0.26759803,  training time: 11.53
[488.25, 671.25, 869.25, 1014.5, 1294.0]
Episode 232	 reward: -13.50	 Mean_loss: 0.57486975,  training time: 11.54
[499.25, 715.0, 943.75, 1094.5, 1284.25]
Episode 233	 reward: -12.90	 Mean_loss: 0.44956568,  training time: 11.55
[479.75, 684.25, 934.0, 1097.0, 1258.5]
Episode 234	 reward: -13.69	 Mean_loss: 0.49021664,  training time: 11.55
[471.0, 697.0, 946.0, 1102.75, 1197.25]
Episode 235	 reward: -12.79	 Mean_loss: 0.37389785,  training time: 11.54
[497.25, 692.5, 910.75, 1049.5, 1215.0]
Episode 236	 reward: -12.69	 Mean_loss: 0.30887863,  training time: 11.55
[474.25, 731.75, 901.75, 1106.75, 1177.0]
Episode 237	 reward: -13.01	 Mean_loss: 0.29255325,  training time: 11.56
[494.0, 690.75, 879.75, 1103.5, 1205.75]
Episode 238	 reward: -13.02	 Mean_loss: 0.33355397,  training time: 11.59
[499.75, 707.25, 907.5, 1039.5, 1219.5]
Episode 239	 reward: -12.91	 Mean_loss: 0.43143746,  training time: 11.58
[449.25, 728.25, 871.0, 1039.75, 1208.0]
Episode 240	 reward: -13.46	 Mean_loss: 0.30782327,  training time: 11.56
[475.75, 675.0, 908.25, 1213.75, 1264.75]
Episode 241	 reward: -13.69	 Mean_loss: 0.54953539,  training time: 11.75
[532.0, 683.5, 933.0, 1181.0, 1228.0]
Episode 242	 reward: -13.39	 Mean_loss: 0.36929154,  training time: 11.60
[479.0, 653.75, 897.5, 1074.25, 1319.5]
Episode 243	 reward: -13.33	 Mean_loss: 0.50587362,  training time: 11.67
[494.0, 637.5, 929.0, 1111.75, 1227.75]
Episode 244	 reward: -13.71	 Mean_loss: 0.45950383,  training time: 11.66
[475.0, 687.25, 931.5, 1193.75, 1282.25]
Episode 245	 reward: -13.36	 Mean_loss: 0.41704315,  training time: 11.60
[547.0, 664.0, 894.5, 1147.25, 1197.25]
Episode 246	 reward: -13.21	 Mean_loss: 0.50654715,  training time: 11.56
[443.0, 647.5, 895.0, 1132.25, 1320.75]
Episode 247	 reward: -12.89	 Mean_loss: 0.49993029,  training time: 11.59
[486.5, 646.0, 886.5, 1102.5, 1198.25]
Episode 248	 reward: -13.65	 Mean_loss: 0.36609986,  training time: 11.62
[522.0, 659.0, 903.25, 1081.75, 1382.75]
Episode 249	 reward: -14.05	 Mean_loss: 1.09292054,  training time: 11.53
[565.0, 630.0, 868.75, 1046.0, 1265.0]
Episode 250	 reward: -13.38	 Mean_loss: 0.48221305,  training time: 11.56
[493.5, 644.5, 889.0, 1030.75, 1254.75]
Episode 251	 reward: -13.83	 Mean_loss: 0.37559617,  training time: 11.56
[522.0, 607.5, 887.25, 1132.5, 1238.75]
Episode 252	 reward: -13.24	 Mean_loss: 0.51291651,  training time: 11.64
[484.75, 688.75, 914.0, 1086.5, 1191.0]
Episode 253	 reward: -13.60	 Mean_loss: 0.36777198,  training time: 11.62
[510.0, 631.25, 899.0, 1039.5, 1279.5]
Episode 254	 reward: -13.32	 Mean_loss: 0.46651632,  training time: 11.65
[492.25, 645.0, 848.5, 1077.75, 1222.5]
Episode 255	 reward: -13.86	 Mean_loss: 0.41124836,  training time: 11.65
[506.0, 660.0, 889.0, 1079.75, 1301.0]
Episode 256	 reward: -13.87	 Mean_loss: 0.67395091,  training time: 11.62
[560.25, 653.5, 969.5, 1119.5, 1246.75]
Episode 257	 reward: -13.30	 Mean_loss: 0.32777560,  training time: 11.64
[493.75, 625.25, 898.5, 1012.0, 1162.25]
Episode 258	 reward: -13.82	 Mean_loss: 0.35769719,  training time: 11.53
[556.25, 681.25, 889.25, 1134.25, 1225.0]
Episode 259	 reward: -13.28	 Mean_loss: 0.40867847,  training time: 11.55
[532.25, 636.0, 854.75, 1125.75, 1187.5]
Episode 260	 reward: -13.93	 Mean_loss: 0.32845518,  training time: 11.57
[504.0, 679.5, 911.0, 982.5, 1255.25]
Episode 261	 reward: -13.78	 Mean_loss: 0.40100768,  training time: 11.61
[443.25, 709.75, 861.5, 1139.0, 1287.75]
Episode 262	 reward: -13.76	 Mean_loss: 0.55355978,  training time: 11.54
[476.75, 649.75, 882.5, 1040.75, 1273.25]
Episode 263	 reward: -13.77	 Mean_loss: 0.37529266,  training time: 11.52
[468.75, 620.25, 919.5, 991.5, 1261.0]
Episode 264	 reward: -14.32	 Mean_loss: 0.46935248,  training time: 11.52
[465.5, 677.25, 879.5, 1028.0, 1252.75]
Episode 265	 reward: -13.68	 Mean_loss: 0.43418288,  training time: 11.52
[424.0, 699.25, 863.0, 999.25, 1292.75]
Episode 266	 reward: -13.23	 Mean_loss: 0.48876712,  training time: 11.75
[471.75, 660.75, 909.75, 959.5, 1305.0]
Episode 267	 reward: -14.24	 Mean_loss: 0.64943111,  training time: 11.62
[405.25, 672.75, 822.0, 982.5, 1248.25]
Episode 268	 reward: -14.30	 Mean_loss: 0.43460324,  training time: 11.66
[479.25, 630.5, 877.0, 1052.75, 1310.0]
Episode 269	 reward: -13.52	 Mean_loss: 0.52556556,  training time: 11.68
[450.75, 625.75, 873.25, 1026.5, 1258.5]
Episode 270	 reward: -13.40	 Mean_loss: 0.40492111,  training time: 11.63
[489.0, 632.0, 896.75, 994.5, 1251.0]
Episode 271	 reward: -13.66	 Mean_loss: 0.41866350,  training time: 11.63
[458.0, 641.75, 864.75, 1007.75, 1297.75]
Episode 272	 reward: -14.15	 Mean_loss: 0.51204282,  training time: 11.63
[427.25, 593.25, 914.25, 962.5, 1292.0]
Episode 273	 reward: -14.37	 Mean_loss: 0.50636840,  training time: 11.63
[418.0, 620.5, 861.75, 1055.0, 1227.75]
Episode 274	 reward: -13.29	 Mean_loss: 0.33662662,  training time: 11.63
[440.0, 655.5, 883.25, 1094.25, 1270.75]
Episode 275	 reward: -14.05	 Mean_loss: 0.51333708,  training time: 11.65
[459.5, 646.0, 859.75, 961.5, 1303.75]
Episode 276	 reward: -13.62	 Mean_loss: 0.67179334,  training time: 11.60
[437.25, 736.5, 839.75, 1018.5, 1331.75]
Episode 277	 reward: -13.97	 Mean_loss: 0.48210922,  training time: 11.65
[407.75, 669.75, 865.75, 1066.0, 1259.75]
Episode 278	 reward: -14.13	 Mean_loss: 0.43640661,  training time: 11.65
[468.0, 669.0, 924.25, 1037.25, 1249.5]
Episode 279	 reward: -13.84	 Mean_loss: 0.40096372,  training time: 11.66
[443.25, 641.75, 906.25, 1024.25, 1279.25]
Episode 280	 reward: -13.86	 Mean_loss: 0.53995872,  training time: 11.65
[451.0, 700.25, 871.75, 1056.25, 1235.0]
Episode 281	 reward: -13.56	 Mean_loss: 0.47200897,  training time: 11.67
[452.5, 737.75, 855.0, 1068.75, 1274.0]
Episode 282	 reward: -13.46	 Mean_loss: 0.48666757,  training time: 11.62
[452.5, 705.5, 880.75, 1116.75, 1244.75]
Episode 283	 reward: -13.85	 Mean_loss: 0.46027845,  training time: 11.57
[442.75, 698.5, 908.75, 1102.0, 1285.5]
Episode 284	 reward: -13.76	 Mean_loss: 0.54821134,  training time: 11.56
[471.25, 644.25, 882.0, 1152.75, 1239.25]
Episode 285	 reward: -13.83	 Mean_loss: 0.40179211,  training time: 11.61
[442.25, 675.25, 818.0, 1092.25, 1300.25]
Episode 286	 reward: -13.06	 Mean_loss: 0.43098053,  training time: 11.52
[430.25, 718.0, 883.0, 1086.75, 1267.5]
Episode 287	 reward: -13.82	 Mean_loss: 0.45575848,  training time: 11.56
[440.75, 692.0, 862.75, 1132.0, 1242.0]
Episode 288	 reward: -13.86	 Mean_loss: 0.36466607,  training time: 11.55
[492.0, 734.5, 837.25, 1129.0, 1228.25]
Episode 289	 reward: -13.84	 Mean_loss: 0.40240121,  training time: 11.52
[452.25, 689.25, 868.0, 1099.25, 1243.25]
Episode 290	 reward: -13.36	 Mean_loss: 0.36883965,  training time: 11.60
[419.75, 671.25, 840.5, 1093.5, 1227.0]
Episode 291	 reward: -13.51	 Mean_loss: 0.30829051,  training time: 11.44
[430.25, 734.5, 852.5, 1105.25, 1259.75]
Episode 292	 reward: -13.40	 Mean_loss: 0.46243569,  training time: 11.47
[456.0, 750.25, 881.75, 1146.0, 1253.0]
Episode 293	 reward: -13.49	 Mean_loss: 0.45600638,  training time: 11.46
[444.75, 729.75, 861.25, 1115.25, 1266.5]
Episode 294	 reward: -14.03	 Mean_loss: 0.55175835,  training time: 11.45
[474.0, 651.5, 898.5, 1054.5, 1250.5]
Episode 295	 reward: -14.49	 Mean_loss: 0.40184659,  training time: 11.49
[478.0, 706.0, 834.25, 1156.0, 1287.75]
Episode 296	 reward: -13.26	 Mean_loss: 0.47380468,  training time: 11.50
[453.0, 687.25, 861.75, 1111.75, 1265.25]
Episode 297	 reward: -14.08	 Mean_loss: 0.44854769,  training time: 11.48
[446.0, 663.0, 866.5, 1109.5, 1286.5]
Episode 298	 reward: -13.46	 Mean_loss: 0.52646184,  training time: 11.53
[476.25, 720.5, 850.75, 1168.5, 1288.75]
Episode 299	 reward: -13.10	 Mean_loss: 0.54557663,  training time: 11.47
[422.0, 724.25, 906.25, 1089.5, 1226.75]
Episode 300	 reward: -13.45	 Mean_loss: 0.35225609,  training time: 11.49
[460.25, 581.75, 887.25, 1079.25, 1275.5]
Episode 301	 reward: -13.98	 Mean_loss: 0.46181947,  training time: 11.53
[501.25, 640.0, 861.25, 1068.25, 1237.5]
Episode 302	 reward: -14.09	 Mean_loss: 0.37685141,  training time: 11.47
[481.25, 703.25, 973.75, 1017.5, 1275.75]
Episode 303	 reward: -13.68	 Mean_loss: 0.72130179,  training time: 11.50
[538.0, 573.25, 853.5, 1067.5, 1349.75]
Episode 304	 reward: -13.94	 Mean_loss: 0.55238307,  training time: 11.48
[547.0, 636.0, 883.5, 1084.75, 1327.75]
Episode 305	 reward: -14.46	 Mean_loss: 0.38097373,  training time: 11.52
[469.5, 611.75, 833.75, 1058.5, 1352.5]
Episode 306	 reward: -13.97	 Mean_loss: 0.48970890,  training time: 11.52
[513.75, 594.75, 876.75, 1093.75, 1310.25]
Episode 307	 reward: -13.64	 Mean_loss: 0.45234799,  training time: 11.49
[533.75, 645.25, 809.25, 1090.75, 1266.75]
Episode 308	 reward: -13.53	 Mean_loss: 0.66684514,  training time: 11.50
[522.5, 596.0, 903.5, 1063.5, 1327.75]
Episode 309	 reward: -14.16	 Mean_loss: 0.52418232,  training time: 11.53
[468.75, 628.5, 848.5, 1128.5, 1275.0]
Episode 310	 reward: -14.43	 Mean_loss: 0.44528499,  training time: 11.62
[447.25, 629.25, 854.75, 1093.25, 1254.5]
Episode 311	 reward: -13.99	 Mean_loss: 0.38091803,  training time: 11.50
[514.0, 582.0, 859.5, 1063.0, 1279.5]
Episode 312	 reward: -14.24	 Mean_loss: 0.53115785,  training time: 11.49
[481.0, 616.5, 874.5, 1102.75, 1296.75]
Episode 313	 reward: -13.57	 Mean_loss: 0.31679469,  training time: 11.52
[475.25, 595.0, 842.75, 1052.75, 1251.5]
Episode 314	 reward: -13.19	 Mean_loss: 0.22060467,  training time: 11.50
[445.75, 571.0, 863.25, 1115.25, 1327.5]
Episode 315	 reward: -14.05	 Mean_loss: 0.68133152,  training time: 11.51
[489.5, 655.75, 845.75, 1152.0, 1299.25]
Episode 316	 reward: -13.58	 Mean_loss: 0.49071422,  training time: 11.50
[473.5, 623.25, 874.0, 1087.25, 1293.25]
Episode 317	 reward: -13.84	 Mean_loss: 0.53106970,  training time: 11.49
[541.5, 632.5, 901.25, 1035.75, 1395.0]
Episode 318	 reward: -13.98	 Mean_loss: 0.89040691,  training time: 11.48
[500.25, 646.75, 843.5, 1068.0, 1213.75]
Episode 319	 reward: -13.97	 Mean_loss: 0.31250426,  training time: 11.48
[466.75, 570.25, 835.75, 1153.5, 1277.5]
Episode 320	 reward: -13.82	 Mean_loss: 0.36603433,  training time: 11.51
[505.5, 607.25, 802.5, 1080.75, 1246.25]
Episode 321	 reward: -14.81	 Mean_loss: 0.30883232,  training time: 11.51
[438.0, 617.0, 904.25, 1135.25, 1205.0]
Episode 322	 reward: -13.51	 Mean_loss: 0.31612098,  training time: 11.48
[467.75, 645.75, 839.5, 1107.5, 1239.5]
Episode 323	 reward: -14.45	 Mean_loss: 0.24374686,  training time: 11.51
[440.0, 647.25, 848.0, 1109.25, 1257.0]
Episode 324	 reward: -13.70	 Mean_loss: 0.43239531,  training time: 11.43
[472.75, 586.75, 852.5, 1042.25, 1284.25]
Episode 325	 reward: -13.48	 Mean_loss: 0.41858095,  training time: 11.50
[431.75, 593.5, 861.75, 1065.5, 1328.25]
Episode 326	 reward: -14.18	 Mean_loss: 0.49232799,  training time: 11.49
[510.0, 624.25, 848.0, 1018.25, 1366.5]
Episode 327	 reward: -14.15	 Mean_loss: 0.48465064,  training time: 11.51
[529.0, 628.0, 810.5, 1059.25, 1229.5]
Episode 328	 reward: -13.90	 Mean_loss: 0.43686327,  training time: 11.50
[499.0, 617.5, 786.25, 1047.5, 1288.25]
Episode 329	 reward: -14.33	 Mean_loss: 0.44445944,  training time: 11.46
[419.0, 638.25, 868.0, 1090.5, 1262.5]
Episode 330	 reward: -13.84	 Mean_loss: 0.28442118,  training time: 11.51
[420.0, 620.75, 845.75, 1087.75, 1258.5]
Episode 331	 reward: -13.78	 Mean_loss: 0.40510422,  training time: 11.49
[436.25, 642.0, 802.25, 1071.5, 1299.75]
Episode 332	 reward: -13.54	 Mean_loss: 0.47069553,  training time: 11.49
[462.75, 594.25, 826.25, 1069.5, 1297.75]
Episode 333	 reward: -14.77	 Mean_loss: 0.42886922,  training time: 11.50
[505.25, 628.75, 800.0, 1044.25, 1289.5]
Episode 334	 reward: -13.47	 Mean_loss: 0.34805167,  training time: 11.50
[434.25, 608.0, 803.0, 1096.0, 1190.0]
Episode 335	 reward: -13.47	 Mean_loss: 0.32474416,  training time: 11.49
[489.25, 596.25, 808.75, 1035.25, 1312.75]
Episode 336	 reward: -13.36	 Mean_loss: 0.54371482,  training time: 11.51
[482.25, 615.25, 826.25, 1006.75, 1263.5]
Episode 337	 reward: -14.24	 Mean_loss: 0.47321334,  training time: 11.49
[391.75, 637.5, 793.0, 1034.75, 1237.5]
Episode 338	 reward: -14.01	 Mean_loss: 0.43062377,  training time: 11.47
[443.25, 601.25, 826.25, 1068.0, 1195.0]
Episode 339	 reward: -14.19	 Mean_loss: 0.27388963,  training time: 11.51
[454.75, 614.0, 863.25, 1034.75, 1234.75]
Episode 340	 reward: -14.57	 Mean_loss: 0.37013680,  training time: 11.48
[442.0, 636.25, 925.75, 1033.25, 1322.0]
Episode 341	 reward: -13.72	 Mean_loss: 0.44952041,  training time: 11.55
[433.5, 610.5, 903.0, 1036.75, 1288.75]
Episode 342	 reward: -14.06	 Mean_loss: 0.28856295,  training time: 11.49
[446.0, 633.5, 934.5, 992.0, 1218.5]
Episode 343	 reward: -14.80	 Mean_loss: 0.25716379,  training time: 11.56
[460.25, 622.5, 925.0, 1023.5, 1359.25]
Episode 344	 reward: -13.35	 Mean_loss: 0.46237883,  training time: 11.47
[460.75, 651.25, 861.25, 1048.25, 1275.5]
Episode 345	 reward: -13.85	 Mean_loss: 0.38343933,  training time: 11.47
[445.0, 611.0, 911.0, 1090.25, 1277.75]
Episode 346	 reward: -14.44	 Mean_loss: 0.36907721,  training time: 11.50
[475.25, 658.5, 915.25, 1038.25, 1316.0]
Episode 347	 reward: -13.99	 Mean_loss: 0.29359916,  training time: 11.44
[462.5, 616.25, 889.0, 1036.0, 1268.75]
Episode 348	 reward: -14.34	 Mean_loss: 0.49357370,  training time: 11.49
[465.25, 613.75, 909.5, 1046.75, 1396.5]
Episode 349	 reward: -13.46	 Mean_loss: 0.59141678,  training time: 11.52
[491.0, 666.5, 969.5, 1049.25, 1284.0]
Episode 350	 reward: -13.78	 Mean_loss: 0.34195971,  training time: 11.51
[471.25, 647.75, 869.25, 1029.0, 1295.5]
Episode 351	 reward: -14.56	 Mean_loss: 0.36027375,  training time: 11.50
[469.0, 646.75, 904.0, 1047.25, 1334.0]
Episode 352	 reward: -14.23	 Mean_loss: 0.41661581,  training time: 11.50
[473.0, 635.25, 933.5, 1075.25, 1263.0]
Episode 353	 reward: -14.40	 Mean_loss: 0.34614235,  training time: 11.53
[504.75, 623.75, 858.5, 1068.25, 1267.0]
Episode 354	 reward: -13.59	 Mean_loss: 0.38407645,  training time: 11.50
[423.5, 650.0, 825.75, 1042.0, 1240.0]
Episode 355	 reward: -14.07	 Mean_loss: 0.31950656,  training time: 11.52
[442.0, 632.75, 828.0, 1097.25, 1249.75]
Episode 356	 reward: -13.64	 Mean_loss: 0.34577617,  training time: 11.53
[443.75, 623.75, 825.75, 1070.0, 1281.0]
Episode 357	 reward: -13.56	 Mean_loss: 0.36269990,  training time: 11.52
[487.25, 678.25, 934.25, 1083.25, 1265.25]
Episode 358	 reward: -14.02	 Mean_loss: 0.23760834,  training time: 11.49
[461.75, 671.5, 822.0, 1043.25, 1275.5]
Episode 359	 reward: -14.73	 Mean_loss: 0.38637030,  training time: 11.51
[475.5, 676.0, 934.0, 1003.25, 1205.5]
Episode 360	 reward: -14.57	 Mean_loss: 0.21180847,  training time: 11.48
[448.25, 621.5, 840.5, 976.5, 1374.25]
Episode 361	 reward: -13.64	 Mean_loss: 0.85864782,  training time: 11.58
[426.75, 732.0, 826.75, 1025.5, 1245.75]
Episode 362	 reward: -13.54	 Mean_loss: 0.46778649,  training time: 11.49
[461.0, 597.0, 873.25, 1081.25, 1208.25]
Episode 363	 reward: -14.68	 Mean_loss: 0.39395699,  training time: 11.51
[421.5, 678.5, 803.5, 1061.75, 1223.0]
Episode 364	 reward: -13.97	 Mean_loss: 0.51897484,  training time: 11.26
[381.75, 676.25, 857.25, 1014.0, 1243.75]
Episode 365	 reward: -14.04	 Mean_loss: 0.37533471,  training time: 11.31
[409.25, 631.0, 844.75, 1047.25, 1304.25]
Episode 366	 reward: -13.68	 Mean_loss: 0.56685966,  training time: 11.32
[404.0, 633.25, 815.5, 1020.75, 1288.0]
Episode 367	 reward: -13.51	 Mean_loss: 0.41783747,  training time: 11.31
[397.75, 660.75, 812.5, 1043.25, 1297.0]
Episode 368	 reward: -14.25	 Mean_loss: 0.44480520,  training time: 11.28
[430.0, 649.5, 877.0, 1112.5, 1303.0]
Episode 369	 reward: -13.65	 Mean_loss: 0.62397021,  training time: 11.30
[451.0, 629.0, 832.75, 1057.5, 1185.5]
Episode 370	 reward: -13.83	 Mean_loss: 0.20994839,  training time: 11.31
[468.25, 622.75, 827.25, 1037.75, 1240.5]
Episode 371	 reward: -13.42	 Mean_loss: 0.48197347,  training time: 11.37
[407.0, 659.75, 928.5, 991.5, 1233.25]
Episode 372	 reward: -13.92	 Mean_loss: 0.28428632,  training time: 11.26
[361.5, 696.0, 803.0, 968.75, 1240.25]
Episode 373	 reward: -13.30	 Mean_loss: 0.28645638,  training time: 11.25
[425.5, 643.25, 860.25, 1006.0, 1258.5]
Episode 374	 reward: -13.40	 Mean_loss: 0.44178224,  training time: 11.27
[418.0, 769.75, 830.0, 973.0, 1241.5]
Episode 375	 reward: -14.19	 Mean_loss: 0.45894581,  training time: 11.30
[401.0, 699.5, 816.25, 1039.5, 1285.25]
Episode 376	 reward: -13.86	 Mean_loss: 0.44521704,  training time: 11.30
[473.5, 641.0, 778.75, 1085.25, 1282.0]
Episode 377	 reward: -13.53	 Mean_loss: 0.53083694,  training time: 11.26
[399.25, 660.75, 812.0, 1046.0, 1291.25]
Episode 378	 reward: -13.84	 Mean_loss: 0.57224691,  training time: 11.29
[426.25, 616.75, 894.0, 1001.25, 1305.0]
Episode 379	 reward: -13.69	 Mean_loss: 0.75245720,  training time: 11.31
[405.0, 660.75, 823.5, 1035.5, 1257.75]
Episode 380	 reward: -14.15	 Mean_loss: 0.35362127,  training time: 11.37
[423.25, 730.25, 846.5, 1107.0, 1196.0]
Episode 381	 reward: -13.78	 Mean_loss: 0.33524427,  training time: 11.35
[494.25, 702.0, 835.0, 1067.25, 1146.5]
Episode 382	 reward: -12.82	 Mean_loss: 0.22330877,  training time: 11.31
[427.75, 750.25, 819.0, 1060.75, 1144.5]
Episode 383	 reward: -12.76	 Mean_loss: 0.27601802,  training time: 11.28
[455.75, 732.75, 822.75, 995.25, 1200.5]
Episode 384	 reward: -13.88	 Mean_loss: 0.30199200,  training time: 11.33
[462.25, 682.25, 868.75, 1092.75, 1205.75]
Episode 385	 reward: -13.27	 Mean_loss: 0.26558331,  training time: 11.34
[437.5, 672.0, 824.25, 1033.25, 1201.0]
Episode 386	 reward: -13.19	 Mean_loss: 0.27734190,  training time: 11.32
[449.75, 670.75, 846.25, 1115.75, 1291.5]
Episode 387	 reward: -13.39	 Mean_loss: 0.41912290,  training time: 11.32
[440.5, 687.5, 808.75, 1142.0, 1149.5]
Episode 388	 reward: -13.31	 Mean_loss: 0.22333805,  training time: 11.33
[444.25, 668.25, 745.25, 1063.5, 1165.75]
Episode 389	 reward: -13.23	 Mean_loss: 0.22490577,  training time: 11.32
[450.0, 640.5, 834.5, 1000.25, 1170.25]
Episode 390	 reward: -13.04	 Mean_loss: 0.19677894,  training time: 11.43
[485.5, 686.25, 804.0, 1085.0, 1230.5]
Episode 391	 reward: -13.58	 Mean_loss: 0.31977931,  training time: 11.33
[426.25, 749.5, 770.5, 1040.5, 1176.0]
Episode 392	 reward: -13.23	 Mean_loss: 0.29799709,  training time: 11.32
[442.75, 644.25, 792.0, 1074.5, 1119.75]
Episode 393	 reward: -13.19	 Mean_loss: 0.26591885,  training time: 11.30
[469.75, 677.5, 822.5, 1053.25, 1184.0]
Episode 394	 reward: -13.30	 Mean_loss: 0.26666856,  training time: 11.36
[470.0, 681.25, 810.5, 1096.0, 1144.25]
Episode 395	 reward: -12.64	 Mean_loss: 0.23665228,  training time: 11.32
[477.5, 675.75, 852.75, 1098.0, 1256.25]
Episode 396	 reward: -13.54	 Mean_loss: 0.46786931,  training time: 11.35
[432.0, 760.75, 929.75, 1071.75, 1209.25]
Episode 397	 reward: -13.15	 Mean_loss: 0.21604382,  training time: 11.32
[446.25, 717.25, 791.0, 1067.25, 1154.0]
Episode 398	 reward: -14.16	 Mean_loss: 0.25513288,  training time: 11.32
[452.25, 662.25, 804.0, 1125.25, 1249.75]
Episode 399	 reward: -12.76	 Mean_loss: 0.26573542,  training time: 11.35
[447.0, 693.5, 824.75, 1032.75, 1216.0]
Episode 400	 reward: -14.08	 Mean_loss: 0.25987083,  training time: 11.25
[451.75, 744.25, 857.5, 1066.75, 1236.25]
Episode 401	 reward: -13.73	 Mean_loss: 0.40906027,  training time: 11.29
[461.25, 703.75, 893.0, 1008.5, 1235.25]
Episode 402	 reward: -13.85	 Mean_loss: 0.48294210,  training time: 11.24
[446.25, 749.75, 801.0, 1043.75, 1182.5]
Episode 403	 reward: -14.17	 Mean_loss: 0.30647808,  training time: 11.29
[461.0, 662.5, 840.5, 1043.5, 1272.75]
Episode 404	 reward: -14.19	 Mean_loss: 0.54743975,  training time: 11.44
[447.75, 677.5, 840.25, 1040.0, 1247.5]
Episode 405	 reward: -13.59	 Mean_loss: 0.33513349,  training time: 11.48
[456.75, 726.25, 838.5, 1045.0, 1283.75]
Episode 406	 reward: -13.44	 Mean_loss: 0.42350054,  training time: 11.49
[501.5, 733.5, 873.75, 1111.25, 1226.5]
Episode 407	 reward: -14.72	 Mean_loss: 0.39475077,  training time: 11.49
[425.75, 745.5, 779.5, 982.5, 1303.5]
Episode 408	 reward: -14.13	 Mean_loss: 0.45449045,  training time: 11.47
[465.5, 701.75, 836.0, 1015.5, 1247.5]
Episode 409	 reward: -14.53	 Mean_loss: 0.41721743,  training time: 11.50
[518.75, 714.0, 842.0, 1068.25, 1244.0]
Episode 410	 reward: -14.46	 Mean_loss: 0.23541537,  training time: 11.55
[467.0, 657.0, 816.0, 1065.75, 1216.25]
Episode 411	 reward: -14.16	 Mean_loss: 0.32047927,  training time: 11.55
[458.25, 655.25, 866.0, 1019.75, 1241.75]
Episode 412	 reward: -14.41	 Mean_loss: 0.31160057,  training time: 11.55
[443.25, 684.5, 824.75, 1030.25, 1270.75]
Episode 413	 reward: -13.99	 Mean_loss: 0.48858061,  training time: 11.55
[470.75, 637.5, 843.25, 986.5, 1223.75]
Episode 414	 reward: -14.85	 Mean_loss: 0.40933624,  training time: 11.50
[480.75, 793.75, 808.75, 1091.25, 1279.25]
Episode 415	 reward: -14.08	 Mean_loss: 0.39563328,  training time: 11.56
[459.25, 646.5, 868.0, 1058.0, 1252.5]
Episode 416	 reward: -13.55	 Mean_loss: 0.34369507,  training time: 11.48
[447.75, 676.75, 850.25, 986.0, 1263.5]
Episode 417	 reward: -14.11	 Mean_loss: 0.47102806,  training time: 11.48
[499.5, 672.75, 850.0, 1061.0, 1251.75]
Episode 418	 reward: -13.56	 Mean_loss: 0.27176964,  training time: 11.44
[500.25, 711.0, 839.5, 1048.5, 1287.0]
Episode 419	 reward: -13.90	 Mean_loss: 0.39227340,  training time: 11.43
[462.75, 700.0, 784.25, 995.25, 1310.5]
Episode 420	 reward: -13.55	 Mean_loss: 0.45755568,  training time: 11.42
[446.25, 675.75, 903.25, 1020.0, 1283.5]
Episode 421	 reward: -13.88	 Mean_loss: 0.38312736,  training time: 11.56
[439.25, 636.0, 823.75, 1084.75, 1373.0]
Episode 422	 reward: -14.69	 Mean_loss: 0.73115724,  training time: 11.43
[520.25, 614.75, 838.25, 1058.5, 1279.5]
Episode 423	 reward: -14.06	 Mean_loss: 0.39659223,  training time: 11.44
[458.0, 666.0, 862.5, 1093.0, 1262.5]
Episode 424	 reward: -13.79	 Mean_loss: 0.41698480,  training time: 11.44
[497.75, 600.0, 861.0, 1056.0, 1240.0]
Episode 425	 reward: -14.35	 Mean_loss: 0.24702322,  training time: 11.43
[407.25, 627.5, 853.0, 1103.75, 1224.75]
Episode 426	 reward: -14.42	 Mean_loss: 0.33134663,  training time: 11.42
[494.0, 659.75, 866.25, 1073.75, 1244.0]
Episode 427	 reward: -13.29	 Mean_loss: 0.34486780,  training time: 11.42
[456.25, 627.5, 892.75, 1023.5, 1257.25]
Episode 428	 reward: -14.72	 Mean_loss: 0.32287130,  training time: 11.43
[464.0, 593.25, 806.25, 1043.25, 1274.75]
Episode 429	 reward: -13.68	 Mean_loss: 0.42795756,  training time: 11.42
[484.0, 607.25, 872.5, 1117.25, 1275.0]
Episode 430	 reward: -13.98	 Mean_loss: 0.31236532,  training time: 11.41
[482.75, 642.5, 848.5, 1051.5, 1255.0]
Episode 431	 reward: -14.30	 Mean_loss: 0.27641430,  training time: 11.41
[496.75, 592.25, 868.0, 1037.25, 1238.25]
Episode 432	 reward: -13.29	 Mean_loss: 0.36150390,  training time: 11.47
[514.25, 644.25, 890.25, 1055.25, 1341.0]
Episode 433	 reward: -14.07	 Mean_loss: 0.44674388,  training time: 11.44
[507.25, 615.75, 859.75, 1066.0, 1210.0]
Episode 434	 reward: -14.10	 Mean_loss: 0.32225242,  training time: 11.50
[450.25, 613.0, 887.25, 1021.5, 1250.0]
Episode 435	 reward: -13.96	 Mean_loss: 0.36590955,  training time: 11.38
[503.5, 639.5, 845.0, 1127.25, 1298.5]
Episode 436	 reward: -13.51	 Mean_loss: 0.47324163,  training time: 11.43
[477.0, 580.5, 879.75, 1059.25, 1277.5]
Episode 437	 reward: -14.38	 Mean_loss: 0.42524487,  training time: 11.41
[507.5, 611.75, 894.75, 1014.75, 1271.0]
Episode 438	 reward: -14.43	 Mean_loss: 0.32957372,  training time: 11.43
[428.5, 654.0, 835.5, 1026.5, 1254.5]
Episode 439	 reward: -14.14	 Mean_loss: 0.35365760,  training time: 11.45
[412.0, 626.0, 857.5, 1117.0, 1264.5]
Episode 440	 reward: -13.80	 Mean_loss: 0.41906315,  training time: 11.42
[464.0, 666.75, 776.25, 1076.5, 1254.75]
Episode 441	 reward: -13.50	 Mean_loss: 0.23686662,  training time: 11.49
[446.5, 666.0, 801.0, 1061.0, 1190.0]
Episode 442	 reward: -13.50	 Mean_loss: 0.19896401,  training time: 11.42
[444.25, 699.25, 806.0, 1056.75, 1203.75]
Episode 443	 reward: -13.50	 Mean_loss: 0.23380700,  training time: 11.44
[454.0, 614.75, 829.75, 1096.75, 1263.75]
Episode 444	 reward: -13.34	 Mean_loss: 0.28044602,  training time: 11.42
[509.0, 679.25, 828.5, 1102.25, 1218.5]
Episode 445	 reward: -13.03	 Mean_loss: 0.17905742,  training time: 11.43
[442.5, 730.75, 909.25, 1022.5, 1321.0]
Episode 446	 reward: -14.24	 Mean_loss: 0.48987779,  training time: 11.47
[452.5, 732.0, 817.5, 1101.75, 1232.25]
Episode 447	 reward: -13.33	 Mean_loss: 0.33476311,  training time: 11.41
[446.5, 625.5, 786.25, 1082.5, 1271.75]
Episode 448	 reward: -13.86	 Mean_loss: 0.32091543,  training time: 11.45
[528.0, 632.75, 808.75, 1028.0, 1247.75]
Episode 449	 reward: -13.37	 Mean_loss: 0.33461168,  training time: 11.42
[467.25, 703.25, 831.75, 1055.5, 1230.0]
Episode 450	 reward: -14.21	 Mean_loss: 0.30881235,  training time: 11.45
[469.75, 667.5, 794.5, 1042.25, 1244.5]
Episode 451	 reward: -13.78	 Mean_loss: 0.39803225,  training time: 11.46
[435.75, 704.75, 788.25, 1015.5, 1242.75]
Episode 452	 reward: -13.86	 Mean_loss: 0.36951095,  training time: 11.46
[431.0, 685.75, 821.75, 1059.0, 1265.0]
Episode 453	 reward: -13.54	 Mean_loss: 0.38734445,  training time: 11.46
[447.25, 658.75, 762.5, 1098.25, 1213.5]
Episode 454	 reward: -14.10	 Mean_loss: 0.26348624,  training time: 11.48
[435.75, 659.0, 831.25, 1015.5, 1168.25]
Episode 455	 reward: -14.40	 Mean_loss: 0.14741355,  training time: 11.48
[425.75, 669.0, 835.25, 1048.25, 1219.0]
Episode 456	 reward: -14.07	 Mean_loss: 0.34060702,  training time: 11.43
[445.25, 669.25, 767.75, 1118.75, 1211.25]
Episode 457	 reward: -13.85	 Mean_loss: 0.22722642,  training time: 11.46
[508.75, 659.0, 817.5, 1044.25, 1218.0]
Episode 458	 reward: -13.63	 Mean_loss: 0.32945380,  training time: 11.45
[426.75, 664.0, 781.0, 1068.5, 1199.0]
Episode 459	 reward: -14.15	 Mean_loss: 0.25111377,  training time: 11.53
[450.75, 713.5, 852.75, 1076.0, 1127.0]
Episode 460	 reward: -15.04	 Mean_loss: 0.26026267,  training time: 11.36
[425.25, 661.25, 857.5, 974.5, 1168.0]
Episode 461	 reward: -13.89	 Mean_loss: 0.21723728,  training time: 11.25
[383.25, 666.25, 836.75, 985.25, 1143.5]
Episode 462	 reward: -13.56	 Mean_loss: 0.19999762,  training time: 11.25
[415.0, 673.0, 862.75, 998.25, 1252.25]
Episode 463	 reward: -13.48	 Mean_loss: 0.33426243,  training time: 11.42
[420.0, 663.5, 868.75, 981.5, 1184.25]
Episode 464	 reward: -13.59	 Mean_loss: 0.21332137,  training time: 11.41
[409.0, 680.25, 907.0, 976.25, 1192.0]
Episode 465	 reward: -13.32	 Mean_loss: 0.22597575,  training time: 11.45
[414.5, 657.25, 901.5, 936.25, 1121.75]
Episode 466	 reward: -13.01	 Mean_loss: 0.13750052,  training time: 11.41
[396.75, 646.0, 891.5, 996.5, 1272.0]
Episode 467	 reward: -13.40	 Mean_loss: 0.41850838,  training time: 11.48
[412.5, 655.0, 912.75, 927.75, 1118.75]
Episode 468	 reward: -13.91	 Mean_loss: 0.15942679,  training time: 11.46
[426.5, 729.5, 877.75, 936.75, 1156.5]
Episode 469	 reward: -14.20	 Mean_loss: 0.12981872,  training time: 11.45
[400.0, 717.25, 853.75, 965.75, 1207.25]
Episode 470	 reward: -13.89	 Mean_loss: 0.27712676,  training time: 11.46
[376.25, 689.5, 867.0, 1050.0, 1173.0]
Episode 471	 reward: -13.20	 Mean_loss: 0.19293125,  training time: 11.45
[390.25, 641.5, 866.25, 926.0, 1203.0]
Episode 472	 reward: -13.80	 Mean_loss: 0.22897364,  training time: 11.47
[434.25, 642.0, 897.25, 945.0, 1168.0]
Episode 473	 reward: -13.19	 Mean_loss: 0.22389711,  training time: 11.42
[379.5, 713.5, 841.25, 986.5, 1213.75]
Episode 474	 reward: -13.86	 Mean_loss: 0.29005542,  training time: 11.41
[426.5, 691.25, 896.75, 969.0, 1174.5]
Episode 475	 reward: -13.85	 Mean_loss: 0.14359769,  training time: 11.47
[433.75, 700.75, 882.25, 959.25, 1150.75]
Episode 476	 reward: -12.91	 Mean_loss: 0.23273738,  training time: 11.61
[390.0, 664.5, 845.5, 1042.75, 1174.75]
Episode 477	 reward: -13.20	 Mean_loss: 0.24916600,  training time: 11.56
[433.5, 668.25, 832.5, 966.0, 1164.5]
Episode 478	 reward: -13.01	 Mean_loss: 0.23483060,  training time: 11.52
[429.75, 671.25, 849.25, 991.25, 1239.5]
Episode 479	 reward: -12.80	 Mean_loss: 0.27043533,  training time: 11.55
[412.75, 660.0, 878.75, 1014.5, 1136.75]
Episode 480	 reward: -13.94	 Mean_loss: 0.22829935,  training time: 11.54
[505.25, 647.0, 804.5, 1044.5, 1225.0]
Episode 481	 reward: -13.22	 Mean_loss: 0.25332162,  training time: 11.59
[482.5, 620.0, 866.25, 1009.75, 1199.25]
Episode 482	 reward: -13.25	 Mean_loss: 0.35051098,  training time: 11.54
[494.75, 619.75, 811.5, 1061.0, 1216.0]
Episode 483	 reward: -12.43	 Mean_loss: 0.27876002,  training time: 11.62
[500.0, 643.25, 816.0, 945.5, 1168.0]
Episode 484	 reward: -12.93	 Mean_loss: 0.30703577,  training time: 11.52
[467.25, 613.25, 829.0, 1000.75, 1177.0]
Episode 485	 reward: -13.55	 Mean_loss: 0.24781543,  training time: 11.53
[496.25, 651.25, 769.5, 945.25, 1160.25]
Episode 486	 reward: -13.64	 Mean_loss: 0.27839088,  training time: 11.45
[477.5, 637.25, 886.25, 1014.5, 1163.0]
Episode 487	 reward: -13.70	 Mean_loss: 0.22680366,  training time: 11.39
[486.75, 643.25, 833.75, 994.5, 1205.75]
Episode 488	 reward: -13.37	 Mean_loss: 0.26988450,  training time: 11.36
[449.0, 652.75, 916.5, 1021.0, 1177.25]
Episode 489	 reward: -13.26	 Mean_loss: 0.26100412,  training time: 11.42
[448.0, 665.0, 790.5, 1020.0, 1282.0]
Episode 490	 reward: -12.78	 Mean_loss: 0.53581661,  training time: 11.35
[487.25, 632.5, 795.25, 959.25, 1154.5]
Episode 491	 reward: -13.73	 Mean_loss: 0.24587969,  training time: 11.38
[492.0, 647.0, 847.75, 977.5, 1206.0]
Episode 492	 reward: -13.18	 Mean_loss: 0.35205543,  training time: 11.41
[465.25, 663.25, 762.0, 1010.25, 1179.25]
Episode 493	 reward: -13.36	 Mean_loss: 0.25775230,  training time: 11.41
[486.5, 705.5, 814.5, 989.5, 1198.25]
Episode 494	 reward: -13.26	 Mean_loss: 0.29747793,  training time: 11.40
[504.75, 707.0, 830.75, 982.0, 1183.75]
Episode 495	 reward: -13.91	 Mean_loss: 0.26662394,  training time: 11.39
[469.5, 607.25, 867.5, 1001.0, 1186.75]
Episode 496	 reward: -13.43	 Mean_loss: 0.26996866,  training time: 11.36
[475.75, 656.75, 884.5, 956.25, 1147.75]
Episode 497	 reward: -12.79	 Mean_loss: 0.24144748,  training time: 11.39
[489.25, 677.75, 811.5, 924.75, 1182.25]
Episode 498	 reward: -13.38	 Mean_loss: 0.34093985,  training time: 11.41
[473.75, 663.75, 852.0, 1011.5, 1156.5]
Episode 499	 reward: -14.44	 Mean_loss: 0.24502493,  training time: 11.40
[449.75, 677.25, 805.75, 1002.75, 1140.75]
Episode 500	 reward: -13.82	 Mean_loss: 0.19689049,  training time: 11.38
[487.75, 633.75, 743.75, 1001.25, 1161.0]
Episode 501	 reward: -13.30	 Mean_loss: 0.21706903,  training time: 11.44
[475.5, 669.5, 757.75, 1115.0, 1233.0]
Episode 502	 reward: -13.05	 Mean_loss: 0.39267468,  training time: 11.42
[492.5, 649.25, 830.75, 1039.5, 1160.75]
Episode 503	 reward: -13.41	 Mean_loss: 0.20562266,  training time: 11.46
[461.25, 675.25, 806.75, 1057.0, 1202.5]
Episode 504	 reward: -13.56	 Mean_loss: 0.27605838,  training time: 11.37
[445.75, 652.75, 795.75, 1106.25, 1231.0]
Episode 505	 reward: -13.19	 Mean_loss: 0.30787578,  training time: 11.36
[453.0, 690.0, 783.75, 1060.0, 1107.0]
Episode 506	 reward: -14.09	 Mean_loss: 0.23858652,  training time: 11.40
[404.75, 730.25, 772.75, 1027.75, 1189.5]
Episode 507	 reward: -13.07	 Mean_loss: 0.32668281,  training time: 11.38
[456.75, 646.25, 751.75, 1081.0, 1145.75]
Episode 508	 reward: -12.80	 Mean_loss: 0.17771302,  training time: 11.37
[469.25, 670.75, 812.0, 1073.25, 1130.25]
Episode 509	 reward: -13.04	 Mean_loss: 0.23093545,  training time: 11.42
[429.5, 702.0, 776.0, 1050.75, 1169.25]
Episode 510	 reward: -12.93	 Mean_loss: 0.34158030,  training time: 11.40
[479.0, 693.5, 758.25, 1099.75, 1155.75]
Episode 511	 reward: -12.61	 Mean_loss: 0.28859353,  training time: 11.41
[463.5, 651.5, 753.0, 1067.5, 1178.0]
Episode 512	 reward: -13.88	 Mean_loss: 0.20024419,  training time: 11.44
[514.0, 704.25, 831.25, 986.25, 1122.5]
Episode 513	 reward: -12.96	 Mean_loss: 0.24173343,  training time: 11.37
[422.0, 694.25, 767.25, 1100.25, 1182.75]
Episode 514	 reward: -13.47	 Mean_loss: 0.27165261,  training time: 11.36
[501.25, 638.75, 739.75, 1021.5, 1189.25]
Episode 515	 reward: -13.33	 Mean_loss: 0.29928428,  training time: 11.34
[448.25, 717.0, 735.75, 989.0, 1112.5]
Episode 516	 reward: -13.66	 Mean_loss: 0.23631975,  training time: 11.36
[480.25, 648.5, 766.25, 1068.25, 1167.0]
Episode 517	 reward: -13.21	 Mean_loss: 0.15061812,  training time: 11.37
[473.5, 704.0, 795.75, 1144.25, 1124.25]
Episode 518	 reward: -13.31	 Mean_loss: 0.21421941,  training time: 11.34
[493.0, 711.25, 793.25, 1048.0, 1184.25]
Episode 519	 reward: -13.85	 Mean_loss: 0.29447979,  training time: 11.61
[477.25, 674.5, 813.25, 1042.0, 1105.25]
Episode 520	 reward: -14.05	 Mean_loss: 0.22486240,  training time: 11.54
[437.25, 585.0, 841.25, 1046.0, 1132.5]
Episode 521	 reward: -13.22	 Mean_loss: 0.14788152,  training time: 11.59
[475.75, 638.5, 838.0, 995.5, 1127.25]
Episode 522	 reward: -13.40	 Mean_loss: 0.13246265,  training time: 11.54
[472.25, 661.25, 930.75, 1019.75, 1179.25]
Episode 523	 reward: -13.07	 Mean_loss: 0.24018258,  training time: 11.51
[444.0, 657.75, 821.75, 1075.75, 1185.5]
Episode 524	 reward: -13.47	 Mean_loss: 0.17154735,  training time: 11.54
[428.5, 640.5, 814.75, 1032.25, 1161.75]
Episode 525	 reward: -13.33	 Mean_loss: 0.21279575,  training time: 11.49
[464.75, 695.0, 807.75, 1053.75, 1140.75]
Episode 526	 reward: -13.56	 Mean_loss: 0.15292802,  training time: 11.49
[481.0, 609.75, 855.25, 1068.0, 1158.75]
Episode 527	 reward: -13.41	 Mean_loss: 0.19087970,  training time: 11.42
[459.5, 696.0, 895.5, 1023.0, 1168.75]
Episode 528	 reward: -12.71	 Mean_loss: 0.24373406,  training time: 11.36
[464.25, 721.25, 803.75, 1006.5, 1233.25]
Episode 529	 reward: -13.51	 Mean_loss: 0.28362289,  training time: 11.38
[470.75, 647.0, 855.0, 1010.25, 1134.25]
Episode 530	 reward: -12.76	 Mean_loss: 0.23488525,  training time: 11.40
[479.5, 615.0, 895.25, 1013.25, 1148.75]
Episode 531	 reward: -13.20	 Mean_loss: 0.14875267,  training time: 11.37
[481.25, 621.0, 823.25, 1102.5, 1181.0]
Episode 532	 reward: -12.65	 Mean_loss: 0.18681073,  training time: 11.39
[500.0, 641.75, 842.0, 983.0, 1171.25]
Episode 533	 reward: -13.68	 Mean_loss: 0.19576518,  training time: 11.38
[495.0, 622.0, 826.75, 1096.0, 1208.25]
Episode 534	 reward: -12.88	 Mean_loss: 0.33125526,  training time: 11.39
[467.25, 613.75, 871.75, 1051.25, 1152.75]
Episode 535	 reward: -12.61	 Mean_loss: 0.15774064,  training time: 11.40
[476.75, 679.25, 844.25, 999.25, 1145.75]
Episode 536	 reward: -12.79	 Mean_loss: 0.29931158,  training time: 11.46
[520.5, 651.0, 863.0, 1028.25, 1160.5]
Episode 537	 reward: -13.14	 Mean_loss: 0.27944440,  training time: 11.37
[399.5, 574.5, 900.0, 1042.25, 1179.75]
Episode 538	 reward: -13.23	 Mean_loss: 0.31935140,  training time: 11.36
[477.75, 740.0, 826.75, 1019.25, 1187.25]
Episode 539	 reward: -13.26	 Mean_loss: 0.32222709,  training time: 11.36
[446.0, 590.0, 844.75, 1016.0, 1201.5]
Episode 540	 reward: -13.71	 Mean_loss: 0.34159440,  training time: 11.36
[461.25, 614.25, 823.25, 1014.5, 1189.75]
Episode 541	 reward: -13.80	 Mean_loss: 0.37585708,  training time: 11.43
[455.0, 627.5, 807.5, 1009.25, 1165.25]
Episode 542	 reward: -14.24	 Mean_loss: 0.17062655,  training time: 11.47
[491.25, 658.75, 861.75, 1014.25, 1207.5]
Episode 543	 reward: -13.56	 Mean_loss: 0.27322987,  training time: 11.44
[480.0, 648.25, 850.75, 1032.25, 1301.25]
Episode 544	 reward: -13.62	 Mean_loss: 0.48692864,  training time: 11.42
[458.75, 600.25, 854.75, 1045.0, 1199.0]
Episode 545	 reward: -12.81	 Mean_loss: 0.27979630,  training time: 11.39
[452.25, 656.5, 836.25, 1103.5, 1197.0]
Episode 546	 reward: -13.95	 Mean_loss: 0.27560246,  training time: 11.40
[434.5, 642.0, 861.0, 1046.25, 1197.75]
Episode 547	 reward: -13.37	 Mean_loss: 0.40636083,  training time: 11.36
[427.0, 642.75, 860.25, 1001.75, 1263.0]
Episode 548	 reward: -13.81	 Mean_loss: 0.40646395,  training time: 11.39
[441.5, 611.75, 872.5, 1066.5, 1146.25]
Episode 549	 reward: -13.37	 Mean_loss: 0.27510306,  training time: 11.48
[482.75, 650.5, 852.0, 1043.0, 1153.0]
Episode 550	 reward: -13.86	 Mean_loss: 0.24772155,  training time: 11.43
[438.5, 612.25, 851.25, 1008.75, 1177.5]
Episode 551	 reward: -12.99	 Mean_loss: 0.21312171,  training time: 11.40
[442.25, 583.75, 874.5, 1023.5, 1198.75]
Episode 552	 reward: -14.20	 Mean_loss: 0.26097137,  training time: 11.40
[424.25, 615.0, 841.75, 997.5, 1160.25]
Episode 553	 reward: -13.97	 Mean_loss: 0.26539546,  training time: 11.40
[459.5, 576.25, 825.25, 1031.5, 1194.75]
Episode 554	 reward: -14.04	 Mean_loss: 0.24613346,  training time: 11.38
[438.0, 620.25, 823.25, 1018.75, 1187.0]
Episode 555	 reward: -13.85	 Mean_loss: 0.30367222,  training time: 11.40
[466.5, 676.5, 848.5, 1059.25, 1186.75]
Episode 556	 reward: -13.28	 Mean_loss: 0.27727765,  training time: 11.40
[448.75, 637.5, 814.75, 984.75, 1198.25]
Episode 557	 reward: -13.31	 Mean_loss: 0.28508988,  training time: 11.41
[452.75, 653.75, 807.0, 1044.25, 1140.75]
Episode 558	 reward: -13.34	 Mean_loss: 0.19361177,  training time: 11.45
[459.75, 625.75, 796.0, 1068.75, 1130.25]
Episode 559	 reward: -14.35	 Mean_loss: 0.21907756,  training time: 11.45
[420.25, 660.0, 838.0, 1002.25, 1215.5]
Episode 560	 reward: -13.20	 Mean_loss: 0.43161172,  training time: 11.42
[421.5, 684.0, 834.25, 1081.75, 1271.5]
Episode 561	 reward: -14.37	 Mean_loss: 0.47632837,  training time: 11.44
[449.5, 637.5, 866.5, 1079.25, 1260.75]
Episode 562	 reward: -12.96	 Mean_loss: 0.45412230,  training time: 11.37
[410.25, 659.25, 824.75, 1063.5, 1228.5]
Episode 563	 reward: -13.50	 Mean_loss: 0.26903191,  training time: 11.33
[413.25, 617.0, 803.75, 978.0, 1244.75]
Episode 564	 reward: -13.41	 Mean_loss: 0.34351903,  training time: 11.41
[443.0, 663.0, 849.25, 1056.0, 1185.75]
Episode 565	 reward: -13.68	 Mean_loss: 0.18156570,  training time: 11.34
[454.5, 702.25, 823.25, 1027.25, 1217.75]
Episode 566	 reward: -13.43	 Mean_loss: 0.34813491,  training time: 11.37
[444.75, 676.25, 872.5, 1032.0, 1234.25]
Episode 567	 reward: -13.90	 Mean_loss: 0.34849173,  training time: 11.44
[433.75, 622.25, 893.0, 1052.75, 1199.0]
Episode 568	 reward: -13.72	 Mean_loss: 0.29387540,  training time: 11.38
[462.25, 673.25, 878.25, 1052.5, 1195.25]
Episode 569	 reward: -13.65	 Mean_loss: 0.22230664,  training time: 11.35
[414.0, 669.0, 837.0, 1053.75, 1208.25]
Episode 570	 reward: -14.66	 Mean_loss: 0.33986336,  training time: 11.35
[445.0, 676.0, 844.0, 1042.25, 1229.0]
Episode 571	 reward: -13.53	 Mean_loss: 0.36890540,  training time: 11.37
[383.5, 655.25, 787.75, 1001.25, 1221.75]
Episode 572	 reward: -13.86	 Mean_loss: 0.33412361,  training time: 11.42
[429.75, 675.5, 851.5, 1055.5, 1200.0]
Episode 573	 reward: -13.43	 Mean_loss: 0.24808228,  training time: 11.37
[441.25, 683.5, 846.25, 1136.25, 1127.75]
Episode 574	 reward: -14.06	 Mean_loss: 0.16330449,  training time: 11.35
[437.75, 644.5, 827.5, 1111.5, 1241.0]
Episode 575	 reward: -13.89	 Mean_loss: 0.43283984,  training time: 11.37
[446.25, 691.5, 783.25, 1094.75, 1220.0]
Episode 576	 reward: -14.53	 Mean_loss: 0.38982183,  training time: 11.37
[472.5, 639.25, 875.5, 1041.75, 1165.5]
Episode 577	 reward: -13.11	 Mean_loss: 0.22752951,  training time: 11.41
[444.25, 665.0, 798.0, 1091.25, 1213.0]
Episode 578	 reward: -14.39	 Mean_loss: 0.30099463,  training time: 11.38
[426.75, 646.5, 808.0, 1018.25, 1180.5]
Episode 579	 reward: -13.28	 Mean_loss: 0.21596663,  training time: 11.37
[414.5, 658.25, 808.75, 1122.0, 1269.0]
Episode 580	 reward: -12.82	 Mean_loss: 0.41872537,  training time: 11.36
[454.75, 581.5, 837.25, 1022.25, 1183.0]
Episode 581	 reward: -13.58	 Mean_loss: 0.17341211,  training time: 11.44
[482.75, 651.0, 844.0, 1031.5, 1220.0]
Episode 582	 reward: -13.72	 Mean_loss: 0.24583304,  training time: 11.38
[418.5, 601.5, 794.5, 1047.0, 1281.5]
Episode 583	 reward: -13.24	 Mean_loss: 0.38733062,  training time: 11.44
[430.0, 626.75, 785.75, 1035.25, 1291.75]
Episode 584	 reward: -13.06	 Mean_loss: 0.30330768,  training time: 11.34
[443.25, 612.0, 809.75, 1048.5, 1285.25]
Episode 585	 reward: -14.10	 Mean_loss: 0.33920461,  training time: 11.36
[459.5, 598.0, 825.75, 1049.25, 1291.25]
Episode 586	 reward: -14.40	 Mean_loss: 0.51555312,  training time: 11.41
[413.5, 605.25, 873.5, 1068.25, 1237.0]
Episode 587	 reward: -14.51	 Mean_loss: 0.18040919,  training time: 11.41
[432.0, 611.0, 857.25, 990.25, 1187.5]
Episode 588	 reward: -13.97	 Mean_loss: 0.17360903,  training time: 11.37
[453.25, 577.25, 852.5, 1070.0, 1252.0]
Episode 589	 reward: -13.24	 Mean_loss: 0.31296679,  training time: 11.36
[403.25, 602.0, 827.75, 1024.75, 1196.25]
Episode 590	 reward: -13.65	 Mean_loss: 0.24511503,  training time: 11.40
[419.0, 611.75, 796.75, 1029.75, 1275.0]
Episode 591	 reward: -14.34	 Mean_loss: 0.34837592,  training time: 11.35
[440.25, 633.0, 824.5, 1028.5, 1233.0]
Episode 592	 reward: -13.73	 Mean_loss: 0.23325023,  training time: 11.49
[407.75, 601.75, 831.25, 999.25, 1167.75]
Episode 593	 reward: -13.59	 Mean_loss: 0.25671136,  training time: 11.48
[358.75, 618.25, 777.75, 963.25, 1255.0]
Episode 594	 reward: -13.98	 Mean_loss: 0.40532282,  training time: 11.47
[400.5, 651.0, 885.75, 1051.25, 1209.5]
Episode 595	 reward: -14.02	 Mean_loss: 0.29141968,  training time: 11.54
[419.25, 616.0, 882.25, 1062.75, 1207.0]
Episode 596	 reward: -13.85	 Mean_loss: 0.23246722,  training time: 11.46
[409.0, 627.75, 818.75, 1049.25, 1193.5]
Episode 597	 reward: -14.03	 Mean_loss: 0.21543095,  training time: 11.48
[420.75, 647.5, 824.0, 1044.25, 1242.0]
Episode 598	 reward: -13.91	 Mean_loss: 0.34850988,  training time: 11.49
[411.25, 613.5, 913.75, 1062.5, 1221.75]
Episode 599	 reward: -13.64	 Mean_loss: 0.23000261,  training time: 11.52
[432.0, 630.5, 865.25, 990.0, 1183.25]
Episode 600	 reward: -13.46	 Mean_loss: 0.27035537,  training time: 11.52
[437.5, 669.5, 821.5, 979.0, 1185.0]
Episode 601	 reward: -12.99	 Mean_loss: 0.36491993,  training time: 11.58
[431.75, 695.0, 815.0, 922.25, 1229.0]
Episode 602	 reward: -12.96	 Mean_loss: 0.32471609,  training time: 11.50
[408.0, 625.25, 872.5, 1005.5, 1214.5]
Episode 603	 reward: -13.33	 Mean_loss: 0.35276490,  training time: 11.49
[453.25, 646.5, 877.0, 915.5, 1177.75]
Episode 604	 reward: -13.34	 Mean_loss: 0.28448036,  training time: 11.51
[422.25, 712.75, 850.5, 961.5, 1154.5]
Episode 605	 reward: -13.73	 Mean_loss: 0.23143913,  training time: 11.29
[461.0, 697.25, 905.5, 1007.5, 1299.75]
Episode 606	 reward: -13.38	 Mean_loss: 0.53787452,  training time: 11.29
[412.0, 615.75, 881.75, 1040.0, 1199.75]
Episode 607	 reward: -13.08	 Mean_loss: 0.30191857,  training time: 11.26
[424.5, 593.25, 843.75, 938.0, 1171.25]
Episode 608	 reward: -13.77	 Mean_loss: 0.30940211,  training time: 11.34
[414.25, 702.25, 864.25, 880.0, 1190.25]
Episode 609	 reward: -13.01	 Mean_loss: 0.22800981,  training time: 11.27
[424.0, 670.75, 851.5, 976.0, 1169.25]
Episode 610	 reward: -13.01	 Mean_loss: 0.19590108,  training time: 11.23
[446.25, 631.5, 816.5, 1015.5, 1144.25]
Episode 611	 reward: -13.12	 Mean_loss: 0.20028369,  training time: 11.24
[418.75, 657.75, 916.0, 951.0, 1113.5]
Episode 612	 reward: -13.98	 Mean_loss: 0.15725239,  training time: 11.25
[422.0, 680.0, 891.75, 1007.25, 1183.25]
Episode 613	 reward: -13.93	 Mean_loss: 0.21328062,  training time: 11.23
[440.75, 623.25, 875.75, 976.25, 1209.25]
Episode 614	 reward: -13.94	 Mean_loss: 0.33274785,  training time: 11.28
[418.0, 658.5, 855.5, 1061.5, 1171.5]
Episode 615	 reward: -13.66	 Mean_loss: 0.28632203,  training time: 11.29
[387.75, 643.25, 812.5, 1013.25, 1198.0]
Episode 616	 reward: -13.21	 Mean_loss: 0.30877805,  training time: 11.25
[397.75, 671.5, 878.25, 1064.75, 1182.75]
Episode 617	 reward: -13.91	 Mean_loss: 0.24470867,  training time: 11.22
[405.75, 670.5, 857.5, 1005.5, 1181.25]
Episode 618	 reward: -13.86	 Mean_loss: 0.23477663,  training time: 11.21
[402.0, 665.0, 832.25, 962.0, 1163.75]
Episode 619	 reward: -13.05	 Mean_loss: 0.29269883,  training time: 11.19
[475.75, 623.75, 856.25, 980.0, 1169.0]
Episode 620	 reward: -13.71	 Mean_loss: 0.27946651,  training time: 11.21
[449.0, 661.5, 771.75, 981.75, 1233.0]
Episode 621	 reward: -14.34	 Mean_loss: 0.27199268,  training time: 11.26
[417.75, 665.0, 825.75, 976.75, 1301.5]
Episode 622	 reward: -14.13	 Mean_loss: 0.48357242,  training time: 11.20
[442.5, 685.25, 787.25, 1009.75, 1296.75]
Episode 623	 reward: -14.36	 Mean_loss: 0.57545596,  training time: 11.21
[461.0, 617.5, 778.75, 988.75, 1226.75]
Episode 624	 reward: -14.01	 Mean_loss: 0.23317175,  training time: 11.48
[436.0, 634.0, 818.25, 1013.5, 1194.0]
Episode 625	 reward: -13.61	 Mean_loss: 0.26251295,  training time: 11.43
[470.75, 654.0, 812.75, 1008.5, 1224.75]
Episode 626	 reward: -14.31	 Mean_loss: 0.25823292,  training time: 11.52
[433.25, 620.5, 753.25, 998.5, 1237.0]
Episode 627	 reward: -14.67	 Mean_loss: 0.32290241,  training time: 11.53
[418.75, 645.5, 726.0, 959.0, 1218.75]
Episode 628	 reward: -14.18	 Mean_loss: 0.28902805,  training time: 11.48
[450.75, 629.25, 791.75, 1023.0, 1227.25]
Episode 629	 reward: -13.96	 Mean_loss: 0.35641506,  training time: 11.47
[451.5, 610.75, 791.75, 1002.75, 1245.5]
Episode 630	 reward: -14.19	 Mean_loss: 0.29233539,  training time: 11.47
[422.75, 619.5, 771.5, 986.5, 1249.75]
Episode 631	 reward: -13.67	 Mean_loss: 0.37455994,  training time: 11.47
[462.75, 704.0, 835.75, 980.0, 1267.75]
Episode 632	 reward: -13.35	 Mean_loss: 0.29934365,  training time: 11.46
[503.5, 733.0, 828.25, 991.75, 1182.75]
Episode 633	 reward: -13.82	 Mean_loss: 0.25151744,  training time: 11.55
[420.75, 628.75, 763.75, 1001.0, 1160.75]
Episode 634	 reward: -13.88	 Mean_loss: 0.21092765,  training time: 11.50
[446.5, 656.25, 781.5, 991.5, 1265.5]
Episode 635	 reward: -14.04	 Mean_loss: 0.35422352,  training time: 11.44
[440.75, 603.5, 761.25, 1037.5, 1236.5]
Episode 636	 reward: -13.94	 Mean_loss: 0.29398781,  training time: 11.47
[447.25, 632.75, 775.25, 1066.25, 1264.0]
Episode 637	 reward: -14.56	 Mean_loss: 0.56038266,  training time: 11.50
[428.75, 630.5, 810.5, 977.5, 1296.25]
Episode 638	 reward: -14.43	 Mean_loss: 0.46919909,  training time: 11.48
[463.5, 684.5, 749.0, 1013.75, 1290.0]
Episode 639	 reward: -14.50	 Mean_loss: 0.32064021,  training time: 11.49
[430.75, 616.0, 785.75, 991.0, 1292.75]
Episode 640	 reward: -14.58	 Mean_loss: 0.36782694,  training time: 11.46
[413.0, 584.75, 806.0, 961.0, 1200.25]
Episode 641	 reward: -14.07	 Mean_loss: 0.20693728,  training time: 11.44
[367.5, 588.0, 811.5, 987.75, 1278.5]
Episode 642	 reward: -14.18	 Mean_loss: 0.45741734,  training time: 11.47
[438.0, 691.25, 846.5, 995.75, 1256.0]
Episode 643	 reward: -14.57	 Mean_loss: 0.27617016,  training time: 11.47
[405.0, 654.25, 833.5, 934.25, 1292.0]
Episode 644	 reward: -14.45	 Mean_loss: 0.35116947,  training time: 11.46
[433.75, 617.25, 838.5, 1012.0, 1244.5]
Episode 645	 reward: -13.25	 Mean_loss: 0.29628640,  training time: 11.43
[390.25, 621.0, 852.5, 989.25, 1257.25]
Episode 646	 reward: -13.93	 Mean_loss: 0.38964751,  training time: 11.42
[402.5, 583.0, 852.0, 971.5, 1259.5]
Episode 647	 reward: -14.38	 Mean_loss: 0.35137773,  training time: 11.40
[366.0, 667.5, 862.5, 975.0, 1236.25]
Episode 648	 reward: -14.13	 Mean_loss: 0.25410619,  training time: 11.42
[371.0, 624.75, 819.0, 1040.75, 1247.25]
Episode 649	 reward: -14.60	 Mean_loss: 0.28866395,  training time: 11.40
[424.75, 584.75, 800.75, 999.0, 1245.5]
Episode 650	 reward: -14.02	 Mean_loss: 0.45069146,  training time: 11.43
[407.25, 599.25, 802.25, 974.25, 1149.0]
Episode 651	 reward: -14.74	 Mean_loss: 0.26184511,  training time: 11.40
[419.0, 586.75, 835.75, 994.75, 1208.5]
Episode 652	 reward: -13.95	 Mean_loss: 0.25571886,  training time: 11.50
[429.25, 624.75, 836.5, 994.75, 1264.75]
Episode 653	 reward: -13.82	 Mean_loss: 0.23160326,  training time: 11.42
[388.75, 589.0, 827.25, 946.75, 1260.5]
Episode 654	 reward: -14.03	 Mean_loss: 0.36748821,  training time: 11.40
[427.5, 572.0, 874.0, 963.0, 1161.0]
Episode 655	 reward: -13.90	 Mean_loss: 0.17319572,  training time: 11.46
[401.25, 593.25, 854.5, 973.5, 1239.75]
Episode 656	 reward: -14.18	 Mean_loss: 0.28613254,  training time: 11.45
[391.0, 625.75, 853.5, 939.75, 1209.75]
Episode 657	 reward: -14.02	 Mean_loss: 0.21665677,  training time: 11.43
[403.75, 635.0, 812.75, 961.0, 1180.75]
Episode 658	 reward: -14.11	 Mean_loss: 0.23590314,  training time: 11.38
[405.0, 593.75, 861.5, 1018.25, 1215.25]
Episode 659	 reward: -13.79	 Mean_loss: 0.25060841,  training time: 11.39
[388.25, 558.25, 858.25, 988.0, 1197.25]
Episode 660	 reward: -13.44	 Mean_loss: 0.29218999,  training time: 11.23
[493.25, 617.0, 915.75, 971.75, 1213.25]
Episode 661	 reward: -13.49	 Mean_loss: 0.33203554,  training time: 11.28
[478.5, 677.5, 890.5, 917.0, 1196.0]
Episode 662	 reward: -13.85	 Mean_loss: 0.22900701,  training time: 11.36
[502.25, 612.75, 831.75, 993.5, 1159.75]
Episode 663	 reward: -14.17	 Mean_loss: 0.23659758,  training time: 11.24
[439.75, 595.75, 873.75, 997.5, 1157.0]
Episode 664	 reward: -13.24	 Mean_loss: 0.28352195,  training time: 11.25
[426.25, 623.0, 915.0, 969.25, 1149.0]
Episode 665	 reward: -14.18	 Mean_loss: 0.25188434,  training time: 11.20
[440.0, 619.5, 862.5, 948.25, 1179.75]
Episode 666	 reward: -13.04	 Mean_loss: 0.26626927,  training time: 11.25
[441.75, 621.0, 889.0, 921.25, 1144.0]
Episode 667	 reward: -13.39	 Mean_loss: 0.20644252,  training time: 11.26
[445.25, 708.0, 880.0, 983.5, 1238.75]
Episode 668	 reward: -14.00	 Mean_loss: 0.40236816,  training time: 11.20
[448.5, 616.5, 891.25, 994.25, 1235.75]
Episode 669	 reward: -13.95	 Mean_loss: 0.31657773,  training time: 11.25
[437.0, 612.5, 857.75, 966.5, 1178.25]
Episode 670	 reward: -14.43	 Mean_loss: 0.23976074,  training time: 11.23
[514.5, 666.0, 853.25, 955.5, 1207.25]
Episode 671	 reward: -13.87	 Mean_loss: 0.41649979,  training time: 11.28
[491.0, 600.75, 840.0, 972.25, 1210.0]
Episode 672	 reward: -14.07	 Mean_loss: 0.28662327,  training time: 11.33
[506.0, 629.25, 852.75, 967.5, 1184.75]
Episode 673	 reward: -13.64	 Mean_loss: 0.23777680,  training time: 11.25
[442.75, 623.25, 834.75, 941.75, 1140.5]
Episode 674	 reward: -13.94	 Mean_loss: 0.15844291,  training time: 11.27
[458.5, 643.5, 892.25, 1028.25, 1147.75]
Episode 675	 reward: -14.36	 Mean_loss: 0.21493375,  training time: 11.26
[438.25, 609.75, 878.25, 975.0, 1179.25]
Episode 676	 reward: -14.45	 Mean_loss: 0.16867581,  training time: 11.34
[492.0, 615.5, 903.25, 991.0, 1190.0]
Episode 677	 reward: -12.84	 Mean_loss: 0.22515050,  training time: 11.27
[460.75, 567.0, 896.75, 975.75, 1191.75]
Episode 678	 reward: -14.07	 Mean_loss: 0.22953175,  training time: 11.24
[509.5, 598.75, 845.25, 948.75, 1213.75]
Episode 679	 reward: -13.00	 Mean_loss: 0.28533494,  training time: 11.27
[429.0, 597.25, 893.0, 985.5, 1191.25]
Episode 680	 reward: -13.88	 Mean_loss: 0.21345718,  training time: 11.22
[378.0, 595.75, 784.25, 992.75, 1194.0]
Episode 681	 reward: -13.81	 Mean_loss: 0.38429981,  training time: 11.33
[426.25, 623.5, 805.75, 1035.75, 1200.0]
Episode 682	 reward: -14.27	 Mean_loss: 0.29428604,  training time: 11.26
[435.5, 626.75, 759.0, 1046.25, 1199.5]
Episode 683	 reward: -13.98	 Mean_loss: 0.22699989,  training time: 11.45
[425.0, 643.5, 805.75, 1005.75, 1172.75]
Episode 684	 reward: -12.94	 Mean_loss: 0.20114875,  training time: 11.48
[372.5, 635.25, 781.5, 1026.5, 1193.5]
Episode 685	 reward: -14.20	 Mean_loss: 0.16439597,  training time: 11.46
[386.0, 577.0, 775.5, 1042.0, 1162.25]
Episode 686	 reward: -13.75	 Mean_loss: 0.20072991,  training time: 11.45
[395.75, 620.5, 795.25, 1036.0, 1159.5]
Episode 687	 reward: -13.67	 Mean_loss: 0.21528789,  training time: 11.44
[373.5, 609.75, 770.75, 1042.25, 1199.75]
Episode 688	 reward: -13.62	 Mean_loss: 0.18484554,  training time: 11.40
[380.75, 605.0, 773.25, 1074.25, 1170.5]
Episode 689	 reward: -13.48	 Mean_loss: 0.18336953,  training time: 11.43
[385.5, 615.0, 799.25, 1057.75, 1123.25]
Episode 690	 reward: -13.69	 Mean_loss: 0.11921369,  training time: 11.46
[433.0, 630.25, 746.5, 1021.5, 1165.5]
Episode 691	 reward: -13.69	 Mean_loss: 0.21835648,  training time: 11.49
[440.75, 615.0, 743.0, 1045.5, 1153.75]
Episode 692	 reward: -13.81	 Mean_loss: 0.23991822,  training time: 11.44
[379.25, 616.25, 789.5, 1036.75, 1188.0]
Episode 693	 reward: -13.50	 Mean_loss: 0.20652083,  training time: 11.48
[419.0, 585.5, 778.0, 1050.25, 1164.5]
Episode 694	 reward: -13.72	 Mean_loss: 0.23961888,  training time: 11.45
[410.5, 651.25, 759.0, 1043.25, 1196.25]
Episode 695	 reward: -14.32	 Mean_loss: 0.24873659,  training time: 11.46
[410.5, 612.0, 737.25, 1042.0, 1172.75]
Episode 696	 reward: -13.88	 Mean_loss: 0.22461312,  training time: 11.53
[405.0, 596.25, 797.0, 1024.5, 1206.0]
Episode 697	 reward: -13.51	 Mean_loss: 0.33041239,  training time: 11.44
[361.0, 626.0, 757.75, 1029.75, 1214.5]
Episode 698	 reward: -14.01	 Mean_loss: 0.32013357,  training time: 11.41
[423.5, 597.0, 762.0, 1061.5, 1165.0]
Episode 699	 reward: -13.51	 Mean_loss: 0.17022625,  training time: 11.36
[427.0, 570.75, 747.5, 992.25, 1223.25]
Episode 700	 reward: -13.63	 Mean_loss: 0.26502895,  training time: 11.50
[430.25, 654.75, 859.75, 1076.25, 1174.5]
Episode 701	 reward: -13.90	 Mean_loss: 0.35500243,  training time: 11.55
[424.25, 625.0, 863.25, 1034.5, 1189.75]
Episode 702	 reward: -13.61	 Mean_loss: 0.35029829,  training time: 11.47
[410.75, 673.5, 876.25, 998.0, 1179.5]
Episode 703	 reward: -13.81	 Mean_loss: 0.21805762,  training time: 11.43
[464.0, 666.5, 805.0, 1041.0, 1166.25]
Episode 704	 reward: -13.26	 Mean_loss: 0.16246483,  training time: 11.45
[504.75, 650.5, 796.0, 1043.0, 1178.5]
Episode 705	 reward: -13.80	 Mean_loss: 0.22239204,  training time: 11.45
[388.0, 632.5, 827.0, 986.25, 1218.5]
Episode 706	 reward: -13.74	 Mean_loss: 0.25636780,  training time: 11.55
[374.75, 631.5, 854.25, 1099.5, 1168.75]
Episode 707	 reward: -14.02	 Mean_loss: 0.24551238,  training time: 11.49
[413.75, 640.25, 856.5, 1024.5, 1151.0]
Episode 708	 reward: -13.89	 Mean_loss: 0.25179553,  training time: 11.44
[416.75, 663.5, 894.0, 1034.75, 1151.5]
Episode 709	 reward: -13.74	 Mean_loss: 0.18965006,  training time: 11.49
[404.75, 651.5, 806.25, 1038.25, 1136.75]
Episode 710	 reward: -14.06	 Mean_loss: 0.15717041,  training time: 11.52
[432.5, 626.5, 780.0, 1037.5, 1153.5]
Episode 711	 reward: -13.84	 Mean_loss: 0.17845908,  training time: 11.48
[405.75, 621.75, 792.5, 970.25, 1171.5]
Episode 712	 reward: -14.17	 Mean_loss: 0.16956705,  training time: 11.48
[383.75, 700.0, 798.0, 1059.25, 1176.75]
Episode 713	 reward: -13.30	 Mean_loss: 0.23860812,  training time: 11.48
[436.0, 661.75, 841.0, 1067.75, 1161.25]
Episode 714	 reward: -13.62	 Mean_loss: 0.17893288,  training time: 11.49
[414.5, 614.5, 783.25, 1021.75, 1231.0]
Episode 715	 reward: -13.63	 Mean_loss: 0.29138765,  training time: 11.46
[398.5, 669.75, 863.0, 1033.5, 1195.25]
Episode 716	 reward: -14.37	 Mean_loss: 0.26317731,  training time: 11.46
[438.5, 603.5, 822.5, 1096.75, 1147.75]
Episode 717	 reward: -13.87	 Mean_loss: 0.17526297,  training time: 11.48
[376.5, 625.5, 845.75, 993.75, 1160.5]
Episode 718	 reward: -13.78	 Mean_loss: 0.21491517,  training time: 11.46
[441.5, 739.25, 814.75, 1055.0, 1210.0]
Episode 719	 reward: -13.77	 Mean_loss: 0.26633877,  training time: 11.59
[410.5, 606.25, 769.75, 1071.75, 1224.5]
Episode 720	 reward: -13.43	 Mean_loss: 0.28964210,  training time: 11.51
[392.0, 656.75, 758.5, 999.25, 1160.25]
Episode 721	 reward: -12.88	 Mean_loss: 0.18872184,  training time: 11.52
[385.0, 625.75, 698.5, 975.25, 1163.5]
Episode 722	 reward: -13.08	 Mean_loss: 0.27914163,  training time: 11.45
[382.0, 571.25, 740.25, 1031.75, 1096.0]
Episode 723	 reward: -13.96	 Mean_loss: 0.22711517,  training time: 11.49
[399.5, 610.75, 815.75, 968.25, 1185.5]
Episode 724	 reward: -13.49	 Mean_loss: 0.34470490,  training time: 11.50
[413.25, 568.75, 711.5, 998.75, 1123.75]
Episode 725	 reward: -12.85	 Mean_loss: 0.22685233,  training time: 11.50
[416.25, 627.75, 714.5, 1028.75, 1172.25]
Episode 726	 reward: -13.45	 Mean_loss: 0.21844333,  training time: 11.46
[428.25, 634.0, 778.5, 1000.25, 1169.25]
Episode 727	 reward: -13.04	 Mean_loss: 0.18942846,  training time: 11.53
[399.5, 628.75, 743.5, 959.75, 1221.25]
Episode 728	 reward: -13.73	 Mean_loss: 0.28945553,  training time: 11.50
[414.25, 644.5, 768.75, 1027.75, 1174.5]
Episode 729	 reward: -13.16	 Mean_loss: 0.31152833,  training time: 11.62
[388.0, 616.25, 754.25, 963.25, 1155.25]
Episode 730	 reward: -13.22	 Mean_loss: 0.20548281,  training time: 11.48
[405.0, 616.5, 739.5, 942.75, 1155.0]
Episode 731	 reward: -13.44	 Mean_loss: 0.16879398,  training time: 11.52
[420.5, 591.0, 749.0, 1021.75, 1152.75]
Episode 732	 reward: -13.55	 Mean_loss: 0.21281265,  training time: 11.53
[386.0, 649.25, 684.5, 971.5, 1143.5]
Episode 733	 reward: -12.71	 Mean_loss: 0.17224689,  training time: 11.50
[432.5, 652.75, 748.5, 995.0, 1159.5]
Episode 734	 reward: -12.78	 Mean_loss: 0.32505903,  training time: 11.53
[429.5, 665.25, 717.25, 1002.75, 1093.0]
Episode 735	 reward: -13.24	 Mean_loss: 0.20377377,  training time: 11.53
[417.0, 587.5, 769.5, 973.25, 1205.0]
Episode 736	 reward: -13.49	 Mean_loss: 0.23319519,  training time: 11.51
[443.0, 607.0, 716.25, 1049.75, 1187.75]
Episode 737	 reward: -12.63	 Mean_loss: 0.33170658,  training time: 11.50
[406.75, 587.75, 769.5, 1000.0, 1090.5]
Episode 738	 reward: -13.47	 Mean_loss: 0.10598488,  training time: 11.54
[430.5, 646.0, 716.0, 1031.0, 1107.0]
Episode 739	 reward: -13.73	 Mean_loss: 0.15689446,  training time: 11.46
[409.25, 579.25, 768.25, 981.0, 1190.25]
Episode 740	 reward: -13.17	 Mean_loss: 0.26845977,  training time: 11.51
[454.0, 628.75, 800.5, 1040.25, 1212.0]
Episode 741	 reward: -13.67	 Mean_loss: 0.35004744,  training time: 11.52
[454.25, 660.0, 802.5, 1040.25, 1335.25]
Episode 742	 reward: -14.10	 Mean_loss: 0.62941206,  training time: 11.48
[460.5, 645.25, 798.25, 994.5, 1229.75]
Episode 743	 reward: -14.17	 Mean_loss: 0.42374483,  training time: 11.46
[441.5, 640.75, 805.5, 1081.25, 1224.25]
Episode 744	 reward: -14.42	 Mean_loss: 0.32742843,  training time: 11.51
[443.0, 606.25, 837.25, 994.5, 1185.0]
Episode 745	 reward: -15.06	 Mean_loss: 0.17605911,  training time: 11.46
[463.75, 671.5, 790.75, 1057.75, 1192.0]
Episode 746	 reward: -15.74	 Mean_loss: 0.19979076,  training time: 11.47
[441.0, 635.5, 827.5, 1031.0, 1282.0]
Episode 747	 reward: -15.02	 Mean_loss: 0.34424162,  training time: 11.56
[413.0, 635.25, 785.5, 1028.0, 1241.0]
Episode 748	 reward: -14.54	 Mean_loss: 0.41505191,  training time: 11.59
[442.0, 654.25, 822.0, 1026.75, 1190.0]
Episode 749	 reward: -14.97	 Mean_loss: 0.20738631,  training time: 11.53
[429.5, 654.25, 790.5, 1019.0, 1227.5]
Episode 750	 reward: -15.19	 Mean_loss: 0.39309949,  training time: 11.53
[475.75, 654.25, 857.5, 1056.5, 1214.5]
Episode 751	 reward: -14.05	 Mean_loss: 0.20868836,  training time: 11.55
[469.5, 683.5, 783.5, 1054.0, 1256.75]
Episode 752	 reward: -13.93	 Mean_loss: 0.41954184,  training time: 11.58
[425.5, 648.75, 819.75, 968.5, 1280.5]
Episode 753	 reward: -14.87	 Mean_loss: 0.44934508,  training time: 11.56
[440.25, 615.75, 811.75, 1009.0, 1228.75]
Episode 754	 reward: -14.21	 Mean_loss: 0.25087300,  training time: 11.59
[419.0, 677.25, 805.0, 991.75, 1203.25]
Episode 755	 reward: -14.61	 Mean_loss: 0.26823485,  training time: 11.56
[424.25, 673.0, 786.25, 1055.75, 1231.5]
Episode 756	 reward: -14.43	 Mean_loss: 0.27937549,  training time: 11.55
[432.25, 640.5, 753.75, 1028.75, 1232.0]
Episode 757	 reward: -13.90	 Mean_loss: 0.28813642,  training time: 11.56
[407.5, 647.0, 788.0, 986.5, 1279.5]
Episode 758	 reward: -14.14	 Mean_loss: 0.33170855,  training time: 11.44
[444.25, 675.75, 841.0, 952.75, 1240.0]
Episode 759	 reward: -13.54	 Mean_loss: 0.33661678,  training time: 11.53
[464.5, 703.5, 810.0, 967.0, 1228.0]
Episode 760	 reward: -13.84	 Mean_loss: 0.21833412,  training time: 11.53
[419.0, 643.5, 828.5, 996.75, 1152.0]
Episode 761	 reward: -12.81	 Mean_loss: 0.25357109,  training time: 11.61
[435.75, 664.0, 851.5, 1040.25, 1214.5]
Episode 762	 reward: -13.72	 Mean_loss: 0.25752944,  training time: 11.55
[505.0, 588.5, 812.5, 984.75, 1195.25]
Episode 763	 reward: -13.17	 Mean_loss: 0.25697029,  training time: 11.58
[453.5, 597.75, 780.5, 1023.75, 1148.25]
Episode 764	 reward: -13.82	 Mean_loss: 0.30307606,  training time: 11.60
[457.75, 618.5, 790.0, 936.5, 1138.0]
Episode 765	 reward: -13.21	 Mean_loss: 0.24186681,  training time: 11.58
[482.5, 656.75, 771.75, 939.25, 1209.0]
Episode 766	 reward: -13.99	 Mean_loss: 0.31516925,  training time: 11.59
[454.75, 611.5, 798.0, 990.75, 1191.75]
Episode 767	 reward: -13.07	 Mean_loss: 0.41073465,  training time: 11.56
[452.25, 602.5, 778.75, 1022.75, 1235.5]
Episode 768	 reward: -14.46	 Mean_loss: 0.28124768,  training time: 11.50
[422.75, 612.75, 781.5, 1016.0, 1114.0]
Episode 769	 reward: -14.05	 Mean_loss: 0.25261950,  training time: 11.47
[450.25, 574.5, 864.0, 995.5, 1118.75]
Episode 770	 reward: -13.84	 Mean_loss: 0.22083898,  training time: 11.50
[473.75, 591.25, 819.0, 1002.25, 1312.5]
Episode 771	 reward: -13.46	 Mean_loss: 0.64770699,  training time: 11.49
[437.25, 648.75, 819.75, 997.25, 1139.0]
Episode 772	 reward: -13.28	 Mean_loss: 0.19631124,  training time: 11.47
[438.75, 651.0, 778.75, 1018.5, 1185.5]
Episode 773	 reward: -13.73	 Mean_loss: 0.26260903,  training time: 11.50
[480.0, 607.5, 842.5, 964.25, 1195.5]
Episode 774	 reward: -13.79	 Mean_loss: 0.25494099,  training time: 11.62
[435.75, 591.5, 767.5, 950.5, 1184.75]
Episode 775	 reward: -13.95	 Mean_loss: 0.20770548,  training time: 11.58
[463.0, 613.25, 744.0, 1040.5, 1186.25]
Episode 776	 reward: -14.04	 Mean_loss: 0.35174388,  training time: 11.70
[429.0, 652.5, 823.0, 1042.75, 1129.25]
Episode 777	 reward: -13.26	 Mean_loss: 0.19301227,  training time: 11.57
[450.0, 588.25, 751.75, 1061.25, 1177.0]
Episode 778	 reward: -13.49	 Mean_loss: 0.16836017,  training time: 11.54
[495.5, 593.75, 796.25, 986.5, 1197.5]
Episode 779	 reward: -13.93	 Mean_loss: 0.29171297,  training time: 11.55
[422.75, 618.25, 808.0, 1003.0, 1199.0]
Episode 780	 reward: -14.90	 Mean_loss: 0.22376598,  training time: 11.51
[397.0, 632.75, 789.5, 998.75, 1199.75]
Episode 781	 reward: -14.10	 Mean_loss: 0.29297149,  training time: 11.52
[466.0, 611.5, 796.5, 1004.25, 1171.0]
Episode 782	 reward: -13.24	 Mean_loss: 0.24322018,  training time: 11.51
[427.5, 557.5, 744.25, 1028.25, 1172.5]
Episode 783	 reward: -13.53	 Mean_loss: 0.25628531,  training time: 11.53
[475.5, 580.75, 876.5, 990.25, 1135.25]
Episode 784	 reward: -13.66	 Mean_loss: 0.20640023,  training time: 11.51
[432.5, 626.75, 818.0, 1020.75, 1164.25]
Episode 785	 reward: -13.05	 Mean_loss: 0.16373813,  training time: 11.56
[456.0, 656.5, 780.75, 944.0, 1193.0]
Episode 786	 reward: -13.18	 Mean_loss: 0.27214134,  training time: 11.54
[431.75, 590.5, 857.0, 981.0, 1172.25]
Episode 787	 reward: -13.81	 Mean_loss: 0.22826348,  training time: 11.48
[480.0, 611.5, 837.0, 967.5, 1116.25]
Episode 788	 reward: -13.26	 Mean_loss: 0.18453084,  training time: 11.49
[502.25, 611.0, 828.5, 1042.75, 1086.0]
Episode 789	 reward: -13.25	 Mean_loss: 0.15419561,  training time: 11.46
[455.25, 576.75, 822.0, 981.75, 1187.0]
Episode 790	 reward: -13.12	 Mean_loss: 0.23075332,  training time: 11.47
[424.0, 591.0, 836.25, 1002.5, 1156.0]
Episode 791	 reward: -14.14	 Mean_loss: 0.19689102,  training time: 11.54
[426.5, 613.0, 825.75, 988.0, 1169.0]
Episode 792	 reward: -13.25	 Mean_loss: 0.17971957,  training time: 11.59
[457.0, 557.75, 822.5, 975.25, 1127.25]
Episode 793	 reward: -13.59	 Mean_loss: 0.13816962,  training time: 11.58
[430.5, 604.25, 830.25, 973.25, 1178.5]
Episode 794	 reward: -13.37	 Mean_loss: 0.25391653,  training time: 11.56
[401.0, 567.25, 880.5, 1027.0, 1208.75]
Episode 795	 reward: -13.17	 Mean_loss: 0.29075015,  training time: 11.60
[441.75, 607.5, 789.25, 1018.25, 1147.5]
Episode 796	 reward: -13.12	 Mean_loss: 0.12997344,  training time: 11.60
[453.5, 583.0, 759.25, 942.5, 1125.5]
Episode 797	 reward: -13.43	 Mean_loss: 0.15446335,  training time: 11.60
[420.5, 624.0, 797.0, 1001.0, 1174.75]
Episode 798	 reward: -12.74	 Mean_loss: 0.27048850,  training time: 11.59
[475.75, 589.5, 751.75, 1024.5, 1148.75]
Episode 799	 reward: -13.24	 Mean_loss: 0.15955392,  training time: 11.52
[400.75, 659.25, 744.5, 1013.75, 1162.75]
Episode 800	 reward: -13.99	 Mean_loss: 0.09525725,  training time: 11.50
[453.75, 635.5, 811.75, 1019.5, 1096.0]
Episode 801	 reward: -13.51	 Mean_loss: 0.18024080,  training time: 11.62
[465.0, 615.25, 819.5, 1004.5, 1167.75]
Episode 802	 reward: -13.68	 Mean_loss: 0.28013250,  training time: 11.53
[426.75, 572.75, 812.75, 1032.25, 1124.25]
Episode 803	 reward: -12.58	 Mean_loss: 0.17385697,  training time: 11.55
[432.0, 570.75, 831.0, 1019.0, 1177.0]
Episode 804	 reward: -13.24	 Mean_loss: 0.25775823,  training time: 11.57
[443.25, 602.0, 812.25, 1023.5, 1130.5]
Episode 805	 reward: -13.03	 Mean_loss: 0.17995498,  training time: 11.39
[459.0, 561.0, 859.25, 965.5, 1138.25]
Episode 806	 reward: -13.60	 Mean_loss: 0.13052572,  training time: 11.48
[457.75, 589.75, 844.25, 1049.25, 1167.25]
Episode 807	 reward: -13.69	 Mean_loss: 0.16251552,  training time: 11.38
[450.0, 614.0, 782.0, 1033.25, 1181.0]
Episode 808	 reward: -13.43	 Mean_loss: 0.26338309,  training time: 11.43
[490.75, 631.75, 846.25, 1057.0, 1106.75]
Episode 809	 reward: -13.56	 Mean_loss: 0.21577924,  training time: 11.48
[465.5, 575.25, 828.0, 1050.5, 1165.5]
Episode 810	 reward: -14.23	 Mean_loss: 0.33755001,  training time: 11.47
[443.75, 633.0, 850.0, 979.0, 1143.75]
Episode 811	 reward: -13.72	 Mean_loss: 0.21051061,  training time: 11.49
[447.5, 607.75, 833.25, 974.0, 1101.75]
Episode 812	 reward: -13.24	 Mean_loss: 0.13529155,  training time: 11.40
[458.5, 598.75, 786.75, 1059.25, 1127.5]
Episode 813	 reward: -13.36	 Mean_loss: 0.17074817,  training time: 11.61
[445.0, 602.5, 882.75, 1060.75, 1097.25]
Episode 814	 reward: -13.15	 Mean_loss: 0.18923135,  training time: 11.50
[435.5, 570.75, 777.25, 1066.0, 1081.75]
Episode 815	 reward: -13.43	 Mean_loss: 0.11835475,  training time: 11.42
[429.0, 598.5, 837.25, 1089.0, 1063.25]
Episode 816	 reward: -13.21	 Mean_loss: 0.19682620,  training time: 11.43
[454.25, 647.25, 862.5, 998.5, 1127.25]
Episode 817	 reward: -13.72	 Mean_loss: 0.24949303,  training time: 11.40
[468.25, 553.0, 805.25, 1032.75, 1123.0]
Episode 818	 reward: -13.01	 Mean_loss: 0.26461321,  training time: 11.43
[441.5, 604.25, 773.25, 1009.25, 1113.0]
Episode 819	 reward: -13.37	 Mean_loss: 0.17003770,  training time: 11.41
[443.0, 587.25, 820.0, 1017.75, 1111.0]
Episode 820	 reward: -13.42	 Mean_loss: 0.23707727,  training time: 11.46
[467.75, 602.75, 859.25, 1017.75, 1183.5]
Episode 821	 reward: -13.23	 Mean_loss: 0.25411931,  training time: 11.48
[491.5, 602.5, 850.0, 1033.25, 1108.75]
Episode 822	 reward: -13.16	 Mean_loss: 0.17707607,  training time: 11.41
[463.25, 600.75, 819.25, 957.25, 1074.25]
Episode 823	 reward: -14.28	 Mean_loss: 0.14095972,  training time: 11.39
[421.75, 625.75, 851.25, 1009.0, 1131.75]
Episode 824	 reward: -13.84	 Mean_loss: 0.20516205,  training time: 11.39
[497.75, 577.5, 813.25, 1017.0, 1144.75]
Episode 825	 reward: -13.40	 Mean_loss: 0.17622294,  training time: 11.39
[498.5, 556.25, 803.25, 987.75, 1151.25]
Episode 826	 reward: -14.04	 Mean_loss: 0.24671139,  training time: 11.38
[489.0, 607.5, 805.5, 1037.25, 1115.5]
Episode 827	 reward: -12.74	 Mean_loss: 0.21043247,  training time: 11.38
[441.5, 609.0, 842.25, 1004.0, 1110.5]
Episode 828	 reward: -12.93	 Mean_loss: 0.18023123,  training time: 11.40
[523.5, 605.5, 827.5, 981.0, 1252.0]
Episode 829	 reward: -12.42	 Mean_loss: 0.37636757,  training time: 11.40
[528.25, 574.75, 865.75, 1021.75, 1204.0]
Episode 830	 reward: -13.65	 Mean_loss: 0.26907486,  training time: 11.55
[467.5, 612.0, 820.75, 992.25, 1158.25]
Episode 831	 reward: -13.30	 Mean_loss: 0.18944673,  training time: 11.54
[439.5, 625.75, 833.0, 1087.0, 1145.0]
Episode 832	 reward: -13.27	 Mean_loss: 0.23132050,  training time: 11.50
[427.75, 606.0, 847.75, 959.75, 1198.5]
Episode 833	 reward: -13.02	 Mean_loss: 0.31174016,  training time: 11.48
[467.25, 635.0, 826.5, 1015.75, 1155.75]
Episode 834	 reward: -13.62	 Mean_loss: 0.21345551,  training time: 11.47
[430.5, 584.25, 781.75, 1026.25, 1143.0]
Episode 835	 reward: -13.94	 Mean_loss: 0.17873760,  training time: 11.53
[449.0, 609.0, 856.5, 956.25, 1111.75]
Episode 836	 reward: -12.62	 Mean_loss: 0.14670677,  training time: 11.52
[471.5, 588.0, 848.25, 1024.5, 1151.75]
Episode 837	 reward: -13.53	 Mean_loss: 0.19671439,  training time: 11.46
[458.0, 584.5, 848.5, 1075.75, 1244.75]
Episode 838	 reward: -13.78	 Mean_loss: 0.37189215,  training time: 11.50
[497.0, 571.0, 890.5, 979.25, 1161.25]
Episode 839	 reward: -13.31	 Mean_loss: 0.17957421,  training time: 11.52
[433.75, 594.0, 822.75, 989.0, 1158.25]
Episode 840	 reward: -14.12	 Mean_loss: 0.23198739,  training time: 11.46
[413.0, 594.75, 846.0, 964.25, 1153.0]
Episode 841	 reward: -13.88	 Mean_loss: 0.16541037,  training time: 11.56
[442.5, 620.5, 840.5, 903.5, 1160.5]
Episode 842	 reward: -14.38	 Mean_loss: 0.18003249,  training time: 11.50
[444.75, 578.5, 813.5, 1024.75, 1173.0]
Episode 843	 reward: -13.46	 Mean_loss: 0.17225127,  training time: 11.57
[421.25, 597.0, 804.0, 1028.5, 1152.75]
Episode 844	 reward: -13.52	 Mean_loss: 0.20927502,  training time: 11.52
[378.25, 655.75, 865.5, 953.75, 1201.5]
Episode 845	 reward: -13.77	 Mean_loss: 0.20896521,  training time: 11.60
[420.5, 574.25, 813.25, 921.5, 1122.0]
Episode 846	 reward: -14.12	 Mean_loss: 0.16769865,  training time: 11.51
[405.25, 630.25, 828.0, 935.0, 1224.0]
Episode 847	 reward: -13.48	 Mean_loss: 0.24139936,  training time: 11.51
[418.25, 575.25, 836.75, 935.25, 1199.5]
Episode 848	 reward: -13.94	 Mean_loss: 0.24275635,  training time: 11.50
[415.0, 585.25, 810.5, 1012.75, 1161.0]
Episode 849	 reward: -13.45	 Mean_loss: 0.17176972,  training time: 11.50
[454.75, 608.0, 847.0, 969.25, 1212.0]
Episode 850	 reward: -14.63	 Mean_loss: 0.22145629,  training time: 11.46
[422.25, 631.25, 855.5, 951.0, 1151.25]
Episode 851	 reward: -14.52	 Mean_loss: 0.14096573,  training time: 11.47
[426.0, 588.25, 860.75, 955.0, 1167.0]
Episode 852	 reward: -14.80	 Mean_loss: 0.29964575,  training time: 11.51
[419.0, 618.25, 796.0, 1017.25, 1206.5]
Episode 853	 reward: -13.98	 Mean_loss: 0.27851617,  training time: 11.52
[428.5, 605.5, 825.0, 909.75, 1164.5]
Episode 854	 reward: -14.09	 Mean_loss: 0.21258205,  training time: 11.51
[437.5, 564.75, 814.75, 942.25, 1155.25]
Episode 855	 reward: -13.49	 Mean_loss: 0.17693597,  training time: 11.51
[442.0, 573.75, 804.0, 943.5, 1110.5]
Episode 856	 reward: -13.50	 Mean_loss: 0.20520686,  training time: 11.49
[405.0, 536.75, 883.25, 936.5, 1073.5]
Episode 857	 reward: -14.24	 Mean_loss: 0.13114628,  training time: 11.62
[476.5, 603.75, 847.5, 959.5, 1135.75]
Episode 858	 reward: -14.09	 Mean_loss: 0.21102111,  training time: 11.54
[376.0, 584.75, 863.75, 984.75, 1158.0]
Episode 859	 reward: -13.58	 Mean_loss: 0.21648054,  training time: 11.54
[422.0, 572.75, 861.0, 951.25, 1153.5]
Episode 860	 reward: -13.87	 Mean_loss: 0.17999178,  training time: 11.55
[466.0, 676.25, 819.75, 1053.25, 1227.5]
Episode 861	 reward: -13.61	 Mean_loss: 0.28953868,  training time: 11.60
[435.25, 647.5, 789.5, 1000.75, 1225.75]
Episode 862	 reward: -13.74	 Mean_loss: 0.38429892,  training time: 11.56
[451.5, 627.25, 867.5, 1035.75, 1185.0]
Episode 863	 reward: -14.17	 Mean_loss: 0.26842812,  training time: 11.58
[392.25, 630.25, 799.0, 1007.75, 1156.5]
Episode 864	 reward: -13.81	 Mean_loss: 0.22371416,  training time: 11.61
[455.5, 631.25, 854.0, 1042.75, 1170.5]
Episode 865	 reward: -14.32	 Mean_loss: 0.18744336,  training time: 11.60
[435.75, 624.5, 771.75, 1045.75, 1176.5]
Episode 866	 reward: -14.02	 Mean_loss: 0.21755259,  training time: 11.61
[421.75, 631.75, 801.25, 1049.25, 1143.0]
Episode 867	 reward: -13.69	 Mean_loss: 0.24799885,  training time: 11.57
[403.75, 658.0, 850.5, 987.0, 1143.5]
Episode 868	 reward: -13.70	 Mean_loss: 0.21711786,  training time: 11.55
[461.25, 687.0, 803.0, 991.75, 1100.0]
Episode 869	 reward: -12.92	 Mean_loss: 0.15427190,  training time: 11.68
[468.0, 619.5, 814.0, 1021.5, 1211.75]
Episode 870	 reward: -13.76	 Mean_loss: 0.29768264,  training time: 11.61
[431.5, 700.5, 818.5, 1067.0, 1197.0]
Episode 871	 reward: -14.38	 Mean_loss: 0.19721283,  training time: 11.57
[437.25, 630.5, 796.75, 1014.75, 1160.0]
Episode 872	 reward: -12.88	 Mean_loss: 0.24823008,  training time: 11.64
[482.25, 641.5, 820.5, 1062.75, 1145.75]
Episode 873	 reward: -14.23	 Mean_loss: 0.29825094,  training time: 11.61
[430.25, 651.5, 789.0, 1021.25, 1151.0]
Episode 874	 reward: -13.21	 Mean_loss: 0.17325883,  training time: 11.56
[454.0, 648.0, 790.75, 1003.0, 1177.75]
Episode 875	 reward: -13.29	 Mean_loss: 0.33084548,  training time: 11.53
[423.5, 620.25, 766.0, 997.0, 1200.25]
Episode 876	 reward: -14.02	 Mean_loss: 0.21024065,  training time: 11.54
[462.5, 641.5, 801.75, 964.0, 1148.25]
Episode 877	 reward: -13.65	 Mean_loss: 0.18836392,  training time: 11.59
[492.75, 680.0, 785.5, 990.25, 1153.25]
Episode 878	 reward: -13.94	 Mean_loss: 0.17397697,  training time: 11.58
[482.75, 678.25, 823.0, 1019.5, 1165.75]
Episode 879	 reward: -14.02	 Mean_loss: 0.16458890,  training time: 11.51
[405.0, 617.5, 837.75, 993.75, 1176.75]
Episode 880	 reward: -14.01	 Mean_loss: 0.26477659,  training time: 11.54
[472.25, 665.25, 879.25, 916.75, 1129.25]
Episode 881	 reward: -13.95	 Mean_loss: 0.20615780,  training time: 11.60
[452.25, 660.0, 832.5, 940.0, 1194.75]
Episode 882	 reward: -13.89	 Mean_loss: 0.46689311,  training time: 11.48
[429.25, 645.75, 911.5, 909.25, 1138.75]
Episode 883	 reward: -13.46	 Mean_loss: 0.10703968,  training time: 11.49
[481.5, 676.0, 776.5, 925.75, 1184.75]
Episode 884	 reward: -13.36	 Mean_loss: 0.26558399,  training time: 11.50
[447.5, 681.25, 872.0, 961.75, 1144.0]
Episode 885	 reward: -14.48	 Mean_loss: 0.23290510,  training time: 11.52
[440.0, 631.0, 872.25, 964.5, 1105.75]
Episode 886	 reward: -13.11	 Mean_loss: 0.15614086,  training time: 11.45
[412.75, 607.25, 838.5, 972.0, 1183.75]
Episode 887	 reward: -13.77	 Mean_loss: 0.23007539,  training time: 11.40
[434.25, 643.0, 868.0, 932.25, 1226.5]
Episode 888	 reward: -13.88	 Mean_loss: 0.25334039,  training time: 11.40
[434.25, 616.25, 888.25, 985.25, 1078.25]
Episode 889	 reward: -13.68	 Mean_loss: 0.17021625,  training time: 11.47
[439.5, 613.5, 861.0, 900.25, 1111.5]
Episode 890	 reward: -13.26	 Mean_loss: 0.13939689,  training time: 11.36
[446.75, 665.25, 842.5, 891.25, 1179.75]
Episode 891	 reward: -13.03	 Mean_loss: 0.18397282,  training time: 11.36
[388.25, 624.5, 882.5, 921.5, 1194.25]
Episode 892	 reward: -14.32	 Mean_loss: 0.26193559,  training time: 11.41
[411.0, 659.0, 893.75, 991.25, 1188.25]
Episode 893	 reward: -13.51	 Mean_loss: 0.24006273,  training time: 11.33
[417.0, 621.0, 864.5, 947.0, 1115.0]
Episode 894	 reward: -12.96	 Mean_loss: 0.15651055,  training time: 11.38
[424.5, 629.25, 828.75, 901.75, 1172.0]
Episode 895	 reward: -13.30	 Mean_loss: 0.25114414,  training time: 11.32
[426.75, 638.5, 893.25, 1040.75, 1115.25]
Episode 896	 reward: -13.56	 Mean_loss: 0.17254758,  training time: 11.39
[434.5, 611.0, 843.25, 936.75, 1193.0]
Episode 897	 reward: -13.87	 Mean_loss: 0.22369690,  training time: 11.40
[471.5, 664.25, 876.75, 887.5, 1185.25]
Episode 898	 reward: -13.94	 Mean_loss: 0.15944217,  training time: 11.39
[379.25, 693.25, 811.75, 1000.5, 1169.75]
Episode 899	 reward: -13.66	 Mean_loss: 0.19417745,  training time: 11.43
[467.5, 656.5, 849.0, 916.75, 1148.0]
Episode 900	 reward: -13.76	 Mean_loss: 0.15859932,  training time: 11.40
[459.25, 625.75, 772.5, 998.25, 1204.5]
Episode 901	 reward: -14.26	 Mean_loss: 0.18314622,  training time: 11.44
[468.25, 608.25, 723.5, 937.5, 1174.25]
Episode 902	 reward: -13.68	 Mean_loss: 0.25113687,  training time: 11.42
[454.5, 650.5, 784.25, 945.5, 1252.25]
Episode 903	 reward: -14.06	 Mean_loss: 0.28359032,  training time: 11.38
[480.75, 655.5, 733.0, 999.75, 1226.0]
Episode 904	 reward: -14.55	 Mean_loss: 0.25509572,  training time: 11.41
[471.5, 634.75, 734.75, 958.75, 1203.0]
Episode 905	 reward: -13.57	 Mean_loss: 0.23238043,  training time: 11.39
[487.75, 624.5, 790.75, 939.0, 1166.75]
Episode 906	 reward: -14.43	 Mean_loss: 0.14949599,  training time: 11.44
[462.0, 624.25, 811.5, 972.75, 1196.5]
Episode 907	 reward: -14.49	 Mean_loss: 0.19635229,  training time: 11.43
[407.25, 653.75, 748.75, 962.0, 1253.0]
Episode 908	 reward: -13.82	 Mean_loss: 0.30112776,  training time: 11.41
[473.25, 609.75, 757.5, 999.0, 1201.0]
Episode 909	 reward: -14.47	 Mean_loss: 0.19081584,  training time: 11.40
[493.25, 627.0, 741.0, 927.0, 1210.0]
Episode 910	 reward: -14.21	 Mean_loss: 0.24145420,  training time: 11.40
[462.25, 642.5, 736.0, 946.5, 1236.5]
Episode 911	 reward: -13.26	 Mean_loss: 0.24790673,  training time: 11.42
[488.75, 581.75, 716.75, 937.5, 1217.5]
Episode 912	 reward: -14.02	 Mean_loss: 0.21773094,  training time: 11.40
[450.0, 611.5, 755.5, 887.5, 1220.0]
Episode 913	 reward: -14.33	 Mean_loss: 0.35141462,  training time: 11.38
[467.5, 666.75, 757.75, 1045.75, 1182.5]
Episode 914	 reward: -13.45	 Mean_loss: 0.18194175,  training time: 11.39
[450.25, 680.0, 736.0, 997.25, 1179.5]
Episode 915	 reward: -14.03	 Mean_loss: 0.20268454,  training time: 11.38
[437.75, 625.5, 806.0, 944.5, 1233.0]
Episode 916	 reward: -15.01	 Mean_loss: 0.18104038,  training time: 11.42
[460.5, 574.25, 755.75, 922.5, 1202.75]
Episode 917	 reward: -13.90	 Mean_loss: 0.26223701,  training time: 11.39
[460.5, 612.75, 729.0, 960.75, 1234.75]
Episode 918	 reward: -13.93	 Mean_loss: 0.16776939,  training time: 11.38
[431.5, 603.75, 791.75, 958.25, 1292.5]
Episode 919	 reward: -14.69	 Mean_loss: 0.34615946,  training time: 11.44
[459.0, 613.5, 768.5, 964.75, 1161.0]
Episode 920	 reward: -13.89	 Mean_loss: 0.23784241,  training time: 11.39
[441.25, 651.5, 742.25, 947.25, 1153.25]
Episode 921	 reward: -13.73	 Mean_loss: 0.19243041,  training time: 11.48
[400.0, 605.0, 781.25, 974.0, 1186.0]
Episode 922	 reward: -13.91	 Mean_loss: 0.21892808,  training time: 11.51
[416.0, 691.75, 834.0, 921.5, 1228.75]
Episode 923	 reward: -13.76	 Mean_loss: 0.32507604,  training time: 11.38
[381.0, 669.25, 830.25, 971.75, 1199.75]
Episode 924	 reward: -14.01	 Mean_loss: 0.23670894,  training time: 11.38
[449.75, 641.75, 837.75, 983.0, 1216.5]
Episode 925	 reward: -13.93	 Mean_loss: 0.35091284,  training time: 11.41
[447.5, 683.25, 870.75, 947.25, 1166.5]
Episode 926	 reward: -13.88	 Mean_loss: 0.19455129,  training time: 11.44
[413.25, 654.75, 793.5, 984.5, 1231.75]
Episode 927	 reward: -13.52	 Mean_loss: 0.39113817,  training time: 11.38
[413.75, 632.5, 817.25, 924.5, 1167.0]
Episode 928	 reward: -13.99	 Mean_loss: 0.16459256,  training time: 11.39
[418.25, 672.25, 789.75, 941.75, 1194.0]
Episode 929	 reward: -13.74	 Mean_loss: 0.33409125,  training time: 11.41
[482.25, 650.5, 833.5, 970.75, 1246.25]
Episode 930	 reward: -13.86	 Mean_loss: 0.39185274,  training time: 11.40
[446.5, 653.25, 821.0, 1005.5, 1234.25]
Episode 931	 reward: -14.68	 Mean_loss: 0.43583447,  training time: 11.39
[439.75, 616.25, 825.75, 955.5, 1127.5]
Episode 932	 reward: -13.74	 Mean_loss: 0.24091385,  training time: 11.43
[460.25, 615.25, 834.5, 950.0, 1164.25]
Episode 933	 reward: -13.64	 Mean_loss: 0.26824513,  training time: 11.41
[434.25, 646.0, 806.75, 924.25, 1168.25]
Episode 934	 reward: -13.80	 Mean_loss: 0.24431285,  training time: 11.39
[469.75, 647.5, 885.25, 973.25, 1234.25]
Episode 935	 reward: -14.09	 Mean_loss: 0.40781239,  training time: 11.39
[459.5, 667.25, 825.75, 964.0, 1215.0]
Episode 936	 reward: -13.32	 Mean_loss: 0.25555158,  training time: 11.42
[414.0, 691.0, 815.75, 936.75, 1176.5]
Episode 937	 reward: -14.14	 Mean_loss: 0.28105891,  training time: 11.38
[450.75, 657.5, 848.5, 929.0, 1269.75]
Episode 938	 reward: -14.15	 Mean_loss: 0.46054688,  training time: 11.41
[434.25, 672.75, 843.25, 1013.75, 1159.75]
Episode 939	 reward: -14.00	 Mean_loss: 0.21420883,  training time: 11.39
[434.25, 628.0, 783.25, 932.25, 1138.75]
Episode 940	 reward: -14.04	 Mean_loss: 0.24204139,  training time: 11.36
[432.0, 580.0, 891.5, 900.25, 1312.5]
Episode 941	 reward: -14.61	 Mean_loss: 0.37667760,  training time: 11.47
[434.0, 707.75, 863.25, 892.0, 1221.75]
Episode 942	 reward: -14.03	 Mean_loss: 0.19728170,  training time: 11.39
[408.25, 630.25, 825.0, 1007.25, 1292.25]
Episode 943	 reward: -14.34	 Mean_loss: 0.40325516,  training time: 11.40
[429.0, 652.25, 848.5, 924.5, 1313.0]
Episode 944	 reward: -14.53	 Mean_loss: 0.54197419,  training time: 11.39
[424.5, 628.5, 818.25, 912.5, 1274.75]
Episode 945	 reward: -14.82	 Mean_loss: 0.21975724,  training time: 11.38
[406.5, 632.75, 826.0, 883.25, 1266.75]
Episode 946	 reward: -13.65	 Mean_loss: 0.30286792,  training time: 11.36
[433.75, 651.5, 795.25, 912.5, 1231.75]
Episode 947	 reward: -14.22	 Mean_loss: 0.33208066,  training time: 11.39
[428.5, 616.5, 851.5, 938.75, 1303.0]
Episode 948	 reward: -14.20	 Mean_loss: 0.34027743,  training time: 11.38
[414.25, 613.75, 846.5, 1000.75, 1232.0]
Episode 949	 reward: -14.29	 Mean_loss: 0.17771474,  training time: 11.37
[381.75, 645.5, 848.0, 947.25, 1247.75]
Episode 950	 reward: -14.88	 Mean_loss: 0.31022134,  training time: 11.43
[406.75, 616.0, 814.25, 965.25, 1231.0]
Episode 951	 reward: -13.67	 Mean_loss: 0.22770880,  training time: 11.40
[423.75, 623.75, 855.5, 893.75, 1284.75]
Episode 952	 reward: -14.67	 Mean_loss: 0.29018065,  training time: 11.38
[397.75, 580.0, 789.0, 891.5, 1196.25]
Episode 953	 reward: -14.42	 Mean_loss: 0.19502814,  training time: 11.43
[394.5, 605.0, 805.5, 944.25, 1244.0]
Episode 954	 reward: -15.08	 Mean_loss: 0.28417081,  training time: 11.42
[404.75, 599.25, 842.25, 921.5, 1242.75]
Episode 955	 reward: -15.03	 Mean_loss: 0.21908669,  training time: 11.43
[442.5, 632.25, 827.25, 879.5, 1228.25]
Episode 956	 reward: -14.45	 Mean_loss: 0.19500352,  training time: 11.44
[395.0, 608.5, 806.75, 935.25, 1179.25]
Episode 957	 reward: -14.02	 Mean_loss: 0.13861150,  training time: 11.44
[409.5, 613.5, 888.5, 893.0, 1294.75]
Episode 958	 reward: -14.65	 Mean_loss: 0.33336547,  training time: 11.41
[406.25, 619.75, 864.0, 961.25, 1224.25]
Episode 959	 reward: -15.49	 Mean_loss: 0.21575439,  training time: 11.39
[414.25, 600.75, 861.5, 880.75, 1321.75]
Episode 960	 reward: -14.50	 Mean_loss: 0.61115295,  training time: 11.41
[451.0, 589.75, 724.25, 938.5, 1184.0]
Episode 961	 reward: -13.68	 Mean_loss: 0.23529884,  training time: 11.45
[427.5, 582.75, 727.75, 944.0, 1127.5]
Episode 962	 reward: -13.39	 Mean_loss: 0.19992729,  training time: 11.43
[454.25, 560.25, 734.75, 877.0, 1191.75]
Episode 963	 reward: -13.31	 Mean_loss: 0.27245024,  training time: 11.43
[480.0, 530.5, 764.75, 919.5, 1183.0]
Episode 964	 reward: -13.55	 Mean_loss: 0.26486447,  training time: 11.44
[410.75, 546.25, 758.25, 894.75, 1229.5]
Episode 965	 reward: -14.11	 Mean_loss: 0.24676132,  training time: 11.51
[410.5, 557.0, 789.25, 874.75, 1230.0]
Episode 966	 reward: -15.24	 Mean_loss: 0.25926858,  training time: 11.35
[424.0, 605.0, 764.0, 926.75, 1222.25]
Episode 967	 reward: -14.33	 Mean_loss: 0.27516824,  training time: 11.37
[431.25, 592.0, 722.0, 895.25, 1154.75]
Episode 968	 reward: -13.37	 Mean_loss: 0.15987076,  training time: 11.36
[459.0, 559.5, 712.0, 903.0, 1164.75]
Episode 969	 reward: -14.19	 Mean_loss: 0.21555102,  training time: 11.45
[425.5, 564.25, 745.5, 922.25, 1171.5]
Episode 970	 reward: -12.75	 Mean_loss: 0.31540650,  training time: 11.44
[419.0, 550.5, 723.0, 920.0, 1239.5]
Episode 971	 reward: -14.30	 Mean_loss: 0.35979435,  training time: 11.47
[471.75, 561.5, 786.25, 960.5, 1135.5]
Episode 972	 reward: -13.60	 Mean_loss: 0.17028730,  training time: 11.43
[449.75, 617.5, 724.5, 941.0, 1177.5]
Episode 973	 reward: -14.06	 Mean_loss: 0.20817591,  training time: 11.41
[433.5, 563.25, 741.5, 951.25, 1174.5]
Episode 974	 reward: -13.94	 Mean_loss: 0.24053648,  training time: 11.41
[480.25, 558.75, 730.5, 915.5, 1126.25]
Episode 975	 reward: -13.97	 Mean_loss: 0.29375467,  training time: 11.40
[447.25, 564.5, 733.0, 886.25, 1191.5]
Episode 976	 reward: -14.05	 Mean_loss: 0.22335672,  training time: 11.39
[467.25, 569.75, 745.25, 931.25, 1205.0]
Episode 977	 reward: -13.22	 Mean_loss: 0.31368506,  training time: 11.36
[424.25, 566.0, 780.0, 936.75, 1191.75]
Episode 978	 reward: -14.38	 Mean_loss: 0.22437748,  training time: 11.35
[464.25, 591.75, 785.75, 887.25, 1192.75]
Episode 979	 reward: -13.78	 Mean_loss: 0.23125556,  training time: 11.39
[440.25, 538.0, 740.5, 941.0, 1208.0]
Episode 980	 reward: -13.60	 Mean_loss: 0.23529273,  training time: 11.35
[409.5, 587.5, 776.5, 1093.0, 1247.5]
Episode 981	 reward: -14.72	 Mean_loss: 0.40494117,  training time: 11.43
[400.5, 600.0, 768.25, 1009.5, 1203.25]
Episode 982	 reward: -14.48	 Mean_loss: 0.22645602,  training time: 11.38
[402.0, 567.25, 804.25, 1073.0, 1228.25]
Episode 983	 reward: -13.80	 Mean_loss: 0.28111294,  training time: 11.39
[403.5, 613.0, 786.25, 1024.5, 1247.0]
Episode 984	 reward: -15.12	 Mean_loss: 0.26505214,  training time: 11.40
[385.75, 626.75, 758.5, 999.0, 1208.75]
Episode 985	 reward: -14.00	 Mean_loss: 0.22571473,  training time: 11.41
[405.5, 620.5, 784.25, 1058.75, 1248.25]
Episode 986	 reward: -13.70	 Mean_loss: 0.23519027,  training time: 11.43
[407.25, 614.25, 796.25, 991.25, 1209.0]
Episode 987	 reward: -13.73	 Mean_loss: 0.22395293,  training time: 11.44
[424.75, 625.75, 778.0, 1028.75, 1138.75]
Episode 988	 reward: -13.54	 Mean_loss: 0.22305235,  training time: 11.46
[406.5, 618.75, 806.5, 1003.0, 1227.25]
Episode 989	 reward: -13.68	 Mean_loss: 0.27618331,  training time: 11.44
[447.0, 597.75, 786.75, 964.75, 1170.5]
Episode 990	 reward: -13.71	 Mean_loss: 0.19389820,  training time: 11.45
[373.25, 624.5, 757.0, 1067.0, 1249.5]
Episode 991	 reward: -14.56	 Mean_loss: 0.30076686,  training time: 11.45
[392.5, 617.25, 824.75, 1003.25, 1241.0]
Episode 992	 reward: -13.41	 Mean_loss: 0.29126233,  training time: 11.45
[440.0, 650.25, 821.75, 1052.25, 1263.25]
Episode 993	 reward: -13.92	 Mean_loss: 0.27770916,  training time: 11.46
[406.0, 580.5, 773.5, 995.75, 1204.5]
Episode 994	 reward: -16.04	 Mean_loss: 0.23810041,  training time: 11.47
[446.75, 628.75, 739.75, 1112.25, 1231.25]
Episode 995	 reward: -14.44	 Mean_loss: 0.18195315,  training time: 11.36
[427.25, 572.5, 796.5, 988.5, 1173.25]
Episode 996	 reward: -13.99	 Mean_loss: 0.12411887,  training time: 11.42
[404.25, 578.25, 823.75, 1085.0, 1258.75]
Episode 997	 reward: -13.93	 Mean_loss: 0.28918079,  training time: 11.27
[418.25, 631.5, 724.25, 1122.5, 1177.25]
Episode 998	 reward: -13.98	 Mean_loss: 0.17396890,  training time: 11.30
[387.5, 593.5, 747.5, 1060.5, 1283.5]
Episode 999	 reward: -14.63	 Mean_loss: 0.30984014,  training time: 11.27
[382.0, 601.75, 764.5, 983.75, 1214.25]
Episode 1000	 reward: -14.11	 Mean_loss: 0.19132508,  training time: 11.24
+ logdir_maml_finetuning=./runs/exp15/maml_finetuning
+ model=maml+exp15_1000_64_3
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob4 --model_suffix exp13_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp13_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.82	 makespan: 576.50	 Mean_loss: 0.40191680,  training time: 2.02
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:02<01:39,  2.02s/it]                                                        Episode 2	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.12636000,  training time: 0.87
progress:   2%|[34m▏         [0m| 1/50 [00:02<01:39,  2.02s/it]progress:   4%|[34m▍         [0m| 2/50 [00:02<01:04,  1.35s/it]                                                        Episode 3	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.10313880,  training time: 0.89
progress:   4%|[34m▍         [0m| 2/50 [00:03<01:04,  1.35s/it]progress:   6%|[34m▌         [0m| 3/50 [00:03<00:53,  1.14s/it]                                                        Episode 4	 reward: -4.81	 makespan: 475.75	 Mean_loss: 0.12481765,  training time: 0.87
progress:   6%|[34m▌         [0m| 3/50 [00:04<00:53,  1.14s/it]progress:   8%|[34m▊         [0m| 4/50 [00:04<00:47,  1.03s/it]                                                        Episode 5	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.11468191,  training time: 0.84
progress:   8%|[34m▊         [0m| 4/50 [00:05<00:47,  1.03s/it]progress:  10%|[34m█         [0m| 5/50 [00:05<00:43,  1.04it/s]                                                        Episode 6	 reward: -5.09	 makespan: 503.75	 Mean_loss: 0.11043388,  training time: 0.85
progress:  10%|[34m█         [0m| 5/50 [00:06<00:43,  1.04it/s]progress:  12%|[34m█▏        [0m| 6/50 [00:06<00:40,  1.08it/s]                                                        Episode 7	 reward: -4.42	 makespan: 437.75	 Mean_loss: 0.06855130,  training time: 0.86
progress:  12%|[34m█▏        [0m| 6/50 [00:07<00:40,  1.08it/s]progress:  14%|[34m█▍        [0m| 7/50 [00:07<00:38,  1.11it/s]                                                        Episode 8	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.07998642,  training time: 0.89
progress:  14%|[34m█▍        [0m| 7/50 [00:08<00:38,  1.11it/s]progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:37,  1.11it/s]                                                        Episode 9	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.12108960,  training time: 0.91
progress:  16%|[34m█▌        [0m| 8/50 [00:09<00:37,  1.11it/s]progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:37,  1.11it/s]                                                        Episode 10	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.07928500,  training time: 0.88
progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:37,  1.11it/s]progress:  20%|[34m██        [0m| 10/50 [00:09<00:35,  1.12it/s]                                                         Episode 11	 reward: -4.58	 makespan: 453.75	 Mean_loss: 0.03100837,  training time: 0.91
progress:  20%|[34m██        [0m| 10/50 [00:10<00:35,  1.12it/s]progress:  22%|[34m██▏       [0m| 11/50 [00:10<00:35,  1.11it/s]                                                         Episode 12	 reward: -4.72	 makespan: 467.50	 Mean_loss: 0.03268960,  training time: 0.87
progress:  22%|[34m██▏       [0m| 11/50 [00:11<00:35,  1.11it/s]progress:  24%|[34m██▍       [0m| 12/50 [00:11<00:33,  1.12it/s]                                                         Episode 13	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.04591559,  training time: 0.91
progress:  24%|[34m██▍       [0m| 12/50 [00:12<00:33,  1.12it/s]progress:  26%|[34m██▌       [0m| 13/50 [00:12<00:33,  1.12it/s]                                                         Episode 14	 reward: -4.69	 makespan: 464.75	 Mean_loss: 0.06640686,  training time: 0.89
progress:  26%|[34m██▌       [0m| 13/50 [00:13<00:33,  1.12it/s]progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:32,  1.12it/s]                                                         Episode 15	 reward: -4.37	 makespan: 432.75	 Mean_loss: 0.04918668,  training time: 0.86
progress:  28%|[34m██▊       [0m| 14/50 [00:14<00:32,  1.12it/s]progress:  30%|[34m███       [0m| 15/50 [00:14<00:31,  1.13it/s]                                                         Episode 16	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.15885220,  training time: 0.85
progress:  30%|[34m███       [0m| 15/50 [00:15<00:31,  1.13it/s]progress:  32%|[34m███▏      [0m| 16/50 [00:15<00:29,  1.14it/s]                                                         Episode 17	 reward: -4.47	 makespan: 442.50	 Mean_loss: 0.08440518,  training time: 0.89
progress:  32%|[34m███▏      [0m| 16/50 [00:16<00:29,  1.14it/s]progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:29,  1.14it/s]                                                         Episode 18	 reward: -4.88	 makespan: 483.50	 Mean_loss: 0.13404649,  training time: 0.85
progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:29,  1.14it/s]progress:  36%|[34m███▌      [0m| 18/50 [00:16<00:27,  1.15it/s]                                                         Episode 19	 reward: -4.46	 makespan: 442.00	 Mean_loss: 0.07250276,  training time: 0.86
progress:  36%|[34m███▌      [0m| 18/50 [00:17<00:27,  1.15it/s]progress:  38%|[34m███▊      [0m| 19/50 [00:17<00:26,  1.15it/s]                                                         Episode 20	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.04927484,  training time: 0.90
progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:26,  1.15it/s]progress:  40%|[34m████      [0m| 20/50 [00:18<00:26,  1.14it/s]                                                         Episode 21	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.06154817,  training time: 0.85
progress:  40%|[34m████      [0m| 20/50 [00:19<00:26,  1.14it/s]progress:  42%|[34m████▏     [0m| 21/50 [00:19<00:25,  1.15it/s]                                                         Episode 22	 reward: -4.27	 makespan: 422.25	 Mean_loss: 0.06213286,  training time: 0.89
progress:  42%|[34m████▏     [0m| 21/50 [00:20<00:25,  1.15it/s]progress:  44%|[34m████▍     [0m| 22/50 [00:20<00:24,  1.14it/s]                                                         Episode 23	 reward: -4.42	 makespan: 437.50	 Mean_loss: 0.05234169,  training time: 0.93
progress:  44%|[34m████▍     [0m| 22/50 [00:21<00:24,  1.14it/s]progress:  46%|[34m████▌     [0m| 23/50 [00:21<00:24,  1.12it/s]                                                         Episode 24	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.05900634,  training time: 0.85
progress:  46%|[34m████▌     [0m| 23/50 [00:22<00:24,  1.12it/s]progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:22,  1.14it/s]                                                         Episode 25	 reward: -4.57	 makespan: 452.00	 Mean_loss: 0.07158193,  training time: 0.88
progress:  48%|[34m████▊     [0m| 24/50 [00:23<00:22,  1.14it/s]progress:  50%|[34m█████     [0m| 25/50 [00:23<00:21,  1.14it/s]                                                         Episode 26	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.03984592,  training time: 0.86
progress:  50%|[34m█████     [0m| 25/50 [00:23<00:21,  1.14it/s]progress:  52%|[34m█████▏    [0m| 26/50 [00:23<00:20,  1.15it/s]                                                         Episode 27	 reward: -4.01	 makespan: 396.75	 Mean_loss: 0.03485707,  training time: 0.90
progress:  52%|[34m█████▏    [0m| 26/50 [00:24<00:20,  1.15it/s]progress:  54%|[34m█████▍    [0m| 27/50 [00:24<00:20,  1.13it/s]                                                         Episode 28	 reward: -4.40	 makespan: 436.00	 Mean_loss: 0.02730844,  training time: 0.84
progress:  54%|[34m█████▍    [0m| 27/50 [00:25<00:20,  1.13it/s]progress:  56%|[34m█████▌    [0m| 28/50 [00:25<00:19,  1.15it/s]                                                         Episode 29	 reward: -4.56	 makespan: 451.25	 Mean_loss: 0.05349950,  training time: 0.86
progress:  56%|[34m█████▌    [0m| 28/50 [00:26<00:19,  1.15it/s]progress:  58%|[34m█████▊    [0m| 29/50 [00:26<00:18,  1.15it/s]                                                         Episode 30	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.03492607,  training time: 0.87
progress:  58%|[34m█████▊    [0m| 29/50 [00:27<00:18,  1.15it/s]progress:  60%|[34m██████    [0m| 30/50 [00:27<00:17,  1.15it/s]                                                         Episode 31	 reward: -4.56	 makespan: 451.00	 Mean_loss: 0.04861987,  training time: 0.91
progress:  60%|[34m██████    [0m| 30/50 [00:28<00:17,  1.15it/s]progress:  62%|[34m██████▏   [0m| 31/50 [00:28<00:16,  1.13it/s]                                                         Episode 32	 reward: -4.74	 makespan: 469.75	 Mean_loss: 0.02771069,  training time: 0.91
progress:  62%|[34m██████▏   [0m| 31/50 [00:29<00:16,  1.13it/s]progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:16,  1.12it/s]                                                         Episode 33	 reward: -4.45	 makespan: 441.00	 Mean_loss: 0.03330266,  training time: 0.88
progress:  64%|[34m██████▍   [0m| 32/50 [00:30<00:16,  1.12it/s]progress:  66%|[34m██████▌   [0m| 33/50 [00:30<00:15,  1.13it/s]                                                         Episode 34	 reward: -4.51	 makespan: 446.25	 Mean_loss: 0.04183808,  training time: 0.90
progress:  66%|[34m██████▌   [0m| 33/50 [00:31<00:15,  1.13it/s]progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:14,  1.12it/s]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.02752976,  training time: 0.90
progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:14,  1.12it/s]progress:  70%|[34m███████   [0m| 35/50 [00:31<00:13,  1.12it/s]                                                         Episode 36	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.04761191,  training time: 0.89
progress:  70%|[34m███████   [0m| 35/50 [00:32<00:13,  1.12it/s]progress:  72%|[34m███████▏  [0m| 36/50 [00:32<00:12,  1.12it/s]                                                         Episode 37	 reward: -4.56	 makespan: 451.75	 Mean_loss: 0.04792244,  training time: 0.90
progress:  72%|[34m███████▏  [0m| 36/50 [00:33<00:12,  1.12it/s]progress:  74%|[34m███████▍  [0m| 37/50 [00:33<00:11,  1.12it/s]                                                         Episode 38	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.02249994,  training time: 0.88
progress:  74%|[34m███████▍  [0m| 37/50 [00:34<00:11,  1.12it/s]progress:  76%|[34m███████▌  [0m| 38/50 [00:34<00:10,  1.12it/s]                                                         Episode 39	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.01629904,  training time: 0.90
progress:  76%|[34m███████▌  [0m| 38/50 [00:35<00:10,  1.12it/s]progress:  78%|[34m███████▊  [0m| 39/50 [00:35<00:09,  1.12it/s]                                                         Episode 40	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.02778888,  training time: 0.88
progress:  78%|[34m███████▊  [0m| 39/50 [00:36<00:09,  1.12it/s]progress:  80%|[34m████████  [0m| 40/50 [00:36<00:08,  1.12it/s]                                                         Episode 41	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.10707261,  training time: 0.90
progress:  80%|[34m████████  [0m| 40/50 [00:37<00:08,  1.12it/s]progress:  82%|[34m████████▏ [0m| 41/50 [00:37<00:08,  1.12it/s]                                                         Episode 42	 reward: -4.56	 makespan: 451.50	 Mean_loss: 0.04915689,  training time: 0.90
progress:  82%|[34m████████▏ [0m| 41/50 [00:38<00:08,  1.12it/s]progress:  84%|[34m████████▍ [0m| 42/50 [00:38<00:07,  1.12it/s]                                                         Episode 43	 reward: -4.67	 makespan: 462.00	 Mean_loss: 0.02471277,  training time: 0.91
progress:  84%|[34m████████▍ [0m| 42/50 [00:39<00:07,  1.12it/s]progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.11it/s]                                                         Episode 44	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.06165908,  training time: 0.90
progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.11it/s]progress:  88%|[34m████████▊ [0m| 44/50 [00:39<00:05,  1.11it/s]                                                         Episode 45	 reward: -4.91	 makespan: 486.25	 Mean_loss: 0.02938607,  training time: 0.87
progress:  88%|[34m████████▊ [0m| 44/50 [00:40<00:05,  1.11it/s]progress:  90%|[34m█████████ [0m| 45/50 [00:40<00:04,  1.12it/s]                                                         Episode 46	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.07713498,  training time: 0.90
progress:  90%|[34m█████████ [0m| 45/50 [00:41<00:04,  1.12it/s]progress:  92%|[34m█████████▏[0m| 46/50 [00:41<00:03,  1.12it/s]                                                         Episode 47	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.04396790,  training time: 0.92
progress:  92%|[34m█████████▏[0m| 46/50 [00:42<00:03,  1.12it/s]progress:  94%|[34m█████████▍[0m| 47/50 [00:42<00:02,  1.11it/s]                                                         Episode 48	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.05814299,  training time: 0.91
progress:  94%|[34m█████████▍[0m| 47/50 [00:43<00:02,  1.11it/s]progress:  96%|[34m█████████▌[0m| 48/50 [00:43<00:01,  1.11it/s]                                                         Episode 49	 reward: -4.76	 makespan: 471.00	 Mean_loss: 0.08827530,  training time: 0.89
progress:  96%|[34m█████████▌[0m| 48/50 [00:44<00:01,  1.11it/s]progress:  98%|[34m█████████▊[0m| 49/50 [00:44<00:00,  1.11it/s]                                                         Episode 50	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.09780839,  training time: 0.88
progress:  98%|[34m█████████▊[0m| 49/50 [00:45<00:00,  1.11it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.12it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.10it/s]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob6 --model_suffix exp13_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp13_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.82	 makespan: 576.50	 Mean_loss: 0.40191680,  training time: 1.95
progress:   0%|[34m          [0m| 0/50 [00:01<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:01<01:35,  1.95s/it]                                                        Episode 2	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.12636000,  training time: 0.88
progress:   2%|[34m▏         [0m| 1/50 [00:02<01:35,  1.95s/it]progress:   4%|[34m▍         [0m| 2/50 [00:02<01:03,  1.32s/it]                                                        Episode 3	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.10313880,  training time: 0.88
progress:   4%|[34m▍         [0m| 2/50 [00:03<01:03,  1.32s/it]progress:   6%|[34m▌         [0m| 3/50 [00:03<00:52,  1.12s/it]                                                        Episode 4	 reward: -4.81	 makespan: 475.75	 Mean_loss: 0.12481765,  training time: 0.86
progress:   6%|[34m▌         [0m| 3/50 [00:04<00:52,  1.12s/it]progress:   8%|[34m▊         [0m| 4/50 [00:04<00:46,  1.02s/it]                                                        Episode 5	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.11468191,  training time: 0.89
progress:   8%|[34m▊         [0m| 4/50 [00:05<00:46,  1.02s/it]progress:  10%|[34m█         [0m| 5/50 [00:05<00:43,  1.03it/s]                                                        Episode 6	 reward: -5.09	 makespan: 503.75	 Mean_loss: 0.11043388,  training time: 0.87
progress:  10%|[34m█         [0m| 5/50 [00:06<00:43,  1.03it/s]progress:  12%|[34m█▏        [0m| 6/50 [00:06<00:41,  1.07it/s]                                                        Episode 7	 reward: -4.42	 makespan: 437.75	 Mean_loss: 0.06855130,  training time: 0.89
progress:  12%|[34m█▏        [0m| 6/50 [00:07<00:41,  1.07it/s]progress:  14%|[34m█▍        [0m| 7/50 [00:07<00:39,  1.09it/s]                                                        Episode 8	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.07998642,  training time: 0.90
progress:  14%|[34m█▍        [0m| 7/50 [00:08<00:39,  1.09it/s]progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:38,  1.09it/s]                                                        Episode 9	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.12108960,  training time: 0.88
progress:  16%|[34m█▌        [0m| 8/50 [00:09<00:38,  1.09it/s]progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:37,  1.10it/s]                                                        Episode 10	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.07928500,  training time: 0.87
progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:37,  1.10it/s]progress:  20%|[34m██        [0m| 10/50 [00:09<00:35,  1.12it/s]                                                         Episode 11	 reward: -4.58	 makespan: 453.75	 Mean_loss: 0.03100837,  training time: 0.90
progress:  20%|[34m██        [0m| 10/50 [00:10<00:35,  1.12it/s]progress:  22%|[34m██▏       [0m| 11/50 [00:10<00:35,  1.11it/s]                                                         Episode 12	 reward: -4.72	 makespan: 467.50	 Mean_loss: 0.03268960,  training time: 0.90
progress:  22%|[34m██▏       [0m| 11/50 [00:11<00:35,  1.11it/s]progress:  24%|[34m██▍       [0m| 12/50 [00:11<00:34,  1.11it/s]                                                         Episode 13	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.04591559,  training time: 0.89
progress:  24%|[34m██▍       [0m| 12/50 [00:12<00:34,  1.11it/s]progress:  26%|[34m██▌       [0m| 13/50 [00:12<00:33,  1.12it/s]                                                         Episode 14	 reward: -4.69	 makespan: 464.75	 Mean_loss: 0.06640686,  training time: 0.85
progress:  26%|[34m██▌       [0m| 13/50 [00:13<00:33,  1.12it/s]progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:31,  1.13it/s]                                                         Episode 15	 reward: -4.37	 makespan: 432.75	 Mean_loss: 0.04918668,  training time: 0.93
progress:  28%|[34m██▊       [0m| 14/50 [00:14<00:31,  1.13it/s]progress:  30%|[34m███       [0m| 15/50 [00:14<00:31,  1.12it/s]                                                         Episode 16	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.15885220,  training time: 0.85
progress:  30%|[34m███       [0m| 15/50 [00:15<00:31,  1.12it/s]progress:  32%|[34m███▏      [0m| 16/50 [00:15<00:29,  1.13it/s]                                                         Episode 17	 reward: -4.47	 makespan: 442.50	 Mean_loss: 0.08440518,  training time: 0.86
progress:  32%|[34m███▏      [0m| 16/50 [00:16<00:29,  1.13it/s]progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:28,  1.14it/s]                                                         Episode 18	 reward: -4.88	 makespan: 483.50	 Mean_loss: 0.13404649,  training time: 0.86
progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:28,  1.14it/s]progress:  36%|[34m███▌      [0m| 18/50 [00:16<00:27,  1.15it/s]                                                         Episode 19	 reward: -4.46	 makespan: 442.00	 Mean_loss: 0.07250276,  training time: 0.89
progress:  36%|[34m███▌      [0m| 18/50 [00:17<00:27,  1.15it/s]progress:  38%|[34m███▊      [0m| 19/50 [00:17<00:27,  1.14it/s]                                                         Episode 20	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.04927484,  training time: 0.86
progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:27,  1.14it/s]progress:  40%|[34m████      [0m| 20/50 [00:18<00:26,  1.15it/s]                                                         Episode 21	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.06154817,  training time: 0.85
progress:  40%|[34m████      [0m| 20/50 [00:19<00:26,  1.15it/s]progress:  42%|[34m████▏     [0m| 21/50 [00:19<00:25,  1.15it/s]                                                         Episode 22	 reward: -4.27	 makespan: 422.25	 Mean_loss: 0.06213286,  training time: 0.85
progress:  42%|[34m████▏     [0m| 21/50 [00:20<00:25,  1.15it/s]progress:  44%|[34m████▍     [0m| 22/50 [00:20<00:24,  1.16it/s]                                                         Episode 23	 reward: -4.42	 makespan: 437.50	 Mean_loss: 0.05234169,  training time: 0.99
progress:  44%|[34m████▍     [0m| 22/50 [00:21<00:24,  1.16it/s]progress:  46%|[34m████▌     [0m| 23/50 [00:21<00:24,  1.11it/s]                                                         Episode 24	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.05900634,  training time: 0.89
progress:  46%|[34m████▌     [0m| 23/50 [00:22<00:24,  1.11it/s]progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:23,  1.11it/s]                                                         Episode 25	 reward: -4.57	 makespan: 452.00	 Mean_loss: 0.07158193,  training time: 0.86
progress:  48%|[34m████▊     [0m| 24/50 [00:23<00:23,  1.11it/s]progress:  50%|[34m█████     [0m| 25/50 [00:23<00:22,  1.13it/s]                                                         Episode 26	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.03984592,  training time: 0.85
progress:  50%|[34m█████     [0m| 25/50 [00:23<00:22,  1.13it/s]progress:  52%|[34m█████▏    [0m| 26/50 [00:23<00:21,  1.14it/s]                                                         Episode 27	 reward: -4.01	 makespan: 396.75	 Mean_loss: 0.03485707,  training time: 0.90
progress:  52%|[34m█████▏    [0m| 26/50 [00:24<00:21,  1.14it/s]progress:  54%|[34m█████▍    [0m| 27/50 [00:24<00:20,  1.13it/s]                                                         Episode 28	 reward: -4.40	 makespan: 436.00	 Mean_loss: 0.02730844,  training time: 0.84
progress:  54%|[34m█████▍    [0m| 27/50 [00:25<00:20,  1.13it/s]progress:  56%|[34m█████▌    [0m| 28/50 [00:25<00:19,  1.15it/s]                                                         Episode 29	 reward: -4.56	 makespan: 451.25	 Mean_loss: 0.05349950,  training time: 0.83
progress:  56%|[34m█████▌    [0m| 28/50 [00:26<00:19,  1.15it/s]progress:  58%|[34m█████▊    [0m| 29/50 [00:26<00:18,  1.17it/s]                                                         Episode 30	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.03492607,  training time: 0.84
progress:  58%|[34m█████▊    [0m| 29/50 [00:27<00:18,  1.17it/s]progress:  60%|[34m██████    [0m| 30/50 [00:27<00:17,  1.17it/s]                                                         Episode 31	 reward: -4.56	 makespan: 451.00	 Mean_loss: 0.04861987,  training time: 0.84
progress:  60%|[34m██████    [0m| 30/50 [00:28<00:17,  1.17it/s]progress:  62%|[34m██████▏   [0m| 31/50 [00:28<00:16,  1.18it/s]                                                         Episode 32	 reward: -4.74	 makespan: 469.75	 Mean_loss: 0.02771069,  training time: 0.84
progress:  62%|[34m██████▏   [0m| 31/50 [00:29<00:16,  1.18it/s]progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:15,  1.18it/s]                                                         Episode 33	 reward: -4.45	 makespan: 441.00	 Mean_loss: 0.03330266,  training time: 0.86
progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:15,  1.18it/s]progress:  66%|[34m██████▌   [0m| 33/50 [00:29<00:14,  1.18it/s]                                                         Episode 34	 reward: -4.51	 makespan: 446.25	 Mean_loss: 0.04183808,  training time: 0.88
progress:  66%|[34m██████▌   [0m| 33/50 [00:30<00:14,  1.18it/s]progress:  68%|[34m██████▊   [0m| 34/50 [00:30<00:13,  1.16it/s]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.02752976,  training time: 0.87
progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:13,  1.16it/s]progress:  70%|[34m███████   [0m| 35/50 [00:31<00:12,  1.16it/s]                                                         Episode 36	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.04761191,  training time: 0.84
progress:  70%|[34m███████   [0m| 35/50 [00:32<00:12,  1.16it/s]progress:  72%|[34m███████▏  [0m| 36/50 [00:32<00:11,  1.17it/s]                                                         Episode 37	 reward: -4.56	 makespan: 451.75	 Mean_loss: 0.04792244,  training time: 0.84
progress:  72%|[34m███████▏  [0m| 36/50 [00:33<00:11,  1.17it/s]progress:  74%|[34m███████▍  [0m| 37/50 [00:33<00:11,  1.18it/s]                                                         Episode 38	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.02249994,  training time: 0.92
progress:  74%|[34m███████▍  [0m| 37/50 [00:34<00:11,  1.18it/s]progress:  76%|[34m███████▌  [0m| 38/50 [00:34<00:10,  1.15it/s]                                                         Episode 39	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.01629904,  training time: 0.85
progress:  76%|[34m███████▌  [0m| 38/50 [00:35<00:10,  1.15it/s]progress:  78%|[34m███████▊  [0m| 39/50 [00:35<00:09,  1.15it/s]                                                         Episode 40	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.02778888,  training time: 0.85
progress:  78%|[34m███████▊  [0m| 39/50 [00:35<00:09,  1.15it/s]progress:  80%|[34m████████  [0m| 40/50 [00:35<00:08,  1.16it/s]                                                         Episode 41	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.10707261,  training time: 0.84
progress:  80%|[34m████████  [0m| 40/50 [00:36<00:08,  1.16it/s]progress:  82%|[34m████████▏ [0m| 41/50 [00:36<00:07,  1.17it/s]                                                         Episode 42	 reward: -4.56	 makespan: 451.50	 Mean_loss: 0.04915689,  training time: 0.85
progress:  82%|[34m████████▏ [0m| 41/50 [00:37<00:07,  1.17it/s]progress:  84%|[34m████████▍ [0m| 42/50 [00:37<00:06,  1.17it/s]                                                         Episode 43	 reward: -4.67	 makespan: 462.00	 Mean_loss: 0.02471277,  training time: 0.86
progress:  84%|[34m████████▍ [0m| 42/50 [00:38<00:06,  1.17it/s]progress:  86%|[34m████████▌ [0m| 43/50 [00:38<00:06,  1.17it/s]                                                         Episode 44	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.06165908,  training time: 0.85
progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.17it/s]progress:  88%|[34m████████▊ [0m| 44/50 [00:39<00:05,  1.17it/s]                                                         Episode 45	 reward: -4.91	 makespan: 486.25	 Mean_loss: 0.02938607,  training time: 0.85
progress:  88%|[34m████████▊ [0m| 44/50 [00:40<00:05,  1.17it/s]progress:  90%|[34m█████████ [0m| 45/50 [00:40<00:04,  1.17it/s]                                                         Episode 46	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.07713498,  training time: 0.84
progress:  90%|[34m█████████ [0m| 45/50 [00:41<00:04,  1.17it/s]progress:  92%|[34m█████████▏[0m| 46/50 [00:41<00:03,  1.17it/s]                                                         Episode 47	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.04396790,  training time: 0.85
progress:  92%|[34m█████████▏[0m| 46/50 [00:41<00:03,  1.17it/s]progress:  94%|[34m█████████▍[0m| 47/50 [00:41<00:02,  1.17it/s]                                                         Episode 48	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.05814299,  training time: 0.88
progress:  94%|[34m█████████▍[0m| 47/50 [00:42<00:02,  1.17it/s]progress:  96%|[34m█████████▌[0m| 48/50 [00:42<00:01,  1.16it/s]                                                         Episode 49	 reward: -4.76	 makespan: 471.00	 Mean_loss: 0.08827530,  training time: 0.84
progress:  96%|[34m█████████▌[0m| 48/50 [00:43<00:01,  1.16it/s]progress:  98%|[34m█████████▊[0m| 49/50 [00:43<00:00,  1.17it/s]                                                         Episode 50	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.09780839,  training time: 0.84
progress:  98%|[34m█████████▊[0m| 49/50 [00:44<00:00,  1.17it/s]progress: 100%|[34m██████████[0m| 50/50 [00:44<00:00,  1.17it/s]progress: 100%|[34m██████████[0m| 50/50 [00:44<00:00,  1.12it/s]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob8 --model_suffix exp13_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp13_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.82	 makespan: 576.50	 Mean_loss: 0.40191680,  training time: 1.91
progress:   0%|[34m          [0m| 0/50 [00:01<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:01<01:33,  1.91s/it]                                                        Episode 2	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.12636000,  training time: 0.93
progress:   2%|[34m▏         [0m| 1/50 [00:02<01:33,  1.91s/it]progress:   4%|[34m▍         [0m| 2/50 [00:02<01:04,  1.34s/it]                                                        Episode 3	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.10313880,  training time: 0.86
progress:   4%|[34m▍         [0m| 2/50 [00:03<01:04,  1.34s/it]progress:   6%|[34m▌         [0m| 3/50 [00:03<00:52,  1.12s/it]                                                        Episode 4	 reward: -4.81	 makespan: 475.75	 Mean_loss: 0.12481765,  training time: 0.85
progress:   6%|[34m▌         [0m| 3/50 [00:04<00:52,  1.12s/it]progress:   8%|[34m▊         [0m| 4/50 [00:04<00:46,  1.01s/it]                                                        Episode 5	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.11468191,  training time: 0.91
progress:   8%|[34m▊         [0m| 4/50 [00:05<00:46,  1.01s/it]progress:  10%|[34m█         [0m| 5/50 [00:05<00:43,  1.03it/s]                                                        Episode 6	 reward: -5.09	 makespan: 503.75	 Mean_loss: 0.11043388,  training time: 0.84
progress:  10%|[34m█         [0m| 5/50 [00:06<00:43,  1.03it/s]progress:  12%|[34m█▏        [0m| 6/50 [00:06<00:40,  1.07it/s]                                                        Episode 7	 reward: -4.42	 makespan: 437.75	 Mean_loss: 0.06855130,  training time: 0.84
progress:  12%|[34m█▏        [0m| 6/50 [00:07<00:40,  1.07it/s]progress:  14%|[34m█▍        [0m| 7/50 [00:07<00:38,  1.11it/s]                                                        Episode 8	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.07998642,  training time: 0.85
progress:  14%|[34m█▍        [0m| 7/50 [00:08<00:38,  1.11it/s]progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:37,  1.13it/s]                                                        Episode 9	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.12108960,  training time: 0.84
progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:37,  1.13it/s]progress:  18%|[34m█▊        [0m| 9/50 [00:08<00:35,  1.14it/s]                                                        Episode 10	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.07928500,  training time: 0.84
progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:35,  1.14it/s]progress:  20%|[34m██        [0m| 10/50 [00:09<00:34,  1.16it/s]                                                         Episode 11	 reward: -4.58	 makespan: 453.75	 Mean_loss: 0.03100837,  training time: 0.86
progress:  20%|[34m██        [0m| 10/50 [00:10<00:34,  1.16it/s]progress:  22%|[34m██▏       [0m| 11/50 [00:10<00:33,  1.16it/s]                                                         Episode 12	 reward: -4.72	 makespan: 467.50	 Mean_loss: 0.03268960,  training time: 0.85
progress:  22%|[34m██▏       [0m| 11/50 [00:11<00:33,  1.16it/s]progress:  24%|[34m██▍       [0m| 12/50 [00:11<00:32,  1.16it/s]                                                         Episode 13	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.04591559,  training time: 0.85
progress:  24%|[34m██▍       [0m| 12/50 [00:12<00:32,  1.16it/s]progress:  26%|[34m██▌       [0m| 13/50 [00:12<00:31,  1.17it/s]                                                         Episode 14	 reward: -4.69	 makespan: 464.75	 Mean_loss: 0.06640686,  training time: 0.84
progress:  26%|[34m██▌       [0m| 13/50 [00:13<00:31,  1.17it/s]progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:30,  1.17it/s]                                                         Episode 15	 reward: -4.37	 makespan: 432.75	 Mean_loss: 0.04918668,  training time: 0.84
progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:30,  1.17it/s]progress:  30%|[34m███       [0m| 15/50 [00:13<00:29,  1.18it/s]                                                         Episode 16	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.15885220,  training time: 0.91
progress:  30%|[34m███       [0m| 15/50 [00:14<00:29,  1.18it/s]progress:  32%|[34m███▏      [0m| 16/50 [00:14<00:29,  1.15it/s]                                                         Episode 17	 reward: -4.47	 makespan: 442.50	 Mean_loss: 0.08440518,  training time: 0.91
progress:  32%|[34m███▏      [0m| 16/50 [00:15<00:29,  1.15it/s]progress:  34%|[34m███▍      [0m| 17/50 [00:15<00:29,  1.14it/s]                                                         Episode 18	 reward: -4.88	 makespan: 483.50	 Mean_loss: 0.13404649,  training time: 0.84
progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:29,  1.14it/s]progress:  36%|[34m███▌      [0m| 18/50 [00:16<00:27,  1.15it/s]                                                         Episode 19	 reward: -4.46	 makespan: 442.00	 Mean_loss: 0.07250276,  training time: 0.83
progress:  36%|[34m███▌      [0m| 18/50 [00:17<00:27,  1.15it/s]progress:  38%|[34m███▊      [0m| 19/50 [00:17<00:26,  1.17it/s]                                                         Episode 20	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.04927484,  training time: 0.90
progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:26,  1.17it/s]progress:  40%|[34m████      [0m| 20/50 [00:18<00:26,  1.15it/s]                                                         Episode 21	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.06154817,  training time: 0.88
progress:  40%|[34m████      [0m| 20/50 [00:19<00:26,  1.15it/s]progress:  42%|[34m████▏     [0m| 21/50 [00:19<00:25,  1.15it/s]                                                         Episode 22	 reward: -4.27	 makespan: 422.25	 Mean_loss: 0.06213286,  training time: 0.90
progress:  42%|[34m████▏     [0m| 21/50 [00:20<00:25,  1.15it/s]progress:  44%|[34m████▍     [0m| 22/50 [00:20<00:24,  1.13it/s]                                                         Episode 23	 reward: -4.42	 makespan: 437.50	 Mean_loss: 0.05234169,  training time: 0.97
progress:  44%|[34m████▍     [0m| 22/50 [00:21<00:24,  1.13it/s]progress:  46%|[34m████▌     [0m| 23/50 [00:21<00:24,  1.10it/s]                                                         Episode 24	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.05900634,  training time: 0.91
progress:  46%|[34m████▌     [0m| 23/50 [00:22<00:24,  1.10it/s]progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:23,  1.10it/s]                                                         Episode 25	 reward: -4.57	 makespan: 452.00	 Mean_loss: 0.07158193,  training time: 0.84
progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:23,  1.10it/s]progress:  50%|[34m█████     [0m| 25/50 [00:22<00:22,  1.13it/s]                                                         Episode 26	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.03984592,  training time: 0.84
progress:  50%|[34m█████     [0m| 25/50 [00:23<00:22,  1.13it/s]progress:  52%|[34m█████▏    [0m| 26/50 [00:23<00:20,  1.15it/s]                                                         Episode 27	 reward: -4.01	 makespan: 396.75	 Mean_loss: 0.03485707,  training time: 0.83
progress:  52%|[34m█████▏    [0m| 26/50 [00:24<00:20,  1.15it/s]progress:  54%|[34m█████▍    [0m| 27/50 [00:24<00:19,  1.16it/s]                                                         Episode 28	 reward: -4.40	 makespan: 436.00	 Mean_loss: 0.02730844,  training time: 0.84
progress:  54%|[34m█████▍    [0m| 27/50 [00:25<00:19,  1.16it/s]progress:  56%|[34m█████▌    [0m| 28/50 [00:25<00:18,  1.17it/s]                                                         Episode 29	 reward: -4.56	 makespan: 451.25	 Mean_loss: 0.05349950,  training time: 0.86
progress:  56%|[34m█████▌    [0m| 28/50 [00:26<00:18,  1.17it/s]progress:  58%|[34m█████▊    [0m| 29/50 [00:26<00:17,  1.17it/s]                                                         Episode 30	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.03492607,  training time: 0.85
progress:  58%|[34m█████▊    [0m| 29/50 [00:27<00:17,  1.17it/s]progress:  60%|[34m██████    [0m| 30/50 [00:27<00:17,  1.17it/s]                                                         Episode 31	 reward: -4.56	 makespan: 451.00	 Mean_loss: 0.04861987,  training time: 0.85
progress:  60%|[34m██████    [0m| 30/50 [00:27<00:17,  1.17it/s]progress:  62%|[34m██████▏   [0m| 31/50 [00:27<00:16,  1.17it/s]                                                         Episode 32	 reward: -4.74	 makespan: 469.75	 Mean_loss: 0.02771069,  training time: 0.84
progress:  62%|[34m██████▏   [0m| 31/50 [00:28<00:16,  1.17it/s]progress:  64%|[34m██████▍   [0m| 32/50 [00:28<00:15,  1.18it/s]                                                         Episode 33	 reward: -4.45	 makespan: 441.00	 Mean_loss: 0.03330266,  training time: 0.86
progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:15,  1.18it/s]progress:  66%|[34m██████▌   [0m| 33/50 [00:29<00:14,  1.18it/s]                                                         Episode 34	 reward: -4.51	 makespan: 446.25	 Mean_loss: 0.04183808,  training time: 0.83
progress:  66%|[34m██████▌   [0m| 33/50 [00:30<00:14,  1.18it/s]progress:  68%|[34m██████▊   [0m| 34/50 [00:30<00:13,  1.18it/s]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.02752976,  training time: 0.84
progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:13,  1.18it/s]progress:  70%|[34m███████   [0m| 35/50 [00:31<00:12,  1.18it/s]                                                         Episode 36	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.04761191,  training time: 0.83
progress:  70%|[34m███████   [0m| 35/50 [00:32<00:12,  1.18it/s]progress:  72%|[34m███████▏  [0m| 36/50 [00:32<00:11,  1.19it/s]                                                         Episode 37	 reward: -4.56	 makespan: 451.75	 Mean_loss: 0.04792244,  training time: 0.84
progress:  72%|[34m███████▏  [0m| 36/50 [00:32<00:11,  1.19it/s]progress:  74%|[34m███████▍  [0m| 37/50 [00:32<00:10,  1.19it/s]                                                         Episode 38	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.02249994,  training time: 0.88
progress:  74%|[34m███████▍  [0m| 37/50 [00:33<00:10,  1.19it/s]progress:  76%|[34m███████▌  [0m| 38/50 [00:33<00:10,  1.17it/s]                                                         Episode 39	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.01629904,  training time: 0.86
progress:  76%|[34m███████▌  [0m| 38/50 [00:34<00:10,  1.17it/s]progress:  78%|[34m███████▊  [0m| 39/50 [00:34<00:09,  1.17it/s]                                                         Episode 40	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.02778888,  training time: 0.92
progress:  78%|[34m███████▊  [0m| 39/50 [00:35<00:09,  1.17it/s]progress:  80%|[34m████████  [0m| 40/50 [00:35<00:08,  1.14it/s]                                                         Episode 41	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.10707261,  training time: 0.90
progress:  80%|[34m████████  [0m| 40/50 [00:36<00:08,  1.14it/s]progress:  82%|[34m████████▏ [0m| 41/50 [00:36<00:07,  1.13it/s]                                                         Episode 42	 reward: -4.56	 makespan: 451.50	 Mean_loss: 0.04915689,  training time: 0.91
progress:  82%|[34m████████▏ [0m| 41/50 [00:37<00:07,  1.13it/s]progress:  84%|[34m████████▍ [0m| 42/50 [00:37<00:07,  1.12it/s]                                                         Episode 43	 reward: -4.67	 makespan: 462.00	 Mean_loss: 0.02471277,  training time: 0.83
progress:  84%|[34m████████▍ [0m| 42/50 [00:38<00:07,  1.12it/s]progress:  86%|[34m████████▌ [0m| 43/50 [00:38<00:06,  1.15it/s]                                                         Episode 44	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.06165908,  training time: 0.83
progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.15it/s]progress:  88%|[34m████████▊ [0m| 44/50 [00:39<00:05,  1.16it/s]                                                         Episode 45	 reward: -4.91	 makespan: 486.25	 Mean_loss: 0.02938607,  training time: 0.87
progress:  88%|[34m████████▊ [0m| 44/50 [00:39<00:05,  1.16it/s]progress:  90%|[34m█████████ [0m| 45/50 [00:39<00:04,  1.16it/s]                                                         Episode 46	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.07713498,  training time: 0.88
progress:  90%|[34m█████████ [0m| 45/50 [00:40<00:04,  1.16it/s]progress:  92%|[34m█████████▏[0m| 46/50 [00:40<00:03,  1.15it/s]                                                         Episode 47	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.04396790,  training time: 0.87
progress:  92%|[34m█████████▏[0m| 46/50 [00:41<00:03,  1.15it/s]progress:  94%|[34m█████████▍[0m| 47/50 [00:41<00:02,  1.15it/s]                                                         Episode 48	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.05814299,  training time: 0.84
progress:  94%|[34m█████████▍[0m| 47/50 [00:42<00:02,  1.15it/s]progress:  96%|[34m█████████▌[0m| 48/50 [00:42<00:01,  1.16it/s]                                                         Episode 49	 reward: -4.76	 makespan: 471.00	 Mean_loss: 0.08827530,  training time: 0.83
progress:  96%|[34m█████████▌[0m| 48/50 [00:43<00:01,  1.16it/s]progress:  98%|[34m█████████▊[0m| 49/50 [00:43<00:00,  1.17it/s]                                                         Episode 50	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.09780839,  training time: 0.90
progress:  98%|[34m█████████▊[0m| 49/50 [00:44<00:00,  1.17it/s]progress: 100%|[34m██████████[0m| 50/50 [00:44<00:00,  1.15it/s]progress: 100%|[34m██████████[0m| 50/50 [00:44<00:00,  1.13it/s]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob10 --model_suffix exp13_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp13_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.82	 makespan: 576.50	 Mean_loss: 0.40191680,  training time: 1.93
progress:   0%|[34m          [0m| 0/50 [00:01<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:01<01:34,  1.94s/it]                                                        Episode 2	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.12636000,  training time: 0.88
progress:   2%|[34m▏         [0m| 1/50 [00:02<01:34,  1.94s/it]progress:   4%|[34m▍         [0m| 2/50 [00:02<01:03,  1.31s/it]                                                        Episode 3	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.10313880,  training time: 0.87
progress:   4%|[34m▍         [0m| 2/50 [00:03<01:03,  1.31s/it]progress:   6%|[34m▌         [0m| 3/50 [00:03<00:52,  1.11s/it]                                                        Episode 4	 reward: -4.81	 makespan: 475.75	 Mean_loss: 0.12481765,  training time: 0.85
progress:   6%|[34m▌         [0m| 3/50 [00:04<00:52,  1.11s/it]progress:   8%|[34m▊         [0m| 4/50 [00:04<00:46,  1.01s/it]                                                        Episode 5	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.11468191,  training time: 0.86
progress:   8%|[34m▊         [0m| 4/50 [00:05<00:46,  1.01s/it]progress:  10%|[34m█         [0m| 5/50 [00:05<00:42,  1.05it/s]                                                        Episode 6	 reward: -5.09	 makespan: 503.75	 Mean_loss: 0.11043388,  training time: 0.92
progress:  10%|[34m█         [0m| 5/50 [00:06<00:42,  1.05it/s]progress:  12%|[34m█▏        [0m| 6/50 [00:06<00:41,  1.06it/s]                                                        Episode 7	 reward: -4.42	 makespan: 437.75	 Mean_loss: 0.06855130,  training time: 0.91
progress:  12%|[34m█▏        [0m| 6/50 [00:07<00:41,  1.06it/s]progress:  14%|[34m█▍        [0m| 7/50 [00:07<00:40,  1.07it/s]                                                        Episode 8	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.07998642,  training time: 0.93
progress:  14%|[34m█▍        [0m| 7/50 [00:08<00:40,  1.07it/s]progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:39,  1.07it/s]                                                        Episode 9	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.12108960,  training time: 0.92
progress:  16%|[34m█▌        [0m| 8/50 [00:09<00:39,  1.07it/s]progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:38,  1.08it/s]                                                        Episode 10	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.07928500,  training time: 0.91
progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:38,  1.08it/s]progress:  20%|[34m██        [0m| 10/50 [00:09<00:36,  1.08it/s]                                                         Episode 11	 reward: -4.58	 makespan: 453.75	 Mean_loss: 0.03100837,  training time: 0.87
progress:  20%|[34m██        [0m| 10/50 [00:10<00:36,  1.08it/s]progress:  22%|[34m██▏       [0m| 11/50 [00:10<00:35,  1.10it/s]                                                         Episode 12	 reward: -4.72	 makespan: 467.50	 Mean_loss: 0.03268960,  training time: 0.92
progress:  22%|[34m██▏       [0m| 11/50 [00:11<00:35,  1.10it/s]progress:  24%|[34m██▍       [0m| 12/50 [00:11<00:34,  1.10it/s]                                                         Episode 13	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.04591559,  training time: 0.95
progress:  24%|[34m██▍       [0m| 12/50 [00:12<00:34,  1.10it/s]progress:  26%|[34m██▌       [0m| 13/50 [00:12<00:34,  1.08it/s]                                                         Episode 14	 reward: -4.69	 makespan: 464.75	 Mean_loss: 0.06640686,  training time: 0.94
progress:  26%|[34m██▌       [0m| 13/50 [00:13<00:34,  1.08it/s]progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:33,  1.08it/s]                                                         Episode 15	 reward: -4.37	 makespan: 432.75	 Mean_loss: 0.04918668,  training time: 0.87
progress:  28%|[34m██▊       [0m| 14/50 [00:14<00:33,  1.08it/s]progress:  30%|[34m███       [0m| 15/50 [00:14<00:31,  1.10it/s]                                                         Episode 16	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.15885220,  training time: 0.93
progress:  30%|[34m███       [0m| 15/50 [00:15<00:31,  1.10it/s]progress:  32%|[34m███▏      [0m| 16/50 [00:15<00:31,  1.09it/s]                                                         Episode 17	 reward: -4.47	 makespan: 442.50	 Mean_loss: 0.08440518,  training time: 0.92
progress:  32%|[34m███▏      [0m| 16/50 [00:16<00:31,  1.09it/s]progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:30,  1.09it/s]                                                         Episode 18	 reward: -4.88	 makespan: 483.50	 Mean_loss: 0.13404649,  training time: 0.90
progress:  34%|[34m███▍      [0m| 17/50 [00:17<00:30,  1.09it/s]progress:  36%|[34m███▌      [0m| 18/50 [00:17<00:29,  1.09it/s]                                                         Episode 19	 reward: -4.46	 makespan: 442.00	 Mean_loss: 0.07250276,  training time: 0.92
progress:  36%|[34m███▌      [0m| 18/50 [00:18<00:29,  1.09it/s]progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:28,  1.09it/s]                                                         Episode 20	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.04927484,  training time: 0.92
progress:  38%|[34m███▊      [0m| 19/50 [00:19<00:28,  1.09it/s]progress:  40%|[34m████      [0m| 20/50 [00:19<00:27,  1.09it/s]                                                         Episode 21	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.06154817,  training time: 0.84
progress:  40%|[34m████      [0m| 20/50 [00:19<00:27,  1.09it/s]progress:  42%|[34m████▏     [0m| 21/50 [00:19<00:25,  1.12it/s]                                                         Episode 22	 reward: -4.27	 makespan: 422.25	 Mean_loss: 0.06213286,  training time: 0.89
progress:  42%|[34m████▏     [0m| 21/50 [00:20<00:25,  1.12it/s]progress:  44%|[34m████▍     [0m| 22/50 [00:20<00:25,  1.12it/s]                                                         Episode 23	 reward: -4.42	 makespan: 437.50	 Mean_loss: 0.05234169,  training time: 1.03
progress:  44%|[34m████▍     [0m| 22/50 [00:21<00:25,  1.12it/s]progress:  46%|[34m████▌     [0m| 23/50 [00:21<00:25,  1.07it/s]                                                         Episode 24	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.05900634,  training time: 0.87
progress:  46%|[34m████▌     [0m| 23/50 [00:22<00:25,  1.07it/s]progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:23,  1.09it/s]                                                         Episode 25	 reward: -4.57	 makespan: 452.00	 Mean_loss: 0.07158193,  training time: 0.89
progress:  48%|[34m████▊     [0m| 24/50 [00:23<00:23,  1.09it/s]progress:  50%|[34m█████     [0m| 25/50 [00:23<00:22,  1.10it/s]                                                         Episode 26	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.03984592,  training time: 0.91
progress:  50%|[34m█████     [0m| 25/50 [00:24<00:22,  1.10it/s]progress:  52%|[34m█████▏    [0m| 26/50 [00:24<00:21,  1.10it/s]                                                         Episode 27	 reward: -4.01	 makespan: 396.75	 Mean_loss: 0.03485707,  training time: 0.90
progress:  52%|[34m█████▏    [0m| 26/50 [00:25<00:21,  1.10it/s]progress:  54%|[34m█████▍    [0m| 27/50 [00:25<00:20,  1.10it/s]                                                         Episode 28	 reward: -4.40	 makespan: 436.00	 Mean_loss: 0.02730844,  training time: 0.90
progress:  54%|[34m█████▍    [0m| 27/50 [00:26<00:20,  1.10it/s]progress:  56%|[34m█████▌    [0m| 28/50 [00:26<00:19,  1.11it/s]                                                         Episode 29	 reward: -4.56	 makespan: 451.25	 Mean_loss: 0.05349950,  training time: 0.92
progress:  56%|[34m█████▌    [0m| 28/50 [00:27<00:19,  1.11it/s]progress:  58%|[34m█████▊    [0m| 29/50 [00:27<00:19,  1.10it/s]                                                         Episode 30	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.03492607,  training time: 0.90
progress:  58%|[34m█████▊    [0m| 29/50 [00:28<00:19,  1.10it/s]progress:  60%|[34m██████    [0m| 30/50 [00:28<00:18,  1.10it/s]                                                         Episode 31	 reward: -4.56	 makespan: 451.00	 Mean_loss: 0.04861987,  training time: 0.90
progress:  60%|[34m██████    [0m| 30/50 [00:29<00:18,  1.10it/s]progress:  62%|[34m██████▏   [0m| 31/50 [00:29<00:17,  1.11it/s]                                                         Episode 32	 reward: -4.74	 makespan: 469.75	 Mean_loss: 0.02771069,  training time: 0.90
progress:  62%|[34m██████▏   [0m| 31/50 [00:29<00:17,  1.11it/s]progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:16,  1.11it/s]                                                         Episode 33	 reward: -4.45	 makespan: 441.00	 Mean_loss: 0.03330266,  training time: 0.89
progress:  64%|[34m██████▍   [0m| 32/50 [00:30<00:16,  1.11it/s]progress:  66%|[34m██████▌   [0m| 33/50 [00:30<00:15,  1.11it/s]                                                         Episode 34	 reward: -4.51	 makespan: 446.25	 Mean_loss: 0.04183808,  training time: 0.86
progress:  66%|[34m██████▌   [0m| 33/50 [00:31<00:15,  1.11it/s]progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:14,  1.13it/s]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.02752976,  training time: 0.85
progress:  68%|[34m██████▊   [0m| 34/50 [00:32<00:14,  1.13it/s]progress:  70%|[34m███████   [0m| 35/50 [00:32<00:13,  1.14it/s]                                                         Episode 36	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.04761191,  training time: 0.91
progress:  70%|[34m███████   [0m| 35/50 [00:33<00:13,  1.14it/s]progress:  72%|[34m███████▏  [0m| 36/50 [00:33<00:12,  1.13it/s]                                                         Episode 37	 reward: -4.56	 makespan: 451.75	 Mean_loss: 0.04792244,  training time: 0.91
progress:  72%|[34m███████▏  [0m| 36/50 [00:34<00:12,  1.13it/s]progress:  74%|[34m███████▍  [0m| 37/50 [00:34<00:11,  1.12it/s]                                                         Episode 38	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.02249994,  training time: 0.88
progress:  74%|[34m███████▍  [0m| 37/50 [00:35<00:11,  1.12it/s]progress:  76%|[34m███████▌  [0m| 38/50 [00:35<00:10,  1.12it/s]                                                         Episode 39	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.01629904,  training time: 0.92
progress:  76%|[34m███████▌  [0m| 38/50 [00:36<00:10,  1.12it/s]progress:  78%|[34m███████▊  [0m| 39/50 [00:36<00:09,  1.11it/s]                                                         Episode 40	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.02778888,  training time: 0.92
progress:  78%|[34m███████▊  [0m| 39/50 [00:37<00:09,  1.11it/s]progress:  80%|[34m████████  [0m| 40/50 [00:37<00:09,  1.11it/s]                                                         Episode 41	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.10707261,  training time: 0.91
progress:  80%|[34m████████  [0m| 40/50 [00:38<00:09,  1.11it/s]progress:  82%|[34m████████▏ [0m| 41/50 [00:38<00:08,  1.10it/s]                                                         Episode 42	 reward: -4.56	 makespan: 451.50	 Mean_loss: 0.04915689,  training time: 0.88
progress:  82%|[34m████████▏ [0m| 41/50 [00:38<00:08,  1.10it/s]progress:  84%|[34m████████▍ [0m| 42/50 [00:38<00:07,  1.11it/s]                                                         Episode 43	 reward: -4.67	 makespan: 462.00	 Mean_loss: 0.02471277,  training time: 0.91
progress:  84%|[34m████████▍ [0m| 42/50 [00:39<00:07,  1.11it/s]progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.11it/s]                                                         Episode 44	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.06165908,  training time: 0.84
progress:  86%|[34m████████▌ [0m| 43/50 [00:40<00:06,  1.11it/s]progress:  88%|[34m████████▊ [0m| 44/50 [00:40<00:05,  1.13it/s]                                                         Episode 45	 reward: -4.91	 makespan: 486.25	 Mean_loss: 0.02938607,  training time: 0.84
progress:  88%|[34m████████▊ [0m| 44/50 [00:41<00:05,  1.13it/s]progress:  90%|[34m█████████ [0m| 45/50 [00:41<00:04,  1.15it/s]                                                         Episode 46	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.07713498,  training time: 0.91
progress:  90%|[34m█████████ [0m| 45/50 [00:42<00:04,  1.15it/s]progress:  92%|[34m█████████▏[0m| 46/50 [00:42<00:03,  1.13it/s]                                                         Episode 47	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.04396790,  training time: 0.91
progress:  92%|[34m█████████▏[0m| 46/50 [00:43<00:03,  1.13it/s]progress:  94%|[34m█████████▍[0m| 47/50 [00:43<00:02,  1.12it/s]                                                         Episode 48	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.05814299,  training time: 0.84
progress:  94%|[34m█████████▍[0m| 47/50 [00:44<00:02,  1.12it/s]progress:  96%|[34m█████████▌[0m| 48/50 [00:44<00:01,  1.14it/s]                                                         Episode 49	 reward: -4.76	 makespan: 471.00	 Mean_loss: 0.08827530,  training time: 0.86
progress:  96%|[34m█████████▌[0m| 48/50 [00:45<00:01,  1.14it/s]progress:  98%|[34m█████████▊[0m| 49/50 [00:45<00:00,  1.15it/s]                                                         Episode 50	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.09780839,  training time: 0.91
progress:  98%|[34m█████████▊[0m| 49/50 [00:45<00:00,  1.15it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.13it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.09it/s]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob12 --model_suffix exp13_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp13_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.82	 makespan: 576.50	 Mean_loss: 0.40191680,  training time: 1.98
progress:   0%|[34m          [0m| 0/50 [00:01<?, ?it/s]progress:   2%|[34m▏         [0m| 1/50 [00:01<01:36,  1.98s/it]                                                        Episode 2	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.12636000,  training time: 0.90
progress:   2%|[34m▏         [0m| 1/50 [00:02<01:36,  1.98s/it]progress:   4%|[34m▍         [0m| 2/50 [00:02<01:04,  1.35s/it]                                                        Episode 3	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.10313880,  training time: 0.92
progress:   4%|[34m▍         [0m| 2/50 [00:03<01:04,  1.35s/it]progress:   6%|[34m▌         [0m| 3/50 [00:03<00:54,  1.15s/it]                                                        Episode 4	 reward: -4.81	 makespan: 475.75	 Mean_loss: 0.12481765,  training time: 0.87
progress:   6%|[34m▌         [0m| 3/50 [00:04<00:54,  1.15s/it]progress:   8%|[34m▊         [0m| 4/50 [00:04<00:47,  1.04s/it]                                                        Episode 5	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.11468191,  training time: 0.86
progress:   8%|[34m▊         [0m| 4/50 [00:05<00:47,  1.04s/it]progress:  10%|[34m█         [0m| 5/50 [00:05<00:43,  1.03it/s]                                                        Episode 6	 reward: -5.09	 makespan: 503.75	 Mean_loss: 0.11043388,  training time: 0.88
progress:  10%|[34m█         [0m| 5/50 [00:06<00:43,  1.03it/s]progress:  12%|[34m█▏        [0m| 6/50 [00:06<00:41,  1.06it/s]                                                        Episode 7	 reward: -4.42	 makespan: 437.75	 Mean_loss: 0.06855130,  training time: 0.89
progress:  12%|[34m█▏        [0m| 6/50 [00:07<00:41,  1.06it/s]progress:  14%|[34m█▍        [0m| 7/50 [00:07<00:39,  1.08it/s]                                                        Episode 8	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.07998642,  training time: 0.85
progress:  14%|[34m█▍        [0m| 7/50 [00:08<00:39,  1.08it/s]progress:  16%|[34m█▌        [0m| 8/50 [00:08<00:37,  1.11it/s]                                                        Episode 9	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.12108960,  training time: 0.88
progress:  16%|[34m█▌        [0m| 8/50 [00:09<00:37,  1.11it/s]progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:36,  1.12it/s]                                                        Episode 10	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.07928500,  training time: 0.92
progress:  18%|[34m█▊        [0m| 9/50 [00:09<00:36,  1.12it/s]progress:  20%|[34m██        [0m| 10/50 [00:09<00:36,  1.11it/s]                                                         Episode 11	 reward: -4.58	 makespan: 453.75	 Mean_loss: 0.03100837,  training time: 0.88
progress:  20%|[34m██        [0m| 10/50 [00:10<00:36,  1.11it/s]progress:  22%|[34m██▏       [0m| 11/50 [00:10<00:34,  1.12it/s]                                                         Episode 12	 reward: -4.72	 makespan: 467.50	 Mean_loss: 0.03268960,  training time: 0.85
progress:  22%|[34m██▏       [0m| 11/50 [00:11<00:34,  1.12it/s]progress:  24%|[34m██▍       [0m| 12/50 [00:11<00:33,  1.13it/s]                                                         Episode 13	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.04591559,  training time: 0.87
progress:  24%|[34m██▍       [0m| 12/50 [00:12<00:33,  1.13it/s]progress:  26%|[34m██▌       [0m| 13/50 [00:12<00:32,  1.14it/s]                                                         Episode 14	 reward: -4.69	 makespan: 464.75	 Mean_loss: 0.06640686,  training time: 0.88
progress:  26%|[34m██▌       [0m| 13/50 [00:13<00:32,  1.14it/s]progress:  28%|[34m██▊       [0m| 14/50 [00:13<00:31,  1.14it/s]                                                         Episode 15	 reward: -4.37	 makespan: 432.75	 Mean_loss: 0.04918668,  training time: 0.90
progress:  28%|[34m██▊       [0m| 14/50 [00:14<00:31,  1.14it/s]progress:  30%|[34m███       [0m| 15/50 [00:14<00:31,  1.13it/s]                                                         Episode 16	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.15885220,  training time: 0.99
progress:  30%|[34m███       [0m| 15/50 [00:15<00:31,  1.13it/s]progress:  32%|[34m███▏      [0m| 16/50 [00:15<00:31,  1.09it/s]                                                         Episode 17	 reward: -4.47	 makespan: 442.50	 Mean_loss: 0.08440518,  training time: 0.89
progress:  32%|[34m███▏      [0m| 16/50 [00:16<00:31,  1.09it/s]progress:  34%|[34m███▍      [0m| 17/50 [00:16<00:30,  1.10it/s]                                                         Episode 18	 reward: -4.88	 makespan: 483.50	 Mean_loss: 0.13404649,  training time: 0.86
progress:  34%|[34m███▍      [0m| 17/50 [00:17<00:30,  1.10it/s]progress:  36%|[34m███▌      [0m| 18/50 [00:17<00:28,  1.12it/s]                                                         Episode 19	 reward: -4.46	 makespan: 442.00	 Mean_loss: 0.07250276,  training time: 0.91
progress:  36%|[34m███▌      [0m| 18/50 [00:18<00:28,  1.12it/s]progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:27,  1.11it/s]                                                         Episode 20	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.04927484,  training time: 0.88
progress:  38%|[34m███▊      [0m| 19/50 [00:18<00:27,  1.11it/s]progress:  40%|[34m████      [0m| 20/50 [00:18<00:26,  1.12it/s]                                                         Episode 21	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.06154817,  training time: 0.89
progress:  40%|[34m████      [0m| 20/50 [00:19<00:26,  1.12it/s]progress:  42%|[34m████▏     [0m| 21/50 [00:19<00:25,  1.12it/s]                                                         Episode 22	 reward: -4.27	 makespan: 422.25	 Mean_loss: 0.06213286,  training time: 0.90
progress:  42%|[34m████▏     [0m| 21/50 [00:20<00:25,  1.12it/s]progress:  44%|[34m████▍     [0m| 22/50 [00:20<00:25,  1.12it/s]                                                         Episode 23	 reward: -4.42	 makespan: 437.50	 Mean_loss: 0.05234169,  training time: 1.06
progress:  44%|[34m████▍     [0m| 22/50 [00:21<00:25,  1.12it/s]progress:  46%|[34m████▌     [0m| 23/50 [00:21<00:25,  1.06it/s]                                                         Episode 24	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.05900634,  training time: 0.89
progress:  46%|[34m████▌     [0m| 23/50 [00:22<00:25,  1.06it/s]progress:  48%|[34m████▊     [0m| 24/50 [00:22<00:24,  1.08it/s]                                                         Episode 25	 reward: -4.57	 makespan: 452.00	 Mean_loss: 0.07158193,  training time: 0.92
progress:  48%|[34m████▊     [0m| 24/50 [00:23<00:24,  1.08it/s]progress:  50%|[34m█████     [0m| 25/50 [00:23<00:23,  1.08it/s]                                                         Episode 26	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.03984592,  training time: 0.90
progress:  50%|[34m█████     [0m| 25/50 [00:24<00:23,  1.08it/s]progress:  52%|[34m█████▏    [0m| 26/50 [00:24<00:22,  1.09it/s]                                                         Episode 27	 reward: -4.01	 makespan: 396.75	 Mean_loss: 0.03485707,  training time: 0.90
progress:  52%|[34m█████▏    [0m| 26/50 [00:25<00:22,  1.09it/s]progress:  54%|[34m█████▍    [0m| 27/50 [00:25<00:20,  1.10it/s]                                                         Episode 28	 reward: -4.40	 makespan: 436.00	 Mean_loss: 0.02730844,  training time: 0.89
progress:  54%|[34m█████▍    [0m| 27/50 [00:26<00:20,  1.10it/s]progress:  56%|[34m█████▌    [0m| 28/50 [00:26<00:19,  1.10it/s]                                                         Episode 29	 reward: -4.56	 makespan: 451.25	 Mean_loss: 0.05349950,  training time: 0.92
progress:  56%|[34m█████▌    [0m| 28/50 [00:27<00:19,  1.10it/s]progress:  58%|[34m█████▊    [0m| 29/50 [00:27<00:19,  1.10it/s]                                                         Episode 30	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.03492607,  training time: 0.90
progress:  58%|[34m█████▊    [0m| 29/50 [00:28<00:19,  1.10it/s]progress:  60%|[34m██████    [0m| 30/50 [00:28<00:18,  1.10it/s]                                                         Episode 31	 reward: -4.56	 makespan: 451.00	 Mean_loss: 0.04861987,  training time: 0.91
progress:  60%|[34m██████    [0m| 30/50 [00:28<00:18,  1.10it/s]progress:  62%|[34m██████▏   [0m| 31/50 [00:28<00:17,  1.10it/s]                                                         Episode 32	 reward: -4.74	 makespan: 469.75	 Mean_loss: 0.02771069,  training time: 0.86
progress:  62%|[34m██████▏   [0m| 31/50 [00:29<00:17,  1.10it/s]progress:  64%|[34m██████▍   [0m| 32/50 [00:29<00:16,  1.12it/s]                                                         Episode 33	 reward: -4.45	 makespan: 441.00	 Mean_loss: 0.03330266,  training time: 0.91
progress:  64%|[34m██████▍   [0m| 32/50 [00:30<00:16,  1.12it/s]progress:  66%|[34m██████▌   [0m| 33/50 [00:30<00:15,  1.11it/s]                                                         Episode 34	 reward: -4.51	 makespan: 446.25	 Mean_loss: 0.04183808,  training time: 0.89
progress:  66%|[34m██████▌   [0m| 33/50 [00:31<00:15,  1.11it/s]progress:  68%|[34m██████▊   [0m| 34/50 [00:31<00:14,  1.11it/s]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.02752976,  training time: 0.86
progress:  68%|[34m██████▊   [0m| 34/50 [00:32<00:14,  1.11it/s]progress:  70%|[34m███████   [0m| 35/50 [00:32<00:13,  1.13it/s]                                                         Episode 36	 reward: -4.67	 makespan: 462.75	 Mean_loss: 0.04761191,  training time: 0.87
progress:  70%|[34m███████   [0m| 35/50 [00:33<00:13,  1.13it/s]progress:  72%|[34m███████▏  [0m| 36/50 [00:33<00:12,  1.13it/s]                                                         Episode 37	 reward: -4.56	 makespan: 451.75	 Mean_loss: 0.04792244,  training time: 0.91
progress:  72%|[34m███████▏  [0m| 36/50 [00:34<00:12,  1.13it/s]progress:  74%|[34m███████▍  [0m| 37/50 [00:34<00:11,  1.12it/s]                                                         Episode 38	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.02249994,  training time: 0.86
progress:  74%|[34m███████▍  [0m| 37/50 [00:35<00:11,  1.12it/s]progress:  76%|[34m███████▌  [0m| 38/50 [00:35<00:10,  1.13it/s]                                                         Episode 39	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.01629904,  training time: 0.90
progress:  76%|[34m███████▌  [0m| 38/50 [00:36<00:10,  1.13it/s]progress:  78%|[34m███████▊  [0m| 39/50 [00:36<00:09,  1.13it/s]                                                         Episode 40	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.02778888,  training time: 0.86
progress:  78%|[34m███████▊  [0m| 39/50 [00:36<00:09,  1.13it/s]progress:  80%|[34m████████  [0m| 40/50 [00:36<00:08,  1.14it/s]                                                         Episode 41	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.10707261,  training time: 0.86
progress:  80%|[34m████████  [0m| 40/50 [00:37<00:08,  1.14it/s]progress:  82%|[34m████████▏ [0m| 41/50 [00:37<00:07,  1.14it/s]                                                         Episode 42	 reward: -4.56	 makespan: 451.50	 Mean_loss: 0.04915689,  training time: 0.85
progress:  82%|[34m████████▏ [0m| 41/50 [00:38<00:07,  1.14it/s]progress:  84%|[34m████████▍ [0m| 42/50 [00:38<00:06,  1.15it/s]                                                         Episode 43	 reward: -4.67	 makespan: 462.00	 Mean_loss: 0.02471277,  training time: 0.87
progress:  84%|[34m████████▍ [0m| 42/50 [00:39<00:06,  1.15it/s]progress:  86%|[34m████████▌ [0m| 43/50 [00:39<00:06,  1.15it/s]                                                         Episode 44	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.06165908,  training time: 0.87
progress:  86%|[34m████████▌ [0m| 43/50 [00:40<00:06,  1.15it/s]progress:  88%|[34m████████▊ [0m| 44/50 [00:40<00:05,  1.15it/s]                                                         Episode 45	 reward: -4.91	 makespan: 486.25	 Mean_loss: 0.02938607,  training time: 0.86
progress:  88%|[34m████████▊ [0m| 44/50 [00:41<00:05,  1.15it/s]progress:  90%|[34m█████████ [0m| 45/50 [00:41<00:04,  1.16it/s]                                                         Episode 46	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.07713498,  training time: 0.86
progress:  90%|[34m█████████ [0m| 45/50 [00:42<00:04,  1.16it/s]progress:  92%|[34m█████████▏[0m| 46/50 [00:42<00:03,  1.16it/s]                                                         Episode 47	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.04396790,  training time: 0.87
progress:  92%|[34m█████████▏[0m| 46/50 [00:42<00:03,  1.16it/s]progress:  94%|[34m█████████▍[0m| 47/50 [00:42<00:02,  1.16it/s]                                                         Episode 48	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.05814299,  training time: 0.85
progress:  94%|[34m█████████▍[0m| 47/50 [00:43<00:02,  1.16it/s]progress:  96%|[34m█████████▌[0m| 48/50 [00:43<00:01,  1.16it/s]                                                         Episode 49	 reward: -4.76	 makespan: 471.00	 Mean_loss: 0.08827530,  training time: 0.86
progress:  96%|[34m█████████▌[0m| 48/50 [00:44<00:01,  1.16it/s]progress:  98%|[34m█████████▊[0m| 49/50 [00:44<00:00,  1.16it/s]                                                         Episode 50	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.09780839,  training time: 0.85
progress:  98%|[34m█████████▊[0m| 49/50 [00:45<00:00,  1.16it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.17it/s]progress: 100%|[34m██████████[0m| 50/50 [00:45<00:00,  1.10it/s]

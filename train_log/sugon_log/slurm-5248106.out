+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 38665 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ TEST_DIR=./test_script
+ exp=exp15
+ echo exp15
exp15
+ cat
op_per_job+MAML
DAN.pyop_per_job_options,baseline
 
MAML
MAML

+ op_per_job_options='4 6 8 10 12'
+ logdir=./runs/exp15
+ hidden_dim_actor=64
+ hidden_dim_critic=64
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ n_j=15
+ n_m=5
+ data_source=SD2
+ logdir_dan=./runs/exp15/DAN
+ options=($op_per_job_options)
+ max_updates_finetune=50
+ lr=0.003
+ first_model_name=15x5+mix+SD2_operjob4
+ last_model_name=15x5+mix+SD2_operjob12
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.96	 makespan: 491.25	 Mean_loss: 0.09648660,  training time: 3.94
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:13,  3.95s/it]                                                        Episode 2	 reward: -4.89	 makespan: 484.00	 Mean_loss: 0.03059829,  training time: 1.06
progress:   2%|[34m         [0m| 1/50 [00:05<03:13,  3.95s/it]progress:   4%|[34m         [0m| 2/50 [00:05<01:47,  2.25s/it]                                                        Episode 3	 reward: -4.76	 makespan: 470.75	 Mean_loss: 0.02223911,  training time: 1.06
progress:   4%|[34m         [0m| 2/50 [00:06<01:47,  2.25s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:20,  1.71s/it]                                                        Episode 4	 reward: -4.99	 makespan: 493.75	 Mean_loss: 0.01911298,  training time: 1.09
progress:   6%|[34m         [0m| 3/50 [00:07<01:20,  1.71s/it]progress:   8%|[34m         [0m| 4/50 [00:07<01:07,  1.46s/it]                                                        Episode 5	 reward: -4.96	 makespan: 491.00	 Mean_loss: 0.01735698,  training time: 1.07
progress:   8%|[34m         [0m| 4/50 [00:08<01:07,  1.46s/it]progress:  10%|[34m         [0m| 5/50 [00:08<00:59,  1.32s/it]                                                        Episode 6	 reward: -4.86	 makespan: 481.50	 Mean_loss: 0.01682472,  training time: 1.06
progress:  10%|[34m         [0m| 5/50 [00:09<00:59,  1.32s/it]progress:  12%|[34m        [0m| 6/50 [00:09<00:54,  1.23s/it]                                                        Episode 7	 reward: -4.85	 makespan: 480.00	 Mean_loss: 0.01915723,  training time: 1.05
progress:  12%|[34m        [0m| 6/50 [00:10<00:54,  1.23s/it]progress:  14%|[34m        [0m| 7/50 [00:10<00:50,  1.17s/it]                                                        Episode 8	 reward: -4.61	 makespan: 456.50	 Mean_loss: 0.03115206,  training time: 1.06
progress:  14%|[34m        [0m| 7/50 [00:11<00:50,  1.17s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:47,  1.14s/it]                                                        Episode 9	 reward: -4.94	 makespan: 489.25	 Mean_loss: 0.02809336,  training time: 1.05
progress:  16%|[34m        [0m| 8/50 [00:12<00:47,  1.14s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:45,  1.11s/it]                                                        Episode 10	 reward: -4.94	 makespan: 489.50	 Mean_loss: 0.03343115,  training time: 1.05
progress:  18%|[34m        [0m| 9/50 [00:13<00:45,  1.11s/it]progress:  20%|[34m        [0m| 10/50 [00:13<00:43,  1.09s/it]                                                         Episode 11	 reward: -4.98	 makespan: 492.75	 Mean_loss: 0.02290792,  training time: 1.06
progress:  20%|[34m        [0m| 10/50 [00:14<00:43,  1.09s/it]progress:  22%|[34m       [0m| 11/50 [00:14<00:42,  1.08s/it]                                                         Episode 12	 reward: -5.17	 makespan: 511.75	 Mean_loss: 0.04431647,  training time: 1.13
progress:  22%|[34m       [0m| 11/50 [00:15<00:42,  1.08s/it]progress:  24%|[34m       [0m| 12/50 [00:15<00:41,  1.10s/it]                                                         Episode 13	 reward: -5.01	 makespan: 496.25	 Mean_loss: 0.02548456,  training time: 1.04
progress:  24%|[34m       [0m| 12/50 [00:16<00:41,  1.10s/it]progress:  26%|[34m       [0m| 13/50 [00:16<00:40,  1.08s/it]                                                         Episode 14	 reward: -4.84	 makespan: 479.50	 Mean_loss: 0.01534088,  training time: 1.05
progress:  26%|[34m       [0m| 13/50 [00:17<00:40,  1.08s/it]progress:  28%|[34m       [0m| 14/50 [00:17<00:38,  1.07s/it]                                                         Episode 15	 reward: -4.90	 makespan: 485.00	 Mean_loss: 0.03391724,  training time: 1.05
progress:  28%|[34m       [0m| 14/50 [00:18<00:38,  1.07s/it]progress:  30%|[34m       [0m| 15/50 [00:18<00:37,  1.06s/it]                                                         Episode 16	 reward: -5.25	 makespan: 519.50	 Mean_loss: 0.03589142,  training time: 1.00
progress:  30%|[34m       [0m| 15/50 [00:19<00:37,  1.06s/it]progress:  32%|[34m      [0m| 16/50 [00:19<00:35,  1.04s/it]                                                         Episode 17	 reward: -5.03	 makespan: 497.50	 Mean_loss: 0.01609196,  training time: 1.05
progress:  32%|[34m      [0m| 16/50 [00:20<00:35,  1.04s/it]progress:  34%|[34m      [0m| 17/50 [00:20<00:34,  1.05s/it]                                                         Episode 18	 reward: -5.04	 makespan: 499.25	 Mean_loss: 0.02020980,  training time: 1.05
progress:  34%|[34m      [0m| 17/50 [00:21<00:34,  1.05s/it]progress:  36%|[34m      [0m| 18/50 [00:21<00:33,  1.05s/it]                                                         Episode 19	 reward: -5.06	 makespan: 501.00	 Mean_loss: 0.02719882,  training time: 1.04
progress:  36%|[34m      [0m| 18/50 [00:22<00:33,  1.05s/it]progress:  38%|[34m      [0m| 19/50 [00:22<00:32,  1.05s/it]                                                         Episode 20	 reward: -5.24	 makespan: 518.75	 Mean_loss: 0.05847230,  training time: 1.04
progress:  38%|[34m      [0m| 19/50 [00:24<00:32,  1.05s/it]progress:  40%|[34m      [0m| 20/50 [00:24<00:31,  1.04s/it]                                                         Episode 21	 reward: -5.00	 makespan: 495.00	 Mean_loss: 0.03009054,  training time: 1.00
progress:  40%|[34m      [0m| 20/50 [00:25<00:31,  1.04s/it]progress:  42%|[34m     [0m| 21/50 [00:25<00:29,  1.03s/it]                                                         Episode 22	 reward: -5.27	 makespan: 522.00	 Mean_loss: 0.03229991,  training time: 1.03
progress:  42%|[34m     [0m| 21/50 [00:26<00:29,  1.03s/it]progress:  44%|[34m     [0m| 22/50 [00:26<00:28,  1.03s/it]                                                         Episode 23	 reward: -4.87	 makespan: 482.00	 Mean_loss: 0.04406933,  training time: 1.01
progress:  44%|[34m     [0m| 22/50 [00:27<00:28,  1.03s/it]progress:  46%|[34m     [0m| 23/50 [00:27<00:27,  1.03s/it]                                                         Episode 24	 reward: -5.08	 makespan: 503.00	 Mean_loss: 0.02393458,  training time: 1.03
progress:  46%|[34m     [0m| 23/50 [00:28<00:27,  1.03s/it]progress:  48%|[34m     [0m| 24/50 [00:28<00:26,  1.03s/it]                                                         Episode 25	 reward: -5.29	 makespan: 523.50	 Mean_loss: 0.08046799,  training time: 1.04
progress:  48%|[34m     [0m| 24/50 [00:29<00:26,  1.03s/it]progress:  50%|[34m     [0m| 25/50 [00:29<00:25,  1.03s/it]                                                         Episode 26	 reward: -5.27	 makespan: 522.00	 Mean_loss: 0.05117209,  training time: 1.02
progress:  50%|[34m     [0m| 25/50 [00:30<00:25,  1.03s/it]progress:  52%|[34m    [0m| 26/50 [00:30<00:24,  1.03s/it]                                                         Episode 27	 reward: -5.16	 makespan: 510.50	 Mean_loss: 0.01878205,  training time: 1.03
progress:  52%|[34m    [0m| 26/50 [00:31<00:24,  1.03s/it]progress:  54%|[34m    [0m| 27/50 [00:31<00:23,  1.03s/it]                                                         Episode 28	 reward: -4.89	 makespan: 484.00	 Mean_loss: 0.02532768,  training time: 0.99
progress:  54%|[34m    [0m| 27/50 [00:32<00:23,  1.03s/it]progress:  56%|[34m    [0m| 28/50 [00:32<00:22,  1.02s/it]                                                         Episode 29	 reward: -5.16	 makespan: 510.75	 Mean_loss: 0.03231180,  training time: 0.99
progress:  56%|[34m    [0m| 28/50 [00:33<00:22,  1.02s/it]progress:  58%|[34m    [0m| 29/50 [00:33<00:21,  1.01s/it]                                                         Episode 30	 reward: -5.13	 makespan: 508.25	 Mean_loss: 0.03168778,  training time: 1.01
progress:  58%|[34m    [0m| 29/50 [00:34<00:21,  1.01s/it]progress:  60%|[34m    [0m| 30/50 [00:34<00:20,  1.01s/it]                                                         Episode 31	 reward: -5.29	 makespan: 524.00	 Mean_loss: 0.04392263,  training time: 0.99
progress:  60%|[34m    [0m| 30/50 [00:35<00:20,  1.01s/it]progress:  62%|[34m   [0m| 31/50 [00:35<00:19,  1.01s/it]                                                         Episode 32	 reward: -4.99	 makespan: 494.50	 Mean_loss: 0.04385610,  training time: 1.05
progress:  62%|[34m   [0m| 31/50 [00:36<00:19,  1.01s/it]progress:  64%|[34m   [0m| 32/50 [00:36<00:18,  1.02s/it]                                                         Episode 33	 reward: -5.41	 makespan: 535.50	 Mean_loss: 0.02794874,  training time: 1.04
progress:  64%|[34m   [0m| 32/50 [00:37<00:18,  1.02s/it]progress:  66%|[34m   [0m| 33/50 [00:37<00:17,  1.02s/it]                                                         Episode 34	 reward: -5.18	 makespan: 513.25	 Mean_loss: 0.05055823,  training time: 1.04
progress:  66%|[34m   [0m| 33/50 [00:38<00:17,  1.02s/it]progress:  68%|[34m   [0m| 34/50 [00:38<00:16,  1.03s/it]                                                         Episode 35	 reward: -5.03	 makespan: 498.00	 Mean_loss: 0.04032473,  training time: 1.03
progress:  68%|[34m   [0m| 34/50 [00:39<00:16,  1.03s/it]progress:  70%|[34m   [0m| 35/50 [00:39<00:15,  1.03s/it]                                                         Episode 36	 reward: -5.02	 makespan: 496.75	 Mean_loss: 0.03385360,  training time: 0.98
progress:  70%|[34m   [0m| 35/50 [00:40<00:15,  1.03s/it]progress:  72%|[34m  [0m| 36/50 [00:40<00:14,  1.01s/it]                                                         Episode 37	 reward: -5.68	 makespan: 562.25	 Mean_loss: 0.11612057,  training time: 1.04
progress:  72%|[34m  [0m| 36/50 [00:41<00:14,  1.01s/it]progress:  74%|[34m  [0m| 37/50 [00:41<00:13,  1.02s/it]                                                         Episode 38	 reward: -5.00	 makespan: 495.25	 Mean_loss: 0.07991778,  training time: 1.01
progress:  74%|[34m  [0m| 37/50 [00:42<00:13,  1.02s/it]progress:  76%|[34m  [0m| 38/50 [00:42<00:12,  1.02s/it]                                                         Episode 39	 reward: -5.14	 makespan: 509.00	 Mean_loss: 0.03378480,  training time: 0.97
progress:  76%|[34m  [0m| 38/50 [00:43<00:12,  1.02s/it]progress:  78%|[34m  [0m| 39/50 [00:43<00:11,  1.00s/it]                                                         Episode 40	 reward: -5.32	 makespan: 526.75	 Mean_loss: 0.06094855,  training time: 1.04
progress:  78%|[34m  [0m| 39/50 [00:44<00:11,  1.00s/it]progress:  80%|[34m  [0m| 40/50 [00:44<00:10,  1.02s/it]                                                         Episode 41	 reward: -5.39	 makespan: 533.50	 Mean_loss: 0.07618643,  training time: 1.04
progress:  80%|[34m  [0m| 40/50 [00:45<00:10,  1.02s/it]progress:  82%|[34m [0m| 41/50 [00:45<00:09,  1.02s/it]                                                         Episode 42	 reward: -5.69	 makespan: 563.00	 Mean_loss: 0.07709843,  training time: 1.04
progress:  82%|[34m [0m| 41/50 [00:46<00:09,  1.02s/it]progress:  84%|[34m [0m| 42/50 [00:46<00:08,  1.03s/it]                                                         Episode 43	 reward: -5.19	 makespan: 513.75	 Mean_loss: 0.06855571,  training time: 0.99
progress:  84%|[34m [0m| 42/50 [00:47<00:08,  1.03s/it]progress:  86%|[34m [0m| 43/50 [00:47<00:07,  1.02s/it]                                                         Episode 44	 reward: -5.13	 makespan: 507.75	 Mean_loss: 0.05886082,  training time: 1.04
progress:  86%|[34m [0m| 43/50 [00:48<00:07,  1.02s/it]progress:  88%|[34m [0m| 44/50 [00:48<00:06,  1.02s/it]                                                         Episode 45	 reward: -5.21	 makespan: 515.50	 Mean_loss: 0.05975897,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:49<00:06,  1.02s/it]progress:  90%|[34m [0m| 45/50 [00:49<00:05,  1.03s/it]                                                         Episode 46	 reward: -5.19	 makespan: 513.75	 Mean_loss: 0.02013336,  training time: 0.98
progress:  90%|[34m [0m| 45/50 [00:50<00:05,  1.03s/it]progress:  92%|[34m[0m| 46/50 [00:50<00:04,  1.02s/it]                                                         Episode 47	 reward: -5.05	 makespan: 500.00	 Mean_loss: 0.05202701,  training time: 0.99
progress:  92%|[34m[0m| 46/50 [00:51<00:04,  1.02s/it]progress:  94%|[34m[0m| 47/50 [00:51<00:03,  1.01s/it]                                                         Episode 48	 reward: -5.35	 makespan: 529.75	 Mean_loss: 0.05581642,  training time: 0.99
progress:  94%|[34m[0m| 47/50 [00:52<00:03,  1.01s/it]progress:  96%|[34m[0m| 48/50 [00:52<00:02,  1.00s/it]                                                         Episode 49	 reward: -5.85	 makespan: 579.25	 Mean_loss: 0.04494917,  training time: 0.98
progress:  96%|[34m[0m| 48/50 [00:53<00:02,  1.00s/it]progress:  98%|[34m[0m| 49/50 [00:53<00:00,  1.00it/s]                                                         Episode 50	 reward: -5.30	 makespan: 524.75	 Mean_loss: 0.09415005,  training time: 1.04
progress:  98%|[34m[0m| 49/50 [00:54<00:00,  1.00it/s]progress: 100%|[34m[0m| 50/50 [00:54<00:00,  1.01s/it]progress: 100%|[34m[0m| 50/50 [00:54<00:00,  1.09s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 6
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.07	 makespan: 600.50	 Mean_loss: 0.09589480,  training time: 2.52
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:03,  2.52s/it]                                                        Episode 2	 reward: -6.35	 makespan: 629.00	 Mean_loss: 0.05735120,  training time: 1.48
progress:   2%|[34m         [0m| 1/50 [00:04<02:03,  2.52s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:31,  1.91s/it]                                                        Episode 3	 reward: -6.23	 makespan: 616.50	 Mean_loss: 0.06752077,  training time: 1.43
progress:   4%|[34m         [0m| 2/50 [00:05<01:31,  1.91s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:19,  1.69s/it]                                                        Episode 4	 reward: -6.61	 makespan: 654.75	 Mean_loss: 0.06355155,  training time: 1.45
progress:   6%|[34m         [0m| 3/50 [00:06<01:19,  1.69s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:13,  1.59s/it]                                                        Episode 5	 reward: -6.48	 makespan: 641.75	 Mean_loss: 0.04834772,  training time: 1.42
progress:   8%|[34m         [0m| 4/50 [00:08<01:13,  1.59s/it]progress:  10%|[34m         [0m| 5/50 [00:08<01:09,  1.53s/it]                                                        Episode 6	 reward: -6.67	 makespan: 660.50	 Mean_loss: 0.05031301,  training time: 1.44
progress:  10%|[34m         [0m| 5/50 [00:09<01:09,  1.53s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:06,  1.50s/it]                                                        Episode 7	 reward: -6.68	 makespan: 661.75	 Mean_loss: 0.05569670,  training time: 1.44
progress:  12%|[34m        [0m| 6/50 [00:11<01:06,  1.50s/it]progress:  14%|[34m        [0m| 7/50 [00:11<01:03,  1.48s/it]                                                        Episode 8	 reward: -6.63	 makespan: 656.25	 Mean_loss: 0.05200927,  training time: 1.43
progress:  14%|[34m        [0m| 7/50 [00:12<01:03,  1.48s/it]progress:  16%|[34m        [0m| 8/50 [00:12<01:01,  1.47s/it]                                                        Episode 9	 reward: -6.87	 makespan: 680.25	 Mean_loss: 0.07046820,  training time: 1.42
progress:  16%|[34m        [0m| 8/50 [00:14<01:01,  1.47s/it]progress:  18%|[34m        [0m| 9/50 [00:14<00:59,  1.45s/it]                                                        Episode 10	 reward: -6.68	 makespan: 661.00	 Mean_loss: 0.07587840,  training time: 1.46
progress:  18%|[34m        [0m| 9/50 [00:15<00:59,  1.45s/it]progress:  20%|[34m        [0m| 10/50 [00:15<00:58,  1.45s/it]                                                         Episode 11	 reward: -6.82	 makespan: 675.25	 Mean_loss: 0.06311530,  training time: 1.44
progress:  20%|[34m        [0m| 10/50 [00:16<00:58,  1.45s/it]progress:  22%|[34m       [0m| 11/50 [00:16<00:56,  1.45s/it]                                                         Episode 12	 reward: -7.24	 makespan: 716.50	 Mean_loss: 0.07099694,  training time: 1.44
progress:  22%|[34m       [0m| 11/50 [00:18<00:56,  1.45s/it]progress:  24%|[34m       [0m| 12/50 [00:18<00:55,  1.45s/it]                                                         Episode 13	 reward: -7.16	 makespan: 709.25	 Mean_loss: 0.10937784,  training time: 1.43
progress:  24%|[34m       [0m| 12/50 [00:19<00:55,  1.45s/it]progress:  26%|[34m       [0m| 13/50 [00:19<00:53,  1.44s/it]                                                         Episode 14	 reward: -6.79	 makespan: 671.75	 Mean_loss: 0.09396543,  training time: 1.47
progress:  26%|[34m       [0m| 13/50 [00:21<00:53,  1.44s/it]progress:  28%|[34m       [0m| 14/50 [00:21<00:52,  1.45s/it]                                                         Episode 15	 reward: -6.97	 makespan: 689.75	 Mean_loss: 0.05727503,  training time: 1.46
progress:  28%|[34m       [0m| 14/50 [00:22<00:52,  1.45s/it]progress:  30%|[34m       [0m| 15/50 [00:22<00:50,  1.45s/it]                                                         Episode 16	 reward: -6.79	 makespan: 672.50	 Mean_loss: 0.07039445,  training time: 1.45
progress:  30%|[34m       [0m| 15/50 [00:24<00:50,  1.45s/it]progress:  32%|[34m      [0m| 16/50 [00:24<00:49,  1.46s/it]                                                         Episode 17	 reward: -6.88	 makespan: 681.25	 Mean_loss: 0.04714143,  training time: 1.57
progress:  32%|[34m      [0m| 16/50 [00:25<00:49,  1.46s/it]progress:  34%|[34m      [0m| 17/50 [00:25<00:49,  1.49s/it]                                                         Episode 18	 reward: -6.98	 makespan: 691.00	 Mean_loss: 0.06391506,  training time: 1.46
progress:  34%|[34m      [0m| 17/50 [00:27<00:49,  1.49s/it]progress:  36%|[34m      [0m| 18/50 [00:27<00:47,  1.48s/it]                                                         Episode 19	 reward: -6.78	 makespan: 671.25	 Mean_loss: 0.03018896,  training time: 1.45
progress:  36%|[34m      [0m| 18/50 [00:28<00:47,  1.48s/it]progress:  38%|[34m      [0m| 19/50 [00:28<00:45,  1.47s/it]                                                         Episode 20	 reward: -6.60	 makespan: 653.00	 Mean_loss: 0.04044926,  training time: 1.50
progress:  38%|[34m      [0m| 19/50 [00:30<00:45,  1.47s/it]progress:  40%|[34m      [0m| 20/50 [00:30<00:44,  1.48s/it]                                                         Episode 21	 reward: -6.68	 makespan: 661.50	 Mean_loss: 0.03128470,  training time: 1.43
progress:  40%|[34m      [0m| 20/50 [00:31<00:44,  1.48s/it]progress:  42%|[34m     [0m| 21/50 [00:31<00:42,  1.47s/it]                                                         Episode 22	 reward: -6.74	 makespan: 667.00	 Mean_loss: 0.04292443,  training time: 1.44
progress:  42%|[34m     [0m| 21/50 [00:33<00:42,  1.47s/it]progress:  44%|[34m     [0m| 22/50 [00:33<00:40,  1.46s/it]                                                         Episode 23	 reward: -6.56	 makespan: 649.00	 Mean_loss: 0.03752064,  training time: 1.45
progress:  44%|[34m     [0m| 22/50 [00:34<00:40,  1.46s/it]progress:  46%|[34m     [0m| 23/50 [00:34<00:39,  1.46s/it]                                                         Episode 24	 reward: -6.49	 makespan: 642.75	 Mean_loss: 0.05457141,  training time: 1.44
progress:  46%|[34m     [0m| 23/50 [00:35<00:39,  1.46s/it]progress:  48%|[34m     [0m| 24/50 [00:35<00:37,  1.45s/it]                                                         Episode 25	 reward: -6.51	 makespan: 644.75	 Mean_loss: 0.03967318,  training time: 1.44
progress:  48%|[34m     [0m| 24/50 [00:37<00:37,  1.45s/it]progress:  50%|[34m     [0m| 25/50 [00:37<00:36,  1.45s/it]                                                         Episode 26	 reward: -6.74	 makespan: 667.75	 Mean_loss: 0.06787761,  training time: 1.45
progress:  50%|[34m     [0m| 25/50 [00:38<00:36,  1.45s/it]progress:  52%|[34m    [0m| 26/50 [00:38<00:34,  1.45s/it]                                                         Episode 27	 reward: -6.22	 makespan: 616.00	 Mean_loss: 0.03682021,  training time: 1.44
progress:  52%|[34m    [0m| 26/50 [00:40<00:34,  1.45s/it]progress:  54%|[34m    [0m| 27/50 [00:40<00:33,  1.45s/it]                                                         Episode 28	 reward: -6.57	 makespan: 650.75	 Mean_loss: 0.02840965,  training time: 1.45
progress:  54%|[34m    [0m| 27/50 [00:41<00:33,  1.45s/it]progress:  56%|[34m    [0m| 28/50 [00:41<00:31,  1.45s/it]                                                         Episode 29	 reward: -6.38	 makespan: 631.50	 Mean_loss: 0.03024349,  training time: 1.45
progress:  56%|[34m    [0m| 28/50 [00:43<00:31,  1.45s/it]progress:  58%|[34m    [0m| 29/50 [00:43<00:30,  1.45s/it]                                                         Episode 30	 reward: -6.44	 makespan: 638.00	 Mean_loss: 0.05032726,  training time: 1.44
progress:  58%|[34m    [0m| 29/50 [00:44<00:30,  1.45s/it]progress:  60%|[34m    [0m| 30/50 [00:44<00:28,  1.45s/it]                                                         Episode 31	 reward: -6.42	 makespan: 635.75	 Mean_loss: 0.01369726,  training time: 1.46
progress:  60%|[34m    [0m| 30/50 [00:46<00:28,  1.45s/it]progress:  62%|[34m   [0m| 31/50 [00:46<00:27,  1.45s/it]                                                         Episode 32	 reward: -7.00	 makespan: 693.00	 Mean_loss: 0.05767053,  training time: 1.45
progress:  62%|[34m   [0m| 31/50 [00:47<00:27,  1.45s/it]progress:  64%|[34m   [0m| 32/50 [00:47<00:26,  1.45s/it]                                                         Episode 33	 reward: -6.63	 makespan: 656.25	 Mean_loss: 0.05894978,  training time: 1.43
progress:  64%|[34m   [0m| 32/50 [00:48<00:26,  1.45s/it]progress:  66%|[34m   [0m| 33/50 [00:48<00:24,  1.44s/it]                                                         Episode 34	 reward: -6.49	 makespan: 642.75	 Mean_loss: 0.04534075,  training time: 1.45
progress:  66%|[34m   [0m| 33/50 [00:50<00:24,  1.44s/it]progress:  68%|[34m   [0m| 34/50 [00:50<00:23,  1.45s/it]                                                         Episode 35	 reward: -6.45	 makespan: 638.75	 Mean_loss: 0.06081270,  training time: 1.41
progress:  68%|[34m   [0m| 34/50 [00:51<00:23,  1.45s/it]progress:  70%|[34m   [0m| 35/50 [00:51<00:21,  1.44s/it]                                                         Episode 36	 reward: -6.34	 makespan: 627.75	 Mean_loss: 0.03397575,  training time: 1.41
progress:  70%|[34m   [0m| 35/50 [00:53<00:21,  1.44s/it]progress:  72%|[34m  [0m| 36/50 [00:53<00:19,  1.43s/it]                                                         Episode 37	 reward: -6.21	 makespan: 615.00	 Mean_loss: 0.04191786,  training time: 1.43
progress:  72%|[34m  [0m| 36/50 [00:54<00:19,  1.43s/it]progress:  74%|[34m  [0m| 37/50 [00:54<00:18,  1.43s/it]                                                         Episode 38	 reward: -6.43	 makespan: 636.25	 Mean_loss: 0.01087176,  training time: 1.41
progress:  74%|[34m  [0m| 37/50 [00:56<00:18,  1.43s/it]progress:  76%|[34m  [0m| 38/50 [00:56<00:17,  1.42s/it]                                                         Episode 39	 reward: -6.43	 makespan: 636.75	 Mean_loss: 0.03557165,  training time: 1.46
progress:  76%|[34m  [0m| 38/50 [00:57<00:17,  1.42s/it]progress:  78%|[34m  [0m| 39/50 [00:57<00:15,  1.43s/it]                                                         Episode 40	 reward: -6.21	 makespan: 614.75	 Mean_loss: 0.01967852,  training time: 1.44
progress:  78%|[34m  [0m| 39/50 [00:59<00:15,  1.43s/it]progress:  80%|[34m  [0m| 40/50 [00:59<00:14,  1.44s/it]                                                         Episode 41	 reward: -6.17	 makespan: 610.50	 Mean_loss: 0.02384276,  training time: 1.44
progress:  80%|[34m  [0m| 40/50 [01:00<00:14,  1.44s/it]progress:  82%|[34m [0m| 41/50 [01:00<00:12,  1.44s/it]                                                         Episode 42	 reward: -6.57	 makespan: 650.00	 Mean_loss: 0.02750751,  training time: 1.46
progress:  82%|[34m [0m| 41/50 [01:01<00:12,  1.44s/it]progress:  84%|[34m [0m| 42/50 [01:01<00:11,  1.45s/it]                                                         Episode 43	 reward: -6.70	 makespan: 663.50	 Mean_loss: 0.05702883,  training time: 1.45
progress:  84%|[34m [0m| 42/50 [01:03<00:11,  1.45s/it]progress:  86%|[34m [0m| 43/50 [01:03<00:10,  1.45s/it]                                                         Episode 44	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.05457490,  training time: 1.44
progress:  86%|[34m [0m| 43/50 [01:04<00:10,  1.45s/it]progress:  88%|[34m [0m| 44/50 [01:04<00:08,  1.45s/it]                                                         Episode 45	 reward: -6.75	 makespan: 668.25	 Mean_loss: 0.03162817,  training time: 1.44
progress:  88%|[34m [0m| 44/50 [01:06<00:08,  1.45s/it]progress:  90%|[34m [0m| 45/50 [01:06<00:07,  1.45s/it]                                                         Episode 46	 reward: -6.64	 makespan: 657.25	 Mean_loss: 0.04610546,  training time: 1.44
progress:  90%|[34m [0m| 45/50 [01:07<00:07,  1.45s/it]progress:  92%|[34m[0m| 46/50 [01:07<00:05,  1.44s/it]                                                         Episode 47	 reward: -6.99	 makespan: 692.50	 Mean_loss: 0.06530228,  training time: 1.44
progress:  92%|[34m[0m| 46/50 [01:09<00:05,  1.44s/it]progress:  94%|[34m[0m| 47/50 [01:09<00:04,  1.44s/it]                                                         Episode 48	 reward: -6.60	 makespan: 653.00	 Mean_loss: 0.03736376,  training time: 1.44
progress:  94%|[34m[0m| 47/50 [01:10<00:04,  1.44s/it]progress:  96%|[34m[0m| 48/50 [01:10<00:02,  1.44s/it]                                                         Episode 49	 reward: -6.73	 makespan: 666.75	 Mean_loss: 0.02185203,  training time: 1.45
progress:  96%|[34m[0m| 48/50 [01:12<00:02,  1.44s/it]progress:  98%|[34m[0m| 49/50 [01:12<00:01,  1.44s/it]                                                         Episode 50	 reward: -6.76	 makespan: 669.00	 Mean_loss: 0.02315839,  training time: 1.47
progress:  98%|[34m[0m| 49/50 [01:13<00:01,  1.44s/it]progress: 100%|[34m[0m| 50/50 [01:13<00:00,  1.45s/it]progress: 100%|[34m[0m| 50/50 [01:13<00:00,  1.47s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 8
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.66	 makespan: 857.00	 Mean_loss: 0.22620916,  training time: 2.93
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:23,  2.93s/it]                                                        Episode 2	 reward: -8.27	 makespan: 818.75	 Mean_loss: 0.15161464,  training time: 1.90
progress:   2%|[34m         [0m| 1/50 [00:04<02:23,  2.93s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:51,  2.32s/it]                                                        Episode 3	 reward: -9.12	 makespan: 902.50	 Mean_loss: 0.25595894,  training time: 1.89
progress:   4%|[34m         [0m| 2/50 [00:06<01:51,  2.32s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:39,  2.12s/it]                                                        Episode 4	 reward: -8.93	 makespan: 883.75	 Mean_loss: 0.19794798,  training time: 1.87
progress:   6%|[34m         [0m| 3/50 [00:08<01:39,  2.12s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:33,  2.03s/it]                                                        Episode 5	 reward: -8.44	 makespan: 835.50	 Mean_loss: 0.16368854,  training time: 1.89
progress:   8%|[34m         [0m| 4/50 [00:10<01:33,  2.03s/it]progress:  10%|[34m         [0m| 5/50 [00:10<01:28,  1.98s/it]                                                        Episode 6	 reward: -8.51	 makespan: 842.75	 Mean_loss: 0.11109926,  training time: 1.88
progress:  10%|[34m         [0m| 5/50 [00:12<01:28,  1.98s/it]progress:  12%|[34m        [0m| 6/50 [00:12<01:25,  1.94s/it]                                                        Episode 7	 reward: -8.56	 makespan: 847.75	 Mean_loss: 0.10647525,  training time: 1.90
progress:  12%|[34m        [0m| 6/50 [00:14<01:25,  1.94s/it]progress:  14%|[34m        [0m| 7/50 [00:14<01:23,  1.93s/it]                                                        Episode 8	 reward: -8.56	 makespan: 847.50	 Mean_loss: 0.05390956,  training time: 1.88
progress:  14%|[34m        [0m| 7/50 [00:16<01:23,  1.93s/it]progress:  16%|[34m        [0m| 8/50 [00:16<01:20,  1.92s/it]                                                        Episode 9	 reward: -9.17	 makespan: 907.75	 Mean_loss: 0.14330837,  training time: 1.88
progress:  16%|[34m        [0m| 8/50 [00:18<01:20,  1.92s/it]progress:  18%|[34m        [0m| 9/50 [00:18<01:18,  1.90s/it]                                                        Episode 10	 reward: -8.57	 makespan: 848.00	 Mean_loss: 0.07848452,  training time: 1.87
progress:  18%|[34m        [0m| 9/50 [00:19<01:18,  1.90s/it]progress:  20%|[34m        [0m| 10/50 [00:19<01:15,  1.90s/it]                                                         Episode 11	 reward: -8.52	 makespan: 843.50	 Mean_loss: 0.08288264,  training time: 1.88
progress:  20%|[34m        [0m| 10/50 [00:21<01:15,  1.90s/it]progress:  22%|[34m       [0m| 11/50 [00:21<01:13,  1.89s/it]                                                         Episode 12	 reward: -8.77	 makespan: 868.50	 Mean_loss: 0.08665246,  training time: 2.02
progress:  22%|[34m       [0m| 11/50 [00:23<01:13,  1.89s/it]progress:  24%|[34m       [0m| 12/50 [00:23<01:13,  1.93s/it]                                                         Episode 13	 reward: -8.53	 makespan: 844.00	 Mean_loss: 0.05412916,  training time: 1.88
progress:  24%|[34m       [0m| 12/50 [00:25<01:13,  1.93s/it]progress:  26%|[34m       [0m| 13/50 [00:25<01:10,  1.92s/it]                                                         Episode 14	 reward: -8.82	 makespan: 873.25	 Mean_loss: 0.10185935,  training time: 1.88
progress:  26%|[34m       [0m| 13/50 [00:27<01:10,  1.92s/it]progress:  28%|[34m       [0m| 14/50 [00:27<01:08,  1.91s/it]                                                         Episode 15	 reward: -8.74	 makespan: 865.00	 Mean_loss: 0.08001015,  training time: 1.89
progress:  28%|[34m       [0m| 14/50 [00:29<01:08,  1.91s/it]progress:  30%|[34m       [0m| 15/50 [00:29<01:06,  1.90s/it]                                                         Episode 16	 reward: -8.68	 makespan: 859.00	 Mean_loss: 0.06792548,  training time: 1.89
progress:  30%|[34m       [0m| 15/50 [00:31<01:06,  1.90s/it]progress:  32%|[34m      [0m| 16/50 [00:31<01:04,  1.90s/it]                                                         Episode 17	 reward: -8.73	 makespan: 864.25	 Mean_loss: 0.07314346,  training time: 1.87
progress:  32%|[34m      [0m| 16/50 [00:33<01:04,  1.90s/it]progress:  34%|[34m      [0m| 17/50 [00:33<01:02,  1.89s/it]                                                         Episode 18	 reward: -8.83	 makespan: 874.00	 Mean_loss: 0.04535807,  training time: 1.88
progress:  34%|[34m      [0m| 17/50 [00:35<01:02,  1.89s/it]progress:  36%|[34m      [0m| 18/50 [00:35<01:00,  1.89s/it]                                                         Episode 19	 reward: -9.05	 makespan: 895.50	 Mean_loss: 0.09428674,  training time: 1.88
progress:  36%|[34m      [0m| 18/50 [00:36<01:00,  1.89s/it]progress:  38%|[34m      [0m| 19/50 [00:36<00:58,  1.88s/it]                                                         Episode 20	 reward: -8.61	 makespan: 852.00	 Mean_loss: 0.09193507,  training time: 1.88
progress:  38%|[34m      [0m| 19/50 [00:38<00:58,  1.88s/it]progress:  40%|[34m      [0m| 20/50 [00:38<00:56,  1.89s/it]                                                         Episode 21	 reward: -8.78	 makespan: 869.00	 Mean_loss: 0.06469464,  training time: 1.88
progress:  40%|[34m      [0m| 20/50 [00:40<00:56,  1.89s/it]progress:  42%|[34m     [0m| 21/50 [00:40<00:54,  1.88s/it]                                                         Episode 22	 reward: -8.78	 makespan: 869.25	 Mean_loss: 0.09839429,  training time: 1.87
progress:  42%|[34m     [0m| 21/50 [00:42<00:54,  1.88s/it]progress:  44%|[34m     [0m| 22/50 [00:42<00:52,  1.88s/it]                                                         Episode 23	 reward: -8.84	 makespan: 875.00	 Mean_loss: 0.04529544,  training time: 1.87
progress:  44%|[34m     [0m| 22/50 [00:44<00:52,  1.88s/it]progress:  46%|[34m     [0m| 23/50 [00:44<00:50,  1.88s/it]                                                         Episode 24	 reward: -8.89	 makespan: 879.75	 Mean_loss: 0.04903419,  training time: 1.92
progress:  46%|[34m     [0m| 23/50 [00:46<00:50,  1.88s/it]progress:  48%|[34m     [0m| 24/50 [00:46<00:49,  1.89s/it]                                                         Episode 25	 reward: -8.80	 makespan: 871.50	 Mean_loss: 0.05258600,  training time: 1.95
progress:  48%|[34m     [0m| 24/50 [00:48<00:49,  1.89s/it]progress:  50%|[34m     [0m| 25/50 [00:48<00:47,  1.91s/it]                                                         Episode 26	 reward: -8.74	 makespan: 865.75	 Mean_loss: 0.03757451,  training time: 1.87
progress:  50%|[34m     [0m| 25/50 [00:50<00:47,  1.91s/it]progress:  52%|[34m    [0m| 26/50 [00:50<00:45,  1.90s/it]                                                         Episode 27	 reward: -8.77	 makespan: 868.50	 Mean_loss: 0.06094254,  training time: 1.88
progress:  52%|[34m    [0m| 26/50 [00:52<00:45,  1.90s/it]progress:  54%|[34m    [0m| 27/50 [00:52<00:43,  1.89s/it]                                                         Episode 28	 reward: -8.86	 makespan: 877.50	 Mean_loss: 0.04408041,  training time: 1.92
progress:  54%|[34m    [0m| 27/50 [00:54<00:43,  1.89s/it]progress:  56%|[34m    [0m| 28/50 [00:54<00:41,  1.90s/it]                                                         Episode 29	 reward: -8.63	 makespan: 854.75	 Mean_loss: 0.05991028,  training time: 1.96
progress:  56%|[34m    [0m| 28/50 [00:56<00:41,  1.90s/it]progress:  58%|[34m    [0m| 29/50 [00:56<00:40,  1.92s/it]                                                         Episode 30	 reward: -9.01	 makespan: 891.50	 Mean_loss: 0.06855057,  training time: 1.87
progress:  58%|[34m    [0m| 29/50 [00:57<00:40,  1.92s/it]progress:  60%|[34m    [0m| 30/50 [00:57<00:38,  1.91s/it]                                                         Episode 31	 reward: -8.87	 makespan: 878.50	 Mean_loss: 0.03431466,  training time: 1.86
progress:  60%|[34m    [0m| 30/50 [00:59<00:38,  1.91s/it]progress:  62%|[34m   [0m| 31/50 [00:59<00:35,  1.89s/it]                                                         Episode 32	 reward: -8.90	 makespan: 881.25	 Mean_loss: 0.04363260,  training time: 1.87
progress:  62%|[34m   [0m| 31/50 [01:01<00:35,  1.89s/it]progress:  64%|[34m   [0m| 32/50 [01:01<00:33,  1.89s/it]                                                         Episode 33	 reward: -8.82	 makespan: 873.00	 Mean_loss: 0.07934945,  training time: 1.86
progress:  64%|[34m   [0m| 32/50 [01:03<00:33,  1.89s/it]progress:  66%|[34m   [0m| 33/50 [01:03<00:31,  1.88s/it]                                                         Episode 34	 reward: -8.90	 makespan: 881.25	 Mean_loss: 0.04981584,  training time: 1.88
progress:  66%|[34m   [0m| 33/50 [01:05<00:31,  1.88s/it]progress:  68%|[34m   [0m| 34/50 [01:05<00:30,  1.88s/it]                                                         Episode 35	 reward: -8.83	 makespan: 874.25	 Mean_loss: 0.06164822,  training time: 1.87
progress:  68%|[34m   [0m| 34/50 [01:07<00:30,  1.88s/it]progress:  70%|[34m   [0m| 35/50 [01:07<00:28,  1.88s/it]                                                         Episode 36	 reward: -8.97	 makespan: 888.00	 Mean_loss: 0.06293282,  training time: 1.89
progress:  70%|[34m   [0m| 35/50 [01:09<00:28,  1.88s/it]progress:  72%|[34m  [0m| 36/50 [01:09<00:26,  1.88s/it]                                                         Episode 37	 reward: -9.14	 makespan: 905.25	 Mean_loss: 0.04139957,  training time: 1.88
progress:  72%|[34m  [0m| 36/50 [01:11<00:26,  1.88s/it]progress:  74%|[34m  [0m| 37/50 [01:11<00:24,  1.88s/it]                                                         Episode 38	 reward: -8.99	 makespan: 890.25	 Mean_loss: 0.04691624,  training time: 1.89
progress:  74%|[34m  [0m| 37/50 [01:12<00:24,  1.88s/it]progress:  76%|[34m  [0m| 38/50 [01:12<00:22,  1.89s/it]                                                         Episode 39	 reward: -8.86	 makespan: 876.75	 Mean_loss: 0.05562234,  training time: 1.87
progress:  76%|[34m  [0m| 38/50 [01:14<00:22,  1.89s/it]progress:  78%|[34m  [0m| 39/50 [01:14<00:20,  1.88s/it]                                                         Episode 40	 reward: -9.09	 makespan: 899.50	 Mean_loss: 0.05781538,  training time: 1.87
progress:  78%|[34m  [0m| 39/50 [01:16<00:20,  1.88s/it]progress:  80%|[34m  [0m| 40/50 [01:16<00:18,  1.88s/it]                                                         Episode 41	 reward: -9.02	 makespan: 893.00	 Mean_loss: 0.05108908,  training time: 1.90
progress:  80%|[34m  [0m| 40/50 [01:18<00:18,  1.88s/it]progress:  82%|[34m [0m| 41/50 [01:18<00:16,  1.88s/it]                                                         Episode 42	 reward: -9.07	 makespan: 897.50	 Mean_loss: 0.05546264,  training time: 1.88
progress:  82%|[34m [0m| 41/50 [01:20<00:16,  1.88s/it]progress:  84%|[34m [0m| 42/50 [01:20<00:15,  1.88s/it]                                                         Episode 43	 reward: -8.83	 makespan: 874.00	 Mean_loss: 0.04268420,  training time: 1.86
progress:  84%|[34m [0m| 42/50 [01:22<00:15,  1.88s/it]progress:  86%|[34m [0m| 43/50 [01:22<00:13,  1.88s/it]                                                         Episode 44	 reward: -9.06	 makespan: 896.50	 Mean_loss: 0.04837980,  training time: 1.88
progress:  86%|[34m [0m| 43/50 [01:24<00:13,  1.88s/it]progress:  88%|[34m [0m| 44/50 [01:24<00:11,  1.88s/it]                                                         Episode 45	 reward: -9.12	 makespan: 903.00	 Mean_loss: 0.05790984,  training time: 1.88
progress:  88%|[34m [0m| 44/50 [01:26<00:11,  1.88s/it]progress:  90%|[34m [0m| 45/50 [01:26<00:09,  1.88s/it]                                                         Episode 46	 reward: -8.89	 makespan: 879.75	 Mean_loss: 0.04815562,  training time: 1.91
progress:  90%|[34m [0m| 45/50 [01:27<00:09,  1.88s/it]progress:  92%|[34m[0m| 46/50 [01:27<00:07,  1.89s/it]                                                         Episode 47	 reward: -9.08	 makespan: 899.00	 Mean_loss: 0.06241715,  training time: 1.88
progress:  92%|[34m[0m| 46/50 [01:29<00:07,  1.89s/it]progress:  94%|[34m[0m| 47/50 [01:29<00:05,  1.89s/it]                                                         Episode 48	 reward: -9.07	 makespan: 897.50	 Mean_loss: 0.06613380,  training time: 1.94
progress:  94%|[34m[0m| 47/50 [01:31<00:05,  1.89s/it]progress:  96%|[34m[0m| 48/50 [01:31<00:03,  1.90s/it]                                                         Episode 49	 reward: -9.16	 makespan: 906.50	 Mean_loss: 0.06876656,  training time: 1.89
progress:  96%|[34m[0m| 48/50 [01:33<00:03,  1.90s/it]progress:  98%|[34m[0m| 49/50 [01:33<00:01,  1.90s/it]                                                         Episode 50	 reward: -8.94	 makespan: 885.00	 Mean_loss: 0.04910371,  training time: 1.91
progress:  98%|[34m[0m| 49/50 [01:35<00:01,  1.90s/it]progress: 100%|[34m[0m| 50/50 [01:35<00:00,  1.90s/it]progress: 100%|[34m[0m| 50/50 [01:35<00:00,  1.91s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -11.25	 makespan: 1114.00	 Mean_loss: 0.44088471,  training time: 3.38
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:45,  3.38s/it]                                                        Episode 2	 reward: -11.40	 makespan: 1128.75	 Mean_loss: 0.40410751,  training time: 2.34
progress:   2%|[34m         [0m| 1/50 [00:05<02:45,  3.38s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:12,  2.77s/it]                                                        Episode 3	 reward: -11.21	 makespan: 1110.00	 Mean_loss: 0.40015459,  training time: 2.31
progress:   4%|[34m         [0m| 2/50 [00:08<02:12,  2.77s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:00,  2.56s/it]                                                        Episode 4	 reward: -10.99	 makespan: 1088.00	 Mean_loss: 0.48805425,  training time: 2.33
progress:   6%|[34m         [0m| 3/50 [00:10<02:00,  2.56s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:53,  2.47s/it]                                                        Episode 5	 reward: -11.60	 makespan: 1148.25	 Mean_loss: 0.37930027,  training time: 2.33
progress:   8%|[34m         [0m| 4/50 [00:12<01:53,  2.47s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:48,  2.42s/it]                                                        Episode 6	 reward: -10.95	 makespan: 1084.25	 Mean_loss: 0.28553089,  training time: 2.46
progress:  10%|[34m         [0m| 5/50 [00:15<01:48,  2.42s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:47,  2.44s/it]                                                        Episode 7	 reward: -11.64	 makespan: 1152.25	 Mean_loss: 0.28448606,  training time: 2.34
progress:  12%|[34m        [0m| 6/50 [00:17<01:47,  2.44s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:43,  2.40s/it]                                                        Episode 8	 reward: -11.49	 makespan: 1137.25	 Mean_loss: 0.25141239,  training time: 2.31
progress:  14%|[34m        [0m| 7/50 [00:19<01:43,  2.40s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:39,  2.37s/it]                                                        Episode 9	 reward: -11.58	 makespan: 1146.25	 Mean_loss: 0.25048110,  training time: 2.31
progress:  16%|[34m        [0m| 8/50 [00:22<01:39,  2.37s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:36,  2.36s/it]                                                        Episode 10	 reward: -11.50	 makespan: 1138.25	 Mean_loss: 0.19620293,  training time: 2.30
progress:  18%|[34m        [0m| 9/50 [00:24<01:36,  2.36s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:33,  2.34s/it]                                                         Episode 11	 reward: -11.73	 makespan: 1161.50	 Mean_loss: 0.19133352,  training time: 2.31
progress:  20%|[34m        [0m| 10/50 [00:26<01:33,  2.34s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:30,  2.33s/it]                                                         Episode 12	 reward: -11.32	 makespan: 1121.00	 Mean_loss: 0.28150675,  training time: 2.31
progress:  22%|[34m       [0m| 11/50 [00:29<01:30,  2.33s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:28,  2.32s/it]                                                         Episode 13	 reward: -11.59	 makespan: 1147.25	 Mean_loss: 0.19070791,  training time: 2.31
progress:  24%|[34m       [0m| 12/50 [00:31<01:28,  2.32s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:25,  2.32s/it]                                                         Episode 14	 reward: -11.30	 makespan: 1118.75	 Mean_loss: 0.17029494,  training time: 2.29
progress:  26%|[34m       [0m| 13/50 [00:33<01:25,  2.32s/it]progress:  28%|[34m       [0m| 14/50 [00:33<01:23,  2.31s/it]                                                         Episode 15	 reward: -11.49	 makespan: 1137.75	 Mean_loss: 0.14510748,  training time: 2.31
progress:  28%|[34m       [0m| 14/50 [00:35<01:23,  2.31s/it]progress:  30%|[34m       [0m| 15/50 [00:35<01:20,  2.31s/it]                                                         Episode 16	 reward: -11.54	 makespan: 1142.00	 Mean_loss: 0.11280050,  training time: 2.31
progress:  30%|[34m       [0m| 15/50 [00:38<01:20,  2.31s/it]progress:  32%|[34m      [0m| 16/50 [00:38<01:18,  2.31s/it]                                                         Episode 17	 reward: -11.33	 makespan: 1121.25	 Mean_loss: 0.12628043,  training time: 2.31
progress:  32%|[34m      [0m| 16/50 [00:40<01:18,  2.31s/it]progress:  34%|[34m      [0m| 17/50 [00:40<01:16,  2.31s/it]                                                         Episode 18	 reward: -11.60	 makespan: 1148.00	 Mean_loss: 0.13235928,  training time: 2.31
progress:  34%|[34m      [0m| 17/50 [00:42<01:16,  2.31s/it]progress:  36%|[34m      [0m| 18/50 [00:42<01:13,  2.31s/it]                                                         Episode 19	 reward: -11.28	 makespan: 1116.25	 Mean_loss: 0.11070076,  training time: 2.31
progress:  36%|[34m      [0m| 18/50 [00:45<01:13,  2.31s/it]progress:  38%|[34m      [0m| 19/50 [00:45<01:11,  2.31s/it]                                                         Episode 20	 reward: -11.45	 makespan: 1133.25	 Mean_loss: 0.10124712,  training time: 2.28
progress:  38%|[34m      [0m| 19/50 [00:47<01:11,  2.31s/it]progress:  40%|[34m      [0m| 20/50 [00:47<01:09,  2.30s/it]                                                         Episode 21	 reward: -11.58	 makespan: 1146.00	 Mean_loss: 0.12062308,  training time: 2.32
progress:  40%|[34m      [0m| 20/50 [00:49<01:09,  2.30s/it]progress:  42%|[34m     [0m| 21/50 [00:49<01:06,  2.31s/it]                                                         Episode 22	 reward: -11.37	 makespan: 1126.00	 Mean_loss: 0.09784928,  training time: 2.30
progress:  42%|[34m     [0m| 21/50 [00:52<01:06,  2.31s/it]progress:  44%|[34m     [0m| 22/50 [00:52<01:04,  2.31s/it]                                                         Episode 23	 reward: -11.42	 makespan: 1130.50	 Mean_loss: 0.14685413,  training time: 2.29
progress:  44%|[34m     [0m| 22/50 [00:54<01:04,  2.31s/it]progress:  46%|[34m     [0m| 23/50 [00:54<01:02,  2.30s/it]                                                         Episode 24	 reward: -11.54	 makespan: 1142.25	 Mean_loss: 0.15068486,  training time: 2.29
progress:  46%|[34m     [0m| 23/50 [00:56<01:02,  2.30s/it]progress:  48%|[34m     [0m| 24/50 [00:56<00:59,  2.30s/it]                                                         Episode 25	 reward: -11.68	 makespan: 1156.50	 Mean_loss: 0.10717967,  training time: 2.29
progress:  48%|[34m     [0m| 24/50 [00:58<00:59,  2.30s/it]progress:  50%|[34m     [0m| 25/50 [00:58<00:57,  2.29s/it]                                                         Episode 26	 reward: -11.29	 makespan: 1118.00	 Mean_loss: 0.09668046,  training time: 2.29
progress:  50%|[34m     [0m| 25/50 [01:01<00:57,  2.29s/it]progress:  52%|[34m    [0m| 26/50 [01:01<00:55,  2.29s/it]                                                         Episode 27	 reward: -11.26	 makespan: 1114.75	 Mean_loss: 0.08971438,  training time: 2.28
progress:  52%|[34m    [0m| 26/50 [01:03<00:55,  2.29s/it]progress:  54%|[34m    [0m| 27/50 [01:03<00:52,  2.29s/it]                                                         Episode 28	 reward: -11.39	 makespan: 1128.00	 Mean_loss: 0.17307192,  training time: 2.30
progress:  54%|[34m    [0m| 27/50 [01:05<00:52,  2.29s/it]progress:  56%|[34m    [0m| 28/50 [01:05<00:50,  2.29s/it]                                                         Episode 29	 reward: -11.57	 makespan: 1145.75	 Mean_loss: 0.07995073,  training time: 2.28
progress:  56%|[34m    [0m| 28/50 [01:08<00:50,  2.29s/it]progress:  58%|[34m    [0m| 29/50 [01:08<00:48,  2.29s/it]                                                         Episode 30	 reward: -11.27	 makespan: 1116.00	 Mean_loss: 0.06872290,  training time: 2.31
progress:  58%|[34m    [0m| 29/50 [01:10<00:48,  2.29s/it]progress:  60%|[34m    [0m| 30/50 [01:10<00:45,  2.30s/it]                                                         Episode 31	 reward: -11.19	 makespan: 1108.00	 Mean_loss: 0.07992943,  training time: 2.28
progress:  60%|[34m    [0m| 30/50 [01:12<00:45,  2.30s/it]progress:  62%|[34m   [0m| 31/50 [01:12<00:43,  2.29s/it]                                                         Episode 32	 reward: -11.47	 makespan: 1135.50	 Mean_loss: 0.09261413,  training time: 2.31
progress:  62%|[34m   [0m| 31/50 [01:15<00:43,  2.29s/it]progress:  64%|[34m   [0m| 32/50 [01:15<00:41,  2.30s/it]                                                         Episode 33	 reward: -11.35	 makespan: 1124.00	 Mean_loss: 0.06841959,  training time: 2.28
progress:  64%|[34m   [0m| 32/50 [01:17<00:41,  2.30s/it]progress:  66%|[34m   [0m| 33/50 [01:17<00:38,  2.29s/it]                                                         Episode 34	 reward: -11.96	 makespan: 1183.75	 Mean_loss: 0.10516817,  training time: 2.33
progress:  66%|[34m   [0m| 33/50 [01:19<00:38,  2.29s/it]progress:  68%|[34m   [0m| 34/50 [01:19<00:36,  2.31s/it]                                                         Episode 35	 reward: -11.40	 makespan: 1128.50	 Mean_loss: 0.06781723,  training time: 2.27
progress:  68%|[34m   [0m| 34/50 [01:21<00:36,  2.31s/it]progress:  70%|[34m   [0m| 35/50 [01:21<00:34,  2.30s/it]                                                         Episode 36	 reward: -11.32	 makespan: 1120.50	 Mean_loss: 0.07648462,  training time: 2.26
progress:  70%|[34m   [0m| 35/50 [01:24<00:34,  2.30s/it]progress:  72%|[34m  [0m| 36/50 [01:24<00:31,  2.29s/it]                                                         Episode 37	 reward: -11.16	 makespan: 1105.25	 Mean_loss: 0.09560543,  training time: 2.29
progress:  72%|[34m  [0m| 36/50 [01:26<00:31,  2.29s/it]progress:  74%|[34m  [0m| 37/50 [01:26<00:29,  2.29s/it]                                                         Episode 38	 reward: -11.31	 makespan: 1120.00	 Mean_loss: 0.09694563,  training time: 2.26
progress:  74%|[34m  [0m| 37/50 [01:28<00:29,  2.29s/it]progress:  76%|[34m  [0m| 38/50 [01:28<00:27,  2.28s/it]                                                         Episode 39	 reward: -11.22	 makespan: 1111.25	 Mean_loss: 0.07142860,  training time: 2.26
progress:  76%|[34m  [0m| 38/50 [01:30<00:27,  2.28s/it]progress:  78%|[34m  [0m| 39/50 [01:30<00:25,  2.27s/it]                                                         Episode 40	 reward: -11.38	 makespan: 1127.00	 Mean_loss: 0.06550961,  training time: 2.25
progress:  78%|[34m  [0m| 39/50 [01:33<00:25,  2.27s/it]progress:  80%|[34m  [0m| 40/50 [01:33<00:22,  2.27s/it]                                                         Episode 41	 reward: -11.12	 makespan: 1100.75	 Mean_loss: 0.04923354,  training time: 2.28
progress:  80%|[34m  [0m| 40/50 [01:35<00:22,  2.27s/it]progress:  82%|[34m [0m| 41/50 [01:35<00:20,  2.27s/it]                                                         Episode 42	 reward: -11.18	 makespan: 1107.25	 Mean_loss: 0.06204730,  training time: 2.28
progress:  82%|[34m [0m| 41/50 [01:37<00:20,  2.27s/it]progress:  84%|[34m [0m| 42/50 [01:37<00:18,  2.27s/it]                                                         Episode 43	 reward: -11.34	 makespan: 1122.75	 Mean_loss: 0.07859906,  training time: 2.28
progress:  84%|[34m [0m| 42/50 [01:40<00:18,  2.27s/it]progress:  86%|[34m [0m| 43/50 [01:40<00:15,  2.28s/it]                                                         Episode 44	 reward: -11.06	 makespan: 1094.50	 Mean_loss: 0.08224241,  training time: 2.25
progress:  86%|[34m [0m| 43/50 [01:42<00:15,  2.28s/it]progress:  88%|[34m [0m| 44/50 [01:42<00:13,  2.27s/it]                                                         Episode 45	 reward: -11.58	 makespan: 1146.50	 Mean_loss: 0.06724748,  training time: 2.28
progress:  88%|[34m [0m| 44/50 [01:44<00:13,  2.27s/it]progress:  90%|[34m [0m| 45/50 [01:44<00:11,  2.27s/it]                                                         Episode 46	 reward: -11.47	 makespan: 1135.25	 Mean_loss: 0.05314105,  training time: 2.28
progress:  90%|[34m [0m| 45/50 [01:46<00:11,  2.27s/it]progress:  92%|[34m[0m| 46/50 [01:46<00:09,  2.28s/it]                                                         Episode 47	 reward: -11.39	 makespan: 1128.00	 Mean_loss: 0.06352748,  training time: 2.28
progress:  92%|[34m[0m| 46/50 [01:49<00:09,  2.28s/it]progress:  94%|[34m[0m| 47/50 [01:49<00:06,  2.28s/it]                                                         Episode 48	 reward: -11.53	 makespan: 1141.50	 Mean_loss: 0.06063436,  training time: 2.30
progress:  94%|[34m[0m| 47/50 [01:51<00:06,  2.28s/it]progress:  96%|[34m[0m| 48/50 [01:51<00:04,  2.28s/it]                                                         Episode 49	 reward: -11.72	 makespan: 1160.25	 Mean_loss: 0.06254958,  training time: 2.29
progress:  96%|[34m[0m| 48/50 [01:53<00:04,  2.28s/it]progress:  98%|[34m[0m| 49/50 [01:53<00:02,  2.28s/it]                                                         Episode 50	 reward: -11.60	 makespan: 1148.00	 Mean_loss: 0.04779495,  training time: 2.30
progress:  98%|[34m[0m| 49/50 [01:56<00:02,  2.28s/it]progress: 100%|[34m[0m| 50/50 [01:56<00:00,  2.29s/it]progress: 100%|[34m[0m| 50/50 [01:56<00:00,  2.32s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -13.23	 makespan: 1309.75	 Mean_loss: 0.71270525,  training time: 3.81
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:06,  3.81s/it]                                                        Episode 2	 reward: -13.29	 makespan: 1315.75	 Mean_loss: 0.48738793,  training time: 2.78
progress:   2%|[34m         [0m| 1/50 [00:06<03:06,  3.81s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:33,  3.21s/it]                                                        Episode 3	 reward: -13.54	 makespan: 1340.75	 Mean_loss: 0.59640855,  training time: 2.74
progress:   4%|[34m         [0m| 2/50 [00:09<02:33,  3.21s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:20,  3.00s/it]                                                        Episode 4	 reward: -13.37	 makespan: 1324.00	 Mean_loss: 0.57866538,  training time: 2.74
progress:   6%|[34m         [0m| 3/50 [00:12<02:20,  3.00s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:13,  2.89s/it]                                                        Episode 5	 reward: -13.89	 makespan: 1375.50	 Mean_loss: 0.85811937,  training time: 2.89
progress:   8%|[34m         [0m| 4/50 [00:14<02:13,  2.89s/it]progress:  10%|[34m         [0m| 5/50 [00:14<02:10,  2.89s/it]                                                        Episode 6	 reward: -13.70	 makespan: 1356.75	 Mean_loss: 0.50093234,  training time: 2.73
progress:  10%|[34m         [0m| 5/50 [00:17<02:10,  2.89s/it]progress:  12%|[34m        [0m| 6/50 [00:17<02:04,  2.84s/it]                                                        Episode 7	 reward: -13.99	 makespan: 1385.25	 Mean_loss: 0.41907540,  training time: 2.73
progress:  12%|[34m        [0m| 6/50 [00:20<02:04,  2.84s/it]progress:  14%|[34m        [0m| 7/50 [00:20<02:00,  2.80s/it]                                                        Episode 8	 reward: -13.64	 makespan: 1350.25	 Mean_loss: 0.40183431,  training time: 2.72
progress:  14%|[34m        [0m| 7/50 [00:23<02:00,  2.80s/it]progress:  16%|[34m        [0m| 8/50 [00:23<01:56,  2.78s/it]                                                        Episode 9	 reward: -13.71	 makespan: 1357.75	 Mean_loss: 0.31244937,  training time: 2.73
progress:  16%|[34m        [0m| 8/50 [00:25<01:56,  2.78s/it]progress:  18%|[34m        [0m| 9/50 [00:25<01:53,  2.76s/it]                                                        Episode 10	 reward: -13.76	 makespan: 1361.75	 Mean_loss: 0.29794747,  training time: 2.72
progress:  18%|[34m        [0m| 9/50 [00:28<01:53,  2.76s/it]progress:  20%|[34m        [0m| 10/50 [00:28<01:50,  2.75s/it]                                                         Episode 11	 reward: -13.40	 makespan: 1326.75	 Mean_loss: 0.31327212,  training time: 2.72
progress:  20%|[34m        [0m| 10/50 [00:31<01:50,  2.75s/it]progress:  22%|[34m       [0m| 11/50 [00:31<01:46,  2.74s/it]                                                         Episode 12	 reward: -13.57	 makespan: 1343.50	 Mean_loss: 0.23909801,  training time: 2.73
progress:  22%|[34m       [0m| 11/50 [00:34<01:46,  2.74s/it]progress:  24%|[34m       [0m| 12/50 [00:34<01:44,  2.74s/it]                                                         Episode 13	 reward: -13.78	 makespan: 1363.75	 Mean_loss: 0.26957241,  training time: 2.73
progress:  24%|[34m       [0m| 12/50 [00:36<01:44,  2.74s/it]progress:  26%|[34m       [0m| 13/50 [00:36<01:41,  2.74s/it]                                                         Episode 14	 reward: -13.62	 makespan: 1348.75	 Mean_loss: 0.28504843,  training time: 2.72
progress:  26%|[34m       [0m| 13/50 [00:39<01:41,  2.74s/it]progress:  28%|[34m       [0m| 14/50 [00:39<01:38,  2.73s/it]                                                         Episode 15	 reward: -13.39	 makespan: 1326.00	 Mean_loss: 0.16130663,  training time: 2.73
progress:  28%|[34m       [0m| 14/50 [00:42<01:38,  2.73s/it]progress:  30%|[34m       [0m| 15/50 [00:42<01:35,  2.73s/it]                                                         Episode 16	 reward: -14.06	 makespan: 1392.25	 Mean_loss: 0.29750255,  training time: 2.73
progress:  30%|[34m       [0m| 15/50 [00:44<01:35,  2.73s/it]progress:  32%|[34m      [0m| 16/50 [00:44<01:32,  2.73s/it]                                                         Episode 17	 reward: -13.55	 makespan: 1341.25	 Mean_loss: 0.17905077,  training time: 2.72
progress:  32%|[34m      [0m| 16/50 [00:47<01:32,  2.73s/it]progress:  34%|[34m      [0m| 17/50 [00:47<01:30,  2.73s/it]                                                         Episode 18	 reward: -13.91	 makespan: 1377.25	 Mean_loss: 0.19812824,  training time: 2.72
progress:  34%|[34m      [0m| 17/50 [00:50<01:30,  2.73s/it]progress:  36%|[34m      [0m| 18/50 [00:50<01:27,  2.73s/it]                                                         Episode 19	 reward: -13.31	 makespan: 1317.75	 Mean_loss: 0.13368982,  training time: 2.71
progress:  36%|[34m      [0m| 18/50 [00:53<01:27,  2.73s/it]progress:  38%|[34m      [0m| 19/50 [00:53<01:24,  2.72s/it]                                                         Episode 20	 reward: -13.71	 makespan: 1357.75	 Mean_loss: 0.17271322,  training time: 2.71
progress:  38%|[34m      [0m| 19/50 [00:55<01:24,  2.72s/it]progress:  40%|[34m      [0m| 20/50 [00:55<01:21,  2.72s/it]                                                         Episode 21	 reward: -13.67	 makespan: 1353.00	 Mean_loss: 0.12001365,  training time: 2.72
progress:  40%|[34m      [0m| 20/50 [00:58<01:21,  2.72s/it]progress:  42%|[34m     [0m| 21/50 [00:58<01:18,  2.72s/it]                                                         Episode 22	 reward: -13.28	 makespan: 1315.00	 Mean_loss: 0.12395359,  training time: 2.71
progress:  42%|[34m     [0m| 21/50 [01:01<01:18,  2.72s/it]progress:  44%|[34m     [0m| 22/50 [01:01<01:16,  2.72s/it]                                                         Episode 23	 reward: -13.72	 makespan: 1358.00	 Mean_loss: 0.12829849,  training time: 2.72
progress:  44%|[34m     [0m| 22/50 [01:03<01:16,  2.72s/it]progress:  46%|[34m     [0m| 23/50 [01:03<01:13,  2.72s/it]                                                         Episode 24	 reward: -13.30	 makespan: 1316.75	 Mean_loss: 0.13267401,  training time: 2.71
progress:  46%|[34m     [0m| 23/50 [01:06<01:13,  2.72s/it]progress:  48%|[34m     [0m| 24/50 [01:06<01:10,  2.71s/it]                                                         Episode 25	 reward: -13.23	 makespan: 1310.00	 Mean_loss: 0.12331721,  training time: 2.70
progress:  48%|[34m     [0m| 24/50 [01:09<01:10,  2.71s/it]progress:  50%|[34m     [0m| 25/50 [01:09<01:07,  2.71s/it]                                                         Episode 26	 reward: -13.26	 makespan: 1313.00	 Mean_loss: 0.08828773,  training time: 2.70
progress:  50%|[34m     [0m| 25/50 [01:12<01:07,  2.71s/it]progress:  52%|[34m    [0m| 26/50 [01:12<01:05,  2.71s/it]                                                         Episode 27	 reward: -13.46	 makespan: 1332.75	 Mean_loss: 0.11457662,  training time: 2.69
progress:  52%|[34m    [0m| 26/50 [01:14<01:05,  2.71s/it]progress:  54%|[34m    [0m| 27/50 [01:14<01:02,  2.70s/it]                                                         Episode 28	 reward: -13.38	 makespan: 1324.25	 Mean_loss: 0.13561419,  training time: 2.70
progress:  54%|[34m    [0m| 27/50 [01:17<01:02,  2.70s/it]progress:  56%|[34m    [0m| 28/50 [01:17<00:59,  2.70s/it]                                                         Episode 29	 reward: -13.44	 makespan: 1330.25	 Mean_loss: 0.08010605,  training time: 2.71
progress:  56%|[34m    [0m| 28/50 [01:20<00:59,  2.70s/it]progress:  58%|[34m    [0m| 29/50 [01:20<00:56,  2.71s/it]                                                         Episode 30	 reward: -13.30	 makespan: 1316.25	 Mean_loss: 0.08879985,  training time: 2.71
progress:  58%|[34m    [0m| 29/50 [01:22<00:56,  2.71s/it]progress:  60%|[34m    [0m| 30/50 [01:22<00:54,  2.71s/it]                                                         Episode 31	 reward: -13.22	 makespan: 1308.75	 Mean_loss: 0.11018363,  training time: 2.71
progress:  60%|[34m    [0m| 30/50 [01:25<00:54,  2.71s/it]progress:  62%|[34m   [0m| 31/50 [01:25<00:51,  2.71s/it]                                                         Episode 32	 reward: -13.78	 makespan: 1364.00	 Mean_loss: 0.06962658,  training time: 2.70
progress:  62%|[34m   [0m| 31/50 [01:28<00:51,  2.71s/it]progress:  64%|[34m   [0m| 32/50 [01:28<00:48,  2.71s/it]                                                         Episode 33	 reward: -13.60	 makespan: 1346.75	 Mean_loss: 0.09687642,  training time: 2.71
progress:  64%|[34m   [0m| 32/50 [01:31<00:48,  2.71s/it]progress:  66%|[34m   [0m| 33/50 [01:31<00:46,  2.71s/it]                                                         Episode 34	 reward: -13.12	 makespan: 1299.25	 Mean_loss: 0.09483853,  training time: 2.71
progress:  66%|[34m   [0m| 33/50 [01:33<00:46,  2.71s/it]progress:  68%|[34m   [0m| 34/50 [01:33<00:43,  2.71s/it]                                                         Episode 35	 reward: -13.66	 makespan: 1352.50	 Mean_loss: 0.07032368,  training time: 2.73
progress:  68%|[34m   [0m| 34/50 [01:36<00:43,  2.71s/it]progress:  70%|[34m   [0m| 35/50 [01:36<00:40,  2.72s/it]                                                         Episode 36	 reward: -13.21	 makespan: 1307.75	 Mean_loss: 0.07226475,  training time: 2.71
progress:  70%|[34m   [0m| 35/50 [01:39<00:40,  2.72s/it]progress:  72%|[34m  [0m| 36/50 [01:39<00:37,  2.71s/it]                                                         Episode 37	 reward: -13.20	 makespan: 1307.25	 Mean_loss: 0.05641359,  training time: 2.73
progress:  72%|[34m  [0m| 36/50 [01:41<00:37,  2.71s/it]progress:  74%|[34m  [0m| 37/50 [01:41<00:35,  2.72s/it]                                                         Episode 38	 reward: -13.63	 makespan: 1349.25	 Mean_loss: 0.08580425,  training time: 2.73
progress:  74%|[34m  [0m| 37/50 [01:44<00:35,  2.72s/it]progress:  76%|[34m  [0m| 38/50 [01:44<00:32,  2.72s/it]                                                         Episode 39	 reward: -13.28	 makespan: 1315.00	 Mean_loss: 0.05666004,  training time: 2.70
progress:  76%|[34m  [0m| 38/50 [01:47<00:32,  2.72s/it]progress:  78%|[34m  [0m| 39/50 [01:47<00:29,  2.71s/it]                                                         Episode 40	 reward: -13.54	 makespan: 1340.00	 Mean_loss: 0.06041805,  training time: 2.73
progress:  78%|[34m  [0m| 39/50 [01:50<00:29,  2.71s/it]progress:  80%|[34m  [0m| 40/50 [01:50<00:27,  2.72s/it]                                                         Episode 41	 reward: -13.34	 makespan: 1321.00	 Mean_loss: 0.05661024,  training time: 2.72
progress:  80%|[34m  [0m| 40/50 [01:52<00:27,  2.72s/it]progress:  82%|[34m [0m| 41/50 [01:52<00:24,  2.72s/it]                                                         Episode 42	 reward: -13.38	 makespan: 1324.75	 Mean_loss: 0.04900745,  training time: 2.70
progress:  82%|[34m [0m| 41/50 [01:55<00:24,  2.72s/it]progress:  84%|[34m [0m| 42/50 [01:55<00:21,  2.71s/it]                                                         Episode 43	 reward: -13.48	 makespan: 1334.75	 Mean_loss: 0.05893671,  training time: 2.72
progress:  84%|[34m [0m| 42/50 [01:58<00:21,  2.71s/it]progress:  86%|[34m [0m| 43/50 [01:58<00:19,  2.72s/it]                                                         Episode 44	 reward: -13.53	 makespan: 1339.50	 Mean_loss: 0.07535788,  training time: 2.71
progress:  86%|[34m [0m| 43/50 [02:00<00:19,  2.72s/it]progress:  88%|[34m [0m| 44/50 [02:00<00:16,  2.72s/it]                                                         Episode 45	 reward: -13.34	 makespan: 1320.75	 Mean_loss: 0.05424844,  training time: 2.71
progress:  88%|[34m [0m| 44/50 [02:03<00:16,  2.72s/it]progress:  90%|[34m [0m| 45/50 [02:03<00:13,  2.71s/it]                                                         Episode 46	 reward: -13.23	 makespan: 1309.75	 Mean_loss: 0.03470834,  training time: 2.70
progress:  90%|[34m [0m| 45/50 [02:06<00:13,  2.71s/it]progress:  92%|[34m[0m| 46/50 [02:06<00:10,  2.71s/it]                                                         Episode 47	 reward: -13.27	 makespan: 1313.25	 Mean_loss: 0.06063420,  training time: 2.72
progress:  92%|[34m[0m| 46/50 [02:09<00:10,  2.71s/it]progress:  94%|[34m[0m| 47/50 [02:09<00:08,  2.71s/it]                                                         Episode 48	 reward: -13.23	 makespan: 1310.25	 Mean_loss: 0.04110678,  training time: 2.71
progress:  94%|[34m[0m| 47/50 [02:11<00:08,  2.71s/it]progress:  96%|[34m[0m| 48/50 [02:11<00:05,  2.71s/it]                                                         Episode 49	 reward: -13.10	 makespan: 1297.25	 Mean_loss: 0.05776476,  training time: 2.72
progress:  96%|[34m[0m| 48/50 [02:14<00:05,  2.71s/it]progress:  98%|[34m[0m| 49/50 [02:14<00:02,  2.72s/it]                                                         Episode 50	 reward: -13.10	 makespan: 1297.00	 Mean_loss: 0.05681087,  training time: 2.73
progress:  98%|[34m[0m| 49/50 [02:17<00:02,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:17<00:00,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:17<00:00,  2.74s/it]
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.67	 makespan: 462.50	 Mean_loss: 0.28960487,  training time: 2.09
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:42,  2.09s/it]                                                        Episode 2	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.09359848,  training time: 1.00
progress:   2%|[34m         [0m| 1/50 [00:03<01:42,  2.09s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:09,  1.45s/it]                                                        Episode 3	 reward: -4.67	 makespan: 462.50	 Mean_loss: 0.02705931,  training time: 1.02
progress:   4%|[34m         [0m| 2/50 [00:04<01:09,  1.45s/it]progress:   6%|[34m         [0m| 3/50 [00:04<00:58,  1.25s/it]                                                        Episode 4	 reward: -4.87	 makespan: 482.50	 Mean_loss: 0.03371808,  training time: 0.99
progress:   6%|[34m         [0m| 3/50 [00:05<00:58,  1.25s/it]progress:   8%|[34m         [0m| 4/50 [00:05<00:52,  1.15s/it]                                                        Episode 5	 reward: -4.91	 makespan: 486.50	 Mean_loss: 0.00542393,  training time: 0.99
progress:   8%|[34m         [0m| 4/50 [00:06<00:52,  1.15s/it]progress:  10%|[34m         [0m| 5/50 [00:06<00:49,  1.09s/it]                                                        Episode 6	 reward: -4.86	 makespan: 481.50	 Mean_loss: 0.01951391,  training time: 1.05
progress:  10%|[34m         [0m| 5/50 [00:07<00:49,  1.09s/it]progress:  12%|[34m        [0m| 6/50 [00:07<00:47,  1.08s/it]                                                        Episode 7	 reward: -4.71	 makespan: 466.00	 Mean_loss: 0.02619784,  training time: 1.01
progress:  12%|[34m        [0m| 6/50 [00:08<00:47,  1.08s/it]progress:  14%|[34m        [0m| 7/50 [00:08<00:45,  1.06s/it]                                                        Episode 8	 reward: -4.86	 makespan: 481.50	 Mean_loss: 0.00844457,  training time: 1.05
progress:  14%|[34m        [0m| 7/50 [00:09<00:45,  1.06s/it]progress:  16%|[34m        [0m| 8/50 [00:09<00:44,  1.06s/it]                                                        Episode 9	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.01034329,  training time: 1.05
progress:  16%|[34m        [0m| 8/50 [00:10<00:44,  1.06s/it]progress:  18%|[34m        [0m| 9/50 [00:10<00:43,  1.05s/it]                                                        Episode 10	 reward: -5.22	 makespan: 517.25	 Mean_loss: 0.03890472,  training time: 1.06
progress:  18%|[34m        [0m| 9/50 [00:11<00:43,  1.05s/it]progress:  20%|[34m        [0m| 10/50 [00:11<00:42,  1.06s/it]                                                         Episode 11	 reward: -5.08	 makespan: 503.25	 Mean_loss: 0.01201362,  training time: 1.06
progress:  20%|[34m        [0m| 10/50 [00:12<00:42,  1.06s/it]progress:  22%|[34m       [0m| 11/50 [00:12<00:41,  1.06s/it]                                                         Episode 12	 reward: -5.16	 makespan: 511.00	 Mean_loss: 0.03055512,  training time: 1.10
progress:  22%|[34m       [0m| 11/50 [00:13<00:41,  1.06s/it]progress:  24%|[34m       [0m| 12/50 [00:13<00:40,  1.07s/it]                                                         Episode 13	 reward: -4.99	 makespan: 493.75	 Mean_loss: 0.00973965,  training time: 1.05
progress:  24%|[34m       [0m| 12/50 [00:14<00:40,  1.07s/it]progress:  26%|[34m       [0m| 13/50 [00:14<00:39,  1.07s/it]                                                         Episode 14	 reward: -5.06	 makespan: 500.75	 Mean_loss: 0.00912871,  training time: 1.04
progress:  26%|[34m       [0m| 13/50 [00:15<00:39,  1.07s/it]progress:  28%|[34m       [0m| 14/50 [00:15<00:38,  1.06s/it]                                                         Episode 15	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.02030253,  training time: 1.05
progress:  28%|[34m       [0m| 14/50 [00:16<00:38,  1.06s/it]progress:  30%|[34m       [0m| 15/50 [00:16<00:37,  1.06s/it]                                                         Episode 16	 reward: -4.80	 makespan: 474.75	 Mean_loss: 0.01013679,  training time: 1.05
progress:  30%|[34m       [0m| 15/50 [00:17<00:37,  1.06s/it]progress:  32%|[34m      [0m| 16/50 [00:17<00:35,  1.06s/it]                                                         Episode 17	 reward: -4.96	 makespan: 490.75	 Mean_loss: 0.02193755,  training time: 1.01
progress:  32%|[34m      [0m| 16/50 [00:18<00:35,  1.06s/it]progress:  34%|[34m      [0m| 17/50 [00:18<00:34,  1.04s/it]                                                         Episode 18	 reward: -4.78	 makespan: 473.00	 Mean_loss: 0.01503579,  training time: 1.04
progress:  34%|[34m      [0m| 17/50 [00:19<00:34,  1.04s/it]progress:  36%|[34m      [0m| 18/50 [00:19<00:33,  1.04s/it]                                                         Episode 19	 reward: -4.89	 makespan: 483.75	 Mean_loss: 0.01492190,  training time: 0.99
progress:  36%|[34m      [0m| 18/50 [00:20<00:33,  1.04s/it]progress:  38%|[34m      [0m| 19/50 [00:20<00:31,  1.03s/it]                                                         Episode 20	 reward: -4.63	 makespan: 458.50	 Mean_loss: 0.01991994,  training time: 1.06
progress:  38%|[34m      [0m| 19/50 [00:21<00:31,  1.03s/it]progress:  40%|[34m      [0m| 20/50 [00:21<00:31,  1.04s/it]                                                         Episode 21	 reward: -4.75	 makespan: 470.00	 Mean_loss: 0.01421385,  training time: 1.00
progress:  40%|[34m      [0m| 20/50 [00:22<00:31,  1.04s/it]progress:  42%|[34m     [0m| 21/50 [00:22<00:29,  1.03s/it]                                                         Episode 22	 reward: -4.86	 makespan: 481.50	 Mean_loss: 0.00423007,  training time: 1.03
progress:  42%|[34m     [0m| 21/50 [00:23<00:29,  1.03s/it]progress:  44%|[34m     [0m| 22/50 [00:23<00:28,  1.03s/it]                                                         Episode 23	 reward: -4.93	 makespan: 488.00	 Mean_loss: 0.01657647,  training time: 1.04
progress:  44%|[34m     [0m| 22/50 [00:24<00:28,  1.03s/it]progress:  46%|[34m     [0m| 23/50 [00:24<00:27,  1.03s/it]                                                         Episode 24	 reward: -4.94	 makespan: 489.00	 Mean_loss: 0.01341027,  training time: 1.05
progress:  46%|[34m     [0m| 23/50 [00:25<00:27,  1.03s/it]progress:  48%|[34m     [0m| 24/50 [00:25<00:26,  1.04s/it]                                                         Episode 25	 reward: -4.87	 makespan: 482.25	 Mean_loss: 0.01537248,  training time: 1.05
progress:  48%|[34m     [0m| 24/50 [00:26<00:26,  1.04s/it]progress:  50%|[34m     [0m| 25/50 [00:26<00:26,  1.04s/it]                                                         Episode 26	 reward: -4.81	 makespan: 476.50	 Mean_loss: 0.02390396,  training time: 1.09
progress:  50%|[34m     [0m| 25/50 [00:28<00:26,  1.04s/it]progress:  52%|[34m    [0m| 26/50 [00:28<00:25,  1.06s/it]                                                         Episode 27	 reward: -5.04	 makespan: 498.50	 Mean_loss: 0.04603003,  training time: 1.05
progress:  52%|[34m    [0m| 26/50 [00:29<00:25,  1.06s/it]progress:  54%|[34m    [0m| 27/50 [00:29<00:24,  1.06s/it]                                                         Episode 28	 reward: -4.91	 makespan: 486.50	 Mean_loss: 0.03195161,  training time: 1.00
progress:  54%|[34m    [0m| 27/50 [00:30<00:24,  1.06s/it]progress:  56%|[34m    [0m| 28/50 [00:30<00:22,  1.04s/it]                                                         Episode 29	 reward: -5.13	 makespan: 507.75	 Mean_loss: 0.00619102,  training time: 0.99
progress:  56%|[34m    [0m| 28/50 [00:31<00:22,  1.04s/it]progress:  58%|[34m    [0m| 29/50 [00:31<00:21,  1.02s/it]                                                         Episode 30	 reward: -4.86	 makespan: 481.25	 Mean_loss: 0.02543881,  training time: 1.04
progress:  58%|[34m    [0m| 29/50 [00:32<00:21,  1.02s/it]progress:  60%|[34m    [0m| 30/50 [00:32<00:20,  1.03s/it]                                                         Episode 31	 reward: -4.92	 makespan: 487.50	 Mean_loss: 0.00999448,  training time: 1.05
progress:  60%|[34m    [0m| 30/50 [00:33<00:20,  1.03s/it]progress:  62%|[34m   [0m| 31/50 [00:33<00:19,  1.04s/it]                                                         Episode 32	 reward: -4.83	 makespan: 477.75	 Mean_loss: 0.01069039,  training time: 1.06
progress:  62%|[34m   [0m| 31/50 [00:34<00:19,  1.04s/it]progress:  64%|[34m   [0m| 32/50 [00:34<00:18,  1.04s/it]                                                         Episode 33	 reward: -4.98	 makespan: 493.00	 Mean_loss: 0.02916778,  training time: 1.07
progress:  64%|[34m   [0m| 32/50 [00:35<00:18,  1.04s/it]progress:  66%|[34m   [0m| 33/50 [00:35<00:17,  1.05s/it]                                                         Episode 34	 reward: -4.72	 makespan: 467.25	 Mean_loss: 0.02490691,  training time: 0.98
progress:  66%|[34m   [0m| 33/50 [00:36<00:17,  1.05s/it]progress:  68%|[34m   [0m| 34/50 [00:36<00:16,  1.03s/it]                                                         Episode 35	 reward: -4.64	 makespan: 459.00	 Mean_loss: 0.01504578,  training time: 1.05
progress:  68%|[34m   [0m| 34/50 [00:37<00:16,  1.03s/it]progress:  70%|[34m   [0m| 35/50 [00:37<00:15,  1.04s/it]                                                         Episode 36	 reward: -4.93	 makespan: 487.75	 Mean_loss: 0.01120464,  training time: 1.00
progress:  70%|[34m   [0m| 35/50 [00:38<00:15,  1.04s/it]progress:  72%|[34m  [0m| 36/50 [00:38<00:14,  1.03s/it]                                                         Episode 37	 reward: -4.85	 makespan: 480.50	 Mean_loss: 0.00801983,  training time: 1.02
progress:  72%|[34m  [0m| 36/50 [00:39<00:14,  1.03s/it]progress:  74%|[34m  [0m| 37/50 [00:39<00:13,  1.03s/it]                                                         Episode 38	 reward: -4.72	 makespan: 467.75	 Mean_loss: 0.00350019,  training time: 1.01
progress:  74%|[34m  [0m| 37/50 [00:40<00:13,  1.03s/it]progress:  76%|[34m  [0m| 38/50 [00:40<00:12,  1.02s/it]                                                         Episode 39	 reward: -5.12	 makespan: 506.75	 Mean_loss: 0.03958437,  training time: 1.00
progress:  76%|[34m  [0m| 38/50 [00:41<00:12,  1.02s/it]progress:  78%|[34m  [0m| 39/50 [00:41<00:11,  1.01s/it]                                                         Episode 40	 reward: -4.98	 makespan: 493.50	 Mean_loss: 0.01550040,  training time: 0.99
progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.01s/it]progress:  80%|[34m  [0m| 40/50 [00:42<00:10,  1.01s/it]                                                         Episode 41	 reward: -4.89	 makespan: 484.00	 Mean_loss: 0.02623162,  training time: 1.01
progress:  80%|[34m  [0m| 40/50 [00:43<00:10,  1.01s/it]progress:  82%|[34m [0m| 41/50 [00:43<00:09,  1.01s/it]                                                         Episode 42	 reward: -4.95	 makespan: 490.00	 Mean_loss: 0.00058289,  training time: 1.04
progress:  82%|[34m [0m| 41/50 [00:44<00:09,  1.01s/it]progress:  84%|[34m [0m| 42/50 [00:44<00:08,  1.02s/it]                                                         Episode 43	 reward: -4.91	 makespan: 486.00	 Mean_loss: -0.00097626,  training time: 0.99
progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.02s/it]progress:  86%|[34m [0m| 43/50 [00:45<00:07,  1.01s/it]                                                         Episode 44	 reward: -4.94	 makespan: 489.25	 Mean_loss: 0.01615213,  training time: 1.01
progress:  86%|[34m [0m| 43/50 [00:46<00:07,  1.01s/it]progress:  88%|[34m [0m| 44/50 [00:46<00:06,  1.01s/it]                                                         Episode 45	 reward: -4.84	 makespan: 478.75	 Mean_loss: 0.01643666,  training time: 1.05
progress:  88%|[34m [0m| 44/50 [00:47<00:06,  1.01s/it]progress:  90%|[34m [0m| 45/50 [00:47<00:05,  1.02s/it]                                                         Episode 46	 reward: -5.06	 makespan: 501.25	 Mean_loss: 0.02094504,  training time: 1.04
progress:  90%|[34m [0m| 45/50 [00:48<00:05,  1.02s/it]progress:  92%|[34m[0m| 46/50 [00:48<00:04,  1.03s/it]                                                         Episode 47	 reward: -4.97	 makespan: 492.25	 Mean_loss: 0.01501600,  training time: 1.04
progress:  92%|[34m[0m| 46/50 [00:49<00:04,  1.03s/it]progress:  94%|[34m[0m| 47/50 [00:49<00:03,  1.03s/it]                                                         Episode 48	 reward: -5.38	 makespan: 532.50	 Mean_loss: 0.02314112,  training time: 1.03
progress:  94%|[34m[0m| 47/50 [00:50<00:03,  1.03s/it]progress:  96%|[34m[0m| 48/50 [00:50<00:02,  1.03s/it]                                                         Episode 49	 reward: -4.82	 makespan: 477.00	 Mean_loss: 0.03135926,  training time: 1.03
progress:  96%|[34m[0m| 48/50 [00:51<00:02,  1.03s/it]progress:  98%|[34m[0m| 49/50 [00:51<00:01,  1.03s/it]                                                         Episode 50	 reward: -5.04	 makespan: 499.25	 Mean_loss: 0.02444602,  training time: 1.05
progress:  98%|[34m[0m| 49/50 [00:52<00:01,  1.03s/it]progress: 100%|[34m[0m| 50/50 [00:52<00:00,  1.04s/it]progress: 100%|[34m[0m| 50/50 [00:52<00:00,  1.05s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 6
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.01	 makespan: 594.50	 Mean_loss: 0.45996237,  training time: 2.54
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:04,  2.54s/it]                                                        Episode 2	 reward: -6.13	 makespan: 606.50	 Mean_loss: 0.16037753,  training time: 1.44
progress:   2%|[34m         [0m| 1/50 [00:03<02:04,  2.54s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:30,  1.89s/it]                                                        Episode 3	 reward: -6.36	 makespan: 629.75	 Mean_loss: 0.07105688,  training time: 1.50
progress:   4%|[34m         [0m| 2/50 [00:05<01:30,  1.89s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:20,  1.71s/it]                                                        Episode 4	 reward: -6.23	 makespan: 617.25	 Mean_loss: 0.03652340,  training time: 1.46
progress:   6%|[34m         [0m| 3/50 [00:06<01:20,  1.71s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:14,  1.61s/it]                                                        Episode 5	 reward: -6.20	 makespan: 614.00	 Mean_loss: 0.02170036,  training time: 1.44
progress:   8%|[34m         [0m| 4/50 [00:08<01:14,  1.61s/it]progress:  10%|[34m         [0m| 5/50 [00:08<01:09,  1.55s/it]                                                        Episode 6	 reward: -6.07	 makespan: 601.00	 Mean_loss: 0.01415346,  training time: 1.57
progress:  10%|[34m         [0m| 5/50 [00:09<01:09,  1.55s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:08,  1.56s/it]                                                        Episode 7	 reward: -6.15	 makespan: 608.50	 Mean_loss: 0.02532651,  training time: 1.50
progress:  12%|[34m        [0m| 6/50 [00:11<01:08,  1.56s/it]progress:  14%|[34m        [0m| 7/50 [00:11<01:06,  1.54s/it]                                                        Episode 8	 reward: -6.07	 makespan: 600.75	 Mean_loss: 0.01383726,  training time: 1.49
progress:  14%|[34m        [0m| 7/50 [00:12<01:06,  1.54s/it]progress:  16%|[34m        [0m| 8/50 [00:12<01:03,  1.52s/it]                                                        Episode 9	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.00716629,  training time: 1.44
progress:  16%|[34m        [0m| 8/50 [00:14<01:03,  1.52s/it]progress:  18%|[34m        [0m| 9/50 [00:14<01:01,  1.50s/it]                                                        Episode 10	 reward: -6.03	 makespan: 597.00	 Mean_loss: 0.01421942,  training time: 1.48
progress:  18%|[34m        [0m| 9/50 [00:15<01:01,  1.50s/it]progress:  20%|[34m        [0m| 10/50 [00:15<00:59,  1.49s/it]                                                         Episode 11	 reward: -6.22	 makespan: 616.25	 Mean_loss: 0.01974154,  training time: 1.44
progress:  20%|[34m        [0m| 10/50 [00:17<00:59,  1.49s/it]progress:  22%|[34m       [0m| 11/50 [00:17<00:57,  1.47s/it]                                                         Episode 12	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.03056179,  training time: 1.43
progress:  22%|[34m       [0m| 11/50 [00:18<00:57,  1.47s/it]progress:  24%|[34m       [0m| 12/50 [00:18<00:55,  1.46s/it]                                                         Episode 13	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.01616811,  training time: 1.46
progress:  24%|[34m       [0m| 12/50 [00:20<00:55,  1.46s/it]progress:  26%|[34m       [0m| 13/50 [00:20<00:54,  1.46s/it]                                                         Episode 14	 reward: -6.01	 makespan: 594.75	 Mean_loss: 0.01165781,  training time: 1.45
progress:  26%|[34m       [0m| 13/50 [00:21<00:54,  1.46s/it]progress:  28%|[34m       [0m| 14/50 [00:21<00:52,  1.46s/it]                                                         Episode 15	 reward: -6.09	 makespan: 602.75	 Mean_loss: 0.00898757,  training time: 1.45
progress:  28%|[34m       [0m| 14/50 [00:23<00:52,  1.46s/it]progress:  30%|[34m       [0m| 15/50 [00:23<00:51,  1.46s/it]                                                         Episode 16	 reward: -6.02	 makespan: 596.25	 Mean_loss: 0.02169131,  training time: 1.38
progress:  30%|[34m       [0m| 15/50 [00:24<00:51,  1.46s/it]progress:  32%|[34m      [0m| 16/50 [00:24<00:48,  1.43s/it]                                                         Episode 17	 reward: -6.24	 makespan: 618.25	 Mean_loss: 0.02141548,  training time: 1.50
progress:  32%|[34m      [0m| 16/50 [00:25<00:48,  1.43s/it]progress:  34%|[34m      [0m| 17/50 [00:25<00:47,  1.45s/it]                                                         Episode 18	 reward: -6.37	 makespan: 631.00	 Mean_loss: 0.02785539,  training time: 1.45
progress:  34%|[34m      [0m| 17/50 [00:27<00:47,  1.45s/it]progress:  36%|[34m      [0m| 18/50 [00:27<00:46,  1.45s/it]                                                         Episode 19	 reward: -6.08	 makespan: 601.50	 Mean_loss: 0.03930813,  training time: 1.46
progress:  36%|[34m      [0m| 18/50 [00:28<00:46,  1.45s/it]progress:  38%|[34m      [0m| 19/50 [00:28<00:45,  1.46s/it]                                                         Episode 20	 reward: -6.08	 makespan: 602.00	 Mean_loss: 0.02793472,  training time: 1.40
progress:  38%|[34m      [0m| 19/50 [00:30<00:45,  1.46s/it]progress:  40%|[34m      [0m| 20/50 [00:30<00:43,  1.44s/it]                                                         Episode 21	 reward: -6.05	 makespan: 598.75	 Mean_loss: 0.00682524,  training time: 1.38
progress:  40%|[34m      [0m| 20/50 [00:31<00:43,  1.44s/it]progress:  42%|[34m     [0m| 21/50 [00:31<00:41,  1.42s/it]                                                         Episode 22	 reward: -6.14	 makespan: 607.75	 Mean_loss: 0.02011149,  training time: 1.46
progress:  42%|[34m     [0m| 21/50 [00:33<00:41,  1.42s/it]progress:  44%|[34m     [0m| 22/50 [00:33<00:40,  1.43s/it]                                                         Episode 23	 reward: -6.23	 makespan: 617.00	 Mean_loss: 0.01689223,  training time: 1.38
progress:  44%|[34m     [0m| 22/50 [00:34<00:40,  1.43s/it]progress:  46%|[34m     [0m| 23/50 [00:34<00:38,  1.42s/it]                                                         Episode 24	 reward: -6.32	 makespan: 625.50	 Mean_loss: 0.02134059,  training time: 1.41
progress:  46%|[34m     [0m| 23/50 [00:35<00:38,  1.42s/it]progress:  48%|[34m     [0m| 24/50 [00:35<00:36,  1.42s/it]                                                         Episode 25	 reward: -6.08	 makespan: 601.75	 Mean_loss: 0.00665866,  training time: 1.46
progress:  48%|[34m     [0m| 24/50 [00:37<00:36,  1.42s/it]progress:  50%|[34m     [0m| 25/50 [00:37<00:35,  1.43s/it]                                                         Episode 26	 reward: -6.04	 makespan: 597.75	 Mean_loss: 0.00692195,  training time: 1.40
progress:  50%|[34m     [0m| 25/50 [00:38<00:35,  1.43s/it]progress:  52%|[34m    [0m| 26/50 [00:38<00:34,  1.42s/it]                                                         Episode 27	 reward: -6.11	 makespan: 604.50	 Mean_loss: 0.00550053,  training time: 1.39
progress:  52%|[34m    [0m| 26/50 [00:40<00:34,  1.42s/it]progress:  54%|[34m    [0m| 27/50 [00:40<00:32,  1.41s/it]                                                         Episode 28	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.02181246,  training time: 1.44
progress:  54%|[34m    [0m| 27/50 [00:41<00:32,  1.41s/it]progress:  56%|[34m    [0m| 28/50 [00:41<00:31,  1.42s/it]                                                         Episode 29	 reward: -6.39	 makespan: 632.75	 Mean_loss: 0.01905528,  training time: 1.46
progress:  56%|[34m    [0m| 28/50 [00:43<00:31,  1.42s/it]progress:  58%|[34m    [0m| 29/50 [00:43<00:30,  1.43s/it]                                                         Episode 30	 reward: -6.17	 makespan: 610.75	 Mean_loss: 0.00307070,  training time: 1.46
progress:  58%|[34m    [0m| 29/50 [00:44<00:30,  1.43s/it]progress:  60%|[34m    [0m| 30/50 [00:44<00:28,  1.44s/it]                                                         Episode 31	 reward: -6.24	 makespan: 618.25	 Mean_loss: 0.01100425,  training time: 1.44
progress:  60%|[34m    [0m| 30/50 [00:45<00:28,  1.44s/it]progress:  62%|[34m   [0m| 31/50 [00:45<00:27,  1.44s/it]                                                         Episode 32	 reward: -6.16	 makespan: 610.00	 Mean_loss: 0.02156522,  training time: 1.44
progress:  62%|[34m   [0m| 31/50 [00:47<00:27,  1.44s/it]progress:  64%|[34m   [0m| 32/50 [00:47<00:25,  1.44s/it]                                                         Episode 33	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.01339721,  training time: 1.46
progress:  64%|[34m   [0m| 32/50 [00:48<00:25,  1.44s/it]progress:  66%|[34m   [0m| 33/50 [00:48<00:24,  1.45s/it]                                                         Episode 34	 reward: -6.26	 makespan: 619.50	 Mean_loss: 0.01406584,  training time: 1.45
progress:  66%|[34m   [0m| 33/50 [00:50<00:24,  1.45s/it]progress:  68%|[34m   [0m| 34/50 [00:50<00:23,  1.45s/it]                                                         Episode 35	 reward: -6.25	 makespan: 619.00	 Mean_loss: 0.02655565,  training time: 1.45
progress:  68%|[34m   [0m| 34/50 [00:51<00:23,  1.45s/it]progress:  70%|[34m   [0m| 35/50 [00:51<00:21,  1.45s/it]                                                         Episode 36	 reward: -6.30	 makespan: 624.00	 Mean_loss: 0.01610379,  training time: 1.44
progress:  70%|[34m   [0m| 35/50 [00:53<00:21,  1.45s/it]progress:  72%|[34m  [0m| 36/50 [00:53<00:20,  1.45s/it]                                                         Episode 37	 reward: -5.95	 makespan: 589.50	 Mean_loss: 0.01157720,  training time: 1.42
progress:  72%|[34m  [0m| 36/50 [00:54<00:20,  1.45s/it]progress:  74%|[34m  [0m| 37/50 [00:54<00:18,  1.44s/it]                                                         Episode 38	 reward: -6.07	 makespan: 601.00	 Mean_loss: 0.01178057,  training time: 1.42
progress:  74%|[34m  [0m| 37/50 [00:56<00:18,  1.44s/it]progress:  76%|[34m  [0m| 38/50 [00:56<00:17,  1.43s/it]                                                         Episode 39	 reward: -6.19	 makespan: 612.75	 Mean_loss: 0.01705398,  training time: 1.44
progress:  76%|[34m  [0m| 38/50 [00:57<00:17,  1.43s/it]progress:  78%|[34m  [0m| 39/50 [00:57<00:15,  1.43s/it]                                                         Episode 40	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.00923217,  training time: 1.44
progress:  78%|[34m  [0m| 39/50 [00:58<00:15,  1.43s/it]progress:  80%|[34m  [0m| 40/50 [00:58<00:14,  1.44s/it]                                                         Episode 41	 reward: -6.12	 makespan: 605.75	 Mean_loss: 0.00893362,  training time: 1.38
progress:  80%|[34m  [0m| 40/50 [01:00<00:14,  1.44s/it]progress:  82%|[34m [0m| 41/50 [01:00<00:12,  1.42s/it]                                                         Episode 42	 reward: -6.02	 makespan: 596.00	 Mean_loss: 0.00727931,  training time: 1.38
progress:  82%|[34m [0m| 41/50 [01:01<00:12,  1.42s/it]progress:  84%|[34m [0m| 42/50 [01:01<00:11,  1.41s/it]                                                         Episode 43	 reward: -6.19	 makespan: 612.75	 Mean_loss: 0.00552089,  training time: 1.45
progress:  84%|[34m [0m| 42/50 [01:03<00:11,  1.41s/it]progress:  86%|[34m [0m| 43/50 [01:03<00:09,  1.42s/it]                                                         Episode 44	 reward: -6.00	 makespan: 594.00	 Mean_loss: 0.01475453,  training time: 1.45
progress:  86%|[34m [0m| 43/50 [01:04<00:09,  1.42s/it]progress:  88%|[34m [0m| 44/50 [01:04<00:08,  1.43s/it]                                                         Episode 45	 reward: -6.15	 makespan: 609.25	 Mean_loss: 0.03058187,  training time: 1.45
progress:  88%|[34m [0m| 44/50 [01:06<00:08,  1.43s/it]progress:  90%|[34m [0m| 45/50 [01:06<00:07,  1.44s/it]                                                         Episode 46	 reward: -6.06	 makespan: 600.00	 Mean_loss: 0.01769310,  training time: 1.39
progress:  90%|[34m [0m| 45/50 [01:07<00:07,  1.44s/it]progress:  92%|[34m[0m| 46/50 [01:07<00:05,  1.42s/it]                                                         Episode 47	 reward: -6.27	 makespan: 621.00	 Mean_loss: 0.03147365,  training time: 1.42
progress:  92%|[34m[0m| 46/50 [01:08<00:05,  1.42s/it]progress:  94%|[34m[0m| 47/50 [01:08<00:04,  1.42s/it]                                                         Episode 48	 reward: -6.24	 makespan: 617.75	 Mean_loss: 0.01532723,  training time: 1.46
progress:  94%|[34m[0m| 47/50 [01:10<00:04,  1.42s/it]progress:  96%|[34m[0m| 48/50 [01:10<00:02,  1.43s/it]                                                         Episode 49	 reward: -6.11	 makespan: 605.25	 Mean_loss: 0.01791907,  training time: 1.38
progress:  96%|[34m[0m| 48/50 [01:11<00:02,  1.43s/it]progress:  98%|[34m[0m| 49/50 [01:11<00:01,  1.42s/it]                                                         Episode 50	 reward: -6.26	 makespan: 619.25	 Mean_loss: 0.02339292,  training time: 1.45
progress:  98%|[34m[0m| 49/50 [01:13<00:01,  1.42s/it]progress: 100%|[34m[0m| 50/50 [01:13<00:00,  1.43s/it]progress: 100%|[34m[0m| 50/50 [01:13<00:00,  1.46s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 8
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.26	 makespan: 818.00	 Mean_loss: 0.73176616,  training time: 2.94
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:23,  2.94s/it]                                                        Episode 2	 reward: -8.31	 makespan: 822.25	 Mean_loss: 0.15954742,  training time: 1.84
progress:   2%|[34m         [0m| 1/50 [00:04<02:23,  2.94s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:50,  2.29s/it]                                                        Episode 3	 reward: -8.32	 makespan: 823.75	 Mean_loss: 0.09490718,  training time: 1.85
progress:   4%|[34m         [0m| 2/50 [00:06<01:50,  2.29s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:38,  2.09s/it]                                                        Episode 4	 reward: -9.10	 makespan: 901.25	 Mean_loss: 0.17469266,  training time: 1.99
progress:   6%|[34m         [0m| 3/50 [00:08<01:38,  2.09s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:34,  2.05s/it]                                                        Episode 5	 reward: -8.63	 makespan: 854.75	 Mean_loss: 0.06155092,  training time: 1.85
progress:   8%|[34m         [0m| 4/50 [00:10<01:34,  2.05s/it]progress:  10%|[34m         [0m| 5/50 [00:10<01:29,  1.98s/it]                                                        Episode 6	 reward: -8.52	 makespan: 843.00	 Mean_loss: 0.04650175,  training time: 1.85
progress:  10%|[34m         [0m| 5/50 [00:12<01:29,  1.98s/it]progress:  12%|[34m        [0m| 6/50 [00:12<01:25,  1.94s/it]                                                        Episode 7	 reward: -8.62	 makespan: 853.25	 Mean_loss: 0.03788543,  training time: 1.85
progress:  12%|[34m        [0m| 6/50 [00:14<01:25,  1.94s/it]progress:  14%|[34m        [0m| 7/50 [00:14<01:22,  1.91s/it]                                                        Episode 8	 reward: -8.54	 makespan: 845.75	 Mean_loss: 0.03705791,  training time: 1.85
progress:  14%|[34m        [0m| 7/50 [00:16<01:22,  1.91s/it]progress:  16%|[34m        [0m| 8/50 [00:16<01:19,  1.89s/it]                                                        Episode 9	 reward: -8.61	 makespan: 852.00	 Mean_loss: 0.02508121,  training time: 1.85
progress:  16%|[34m        [0m| 8/50 [00:17<01:19,  1.89s/it]progress:  18%|[34m        [0m| 9/50 [00:17<01:16,  1.88s/it]                                                        Episode 10	 reward: -8.84	 makespan: 875.25	 Mean_loss: 0.03525574,  training time: 1.81
progress:  18%|[34m        [0m| 9/50 [00:19<01:16,  1.88s/it]progress:  20%|[34m        [0m| 10/50 [00:19<01:14,  1.86s/it]                                                         Episode 11	 reward: -8.60	 makespan: 851.75	 Mean_loss: 0.04485804,  training time: 1.81
progress:  20%|[34m        [0m| 10/50 [00:21<01:14,  1.86s/it]progress:  22%|[34m       [0m| 11/50 [00:21<01:11,  1.84s/it]                                                         Episode 12	 reward: -8.97	 makespan: 887.75	 Mean_loss: 0.03648613,  training time: 1.91
progress:  22%|[34m       [0m| 11/50 [00:23<01:11,  1.84s/it]progress:  24%|[34m       [0m| 12/50 [00:23<01:10,  1.86s/it]                                                         Episode 13	 reward: -8.66	 makespan: 857.50	 Mean_loss: 0.02174316,  training time: 1.88
progress:  24%|[34m       [0m| 12/50 [00:25<01:10,  1.86s/it]progress:  26%|[34m       [0m| 13/50 [00:25<01:09,  1.87s/it]                                                         Episode 14	 reward: -8.65	 makespan: 856.00	 Mean_loss: 0.02051320,  training time: 1.82
progress:  26%|[34m       [0m| 13/50 [00:27<01:09,  1.87s/it]progress:  28%|[34m       [0m| 14/50 [00:27<01:06,  1.86s/it]                                                         Episode 15	 reward: -8.70	 makespan: 861.75	 Mean_loss: 0.02756896,  training time: 1.89
progress:  28%|[34m       [0m| 14/50 [00:29<01:06,  1.86s/it]progress:  30%|[34m       [0m| 15/50 [00:29<01:05,  1.87s/it]                                                         Episode 16	 reward: -8.62	 makespan: 853.00	 Mean_loss: 0.01979550,  training time: 1.82
progress:  30%|[34m       [0m| 15/50 [00:30<01:05,  1.87s/it]progress:  32%|[34m      [0m| 16/50 [00:30<01:03,  1.85s/it]                                                         Episode 17	 reward: -8.60	 makespan: 851.75	 Mean_loss: 0.01944542,  training time: 1.83
progress:  32%|[34m      [0m| 16/50 [00:32<01:03,  1.85s/it]progress:  34%|[34m      [0m| 17/50 [00:32<01:00,  1.85s/it]                                                         Episode 18	 reward: -8.65	 makespan: 856.25	 Mean_loss: 0.01407987,  training time: 1.83
progress:  34%|[34m      [0m| 17/50 [00:34<01:00,  1.85s/it]progress:  36%|[34m      [0m| 18/50 [00:34<00:58,  1.84s/it]                                                         Episode 19	 reward: -8.72	 makespan: 863.75	 Mean_loss: 0.02501893,  training time: 1.83
progress:  36%|[34m      [0m| 18/50 [00:36<00:58,  1.84s/it]progress:  38%|[34m      [0m| 19/50 [00:36<00:56,  1.84s/it]                                                         Episode 20	 reward: -8.69	 makespan: 860.00	 Mean_loss: 0.02285513,  training time: 1.83
progress:  38%|[34m      [0m| 19/50 [00:38<00:56,  1.84s/it]progress:  40%|[34m      [0m| 20/50 [00:38<00:55,  1.84s/it]                                                         Episode 21	 reward: -8.52	 makespan: 843.50	 Mean_loss: 0.02161865,  training time: 1.85
progress:  40%|[34m      [0m| 20/50 [00:39<00:55,  1.84s/it]progress:  42%|[34m     [0m| 21/50 [00:39<00:53,  1.84s/it]                                                         Episode 22	 reward: -8.60	 makespan: 851.75	 Mean_loss: 0.01991054,  training time: 1.84
progress:  42%|[34m     [0m| 21/50 [00:41<00:53,  1.84s/it]progress:  44%|[34m     [0m| 22/50 [00:41<00:51,  1.84s/it]                                                         Episode 23	 reward: -8.55	 makespan: 846.00	 Mean_loss: 0.01413279,  training time: 1.84
progress:  44%|[34m     [0m| 22/50 [00:43<00:51,  1.84s/it]progress:  46%|[34m     [0m| 23/50 [00:43<00:49,  1.84s/it]                                                         Episode 24	 reward: -8.70	 makespan: 861.25	 Mean_loss: 0.02224954,  training time: 1.83
progress:  46%|[34m     [0m| 23/50 [00:45<00:49,  1.84s/it]progress:  48%|[34m     [0m| 24/50 [00:45<00:47,  1.84s/it]                                                         Episode 25	 reward: -8.67	 makespan: 858.00	 Mean_loss: 0.01879818,  training time: 1.81
progress:  48%|[34m     [0m| 24/50 [00:47<00:47,  1.84s/it]progress:  50%|[34m     [0m| 25/50 [00:47<00:45,  1.83s/it]                                                         Episode 26	 reward: -8.44	 makespan: 835.25	 Mean_loss: 0.01551023,  training time: 1.82
progress:  50%|[34m     [0m| 25/50 [00:49<00:45,  1.83s/it]progress:  52%|[34m    [0m| 26/50 [00:49<00:43,  1.83s/it]                                                         Episode 27	 reward: -8.75	 makespan: 866.50	 Mean_loss: 0.02055173,  training time: 1.82
progress:  52%|[34m    [0m| 26/50 [00:50<00:43,  1.83s/it]progress:  54%|[34m    [0m| 27/50 [00:50<00:41,  1.82s/it]                                                         Episode 28	 reward: -8.28	 makespan: 819.25	 Mean_loss: 0.01487415,  training time: 1.81
progress:  54%|[34m    [0m| 27/50 [00:52<00:41,  1.82s/it]progress:  56%|[34m    [0m| 28/50 [00:52<00:40,  1.82s/it]                                                         Episode 29	 reward: -8.60	 makespan: 851.00	 Mean_loss: 0.02546134,  training time: 1.82
progress:  56%|[34m    [0m| 28/50 [00:54<00:40,  1.82s/it]progress:  58%|[34m    [0m| 29/50 [00:54<00:38,  1.82s/it]                                                         Episode 30	 reward: -8.61	 makespan: 852.75	 Mean_loss: 0.02081133,  training time: 1.81
progress:  58%|[34m    [0m| 29/50 [00:56<00:38,  1.82s/it]progress:  60%|[34m    [0m| 30/50 [00:56<00:36,  1.82s/it]                                                         Episode 31	 reward: -8.62	 makespan: 853.00	 Mean_loss: 0.01918902,  training time: 1.81
progress:  60%|[34m    [0m| 30/50 [00:58<00:36,  1.82s/it]progress:  62%|[34m   [0m| 31/50 [00:58<00:34,  1.82s/it]                                                         Episode 32	 reward: -8.42	 makespan: 833.75	 Mean_loss: 0.01849716,  training time: 1.81
progress:  62%|[34m   [0m| 31/50 [01:00<00:34,  1.82s/it]progress:  64%|[34m   [0m| 32/50 [01:00<00:32,  1.82s/it]                                                         Episode 33	 reward: -8.66	 makespan: 857.00	 Mean_loss: 0.02585222,  training time: 1.82
progress:  64%|[34m   [0m| 32/50 [01:01<00:32,  1.82s/it]progress:  66%|[34m   [0m| 33/50 [01:01<00:30,  1.82s/it]                                                         Episode 34	 reward: -8.66	 makespan: 857.25	 Mean_loss: 0.02305990,  training time: 1.81
progress:  66%|[34m   [0m| 33/50 [01:03<00:30,  1.82s/it]progress:  68%|[34m   [0m| 34/50 [01:03<00:29,  1.82s/it]                                                         Episode 35	 reward: -8.50	 makespan: 841.25	 Mean_loss: 0.01612168,  training time: 1.81
progress:  68%|[34m   [0m| 34/50 [01:05<00:29,  1.82s/it]progress:  70%|[34m   [0m| 35/50 [01:05<00:27,  1.81s/it]                                                         Episode 36	 reward: -8.59	 makespan: 850.25	 Mean_loss: 0.03022083,  training time: 1.82
progress:  70%|[34m   [0m| 35/50 [01:07<00:27,  1.81s/it]progress:  72%|[34m  [0m| 36/50 [01:07<00:25,  1.81s/it]                                                         Episode 37	 reward: -8.43	 makespan: 834.25	 Mean_loss: 0.01979484,  training time: 1.81
progress:  72%|[34m  [0m| 36/50 [01:09<00:25,  1.81s/it]progress:  74%|[34m  [0m| 37/50 [01:09<00:23,  1.81s/it]                                                         Episode 38	 reward: -8.43	 makespan: 834.50	 Mean_loss: 0.01522996,  training time: 1.81
progress:  74%|[34m  [0m| 37/50 [01:10<00:23,  1.81s/it]progress:  76%|[34m  [0m| 38/50 [01:10<00:21,  1.81s/it]                                                         Episode 39	 reward: -8.46	 makespan: 838.00	 Mean_loss: 0.01481895,  training time: 1.81
progress:  76%|[34m  [0m| 38/50 [01:12<00:21,  1.81s/it]progress:  78%|[34m  [0m| 39/50 [01:12<00:19,  1.81s/it]                                                         Episode 40	 reward: -8.77	 makespan: 867.75	 Mean_loss: 0.03025215,  training time: 1.83
progress:  78%|[34m  [0m| 39/50 [01:14<00:19,  1.81s/it]progress:  80%|[34m  [0m| 40/50 [01:14<00:18,  1.82s/it]                                                         Episode 41	 reward: -8.86	 makespan: 877.25	 Mean_loss: 0.02376721,  training time: 1.81
progress:  80%|[34m  [0m| 40/50 [01:16<00:18,  1.82s/it]progress:  82%|[34m [0m| 41/50 [01:16<00:16,  1.82s/it]                                                         Episode 42	 reward: -8.56	 makespan: 847.75	 Mean_loss: 0.01642793,  training time: 1.84
progress:  82%|[34m [0m| 41/50 [01:18<00:16,  1.82s/it]progress:  84%|[34m [0m| 42/50 [01:18<00:14,  1.82s/it]                                                         Episode 43	 reward: -8.92	 makespan: 883.00	 Mean_loss: 0.02328813,  training time: 1.81
progress:  84%|[34m [0m| 42/50 [01:20<00:14,  1.82s/it]progress:  86%|[34m [0m| 43/50 [01:20<00:12,  1.82s/it]                                                         Episode 44	 reward: -8.83	 makespan: 873.75	 Mean_loss: 0.00957941,  training time: 1.81
progress:  86%|[34m [0m| 43/50 [01:21<00:12,  1.82s/it]progress:  88%|[34m [0m| 44/50 [01:21<00:10,  1.82s/it]                                                         Episode 45	 reward: -8.78	 makespan: 869.00	 Mean_loss: 0.02102797,  training time: 1.81
progress:  88%|[34m [0m| 44/50 [01:23<00:10,  1.82s/it]progress:  90%|[34m [0m| 45/50 [01:23<00:09,  1.82s/it]                                                         Episode 46	 reward: -8.74	 makespan: 865.50	 Mean_loss: 0.01689178,  training time: 1.82
progress:  90%|[34m [0m| 45/50 [01:25<00:09,  1.82s/it]progress:  92%|[34m[0m| 46/50 [01:25<00:07,  1.82s/it]                                                         Episode 47	 reward: -8.66	 makespan: 857.00	 Mean_loss: 0.00791093,  training time: 1.81
progress:  92%|[34m[0m| 46/50 [01:27<00:07,  1.82s/it]progress:  94%|[34m[0m| 47/50 [01:27<00:05,  1.82s/it]                                                         Episode 48	 reward: -8.77	 makespan: 867.75	 Mean_loss: 0.01464025,  training time: 1.82
progress:  94%|[34m[0m| 47/50 [01:29<00:05,  1.82s/it]progress:  96%|[34m[0m| 48/50 [01:29<00:03,  1.82s/it]                                                         Episode 49	 reward: -8.87	 makespan: 878.50	 Mean_loss: 0.02633813,  training time: 1.82
progress:  96%|[34m[0m| 48/50 [01:30<00:03,  1.82s/it]progress:  98%|[34m[0m| 49/50 [01:30<00:01,  1.82s/it]                                                         Episode 50	 reward: -8.67	 makespan: 858.75	 Mean_loss: 0.01343042,  training time: 1.82
progress:  98%|[34m[0m| 49/50 [01:32<00:01,  1.82s/it]progress: 100%|[34m[0m| 50/50 [01:32<00:00,  1.82s/it]progress: 100%|[34m[0m| 50/50 [01:32<00:00,  1.85s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -10.40	 makespan: 1029.75	 Mean_loss: 0.86684990,  training time: 3.38
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:45,  3.38s/it]                                                        Episode 2	 reward: -10.74	 makespan: 1063.50	 Mean_loss: 0.17307538,  training time: 2.34
progress:   2%|[34m         [0m| 1/50 [00:05<02:45,  3.38s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:12,  2.77s/it]                                                        Episode 3	 reward: -10.45	 makespan: 1034.25	 Mean_loss: 0.10425595,  training time: 2.32
progress:   4%|[34m         [0m| 2/50 [00:08<02:12,  2.77s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:00,  2.56s/it]                                                        Episode 4	 reward: -10.22	 makespan: 1011.75	 Mean_loss: 0.08755588,  training time: 2.34
progress:   6%|[34m         [0m| 3/50 [00:10<02:00,  2.56s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:53,  2.47s/it]                                                        Episode 5	 reward: -10.30	 makespan: 1019.75	 Mean_loss: 0.04119179,  training time: 2.28
progress:   8%|[34m         [0m| 4/50 [00:12<01:53,  2.47s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:48,  2.40s/it]                                                        Episode 6	 reward: -10.35	 makespan: 1024.75	 Mean_loss: 0.03838626,  training time: 2.41
progress:  10%|[34m         [0m| 5/50 [00:15<01:48,  2.40s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:45,  2.41s/it]                                                        Episode 7	 reward: -10.43	 makespan: 1032.25	 Mean_loss: 0.02801498,  training time: 2.27
progress:  12%|[34m        [0m| 6/50 [00:17<01:45,  2.41s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:41,  2.36s/it]                                                        Episode 8	 reward: -10.40	 makespan: 1029.50	 Mean_loss: 0.02000781,  training time: 2.31
progress:  14%|[34m        [0m| 7/50 [00:19<01:41,  2.36s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:38,  2.35s/it]                                                        Episode 9	 reward: -10.36	 makespan: 1026.00	 Mean_loss: 0.03169279,  training time: 2.31
progress:  16%|[34m        [0m| 8/50 [00:21<01:38,  2.35s/it]progress:  18%|[34m        [0m| 9/50 [00:21<01:35,  2.34s/it]                                                        Episode 10	 reward: -10.44	 makespan: 1033.75	 Mean_loss: 0.01516601,  training time: 2.31
progress:  18%|[34m        [0m| 9/50 [00:24<01:35,  2.34s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:33,  2.33s/it]                                                         Episode 11	 reward: -10.49	 makespan: 1038.50	 Mean_loss: 0.01218513,  training time: 2.30
progress:  20%|[34m        [0m| 10/50 [00:26<01:33,  2.33s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:30,  2.32s/it]                                                         Episode 12	 reward: -10.35	 makespan: 1024.25	 Mean_loss: 0.01650253,  training time: 2.26
progress:  22%|[34m       [0m| 11/50 [00:28<01:30,  2.32s/it]progress:  24%|[34m       [0m| 12/50 [00:28<01:27,  2.30s/it]                                                         Episode 13	 reward: -10.34	 makespan: 1024.00	 Mean_loss: 0.01094800,  training time: 2.32
progress:  24%|[34m       [0m| 12/50 [00:31<01:27,  2.30s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:25,  2.31s/it]                                                         Episode 14	 reward: -10.70	 makespan: 1059.25	 Mean_loss: 0.01947528,  training time: 2.31
progress:  26%|[34m       [0m| 13/50 [00:33<01:25,  2.31s/it]progress:  28%|[34m       [0m| 14/50 [00:33<01:23,  2.31s/it]                                                         Episode 15	 reward: -10.66	 makespan: 1055.25	 Mean_loss: 0.02602994,  training time: 2.26
progress:  28%|[34m       [0m| 14/50 [00:35<01:23,  2.31s/it]progress:  30%|[34m       [0m| 15/50 [00:35<01:20,  2.29s/it]                                                         Episode 16	 reward: -10.68	 makespan: 1057.75	 Mean_loss: 0.04573199,  training time: 2.23
progress:  30%|[34m       [0m| 15/50 [00:37<01:20,  2.29s/it]progress:  32%|[34m      [0m| 16/50 [00:37<01:17,  2.28s/it]                                                         Episode 17	 reward: -10.42	 makespan: 1031.75	 Mean_loss: 0.02742604,  training time: 2.27
progress:  32%|[34m      [0m| 16/50 [00:40<01:17,  2.28s/it]progress:  34%|[34m      [0m| 17/50 [00:40<01:15,  2.27s/it]                                                         Episode 18	 reward: -10.59	 makespan: 1048.50	 Mean_loss: 0.02455953,  training time: 2.25
progress:  34%|[34m      [0m| 17/50 [00:42<01:15,  2.27s/it]progress:  36%|[34m      [0m| 18/50 [00:42<01:12,  2.27s/it]                                                         Episode 19	 reward: -10.34	 makespan: 1023.50	 Mean_loss: 0.00922068,  training time: 2.23
progress:  36%|[34m      [0m| 18/50 [00:44<01:12,  2.27s/it]progress:  38%|[34m      [0m| 19/50 [00:44<01:09,  2.26s/it]                                                         Episode 20	 reward: -10.59	 makespan: 1048.75	 Mean_loss: 0.02630114,  training time: 2.26
progress:  38%|[34m      [0m| 19/50 [00:46<01:09,  2.26s/it]progress:  40%|[34m      [0m| 20/50 [00:46<01:07,  2.26s/it]                                                         Episode 21	 reward: -10.85	 makespan: 1074.25	 Mean_loss: 0.01968719,  training time: 2.28
progress:  40%|[34m      [0m| 20/50 [00:49<01:07,  2.26s/it]progress:  42%|[34m     [0m| 21/50 [00:49<01:05,  2.26s/it]                                                         Episode 22	 reward: -10.86	 makespan: 1075.25	 Mean_loss: 0.03153237,  training time: 2.24
progress:  42%|[34m     [0m| 21/50 [00:51<01:05,  2.26s/it]progress:  44%|[34m     [0m| 22/50 [00:51<01:03,  2.26s/it]                                                         Episode 23	 reward: -10.74	 makespan: 1063.25	 Mean_loss: 0.01727131,  training time: 2.24
progress:  44%|[34m     [0m| 22/50 [00:53<01:03,  2.26s/it]progress:  46%|[34m     [0m| 23/50 [00:53<01:00,  2.25s/it]                                                         Episode 24	 reward: -10.80	 makespan: 1069.25	 Mean_loss: 0.03573827,  training time: 2.31
progress:  46%|[34m     [0m| 23/50 [00:56<01:00,  2.25s/it]progress:  48%|[34m     [0m| 24/50 [00:56<00:59,  2.27s/it]                                                         Episode 25	 reward: -10.82	 makespan: 1070.75	 Mean_loss: 0.02825244,  training time: 2.31
progress:  48%|[34m     [0m| 24/50 [00:58<00:59,  2.27s/it]progress:  50%|[34m     [0m| 25/50 [00:58<00:57,  2.28s/it]                                                         Episode 26	 reward: -10.85	 makespan: 1074.50	 Mean_loss: 0.02229439,  training time: 2.25
progress:  50%|[34m     [0m| 25/50 [01:00<00:57,  2.28s/it]progress:  52%|[34m    [0m| 26/50 [01:00<00:54,  2.27s/it]                                                         Episode 27	 reward: -10.59	 makespan: 1048.50	 Mean_loss: 0.03645172,  training time: 2.30
progress:  52%|[34m    [0m| 26/50 [01:02<00:54,  2.27s/it]progress:  54%|[34m    [0m| 27/50 [01:02<00:52,  2.28s/it]                                                         Episode 28	 reward: -10.87	 makespan: 1076.00	 Mean_loss: 0.03845454,  training time: 2.30
progress:  54%|[34m    [0m| 27/50 [01:05<00:52,  2.28s/it]progress:  56%|[34m    [0m| 28/50 [01:05<00:50,  2.29s/it]                                                         Episode 29	 reward: -10.73	 makespan: 1062.50	 Mean_loss: 0.01848846,  training time: 2.23
progress:  56%|[34m    [0m| 28/50 [01:07<00:50,  2.29s/it]progress:  58%|[34m    [0m| 29/50 [01:07<00:47,  2.27s/it]                                                         Episode 30	 reward: -10.79	 makespan: 1068.25	 Mean_loss: 0.02840318,  training time: 2.30
progress:  58%|[34m    [0m| 29/50 [01:09<00:47,  2.27s/it]progress:  60%|[34m    [0m| 30/50 [01:09<00:45,  2.28s/it]                                                         Episode 31	 reward: -10.97	 makespan: 1086.50	 Mean_loss: 0.03482372,  training time: 2.30
progress:  60%|[34m    [0m| 30/50 [01:12<00:45,  2.28s/it]progress:  62%|[34m   [0m| 31/50 [01:12<00:43,  2.29s/it]                                                         Episode 32	 reward: -11.14	 makespan: 1102.50	 Mean_loss: 0.03098015,  training time: 2.31
progress:  62%|[34m   [0m| 31/50 [01:14<00:43,  2.29s/it]progress:  64%|[34m   [0m| 32/50 [01:14<00:41,  2.29s/it]                                                         Episode 33	 reward: -11.06	 makespan: 1095.00	 Mean_loss: 0.02610726,  training time: 2.28
progress:  64%|[34m   [0m| 32/50 [01:16<00:41,  2.29s/it]progress:  66%|[34m   [0m| 33/50 [01:16<00:38,  2.29s/it]                                                         Episode 34	 reward: -10.72	 makespan: 1061.75	 Mean_loss: 0.03353717,  training time: 2.30
progress:  66%|[34m   [0m| 33/50 [01:18<00:38,  2.29s/it]progress:  68%|[34m   [0m| 34/50 [01:18<00:36,  2.29s/it]                                                         Episode 35	 reward: -10.90	 makespan: 1078.75	 Mean_loss: 0.02406959,  training time: 2.26
progress:  68%|[34m   [0m| 34/50 [01:21<00:36,  2.29s/it]progress:  70%|[34m   [0m| 35/50 [01:21<00:34,  2.29s/it]                                                         Episode 36	 reward: -10.89	 makespan: 1078.50	 Mean_loss: 0.02581779,  training time: 2.32
progress:  70%|[34m   [0m| 35/50 [01:23<00:34,  2.29s/it]progress:  72%|[34m  [0m| 36/50 [01:23<00:32,  2.30s/it]                                                         Episode 37	 reward: -11.38	 makespan: 1127.00	 Mean_loss: 0.04380026,  training time: 2.24
progress:  72%|[34m  [0m| 36/50 [01:25<00:32,  2.30s/it]progress:  74%|[34m  [0m| 37/50 [01:25<00:29,  2.28s/it]                                                         Episode 38	 reward: -10.69	 makespan: 1058.50	 Mean_loss: 0.02138955,  training time: 2.24
progress:  74%|[34m  [0m| 37/50 [01:28<00:29,  2.28s/it]progress:  76%|[34m  [0m| 38/50 [01:28<00:27,  2.27s/it]                                                         Episode 39	 reward: -10.81	 makespan: 1070.25	 Mean_loss: 0.03720642,  training time: 2.31
progress:  76%|[34m  [0m| 38/50 [01:30<00:27,  2.27s/it]progress:  78%|[34m  [0m| 39/50 [01:30<00:25,  2.28s/it]                                                         Episode 40	 reward: -10.50	 makespan: 1039.75	 Mean_loss: 0.02716664,  training time: 2.30
progress:  78%|[34m  [0m| 39/50 [01:32<00:25,  2.28s/it]progress:  80%|[34m  [0m| 40/50 [01:32<00:22,  2.29s/it]                                                         Episode 41	 reward: -10.92	 makespan: 1080.75	 Mean_loss: 0.03281194,  training time: 2.32
progress:  80%|[34m  [0m| 40/50 [01:34<00:22,  2.29s/it]progress:  82%|[34m [0m| 41/50 [01:34<00:20,  2.30s/it]                                                         Episode 42	 reward: -10.74	 makespan: 1063.75	 Mean_loss: 0.01906266,  training time: 2.28
progress:  82%|[34m [0m| 41/50 [01:37<00:20,  2.30s/it]progress:  84%|[34m [0m| 42/50 [01:37<00:18,  2.29s/it]                                                         Episode 43	 reward: -10.93	 makespan: 1082.25	 Mean_loss: 0.03729784,  training time: 2.30
progress:  84%|[34m [0m| 42/50 [01:39<00:18,  2.29s/it]progress:  86%|[34m [0m| 43/50 [01:39<00:16,  2.29s/it]                                                         Episode 44	 reward: -10.81	 makespan: 1070.50	 Mean_loss: 0.02912718,  training time: 2.32
progress:  86%|[34m [0m| 43/50 [01:41<00:16,  2.29s/it]progress:  88%|[34m [0m| 44/50 [01:41<00:13,  2.30s/it]                                                         Episode 45	 reward: -10.58	 makespan: 1047.50	 Mean_loss: 0.02049467,  training time: 2.30
progress:  88%|[34m [0m| 44/50 [01:44<00:13,  2.30s/it]progress:  90%|[34m [0m| 45/50 [01:44<00:11,  2.30s/it]                                                         Episode 46	 reward: -10.58	 makespan: 1047.00	 Mean_loss: 0.02545905,  training time: 2.30
progress:  90%|[34m [0m| 45/50 [01:46<00:11,  2.30s/it]progress:  92%|[34m[0m| 46/50 [01:46<00:09,  2.30s/it]                                                         Episode 47	 reward: -11.03	 makespan: 1092.25	 Mean_loss: 0.03771665,  training time: 2.32
progress:  92%|[34m[0m| 46/50 [01:48<00:09,  2.30s/it]progress:  94%|[34m[0m| 47/50 [01:48<00:06,  2.31s/it]                                                         Episode 48	 reward: -10.79	 makespan: 1067.75	 Mean_loss: 0.02803277,  training time: 2.31
progress:  94%|[34m[0m| 47/50 [01:51<00:06,  2.31s/it]progress:  96%|[34m[0m| 48/50 [01:51<00:04,  2.31s/it]                                                         Episode 49	 reward: -10.94	 makespan: 1083.00	 Mean_loss: 0.02219685,  training time: 2.31
progress:  96%|[34m[0m| 48/50 [01:53<00:04,  2.31s/it]progress:  98%|[34m[0m| 49/50 [01:53<00:02,  2.31s/it]                                                         Episode 50	 reward: -10.94	 makespan: 1082.75	 Mean_loss: 0.01723990,  training time: 2.29
progress:  98%|[34m[0m| 49/50 [01:55<00:02,  2.31s/it]progress: 100%|[34m[0m| 50/50 [01:55<00:00,  2.30s/it]progress: 100%|[34m[0m| 50/50 [01:55<00:00,  2.31s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --lr 0.003 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -12.75	 makespan: 1262.00	 Mean_loss: 0.39247859,  training time: 3.84
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:08,  3.84s/it]                                                        Episode 2	 reward: -12.71	 makespan: 1258.50	 Mean_loss: 0.13213781,  training time: 2.76
progress:   2%|[34m         [0m| 1/50 [00:06<03:08,  3.84s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:33,  3.20s/it]                                                        Episode 3	 reward: -12.58	 makespan: 1245.50	 Mean_loss: 0.08402708,  training time: 2.74
progress:   4%|[34m         [0m| 2/50 [00:09<02:33,  3.20s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:20,  2.99s/it]                                                        Episode 4	 reward: -12.55	 makespan: 1242.25	 Mean_loss: 0.06419822,  training time: 2.75
progress:   6%|[34m         [0m| 3/50 [00:12<02:20,  2.99s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:13,  2.90s/it]                                                        Episode 5	 reward: -12.80	 makespan: 1267.50	 Mean_loss: 0.04940453,  training time: 2.82
progress:   8%|[34m         [0m| 4/50 [00:14<02:13,  2.90s/it]progress:  10%|[34m         [0m| 5/50 [00:14<02:09,  2.87s/it]                                                        Episode 6	 reward: -12.53	 makespan: 1240.00	 Mean_loss: 0.03315493,  training time: 2.82
progress:  10%|[34m         [0m| 5/50 [00:17<02:09,  2.87s/it]progress:  12%|[34m        [0m| 6/50 [00:17<02:05,  2.85s/it]                                                        Episode 7	 reward: -12.74	 makespan: 1261.00	 Mean_loss: 0.03589517,  training time: 2.73
progress:  12%|[34m        [0m| 6/50 [00:20<02:05,  2.85s/it]progress:  14%|[34m        [0m| 7/50 [00:20<02:01,  2.81s/it]                                                        Episode 8	 reward: -12.61	 makespan: 1248.00	 Mean_loss: 0.03240481,  training time: 2.73
progress:  14%|[34m        [0m| 7/50 [00:23<02:01,  2.81s/it]progress:  16%|[34m        [0m| 8/50 [00:23<01:57,  2.79s/it]                                                        Episode 9	 reward: -12.77	 makespan: 1264.00	 Mean_loss: 0.03339752,  training time: 2.74
progress:  16%|[34m        [0m| 8/50 [00:25<01:57,  2.79s/it]progress:  18%|[34m        [0m| 9/50 [00:25<01:53,  2.77s/it]                                                        Episode 10	 reward: -12.69	 makespan: 1256.25	 Mean_loss: 0.05074972,  training time: 2.74
progress:  18%|[34m        [0m| 9/50 [00:28<01:53,  2.77s/it]progress:  20%|[34m        [0m| 10/50 [00:28<01:50,  2.76s/it]                                                         Episode 11	 reward: -12.92	 makespan: 1278.75	 Mean_loss: 0.02641645,  training time: 2.75
progress:  20%|[34m        [0m| 10/50 [00:31<01:50,  2.76s/it]progress:  22%|[34m       [0m| 11/50 [00:31<01:47,  2.76s/it]                                                         Episode 12	 reward: -12.86	 makespan: 1273.00	 Mean_loss: 0.03082507,  training time: 2.72
progress:  22%|[34m       [0m| 11/50 [00:34<01:47,  2.76s/it]progress:  24%|[34m       [0m| 12/50 [00:34<01:44,  2.75s/it]                                                         Episode 13	 reward: -12.82	 makespan: 1269.50	 Mean_loss: 0.02601177,  training time: 2.74
progress:  24%|[34m       [0m| 12/50 [00:36<01:44,  2.75s/it]progress:  26%|[34m       [0m| 13/50 [00:36<01:41,  2.75s/it]                                                         Episode 14	 reward: -12.93	 makespan: 1280.25	 Mean_loss: 0.07209174,  training time: 2.75
progress:  26%|[34m       [0m| 13/50 [00:39<01:41,  2.75s/it]progress:  28%|[34m       [0m| 14/50 [00:39<01:38,  2.75s/it]                                                         Episode 15	 reward: -12.82	 makespan: 1269.50	 Mean_loss: 0.02405033,  training time: 2.73
progress:  28%|[34m       [0m| 14/50 [00:42<01:38,  2.75s/it]progress:  30%|[34m       [0m| 15/50 [00:42<01:35,  2.74s/it]                                                         Episode 16	 reward: -12.76	 makespan: 1263.00	 Mean_loss: 0.02040891,  training time: 2.70
progress:  30%|[34m       [0m| 15/50 [00:45<01:35,  2.74s/it]progress:  32%|[34m      [0m| 16/50 [00:45<01:32,  2.73s/it]                                                         Episode 17	 reward: -12.99	 makespan: 1286.50	 Mean_loss: 0.01984515,  training time: 2.71
progress:  32%|[34m      [0m| 16/50 [00:47<01:32,  2.73s/it]progress:  34%|[34m      [0m| 17/50 [00:47<01:29,  2.73s/it]                                                         Episode 18	 reward: -12.86	 makespan: 1273.25	 Mean_loss: 0.02233825,  training time: 2.70
progress:  34%|[34m      [0m| 17/50 [00:50<01:29,  2.73s/it]progress:  36%|[34m      [0m| 18/50 [00:50<01:27,  2.72s/it]                                                         Episode 19	 reward: -13.07	 makespan: 1294.25	 Mean_loss: 0.02931643,  training time: 2.72
progress:  36%|[34m      [0m| 18/50 [00:53<01:27,  2.72s/it]progress:  38%|[34m      [0m| 19/50 [00:53<01:24,  2.72s/it]                                                         Episode 20	 reward: -13.21	 makespan: 1308.25	 Mean_loss: 0.03622023,  training time: 2.70
progress:  38%|[34m      [0m| 19/50 [00:55<01:24,  2.72s/it]progress:  40%|[34m      [0m| 20/50 [00:55<01:21,  2.71s/it]                                                         Episode 21	 reward: -12.86	 makespan: 1273.25	 Mean_loss: 0.02078637,  training time: 2.71
progress:  40%|[34m      [0m| 20/50 [00:58<01:21,  2.71s/it]progress:  42%|[34m     [0m| 21/50 [00:58<01:18,  2.71s/it]                                                         Episode 22	 reward: -13.27	 makespan: 1314.00	 Mean_loss: 0.03854894,  training time: 2.72
progress:  42%|[34m     [0m| 21/50 [01:01<01:18,  2.71s/it]progress:  44%|[34m     [0m| 22/50 [01:01<01:15,  2.71s/it]                                                         Episode 23	 reward: -12.95	 makespan: 1282.00	 Mean_loss: 0.03174673,  training time: 2.67
progress:  44%|[34m     [0m| 22/50 [01:04<01:15,  2.71s/it]progress:  46%|[34m     [0m| 23/50 [01:04<01:12,  2.70s/it]                                                         Episode 24	 reward: -13.26	 makespan: 1313.00	 Mean_loss: 0.03428245,  training time: 2.72
progress:  46%|[34m     [0m| 23/50 [01:06<01:12,  2.70s/it]progress:  48%|[34m     [0m| 24/50 [01:06<01:10,  2.71s/it]                                                         Episode 25	 reward: -13.28	 makespan: 1315.00	 Mean_loss: 0.02623796,  training time: 2.70
progress:  48%|[34m     [0m| 24/50 [01:09<01:10,  2.71s/it]progress:  50%|[34m     [0m| 25/50 [01:09<01:07,  2.70s/it]                                                         Episode 26	 reward: -13.02	 makespan: 1288.50	 Mean_loss: 0.03303745,  training time: 2.73
progress:  50%|[34m     [0m| 25/50 [01:12<01:07,  2.70s/it]progress:  52%|[34m    [0m| 26/50 [01:12<01:05,  2.71s/it]                                                         Episode 27	 reward: -13.38	 makespan: 1324.50	 Mean_loss: 0.04659046,  training time: 2.71
progress:  52%|[34m    [0m| 26/50 [01:14<01:05,  2.71s/it]progress:  54%|[34m    [0m| 27/50 [01:14<01:02,  2.71s/it]                                                         Episode 28	 reward: -13.30	 makespan: 1316.75	 Mean_loss: 0.04216852,  training time: 2.70
progress:  54%|[34m    [0m| 27/50 [01:17<01:02,  2.71s/it]progress:  56%|[34m    [0m| 28/50 [01:17<00:59,  2.71s/it]                                                         Episode 29	 reward: -13.06	 makespan: 1293.00	 Mean_loss: 0.02464546,  training time: 2.72
progress:  56%|[34m    [0m| 28/50 [01:20<00:59,  2.71s/it]progress:  58%|[34m    [0m| 29/50 [01:20<00:56,  2.71s/it]                                                         Episode 30	 reward: -13.32	 makespan: 1318.25	 Mean_loss: 0.03992937,  training time: 2.70
progress:  58%|[34m    [0m| 29/50 [01:22<00:56,  2.71s/it]progress:  60%|[34m    [0m| 30/50 [01:22<00:54,  2.71s/it]                                                         Episode 31	 reward: -13.02	 makespan: 1288.75	 Mean_loss: 0.02058401,  training time: 2.70
progress:  60%|[34m    [0m| 30/50 [01:25<00:54,  2.71s/it]progress:  62%|[34m   [0m| 31/50 [01:25<00:51,  2.71s/it]                                                         Episode 32	 reward: -13.05	 makespan: 1291.75	 Mean_loss: 0.04321633,  training time: 2.71
progress:  62%|[34m   [0m| 31/50 [01:28<00:51,  2.71s/it]progress:  64%|[34m   [0m| 32/50 [01:28<00:48,  2.71s/it]                                                         Episode 33	 reward: -13.33	 makespan: 1319.75	 Mean_loss: 0.02800212,  training time: 2.71
progress:  64%|[34m   [0m| 32/50 [01:31<00:48,  2.71s/it]progress:  66%|[34m   [0m| 33/50 [01:31<00:46,  2.71s/it]                                                         Episode 34	 reward: -13.13	 makespan: 1299.50	 Mean_loss: 0.01506492,  training time: 2.71
progress:  66%|[34m   [0m| 33/50 [01:33<00:46,  2.71s/it]progress:  68%|[34m   [0m| 34/50 [01:33<00:43,  2.71s/it]                                                         Episode 35	 reward: -13.25	 makespan: 1312.00	 Mean_loss: 0.05935332,  training time: 2.72
progress:  68%|[34m   [0m| 34/50 [01:36<00:43,  2.71s/it]progress:  70%|[34m   [0m| 35/50 [01:36<00:40,  2.71s/it]                                                         Episode 36	 reward: -13.19	 makespan: 1306.25	 Mean_loss: 0.03043852,  training time: 2.72
progress:  70%|[34m   [0m| 35/50 [01:39<00:40,  2.71s/it]progress:  72%|[34m  [0m| 36/50 [01:39<00:38,  2.72s/it]                                                         Episode 37	 reward: -13.74	 makespan: 1360.00	 Mean_loss: 0.02934465,  training time: 2.72
progress:  72%|[34m  [0m| 36/50 [01:41<00:38,  2.72s/it]progress:  74%|[34m  [0m| 37/50 [01:41<00:35,  2.72s/it]                                                         Episode 38	 reward: -13.82	 makespan: 1367.75	 Mean_loss: 0.04967527,  training time: 2.71
progress:  74%|[34m  [0m| 37/50 [01:44<00:35,  2.72s/it]progress:  76%|[34m  [0m| 38/50 [01:44<00:32,  2.72s/it]                                                         Episode 39	 reward: -13.65	 makespan: 1351.25	 Mean_loss: 0.07731742,  training time: 2.70
progress:  76%|[34m  [0m| 38/50 [01:47<00:32,  2.72s/it]progress:  78%|[34m  [0m| 39/50 [01:47<00:29,  2.71s/it]                                                         Episode 40	 reward: -13.61	 makespan: 1347.00	 Mean_loss: 0.04143698,  training time: 2.76
progress:  78%|[34m  [0m| 39/50 [01:50<00:29,  2.71s/it]progress:  80%|[34m  [0m| 40/50 [01:50<00:27,  2.73s/it]                                                         Episode 41	 reward: -13.78	 makespan: 1363.75	 Mean_loss: 0.05424256,  training time: 2.72
progress:  80%|[34m  [0m| 40/50 [01:52<00:27,  2.73s/it]progress:  82%|[34m [0m| 41/50 [01:52<00:24,  2.72s/it]                                                         Episode 42	 reward: -13.87	 makespan: 1373.50	 Mean_loss: 0.06437965,  training time: 2.70
progress:  82%|[34m [0m| 41/50 [01:55<00:24,  2.72s/it]progress:  84%|[34m [0m| 42/50 [01:55<00:21,  2.72s/it]                                                         Episode 43	 reward: -14.10	 makespan: 1396.00	 Mean_loss: 0.05502162,  training time: 2.72
progress:  84%|[34m [0m| 42/50 [01:58<00:21,  2.72s/it]progress:  86%|[34m [0m| 43/50 [01:58<00:19,  2.72s/it]                                                         Episode 44	 reward: -13.66	 makespan: 1352.00	 Mean_loss: 0.03334521,  training time: 2.71
progress:  86%|[34m [0m| 43/50 [02:01<00:19,  2.72s/it]progress:  88%|[34m [0m| 44/50 [02:01<00:16,  2.72s/it]                                                         Episode 45	 reward: -13.96	 makespan: 1382.25	 Mean_loss: 0.03643860,  training time: 2.70
progress:  88%|[34m [0m| 44/50 [02:03<00:16,  2.72s/it]progress:  90%|[34m [0m| 45/50 [02:03<00:13,  2.71s/it]                                                         Episode 46	 reward: -13.46	 makespan: 1332.25	 Mean_loss: 0.03899195,  training time: 2.72
progress:  90%|[34m [0m| 45/50 [02:06<00:13,  2.71s/it]progress:  92%|[34m[0m| 46/50 [02:06<00:10,  2.71s/it]                                                         Episode 47	 reward: -13.41	 makespan: 1327.50	 Mean_loss: 0.02701512,  training time: 2.70
progress:  92%|[34m[0m| 46/50 [02:09<00:10,  2.71s/it]progress:  94%|[34m[0m| 47/50 [02:09<00:08,  2.71s/it]                                                         Episode 48	 reward: -13.59	 makespan: 1345.25	 Mean_loss: 0.03300454,  training time: 2.72
progress:  94%|[34m[0m| 47/50 [02:11<00:08,  2.71s/it]progress:  96%|[34m[0m| 48/50 [02:11<00:05,  2.71s/it]                                                         Episode 49	 reward: -13.65	 makespan: 1351.25	 Mean_loss: 0.03126553,  training time: 2.73
progress:  96%|[34m[0m| 48/50 [02:14<00:05,  2.71s/it]progress:  98%|[34m[0m| 49/50 [02:14<00:02,  2.72s/it]                                                         Episode 50	 reward: -13.44	 makespan: 1330.50	 Mean_loss: 0.03339179,  training time: 2.71
progress:  98%|[34m[0m| 49/50 [02:17<00:02,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:17<00:00,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:17<00:00,  2.75s/it]
+ meta_iterations=1000
+ max_updates_maml=1000
+ model_suffix=exp15_1000_64_3
+ num_tasks=4
+ logdir_maml=exp15/maml
+ logdir_maml_finetuning=./runs/exp15/maml_finetuning
+ model=maml+exp15_1000_64_3
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob4 --model_suffix exp15_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp15_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.11	 makespan: 402.50	 Mean_loss: 0.08220557,  training time: 1.82
progress:   0%|[34m          [0m| 0/50 [00:01<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:01<01:29,  1.82s/it]                                                        Episode 2	 reward: -4.11	 makespan: 402.50	 Mean_loss: 0.09092268,  training time: 0.78
progress:   2%|[34m         [0m| 1/50 [00:02<01:29,  1.82s/it]progress:   4%|[34m         [0m| 2/50 [00:02<00:58,  1.21s/it]                                                        Episode 3	 reward: -4.03	 makespan: 395.25	 Mean_loss: 0.09395989,  training time: 0.75
progress:   4%|[34m         [0m| 2/50 [00:03<00:58,  1.21s/it]progress:   6%|[34m         [0m| 3/50 [00:03<00:47,  1.00s/it]                                                        Episode 4	 reward: -3.92	 makespan: 384.00	 Mean_loss: 0.09024271,  training time: 0.80
progress:   6%|[34m         [0m| 3/50 [00:04<00:47,  1.00s/it]progress:   8%|[34m         [0m| 4/50 [00:04<00:42,  1.08it/s]                                                        Episode 5	 reward: -3.86	 makespan: 378.50	 Mean_loss: 0.06687996,  training time: 0.76
progress:   8%|[34m         [0m| 4/50 [00:04<00:42,  1.08it/s]progress:  10%|[34m         [0m| 5/50 [00:04<00:38,  1.16it/s]                                                        Episode 6	 reward: -3.93	 makespan: 384.75	 Mean_loss: 0.02195971,  training time: 0.75
progress:  10%|[34m         [0m| 5/50 [00:05<00:38,  1.16it/s]progress:  12%|[34m        [0m| 6/50 [00:05<00:36,  1.21it/s]                                                        Episode 7	 reward: -3.78	 makespan: 370.00	 Mean_loss: 0.05611838,  training time: 0.72
progress:  12%|[34m        [0m| 6/50 [00:06<00:36,  1.21it/s]progress:  14%|[34m        [0m| 7/50 [00:06<00:34,  1.26it/s]                                                        Episode 8	 reward: -4.65	 makespan: 455.50	 Mean_loss: 0.08908083,  training time: 0.70
progress:  14%|[34m        [0m| 7/50 [00:07<00:34,  1.26it/s]progress:  16%|[34m        [0m| 8/50 [00:07<00:32,  1.31it/s]                                                        Episode 9	 reward: -3.83	 makespan: 375.75	 Mean_loss: 0.20571630,  training time: 0.71
progress:  16%|[34m        [0m| 8/50 [00:07<00:32,  1.31it/s]progress:  18%|[34m        [0m| 9/50 [00:07<00:30,  1.34it/s]                                                        Episode 10	 reward: -3.78	 makespan: 370.75	 Mean_loss: 0.03915901,  training time: 0.70
progress:  18%|[34m        [0m| 9/50 [00:08<00:30,  1.34it/s]progress:  20%|[34m        [0m| 10/50 [00:08<00:29,  1.37it/s]                                                         Episode 11	 reward: -3.64	 makespan: 356.25	 Mean_loss: 0.02415396,  training time: 0.71
progress:  20%|[34m        [0m| 10/50 [00:09<00:29,  1.37it/s]progress:  22%|[34m       [0m| 11/50 [00:09<00:28,  1.38it/s]                                                         Episode 12	 reward: -3.72	 makespan: 364.75	 Mean_loss: 0.02419012,  training time: 0.71
progress:  22%|[34m       [0m| 11/50 [00:09<00:28,  1.38it/s]progress:  24%|[34m       [0m| 12/50 [00:09<00:27,  1.39it/s]                                                         Episode 13	 reward: -3.35	 makespan: 328.25	 Mean_loss: 0.02414740,  training time: 0.70
progress:  24%|[34m       [0m| 12/50 [00:10<00:27,  1.39it/s]progress:  26%|[34m       [0m| 13/50 [00:10<00:26,  1.40it/s]                                                         Episode 14	 reward: -3.85	 makespan: 377.50	 Mean_loss: 0.04471081,  training time: 0.71
progress:  26%|[34m       [0m| 13/50 [00:11<00:26,  1.40it/s]progress:  28%|[34m       [0m| 14/50 [00:11<00:25,  1.40it/s]                                                         Episode 15	 reward: -3.80	 makespan: 372.00	 Mean_loss: 0.02622734,  training time: 0.75
progress:  28%|[34m       [0m| 14/50 [00:12<00:25,  1.40it/s]progress:  30%|[34m       [0m| 15/50 [00:12<00:25,  1.38it/s]                                                         Episode 16	 reward: -3.61	 makespan: 354.00	 Mean_loss: 0.03847615,  training time: 0.70
progress:  30%|[34m       [0m| 15/50 [00:12<00:25,  1.38it/s]progress:  32%|[34m      [0m| 16/50 [00:12<00:24,  1.39it/s]                                                         Episode 17	 reward: -3.43	 makespan: 336.25	 Mean_loss: 0.03156118,  training time: 0.70
progress:  32%|[34m      [0m| 16/50 [00:13<00:24,  1.39it/s]progress:  34%|[34m      [0m| 17/50 [00:13<00:23,  1.40it/s]                                                         Episode 18	 reward: -3.61	 makespan: 353.75	 Mean_loss: 0.06439368,  training time: 0.70
progress:  34%|[34m      [0m| 17/50 [00:14<00:23,  1.40it/s]progress:  36%|[34m      [0m| 18/50 [00:14<00:22,  1.41it/s]                                                         Episode 19	 reward: -3.51	 makespan: 343.50	 Mean_loss: 0.04103340,  training time: 0.70
progress:  36%|[34m      [0m| 18/50 [00:14<00:22,  1.41it/s]progress:  38%|[34m      [0m| 19/50 [00:14<00:21,  1.41it/s]                                                         Episode 20	 reward: -3.69	 makespan: 361.25	 Mean_loss: 0.00780003,  training time: 0.70
progress:  38%|[34m      [0m| 19/50 [00:15<00:21,  1.41it/s]progress:  40%|[34m      [0m| 20/50 [00:15<00:21,  1.41it/s]                                                         Episode 21	 reward: -3.63	 makespan: 356.00	 Mean_loss: 0.01353325,  training time: 0.71
progress:  40%|[34m      [0m| 20/50 [00:16<00:21,  1.41it/s]progress:  42%|[34m     [0m| 21/50 [00:16<00:20,  1.41it/s]                                                         Episode 22	 reward: -3.71	 makespan: 363.75	 Mean_loss: 0.02451080,  training time: 0.72
progress:  42%|[34m     [0m| 21/50 [00:17<00:20,  1.41it/s]progress:  44%|[34m     [0m| 22/50 [00:17<00:19,  1.40it/s]                                                         Episode 23	 reward: -3.43	 makespan: 336.50	 Mean_loss: -0.00033629,  training time: 0.72
progress:  44%|[34m     [0m| 22/50 [00:17<00:19,  1.40it/s]progress:  46%|[34m     [0m| 23/50 [00:17<00:19,  1.40it/s]                                                         Episode 24	 reward: -3.52	 makespan: 345.00	 Mean_loss: 0.00571934,  training time: 0.69
progress:  46%|[34m     [0m| 23/50 [00:18<00:19,  1.40it/s]progress:  48%|[34m     [0m| 24/50 [00:18<00:18,  1.41it/s]                                                         Episode 25	 reward: -3.57	 makespan: 349.50	 Mean_loss: 0.03842488,  training time: 0.69
progress:  48%|[34m     [0m| 24/50 [00:19<00:18,  1.41it/s]progress:  50%|[34m     [0m| 25/50 [00:19<00:17,  1.42it/s]                                                         Episode 26	 reward: -3.53	 makespan: 346.25	 Mean_loss: 0.02119624,  training time: 0.69
progress:  50%|[34m     [0m| 25/50 [00:19<00:17,  1.42it/s]progress:  52%|[34m    [0m| 26/50 [00:19<00:16,  1.43it/s]                                                         Episode 27	 reward: -3.70	 makespan: 362.75	 Mean_loss: 0.00056308,  training time: 0.72
progress:  52%|[34m    [0m| 26/50 [00:20<00:16,  1.43it/s]progress:  54%|[34m    [0m| 27/50 [00:20<00:16,  1.41it/s]                                                         Episode 28	 reward: -3.73	 makespan: 365.75	 Mean_loss: 0.01564520,  training time: 0.71
progress:  54%|[34m    [0m| 27/50 [00:21<00:16,  1.41it/s]progress:  56%|[34m    [0m| 28/50 [00:21<00:15,  1.41it/s]                                                         Episode 29	 reward: -3.37	 makespan: 330.00	 Mean_loss: 0.01573021,  training time: 0.72
progress:  56%|[34m    [0m| 28/50 [00:21<00:15,  1.41it/s]progress:  58%|[34m    [0m| 29/50 [00:21<00:14,  1.40it/s]                                                         Episode 30	 reward: -4.05	 makespan: 397.00	 Mean_loss: 0.09654720,  training time: 0.74
progress:  58%|[34m    [0m| 29/50 [00:22<00:14,  1.40it/s]progress:  60%|[34m    [0m| 30/50 [00:22<00:14,  1.39it/s]                                                         Episode 31	 reward: -3.57	 makespan: 349.75	 Mean_loss: 0.05868670,  training time: 0.75
progress:  60%|[34m    [0m| 30/50 [00:23<00:14,  1.39it/s]progress:  62%|[34m   [0m| 31/50 [00:23<00:13,  1.37it/s]                                                         Episode 32	 reward: -3.68	 makespan: 360.75	 Mean_loss: 0.03632061,  training time: 0.70
progress:  62%|[34m   [0m| 31/50 [00:24<00:13,  1.37it/s]progress:  64%|[34m   [0m| 32/50 [00:24<00:12,  1.39it/s]                                                         Episode 33	 reward: -3.32	 makespan: 325.25	 Mean_loss: 0.00344841,  training time: 0.69
progress:  64%|[34m   [0m| 32/50 [00:24<00:12,  1.39it/s]progress:  66%|[34m   [0m| 33/50 [00:24<00:12,  1.40it/s]                                                         Episode 34	 reward: -3.30	 makespan: 323.00	 Mean_loss: 0.00806273,  training time: 0.69
progress:  66%|[34m   [0m| 33/50 [00:25<00:12,  1.40it/s]progress:  68%|[34m   [0m| 34/50 [00:25<00:11,  1.41it/s]                                                         Episode 35	 reward: -3.20	 makespan: 313.25	 Mean_loss: 0.00098695,  training time: 0.79
progress:  68%|[34m   [0m| 34/50 [00:26<00:11,  1.41it/s]progress:  70%|[34m   [0m| 35/50 [00:26<00:10,  1.36it/s]                                                         Episode 36	 reward: -3.31	 makespan: 324.00	 Mean_loss: 0.02571584,  training time: 0.70
progress:  70%|[34m   [0m| 35/50 [00:27<00:10,  1.36it/s]progress:  72%|[34m  [0m| 36/50 [00:27<00:10,  1.38it/s]                                                         Episode 37	 reward: -3.67	 makespan: 359.50	 Mean_loss: 0.02001150,  training time: 0.70
progress:  72%|[34m  [0m| 36/50 [00:27<00:10,  1.38it/s]progress:  74%|[34m  [0m| 37/50 [00:27<00:09,  1.40it/s]                                                         Episode 38	 reward: -3.30	 makespan: 323.00	 Mean_loss: 0.02768586,  training time: 0.70
progress:  74%|[34m  [0m| 37/50 [00:28<00:09,  1.40it/s]progress:  76%|[34m  [0m| 38/50 [00:28<00:08,  1.41it/s]                                                         Episode 39	 reward: -3.39	 makespan: 332.50	 Mean_loss: 0.01621333,  training time: 0.70
progress:  76%|[34m  [0m| 38/50 [00:29<00:08,  1.41it/s]progress:  78%|[34m  [0m| 39/50 [00:29<00:07,  1.41it/s]                                                         Episode 40	 reward: -3.50	 makespan: 343.00	 Mean_loss: 0.01762136,  training time: 0.69
progress:  78%|[34m  [0m| 39/50 [00:29<00:07,  1.41it/s]progress:  80%|[34m  [0m| 40/50 [00:29<00:07,  1.42it/s]                                                         Episode 41	 reward: -3.39	 makespan: 332.50	 Mean_loss: -0.00014844,  training time: 0.69
progress:  80%|[34m  [0m| 40/50 [00:30<00:07,  1.42it/s]progress:  82%|[34m [0m| 41/50 [00:30<00:06,  1.43it/s]                                                         Episode 42	 reward: -3.44	 makespan: 337.25	 Mean_loss: 0.06043223,  training time: 0.70
progress:  82%|[34m [0m| 41/50 [00:31<00:06,  1.43it/s]progress:  84%|[34m [0m| 42/50 [00:31<00:05,  1.43it/s]                                                         Episode 43	 reward: -3.50	 makespan: 342.75	 Mean_loss: 0.01389232,  training time: 0.69
progress:  84%|[34m [0m| 42/50 [00:31<00:05,  1.43it/s]progress:  86%|[34m [0m| 43/50 [00:31<00:04,  1.43it/s]                                                         Episode 44	 reward: -3.55	 makespan: 347.50	 Mean_loss: 0.02408803,  training time: 0.70
progress:  86%|[34m [0m| 43/50 [00:32<00:04,  1.43it/s]progress:  88%|[34m [0m| 44/50 [00:32<00:04,  1.43it/s]                                                         Episode 45	 reward: -3.52	 makespan: 345.25	 Mean_loss: 0.01027579,  training time: 0.70
progress:  88%|[34m [0m| 44/50 [00:33<00:04,  1.43it/s]progress:  90%|[34m [0m| 45/50 [00:33<00:03,  1.43it/s]                                                         Episode 46	 reward: -3.58	 makespan: 350.75	 Mean_loss: 0.01815799,  training time: 0.72
progress:  90%|[34m [0m| 45/50 [00:34<00:03,  1.43it/s]progress:  92%|[34m[0m| 46/50 [00:34<00:02,  1.42it/s]                                                         Episode 47	 reward: -3.65	 makespan: 357.50	 Mean_loss: 0.02778237,  training time: 0.71
progress:  92%|[34m[0m| 46/50 [00:34<00:02,  1.42it/s]progress:  94%|[34m[0m| 47/50 [00:34<00:02,  1.42it/s]                                                         Episode 48	 reward: -3.34	 makespan: 327.50	 Mean_loss: 0.01615833,  training time: 0.69
progress:  94%|[34m[0m| 47/50 [00:35<00:02,  1.42it/s]progress:  96%|[34m[0m| 48/50 [00:35<00:01,  1.43it/s]                                                         Episode 49	 reward: -3.55	 makespan: 347.75	 Mean_loss: 0.02472899,  training time: 0.69
progress:  96%|[34m[0m| 48/50 [00:36<00:01,  1.43it/s]progress:  98%|[34m[0m| 49/50 [00:36<00:00,  1.43it/s]                                                         Episode 50	 reward: -3.64	 makespan: 356.50	 Mean_loss: 0.03426112,  training time: 0.69
progress:  98%|[34m[0m| 49/50 [00:36<00:00,  1.43it/s]progress: 100%|[34m[0m| 50/50 [00:36<00:00,  1.43it/s]progress: 100%|[34m[0m| 50/50 [00:36<00:00,  1.36it/s]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob6 --model_suffix exp15_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003 --op_per_job 6
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp15_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.73	 makespan: 666.50	 Mean_loss: 0.31745127,  training time: 2.07
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:41,  2.07s/it]                                                        Episode 2	 reward: -6.83	 makespan: 676.00	 Mean_loss: 0.25726396,  training time: 1.01
progress:   2%|[34m         [0m| 1/50 [00:03<01:41,  2.07s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:09,  1.45s/it]                                                        Episode 3	 reward: -6.25	 makespan: 618.50	 Mean_loss: 0.23300466,  training time: 1.00
progress:   4%|[34m         [0m| 2/50 [00:04<01:09,  1.45s/it]progress:   6%|[34m         [0m| 3/50 [00:04<00:58,  1.24s/it]                                                        Episode 4	 reward: -6.18	 makespan: 611.50	 Mean_loss: 0.25834137,  training time: 1.08
progress:   6%|[34m         [0m| 3/50 [00:05<00:58,  1.24s/it]progress:   8%|[34m         [0m| 4/50 [00:05<00:54,  1.18s/it]                                                        Episode 5	 reward: -6.32	 makespan: 625.75	 Mean_loss: 0.14287072,  training time: 1.03
progress:   8%|[34m         [0m| 4/50 [00:06<00:54,  1.18s/it]progress:  10%|[34m         [0m| 5/50 [00:06<00:50,  1.13s/it]                                                        Episode 6	 reward: -6.65	 makespan: 658.25	 Mean_loss: 0.16399720,  training time: 1.02
progress:  10%|[34m         [0m| 5/50 [00:07<00:50,  1.13s/it]progress:  12%|[34m        [0m| 6/50 [00:07<00:48,  1.09s/it]                                                        Episode 7	 reward: -6.69	 makespan: 662.50	 Mean_loss: 0.20735770,  training time: 1.03
progress:  12%|[34m        [0m| 6/50 [00:08<00:48,  1.09s/it]progress:  14%|[34m        [0m| 7/50 [00:08<00:46,  1.07s/it]                                                        Episode 8	 reward: -6.92	 makespan: 685.50	 Mean_loss: 0.27747336,  training time: 1.02
progress:  14%|[34m        [0m| 7/50 [00:09<00:46,  1.07s/it]progress:  16%|[34m        [0m| 8/50 [00:09<00:44,  1.06s/it]                                                        Episode 9	 reward: -6.55	 makespan: 648.75	 Mean_loss: 0.17824227,  training time: 1.03
progress:  16%|[34m        [0m| 8/50 [00:10<00:44,  1.06s/it]progress:  18%|[34m        [0m| 9/50 [00:10<00:42,  1.05s/it]                                                        Episode 10	 reward: -6.35	 makespan: 628.25	 Mean_loss: 0.09931267,  training time: 1.02
progress:  18%|[34m        [0m| 9/50 [00:11<00:42,  1.05s/it]progress:  20%|[34m        [0m| 10/50 [00:11<00:41,  1.04s/it]                                                         Episode 11	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.12612258,  training time: 1.03
progress:  20%|[34m        [0m| 10/50 [00:12<00:41,  1.04s/it]progress:  22%|[34m       [0m| 11/50 [00:12<00:40,  1.04s/it]                                                         Episode 12	 reward: -6.40	 makespan: 633.50	 Mean_loss: 0.10936729,  training time: 1.13
progress:  22%|[34m       [0m| 11/50 [00:13<00:40,  1.04s/it]progress:  24%|[34m       [0m| 12/50 [00:13<00:40,  1.07s/it]                                                         Episode 13	 reward: -6.33	 makespan: 626.75	 Mean_loss: 0.10227385,  training time: 1.04
progress:  24%|[34m       [0m| 12/50 [00:14<00:40,  1.07s/it]progress:  26%|[34m       [0m| 13/50 [00:14<00:39,  1.06s/it]                                                         Episode 14	 reward: -6.10	 makespan: 604.25	 Mean_loss: 0.10949244,  training time: 1.07
progress:  26%|[34m       [0m| 13/50 [00:15<00:39,  1.06s/it]progress:  28%|[34m       [0m| 14/50 [00:15<00:38,  1.06s/it]                                                         Episode 15	 reward: -6.28	 makespan: 621.75	 Mean_loss: 0.08323729,  training time: 1.02
progress:  28%|[34m       [0m| 14/50 [00:16<00:38,  1.06s/it]progress:  30%|[34m       [0m| 15/50 [00:16<00:36,  1.05s/it]                                                         Episode 16	 reward: -6.09	 makespan: 602.50	 Mean_loss: 0.07342095,  training time: 1.00
progress:  30%|[34m       [0m| 15/50 [00:17<00:36,  1.05s/it]progress:  32%|[34m      [0m| 16/50 [00:17<00:35,  1.04s/it]                                                         Episode 17	 reward: -6.13	 makespan: 606.75	 Mean_loss: 0.06687461,  training time: 1.03
progress:  32%|[34m      [0m| 16/50 [00:18<00:35,  1.04s/it]progress:  34%|[34m      [0m| 17/50 [00:18<00:34,  1.03s/it]                                                         Episode 18	 reward: -5.86	 makespan: 580.50	 Mean_loss: 0.08903408,  training time: 1.01
progress:  34%|[34m      [0m| 17/50 [00:19<00:34,  1.03s/it]progress:  36%|[34m      [0m| 18/50 [00:19<00:32,  1.03s/it]                                                         Episode 19	 reward: -5.82	 makespan: 576.00	 Mean_loss: 0.03793437,  training time: 1.03
progress:  36%|[34m      [0m| 18/50 [00:20<00:32,  1.03s/it]progress:  38%|[34m      [0m| 19/50 [00:20<00:31,  1.03s/it]                                                         Episode 20	 reward: -5.73	 makespan: 567.25	 Mean_loss: 0.04107971,  training time: 1.03
progress:  38%|[34m      [0m| 19/50 [00:21<00:31,  1.03s/it]progress:  40%|[34m      [0m| 20/50 [00:21<00:30,  1.03s/it]                                                         Episode 21	 reward: -5.60	 makespan: 554.25	 Mean_loss: 0.04360684,  training time: 0.99
progress:  40%|[34m      [0m| 20/50 [00:22<00:30,  1.03s/it]progress:  42%|[34m     [0m| 21/50 [00:22<00:29,  1.02s/it]                                                         Episode 22	 reward: -5.55	 makespan: 549.50	 Mean_loss: 0.04331664,  training time: 1.02
progress:  42%|[34m     [0m| 21/50 [00:23<00:29,  1.02s/it]progress:  44%|[34m     [0m| 22/50 [00:23<00:28,  1.02s/it]                                                         Episode 23	 reward: -5.60	 makespan: 554.00	 Mean_loss: 0.02629987,  training time: 1.03
progress:  44%|[34m     [0m| 22/50 [00:24<00:28,  1.02s/it]progress:  46%|[34m     [0m| 23/50 [00:24<00:27,  1.02s/it]                                                         Episode 24	 reward: -5.67	 makespan: 561.25	 Mean_loss: 0.03608741,  training time: 1.01
progress:  46%|[34m     [0m| 23/50 [00:25<00:27,  1.02s/it]progress:  48%|[34m     [0m| 24/50 [00:25<00:26,  1.02s/it]                                                         Episode 25	 reward: -5.89	 makespan: 583.25	 Mean_loss: 0.02503758,  training time: 1.01
progress:  48%|[34m     [0m| 24/50 [00:26<00:26,  1.02s/it]progress:  50%|[34m     [0m| 25/50 [00:26<00:25,  1.02s/it]                                                         Episode 26	 reward: -5.71	 makespan: 565.00	 Mean_loss: 0.04332218,  training time: 1.01
progress:  50%|[34m     [0m| 25/50 [00:27<00:25,  1.02s/it]progress:  52%|[34m    [0m| 26/50 [00:27<00:24,  1.02s/it]                                                         Episode 27	 reward: -5.65	 makespan: 559.25	 Mean_loss: 0.03559155,  training time: 1.02
progress:  52%|[34m    [0m| 26/50 [00:28<00:24,  1.02s/it]progress:  54%|[34m    [0m| 27/50 [00:28<00:23,  1.02s/it]                                                         Episode 28	 reward: -5.57	 makespan: 551.75	 Mean_loss: 0.01723932,  training time: 0.99
progress:  54%|[34m    [0m| 27/50 [00:29<00:23,  1.02s/it]progress:  56%|[34m    [0m| 28/50 [00:29<00:22,  1.01s/it]                                                         Episode 29	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.03470615,  training time: 1.02
progress:  56%|[34m    [0m| 28/50 [00:30<00:22,  1.01s/it]progress:  58%|[34m    [0m| 29/50 [00:30<00:21,  1.01s/it]                                                         Episode 30	 reward: -5.72	 makespan: 566.50	 Mean_loss: 0.08897286,  training time: 1.02
progress:  58%|[34m    [0m| 29/50 [00:31<00:21,  1.01s/it]progress:  60%|[34m    [0m| 30/50 [00:31<00:20,  1.02s/it]                                                         Episode 31	 reward: -5.86	 makespan: 580.00	 Mean_loss: 0.06968991,  training time: 1.01
progress:  60%|[34m    [0m| 30/50 [00:32<00:20,  1.02s/it]progress:  62%|[34m   [0m| 31/50 [00:32<00:19,  1.02s/it]                                                         Episode 32	 reward: -5.90	 makespan: 584.00	 Mean_loss: 0.02582838,  training time: 1.01
progress:  62%|[34m   [0m| 31/50 [00:33<00:19,  1.02s/it]progress:  64%|[34m   [0m| 32/50 [00:33<00:18,  1.01s/it]                                                         Episode 33	 reward: -5.96	 makespan: 590.50	 Mean_loss: 0.03493410,  training time: 1.01
progress:  64%|[34m   [0m| 32/50 [00:34<00:18,  1.01s/it]progress:  66%|[34m   [0m| 33/50 [00:34<00:17,  1.01s/it]                                                         Episode 34	 reward: -5.93	 makespan: 587.50	 Mean_loss: 0.03366226,  training time: 1.08
progress:  66%|[34m   [0m| 33/50 [00:35<00:17,  1.01s/it]progress:  68%|[34m   [0m| 34/50 [00:35<00:16,  1.03s/it]                                                         Episode 35	 reward: -6.10	 makespan: 604.00	 Mean_loss: 0.05118477,  training time: 1.02
progress:  68%|[34m   [0m| 34/50 [00:36<00:16,  1.03s/it]progress:  70%|[34m   [0m| 35/50 [00:36<00:15,  1.03s/it]                                                         Episode 36	 reward: -6.03	 makespan: 596.50	 Mean_loss: 0.06346315,  training time: 1.01
progress:  70%|[34m   [0m| 35/50 [00:38<00:15,  1.03s/it]progress:  72%|[34m  [0m| 36/50 [00:38<00:14,  1.02s/it]                                                         Episode 37	 reward: -5.87	 makespan: 581.25	 Mean_loss: 0.06917571,  training time: 1.04
progress:  72%|[34m  [0m| 36/50 [00:39<00:14,  1.02s/it]progress:  74%|[34m  [0m| 37/50 [00:39<00:13,  1.03s/it]                                                         Episode 38	 reward: -5.82	 makespan: 576.25	 Mean_loss: 0.09083794,  training time: 1.03
progress:  74%|[34m  [0m| 37/50 [00:40<00:13,  1.03s/it]progress:  76%|[34m  [0m| 38/50 [00:40<00:12,  1.03s/it]                                                         Episode 39	 reward: -5.83	 makespan: 577.00	 Mean_loss: 0.04227942,  training time: 1.03
progress:  76%|[34m  [0m| 38/50 [00:41<00:12,  1.03s/it]progress:  78%|[34m  [0m| 39/50 [00:41<00:11,  1.03s/it]                                                         Episode 40	 reward: -5.54	 makespan: 548.75	 Mean_loss: 0.03267338,  training time: 1.04
progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.03s/it]progress:  80%|[34m  [0m| 40/50 [00:42<00:10,  1.03s/it]                                                         Episode 41	 reward: -5.76	 makespan: 570.50	 Mean_loss: 0.03706952,  training time: 1.04
progress:  80%|[34m  [0m| 40/50 [00:43<00:10,  1.03s/it]progress:  82%|[34m [0m| 41/50 [00:43<00:09,  1.04s/it]                                                         Episode 42	 reward: -5.30	 makespan: 524.50	 Mean_loss: 0.03944105,  training time: 1.02
progress:  82%|[34m [0m| 41/50 [00:44<00:09,  1.04s/it]progress:  84%|[34m [0m| 42/50 [00:44<00:08,  1.03s/it]                                                         Episode 43	 reward: -5.50	 makespan: 544.75	 Mean_loss: 0.02681316,  training time: 1.05
progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.03s/it]progress:  86%|[34m [0m| 43/50 [00:45<00:07,  1.04s/it]                                                         Episode 44	 reward: -5.32	 makespan: 526.50	 Mean_loss: 0.01833401,  training time: 1.01
progress:  86%|[34m [0m| 43/50 [00:46<00:07,  1.04s/it]progress:  88%|[34m [0m| 44/50 [00:46<00:06,  1.03s/it]                                                         Episode 45	 reward: -5.44	 makespan: 538.25	 Mean_loss: 0.01560493,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:47<00:06,  1.03s/it]progress:  90%|[34m [0m| 45/50 [00:47<00:05,  1.03s/it]                                                         Episode 46	 reward: -5.58	 makespan: 552.25	 Mean_loss: 0.09326008,  training time: 0.97
progress:  90%|[34m [0m| 45/50 [00:48<00:05,  1.03s/it]progress:  92%|[34m[0m| 46/50 [00:48<00:04,  1.01s/it]                                                         Episode 47	 reward: -5.41	 makespan: 536.00	 Mean_loss: 0.02639663,  training time: 0.97
progress:  92%|[34m[0m| 46/50 [00:49<00:04,  1.01s/it]progress:  94%|[34m[0m| 47/50 [00:49<00:02,  1.00it/s]                                                         Episode 48	 reward: -5.69	 makespan: 563.00	 Mean_loss: 0.02203017,  training time: 1.03
progress:  94%|[34m[0m| 47/50 [00:50<00:02,  1.00it/s]progress:  96%|[34m[0m| 48/50 [00:50<00:02,  1.01s/it]                                                         Episode 49	 reward: -5.48	 makespan: 543.00	 Mean_loss: 0.02711391,  training time: 1.05
progress:  96%|[34m[0m| 48/50 [00:51<00:02,  1.01s/it]progress:  98%|[34m[0m| 49/50 [00:51<00:01,  1.02s/it]                                                         Episode 50	 reward: -5.55	 makespan: 549.00	 Mean_loss: 0.06117346,  training time: 1.00
progress:  98%|[34m[0m| 49/50 [00:52<00:01,  1.02s/it]progress: 100%|[34m[0m| 50/50 [00:52<00:00,  1.02s/it]progress: 100%|[34m[0m| 50/50 [00:52<00:00,  1.05s/it]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob8 --model_suffix exp15_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003 --op_per_job 8
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp15_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.89	 makespan: 880.50	 Mean_loss: 0.61364484,  training time: 2.38
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:56,  2.38s/it]                                                        Episode 2	 reward: -8.85	 makespan: 876.25	 Mean_loss: 0.66301888,  training time: 1.33
progress:   2%|[34m         [0m| 1/50 [00:03<01:56,  2.38s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:24,  1.76s/it]                                                        Episode 3	 reward: -8.40	 makespan: 831.75	 Mean_loss: 0.40780365,  training time: 1.33
progress:   4%|[34m         [0m| 2/50 [00:05<01:24,  1.76s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:13,  1.57s/it]                                                        Episode 4	 reward: -7.86	 makespan: 778.00	 Mean_loss: 0.29567859,  training time: 1.33
progress:   6%|[34m         [0m| 3/50 [00:06<01:13,  1.57s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:07,  1.47s/it]                                                        Episode 5	 reward: -7.79	 makespan: 771.25	 Mean_loss: 0.30350542,  training time: 1.34
progress:   8%|[34m         [0m| 4/50 [00:07<01:07,  1.47s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:04,  1.43s/it]                                                        Episode 6	 reward: -7.25	 makespan: 717.50	 Mean_loss: 0.13232462,  training time: 1.33
progress:  10%|[34m         [0m| 5/50 [00:09<01:04,  1.43s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:01,  1.39s/it]                                                        Episode 7	 reward: -7.83	 makespan: 774.75	 Mean_loss: 0.18417895,  training time: 1.31
progress:  12%|[34m        [0m| 6/50 [00:10<01:01,  1.39s/it]progress:  14%|[34m        [0m| 7/50 [00:10<00:58,  1.37s/it]                                                        Episode 8	 reward: -7.82	 makespan: 773.75	 Mean_loss: 0.19340658,  training time: 1.31
progress:  14%|[34m        [0m| 7/50 [00:11<00:58,  1.37s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:56,  1.35s/it]                                                        Episode 9	 reward: -7.60	 makespan: 752.00	 Mean_loss: 0.14777964,  training time: 1.30
progress:  16%|[34m        [0m| 8/50 [00:12<00:56,  1.35s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:54,  1.33s/it]                                                        Episode 10	 reward: -8.20	 makespan: 811.75	 Mean_loss: 0.15708780,  training time: 1.32
progress:  18%|[34m        [0m| 9/50 [00:14<00:54,  1.33s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:53,  1.33s/it]                                                         Episode 11	 reward: -8.00	 makespan: 791.75	 Mean_loss: 0.18010588,  training time: 1.30
progress:  20%|[34m        [0m| 10/50 [00:15<00:53,  1.33s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:51,  1.32s/it]                                                         Episode 12	 reward: -7.80	 makespan: 771.75	 Mean_loss: 0.10910629,  training time: 1.46
progress:  22%|[34m       [0m| 11/50 [00:17<00:51,  1.32s/it]progress:  24%|[34m       [0m| 12/50 [00:17<00:51,  1.36s/it]                                                         Episode 13	 reward: -8.26	 makespan: 817.25	 Mean_loss: 0.12915896,  training time: 1.31
progress:  24%|[34m       [0m| 12/50 [00:18<00:51,  1.36s/it]progress:  26%|[34m       [0m| 13/50 [00:18<00:49,  1.35s/it]                                                         Episode 14	 reward: -8.04	 makespan: 796.25	 Mean_loss: 0.11979598,  training time: 1.30
progress:  26%|[34m       [0m| 13/50 [00:19<00:49,  1.35s/it]progress:  28%|[34m       [0m| 14/50 [00:19<00:48,  1.33s/it]                                                         Episode 15	 reward: -7.86	 makespan: 778.50	 Mean_loss: 0.12496962,  training time: 1.34
progress:  28%|[34m       [0m| 14/50 [00:20<00:48,  1.33s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:46,  1.34s/it]                                                         Episode 16	 reward: -7.39	 makespan: 731.75	 Mean_loss: 0.10367140,  training time: 1.34
progress:  30%|[34m       [0m| 15/50 [00:22<00:46,  1.34s/it]progress:  32%|[34m      [0m| 16/50 [00:22<00:45,  1.34s/it]                                                         Episode 17	 reward: -7.59	 makespan: 751.25	 Mean_loss: 0.10034260,  training time: 1.29
progress:  32%|[34m      [0m| 16/50 [00:23<00:45,  1.34s/it]progress:  34%|[34m      [0m| 17/50 [00:23<00:43,  1.32s/it]                                                         Episode 18	 reward: -7.52	 makespan: 744.75	 Mean_loss: 0.07691231,  training time: 1.28
progress:  34%|[34m      [0m| 17/50 [00:24<00:43,  1.32s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:41,  1.31s/it]                                                         Episode 19	 reward: -7.64	 makespan: 756.00	 Mean_loss: 0.08004298,  training time: 1.27
progress:  36%|[34m      [0m| 18/50 [00:26<00:41,  1.31s/it]progress:  38%|[34m      [0m| 19/50 [00:26<00:40,  1.30s/it]                                                         Episode 20	 reward: -7.43	 makespan: 735.25	 Mean_loss: 0.09149949,  training time: 1.32
progress:  38%|[34m      [0m| 19/50 [00:27<00:40,  1.30s/it]progress:  40%|[34m      [0m| 20/50 [00:27<00:39,  1.31s/it]                                                         Episode 21	 reward: -7.70	 makespan: 762.25	 Mean_loss: 0.07656429,  training time: 1.32
progress:  40%|[34m      [0m| 20/50 [00:28<00:39,  1.31s/it]progress:  42%|[34m     [0m| 21/50 [00:28<00:37,  1.31s/it]                                                         Episode 22	 reward: -7.01	 makespan: 694.25	 Mean_loss: 0.09256315,  training time: 1.32
progress:  42%|[34m     [0m| 21/50 [00:30<00:37,  1.31s/it]progress:  44%|[34m     [0m| 22/50 [00:30<00:36,  1.31s/it]                                                         Episode 23	 reward: -7.15	 makespan: 707.75	 Mean_loss: 0.06543788,  training time: 1.27
progress:  44%|[34m     [0m| 22/50 [00:31<00:36,  1.31s/it]progress:  46%|[34m     [0m| 23/50 [00:31<00:35,  1.30s/it]                                                         Episode 24	 reward: -7.33	 makespan: 726.00	 Mean_loss: 0.05690774,  training time: 1.27
progress:  46%|[34m     [0m| 23/50 [00:32<00:35,  1.30s/it]progress:  48%|[34m     [0m| 24/50 [00:32<00:33,  1.29s/it]                                                         Episode 25	 reward: -7.51	 makespan: 743.75	 Mean_loss: 0.07391006,  training time: 1.27
progress:  48%|[34m     [0m| 24/50 [00:33<00:33,  1.29s/it]progress:  50%|[34m     [0m| 25/50 [00:33<00:32,  1.29s/it]                                                         Episode 26	 reward: -7.39	 makespan: 731.50	 Mean_loss: 0.08014309,  training time: 1.28
progress:  50%|[34m     [0m| 25/50 [00:35<00:32,  1.29s/it]progress:  52%|[34m    [0m| 26/50 [00:35<00:30,  1.28s/it]                                                         Episode 27	 reward: -7.50	 makespan: 742.50	 Mean_loss: 0.04717182,  training time: 1.32
progress:  52%|[34m    [0m| 26/50 [00:36<00:30,  1.28s/it]progress:  54%|[34m    [0m| 27/50 [00:36<00:29,  1.30s/it]                                                         Episode 28	 reward: -7.28	 makespan: 720.25	 Mean_loss: 0.08431476,  training time: 1.26
progress:  54%|[34m    [0m| 27/50 [00:37<00:29,  1.30s/it]progress:  56%|[34m    [0m| 28/50 [00:37<00:28,  1.29s/it]                                                         Episode 29	 reward: -7.13	 makespan: 705.75	 Mean_loss: 0.06537464,  training time: 1.32
progress:  56%|[34m    [0m| 28/50 [00:39<00:28,  1.29s/it]progress:  58%|[34m    [0m| 29/50 [00:39<00:27,  1.30s/it]                                                         Episode 30	 reward: -7.15	 makespan: 708.25	 Mean_loss: 0.05281432,  training time: 1.39
progress:  58%|[34m    [0m| 29/50 [00:40<00:27,  1.30s/it]progress:  60%|[34m    [0m| 30/50 [00:40<00:26,  1.33s/it]                                                         Episode 31	 reward: -7.14	 makespan: 706.75	 Mean_loss: 0.08111095,  training time: 1.31
progress:  60%|[34m    [0m| 30/50 [00:41<00:26,  1.33s/it]progress:  62%|[34m   [0m| 31/50 [00:41<00:25,  1.32s/it]                                                         Episode 32	 reward: -6.96	 makespan: 689.00	 Mean_loss: 0.06357256,  training time: 1.26
progress:  62%|[34m   [0m| 31/50 [00:43<00:25,  1.32s/it]progress:  64%|[34m   [0m| 32/50 [00:43<00:23,  1.30s/it]                                                         Episode 33	 reward: -7.01	 makespan: 693.50	 Mean_loss: 0.04584822,  training time: 1.28
progress:  64%|[34m   [0m| 32/50 [00:44<00:23,  1.30s/it]progress:  66%|[34m   [0m| 33/50 [00:44<00:22,  1.30s/it]                                                         Episode 34	 reward: -7.04	 makespan: 697.00	 Mean_loss: 0.05448333,  training time: 1.32
progress:  66%|[34m   [0m| 33/50 [00:45<00:22,  1.30s/it]progress:  68%|[34m   [0m| 34/50 [00:45<00:20,  1.30s/it]                                                         Episode 35	 reward: -6.93	 makespan: 686.50	 Mean_loss: 0.03159546,  training time: 1.28
progress:  68%|[34m   [0m| 34/50 [00:46<00:20,  1.30s/it]progress:  70%|[34m   [0m| 35/50 [00:46<00:19,  1.30s/it]                                                         Episode 36	 reward: -6.96	 makespan: 689.25	 Mean_loss: 0.05713436,  training time: 1.29
progress:  70%|[34m   [0m| 35/50 [00:48<00:19,  1.30s/it]progress:  72%|[34m  [0m| 36/50 [00:48<00:18,  1.30s/it]                                                         Episode 37	 reward: -6.89	 makespan: 682.00	 Mean_loss: 0.03337426,  training time: 1.33
progress:  72%|[34m  [0m| 36/50 [00:49<00:18,  1.30s/it]progress:  74%|[34m  [0m| 37/50 [00:49<00:16,  1.30s/it]                                                         Episode 38	 reward: -7.36	 makespan: 728.75	 Mean_loss: 0.05877142,  training time: 1.32
progress:  74%|[34m  [0m| 37/50 [00:50<00:16,  1.30s/it]progress:  76%|[34m  [0m| 38/50 [00:50<00:15,  1.31s/it]                                                         Episode 39	 reward: -7.22	 makespan: 714.50	 Mean_loss: 0.06617515,  training time: 1.32
progress:  76%|[34m  [0m| 38/50 [00:52<00:15,  1.31s/it]progress:  78%|[34m  [0m| 39/50 [00:52<00:14,  1.31s/it]                                                         Episode 40	 reward: -6.93	 makespan: 686.50	 Mean_loss: 0.09793754,  training time: 1.27
progress:  78%|[34m  [0m| 39/50 [00:53<00:14,  1.31s/it]progress:  80%|[34m  [0m| 40/50 [00:53<00:12,  1.30s/it]                                                         Episode 41	 reward: -7.05	 makespan: 697.50	 Mean_loss: 0.07454610,  training time: 1.32
progress:  80%|[34m  [0m| 40/50 [00:54<00:12,  1.30s/it]progress:  82%|[34m [0m| 41/50 [00:54<00:11,  1.31s/it]                                                         Episode 42	 reward: -7.27	 makespan: 719.50	 Mean_loss: 0.07250505,  training time: 1.32
progress:  82%|[34m [0m| 41/50 [00:56<00:11,  1.31s/it]progress:  84%|[34m [0m| 42/50 [00:56<00:10,  1.31s/it]                                                         Episode 43	 reward: -6.69	 makespan: 662.75	 Mean_loss: 0.06844106,  training time: 1.33
progress:  84%|[34m [0m| 42/50 [00:57<00:10,  1.31s/it]progress:  86%|[34m [0m| 43/50 [00:57<00:09,  1.32s/it]                                                         Episode 44	 reward: -6.74	 makespan: 667.25	 Mean_loss: 0.03226773,  training time: 1.32
progress:  86%|[34m [0m| 43/50 [00:58<00:09,  1.32s/it]progress:  88%|[34m [0m| 44/50 [00:58<00:07,  1.32s/it]                                                         Episode 45	 reward: -6.89	 makespan: 682.25	 Mean_loss: 0.05215307,  training time: 1.30
progress:  88%|[34m [0m| 44/50 [01:00<00:07,  1.32s/it]progress:  90%|[34m [0m| 45/50 [01:00<00:06,  1.31s/it]                                                         Episode 46	 reward: -7.19	 makespan: 711.75	 Mean_loss: 0.04089971,  training time: 1.30
progress:  90%|[34m [0m| 45/50 [01:01<00:06,  1.31s/it]progress:  92%|[34m[0m| 46/50 [01:01<00:05,  1.31s/it]                                                         Episode 47	 reward: -7.09	 makespan: 701.50	 Mean_loss: 0.03846713,  training time: 1.32
progress:  92%|[34m[0m| 46/50 [01:02<00:05,  1.31s/it]progress:  94%|[34m[0m| 47/50 [01:02<00:03,  1.31s/it]                                                         Episode 48	 reward: -6.45	 makespan: 638.25	 Mean_loss: 0.04451428,  training time: 1.26
progress:  94%|[34m[0m| 47/50 [01:03<00:03,  1.31s/it]progress:  96%|[34m[0m| 48/50 [01:03<00:02,  1.30s/it]                                                         Episode 49	 reward: -6.83	 makespan: 676.25	 Mean_loss: 0.03826058,  training time: 1.28
progress:  96%|[34m[0m| 48/50 [01:05<00:02,  1.30s/it]progress:  98%|[34m[0m| 49/50 [01:05<00:01,  1.29s/it]                                                         Episode 50	 reward: -6.89	 makespan: 682.25	 Mean_loss: 0.02999221,  training time: 1.30
progress:  98%|[34m[0m| 49/50 [01:06<00:01,  1.29s/it]progress: 100%|[34m[0m| 50/50 [01:06<00:00,  1.30s/it]progress: 100%|[34m[0m| 50/50 [01:06<00:00,  1.33s/it]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob10 --model_suffix exp15_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp15_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -9.67	 makespan: 957.75	 Mean_loss: 0.58387619,  training time: 2.65
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:09,  2.65s/it]                                                        Episode 2	 reward: -9.57	 makespan: 947.00	 Mean_loss: 0.66960001,  training time: 1.59
progress:   2%|[34m         [0m| 1/50 [00:04<02:09,  2.65s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:37,  2.03s/it]                                                        Episode 3	 reward: -9.82	 makespan: 972.25	 Mean_loss: 0.55944508,  training time: 1.59
progress:   4%|[34m         [0m| 2/50 [00:05<01:37,  2.03s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:25,  1.83s/it]                                                        Episode 4	 reward: -10.37	 makespan: 1026.25	 Mean_loss: 0.58497858,  training time: 1.58
progress:   6%|[34m         [0m| 3/50 [00:07<01:25,  1.83s/it]progress:   8%|[34m         [0m| 4/50 [00:07<01:19,  1.73s/it]                                                        Episode 5	 reward: -10.24	 makespan: 1013.50	 Mean_loss: 0.79638284,  training time: 1.56
progress:   8%|[34m         [0m| 4/50 [00:08<01:19,  1.73s/it]progress:  10%|[34m         [0m| 5/50 [00:08<01:15,  1.67s/it]                                                        Episode 6	 reward: -10.62	 makespan: 1051.00	 Mean_loss: 0.56754845,  training time: 1.55
progress:  10%|[34m         [0m| 5/50 [00:10<01:15,  1.67s/it]progress:  12%|[34m        [0m| 6/50 [00:10<01:11,  1.63s/it]                                                        Episode 7	 reward: -10.03	 makespan: 992.50	 Mean_loss: 0.65466017,  training time: 1.56
progress:  12%|[34m        [0m| 6/50 [00:12<01:11,  1.63s/it]progress:  14%|[34m        [0m| 7/50 [00:12<01:09,  1.61s/it]                                                        Episode 8	 reward: -9.87	 makespan: 977.00	 Mean_loss: 0.65586007,  training time: 1.57
progress:  14%|[34m        [0m| 7/50 [00:13<01:09,  1.61s/it]progress:  16%|[34m        [0m| 8/50 [00:13<01:06,  1.59s/it]                                                        Episode 9	 reward: -10.56	 makespan: 1045.00	 Mean_loss: 0.52265930,  training time: 1.57
progress:  16%|[34m        [0m| 8/50 [00:15<01:06,  1.59s/it]progress:  18%|[34m        [0m| 9/50 [00:15<01:05,  1.59s/it]                                                        Episode 10	 reward: -9.37	 makespan: 927.25	 Mean_loss: 0.28050026,  training time: 1.56
progress:  18%|[34m        [0m| 9/50 [00:16<01:05,  1.59s/it]progress:  20%|[34m        [0m| 10/50 [00:16<01:03,  1.58s/it]                                                         Episode 11	 reward: -10.02	 makespan: 991.50	 Mean_loss: 0.28673387,  training time: 1.54
progress:  20%|[34m        [0m| 10/50 [00:18<01:03,  1.58s/it]progress:  22%|[34m       [0m| 11/50 [00:18<01:01,  1.57s/it]                                                         Episode 12	 reward: -10.17	 makespan: 1006.75	 Mean_loss: 0.30975422,  training time: 1.54
progress:  22%|[34m       [0m| 11/50 [00:19<01:01,  1.57s/it]progress:  24%|[34m       [0m| 12/50 [00:19<00:59,  1.56s/it]                                                         Episode 13	 reward: -9.14	 makespan: 905.00	 Mean_loss: 0.30736849,  training time: 1.71
progress:  24%|[34m       [0m| 12/50 [00:21<00:59,  1.56s/it]progress:  26%|[34m       [0m| 13/50 [00:21<00:59,  1.60s/it]                                                         Episode 14	 reward: -10.06	 makespan: 995.50	 Mean_loss: 0.22444537,  training time: 1.54
progress:  26%|[34m       [0m| 13/50 [00:23<00:59,  1.60s/it]progress:  28%|[34m       [0m| 14/50 [00:23<00:57,  1.59s/it]                                                         Episode 15	 reward: -10.21	 makespan: 1010.50	 Mean_loss: 0.25679260,  training time: 1.58
progress:  28%|[34m       [0m| 14/50 [00:24<00:57,  1.59s/it]progress:  30%|[34m       [0m| 15/50 [00:24<00:55,  1.58s/it]                                                         Episode 16	 reward: -9.40	 makespan: 931.00	 Mean_loss: 0.29830426,  training time: 1.59
progress:  30%|[34m       [0m| 15/50 [00:26<00:55,  1.58s/it]progress:  32%|[34m      [0m| 16/50 [00:26<00:53,  1.58s/it]                                                         Episode 17	 reward: -9.43	 makespan: 933.25	 Mean_loss: 0.21070804,  training time: 1.55
progress:  32%|[34m      [0m| 16/50 [00:27<00:53,  1.58s/it]progress:  34%|[34m      [0m| 17/50 [00:27<00:51,  1.57s/it]                                                         Episode 18	 reward: -9.92	 makespan: 982.00	 Mean_loss: 0.26538280,  training time: 1.58
progress:  34%|[34m      [0m| 17/50 [00:29<00:51,  1.57s/it]progress:  36%|[34m      [0m| 18/50 [00:29<00:50,  1.58s/it]                                                         Episode 19	 reward: -9.26	 makespan: 917.00	 Mean_loss: 0.21862268,  training time: 1.58
progress:  36%|[34m      [0m| 18/50 [00:30<00:50,  1.58s/it]progress:  38%|[34m      [0m| 19/50 [00:30<00:48,  1.58s/it]                                                         Episode 20	 reward: -9.28	 makespan: 919.00	 Mean_loss: 0.13288902,  training time: 1.59
progress:  38%|[34m      [0m| 19/50 [00:32<00:48,  1.58s/it]progress:  40%|[34m      [0m| 20/50 [00:32<00:47,  1.58s/it]                                                         Episode 21	 reward: -9.00	 makespan: 890.75	 Mean_loss: 0.13738270,  training time: 1.55
progress:  40%|[34m      [0m| 20/50 [00:34<00:47,  1.58s/it]progress:  42%|[34m     [0m| 21/50 [00:34<00:45,  1.57s/it]                                                         Episode 22	 reward: -9.03	 makespan: 894.00	 Mean_loss: 0.13359620,  training time: 1.56
progress:  42%|[34m     [0m| 21/50 [00:35<00:45,  1.57s/it]progress:  44%|[34m     [0m| 22/50 [00:35<00:43,  1.57s/it]                                                         Episode 23	 reward: -8.97	 makespan: 888.25	 Mean_loss: 0.14161924,  training time: 1.59
progress:  44%|[34m     [0m| 22/50 [00:37<00:43,  1.57s/it]progress:  46%|[34m     [0m| 23/50 [00:37<00:42,  1.57s/it]                                                         Episode 24	 reward: -9.42	 makespan: 932.75	 Mean_loss: 0.15246838,  training time: 1.58
progress:  46%|[34m     [0m| 23/50 [00:38<00:42,  1.57s/it]progress:  48%|[34m     [0m| 24/50 [00:38<00:40,  1.58s/it]                                                         Episode 25	 reward: -8.80	 makespan: 871.25	 Mean_loss: 0.13403398,  training time: 1.58
progress:  48%|[34m     [0m| 24/50 [00:40<00:40,  1.58s/it]progress:  50%|[34m     [0m| 25/50 [00:40<00:39,  1.58s/it]                                                         Episode 26	 reward: -8.87	 makespan: 878.00	 Mean_loss: 0.10372008,  training time: 1.57
progress:  50%|[34m     [0m| 25/50 [00:42<00:39,  1.58s/it]progress:  52%|[34m    [0m| 26/50 [00:42<00:37,  1.58s/it]                                                         Episode 27	 reward: -8.88	 makespan: 879.00	 Mean_loss: 0.14825365,  training time: 1.59
progress:  52%|[34m    [0m| 26/50 [00:43<00:37,  1.58s/it]progress:  54%|[34m    [0m| 27/50 [00:43<00:36,  1.58s/it]                                                         Episode 28	 reward: -8.72	 makespan: 863.00	 Mean_loss: 0.07723099,  training time: 1.58
progress:  54%|[34m    [0m| 27/50 [00:45<00:36,  1.58s/it]progress:  56%|[34m    [0m| 28/50 [00:45<00:34,  1.58s/it]                                                         Episode 29	 reward: -8.46	 makespan: 837.75	 Mean_loss: 0.08641991,  training time: 1.57
progress:  56%|[34m    [0m| 28/50 [00:46<00:34,  1.58s/it]progress:  58%|[34m    [0m| 29/50 [00:46<00:33,  1.58s/it]                                                         Episode 30	 reward: -8.90	 makespan: 881.00	 Mean_loss: 0.07697209,  training time: 1.58
progress:  58%|[34m    [0m| 29/50 [00:48<00:33,  1.58s/it]progress:  60%|[34m    [0m| 30/50 [00:48<00:31,  1.58s/it]                                                         Episode 31	 reward: -8.18	 makespan: 810.25	 Mean_loss: 0.10573798,  training time: 1.57
progress:  60%|[34m    [0m| 30/50 [00:49<00:31,  1.58s/it]progress:  62%|[34m   [0m| 31/50 [00:49<00:29,  1.58s/it]                                                         Episode 32	 reward: -8.49	 makespan: 840.75	 Mean_loss: 0.05528386,  training time: 1.58
progress:  62%|[34m   [0m| 31/50 [00:51<00:29,  1.58s/it]progress:  64%|[34m   [0m| 32/50 [00:51<00:28,  1.58s/it]                                                         Episode 33	 reward: -7.94	 makespan: 785.75	 Mean_loss: 0.08092871,  training time: 1.57
progress:  64%|[34m   [0m| 32/50 [00:53<00:28,  1.58s/it]progress:  66%|[34m   [0m| 33/50 [00:53<00:26,  1.58s/it]                                                         Episode 34	 reward: -8.47	 makespan: 838.25	 Mean_loss: 0.09306317,  training time: 1.57
progress:  66%|[34m   [0m| 33/50 [00:54<00:26,  1.58s/it]progress:  68%|[34m   [0m| 34/50 [00:54<00:25,  1.57s/it]                                                         Episode 35	 reward: -9.54	 makespan: 944.00	 Mean_loss: 0.13309494,  training time: 1.59
progress:  68%|[34m   [0m| 34/50 [00:56<00:25,  1.57s/it]progress:  70%|[34m   [0m| 35/50 [00:56<00:23,  1.58s/it]                                                         Episode 36	 reward: -8.98	 makespan: 888.75	 Mean_loss: 0.20643786,  training time: 1.57
progress:  70%|[34m   [0m| 35/50 [00:57<00:23,  1.58s/it]progress:  72%|[34m  [0m| 36/50 [00:57<00:22,  1.58s/it]                                                         Episode 37	 reward: -8.73	 makespan: 864.00	 Mean_loss: 0.11064000,  training time: 1.55
progress:  72%|[34m  [0m| 36/50 [00:59<00:22,  1.58s/it]progress:  74%|[34m  [0m| 37/50 [00:59<00:20,  1.57s/it]                                                         Episode 38	 reward: -9.22	 makespan: 912.75	 Mean_loss: 0.19091961,  training time: 1.53
progress:  74%|[34m  [0m| 37/50 [01:00<00:20,  1.57s/it]progress:  76%|[34m  [0m| 38/50 [01:00<00:18,  1.56s/it]                                                         Episode 39	 reward: -8.94	 makespan: 885.50	 Mean_loss: 0.08324191,  training time: 1.55
progress:  76%|[34m  [0m| 38/50 [01:02<00:18,  1.56s/it]progress:  78%|[34m  [0m| 39/50 [01:02<00:17,  1.55s/it]                                                         Episode 40	 reward: -8.33	 makespan: 824.50	 Mean_loss: 0.09072085,  training time: 1.53
progress:  78%|[34m  [0m| 39/50 [01:03<00:17,  1.55s/it]progress:  80%|[34m  [0m| 40/50 [01:03<00:15,  1.55s/it]                                                         Episode 41	 reward: -8.88	 makespan: 879.00	 Mean_loss: 0.11897705,  training time: 1.54
progress:  80%|[34m  [0m| 40/50 [01:05<00:15,  1.55s/it]progress:  82%|[34m [0m| 41/50 [01:05<00:13,  1.55s/it]                                                         Episode 42	 reward: -9.08	 makespan: 898.50	 Mean_loss: 0.10205434,  training time: 1.54
progress:  82%|[34m [0m| 41/50 [01:07<00:13,  1.55s/it]progress:  84%|[34m [0m| 42/50 [01:07<00:12,  1.55s/it]                                                         Episode 43	 reward: -8.56	 makespan: 847.75	 Mean_loss: 0.08974735,  training time: 1.55
progress:  84%|[34m [0m| 42/50 [01:08<00:12,  1.55s/it]progress:  86%|[34m [0m| 43/50 [01:08<00:10,  1.55s/it]                                                         Episode 44	 reward: -9.03	 makespan: 894.00	 Mean_loss: 0.06425184,  training time: 1.52
progress:  86%|[34m [0m| 43/50 [01:10<00:10,  1.55s/it]progress:  88%|[34m [0m| 44/50 [01:10<00:09,  1.54s/it]                                                         Episode 45	 reward: -8.47	 makespan: 838.50	 Mean_loss: 0.06880312,  training time: 1.53
progress:  88%|[34m [0m| 44/50 [01:11<00:09,  1.54s/it]progress:  90%|[34m [0m| 45/50 [01:11<00:07,  1.54s/it]                                                         Episode 46	 reward: -9.19	 makespan: 909.75	 Mean_loss: 0.07947638,  training time: 1.54
progress:  90%|[34m [0m| 45/50 [01:13<00:07,  1.54s/it]progress:  92%|[34m[0m| 46/50 [01:13<00:06,  1.54s/it]                                                         Episode 47	 reward: -8.81	 makespan: 872.50	 Mean_loss: 0.06609770,  training time: 1.58
progress:  92%|[34m[0m| 46/50 [01:14<00:06,  1.54s/it]progress:  94%|[34m[0m| 47/50 [01:14<00:04,  1.55s/it]                                                         Episode 48	 reward: -8.76	 makespan: 867.50	 Mean_loss: 0.04812916,  training time: 1.54
progress:  94%|[34m[0m| 47/50 [01:16<00:04,  1.55s/it]progress:  96%|[34m[0m| 48/50 [01:16<00:03,  1.55s/it]                                                         Episode 49	 reward: -8.47	 makespan: 838.75	 Mean_loss: 0.08997752,  training time: 1.52
progress:  96%|[34m[0m| 48/50 [01:17<00:03,  1.55s/it]progress:  98%|[34m[0m| 49/50 [01:17<00:01,  1.54s/it]                                                         Episode 50	 reward: -8.51	 makespan: 842.50	 Mean_loss: 0.05067499,  training time: 1.54
progress:  98%|[34m[0m| 49/50 [01:19<00:01,  1.54s/it]progress: 100%|[34m[0m| 50/50 [01:19<00:00,  1.54s/it]progress: 100%|[34m[0m| 50/50 [01:19<00:00,  1.59s/it]
+ for op_per_job in '"${options[@]}"'
+ python train/DAN_finetuning.py --logdir ./runs/exp15/maml_finetuning/transfermaml+exp15_1000_64_3/operjob12 --model_suffix exp15_maml+exp15_1000_64_3_15x5 --finetuning_model maml+exp15_1000_64_3 --max_updates 50 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  10x5+mix+exp15_maml+exp15_1000_64_3_15x5
./trained_network/SD2/maml+exp15_1000_64_3.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp15_1000_64_3.pth
vali data :./data/data_train_vali/SD2/10x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -11.60	 makespan: 1148.75	 Mean_loss: 0.63804829,  training time: 2.92
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:23,  2.92s/it]                                                        Episode 2	 reward: -11.95	 makespan: 1183.00	 Mean_loss: 0.84645963,  training time: 1.85
progress:   2%|[34m         [0m| 1/50 [00:04<02:23,  2.92s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:49,  2.29s/it]                                                        Episode 3	 reward: -12.48	 makespan: 1236.00	 Mean_loss: 0.96878058,  training time: 1.88
progress:   4%|[34m         [0m| 2/50 [00:06<01:49,  2.29s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:38,  2.10s/it]                                                        Episode 4	 reward: -11.16	 makespan: 1105.00	 Mean_loss: 1.12400138,  training time: 1.85
progress:   6%|[34m         [0m| 3/50 [00:08<01:38,  2.10s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:32,  2.01s/it]                                                        Episode 5	 reward: -11.77	 makespan: 1165.25	 Mean_loss: 0.79053199,  training time: 1.86
progress:   8%|[34m         [0m| 4/50 [00:10<01:32,  2.01s/it]progress:  10%|[34m         [0m| 5/50 [00:10<01:27,  1.95s/it]                                                        Episode 6	 reward: -11.30	 makespan: 1118.75	 Mean_loss: 0.61421841,  training time: 1.87
progress:  10%|[34m         [0m| 5/50 [00:12<01:27,  1.95s/it]progress:  12%|[34m        [0m| 6/50 [00:12<01:24,  1.93s/it]                                                        Episode 7	 reward: -11.41	 makespan: 1130.00	 Mean_loss: 0.60899001,  training time: 1.87
progress:  12%|[34m        [0m| 6/50 [00:14<01:24,  1.93s/it]progress:  14%|[34m        [0m| 7/50 [00:14<01:22,  1.91s/it]                                                        Episode 8	 reward: -11.64	 makespan: 1152.75	 Mean_loss: 0.63577074,  training time: 1.87
progress:  14%|[34m        [0m| 7/50 [00:15<01:22,  1.91s/it]progress:  16%|[34m        [0m| 8/50 [00:15<01:19,  1.90s/it]                                                        Episode 9	 reward: -11.23	 makespan: 1111.50	 Mean_loss: 0.48101938,  training time: 1.86
progress:  16%|[34m        [0m| 8/50 [00:17<01:19,  1.90s/it]progress:  18%|[34m        [0m| 9/50 [00:17<01:17,  1.89s/it]                                                        Episode 10	 reward: -12.23	 makespan: 1211.25	 Mean_loss: 0.67225313,  training time: 1.88
progress:  18%|[34m        [0m| 9/50 [00:19<01:17,  1.89s/it]progress:  20%|[34m        [0m| 10/50 [00:19<01:15,  1.89s/it]                                                         Episode 11	 reward: -11.20	 makespan: 1108.50	 Mean_loss: 0.39636344,  training time: 1.85
progress:  20%|[34m        [0m| 10/50 [00:21<01:15,  1.89s/it]progress:  22%|[34m       [0m| 11/50 [00:21<01:13,  1.88s/it]                                                         Episode 12	 reward: -11.76	 makespan: 1164.50	 Mean_loss: 0.46570629,  training time: 2.02
progress:  22%|[34m       [0m| 11/50 [00:23<01:13,  1.88s/it]progress:  24%|[34m       [0m| 12/50 [00:23<01:13,  1.92s/it]                                                         Episode 13	 reward: -11.44	 makespan: 1132.75	 Mean_loss: 0.28660780,  training time: 1.86
progress:  24%|[34m       [0m| 12/50 [00:25<01:13,  1.92s/it]progress:  26%|[34m       [0m| 13/50 [00:25<01:10,  1.90s/it]                                                         Episode 14	 reward: -10.84	 makespan: 1073.50	 Mean_loss: 0.28142601,  training time: 1.88
progress:  26%|[34m       [0m| 13/50 [00:27<01:10,  1.90s/it]progress:  28%|[34m       [0m| 14/50 [00:27<01:08,  1.90s/it]                                                         Episode 15	 reward: -10.66	 makespan: 1055.00	 Mean_loss: 0.22101022,  training time: 1.87
progress:  28%|[34m       [0m| 14/50 [00:29<01:08,  1.90s/it]progress:  30%|[34m       [0m| 15/50 [00:29<01:06,  1.89s/it]                                                         Episode 16	 reward: -11.39	 makespan: 1128.00	 Mean_loss: 0.17711402,  training time: 1.89
progress:  30%|[34m       [0m| 15/50 [00:31<01:06,  1.89s/it]progress:  32%|[34m      [0m| 16/50 [00:31<01:04,  1.89s/it]                                                         Episode 17	 reward: -11.16	 makespan: 1104.50	 Mean_loss: 0.17001610,  training time: 1.86
progress:  32%|[34m      [0m| 16/50 [00:32<01:04,  1.89s/it]progress:  34%|[34m      [0m| 17/50 [00:32<01:02,  1.88s/it]                                                         Episode 18	 reward: -11.37	 makespan: 1125.50	 Mean_loss: 0.23726514,  training time: 1.86
progress:  34%|[34m      [0m| 17/50 [00:34<01:02,  1.88s/it]progress:  36%|[34m      [0m| 18/50 [00:34<00:59,  1.87s/it]                                                         Episode 19	 reward: -11.04	 makespan: 1092.75	 Mean_loss: 0.21579790,  training time: 1.88
progress:  36%|[34m      [0m| 18/50 [00:36<00:59,  1.87s/it]progress:  38%|[34m      [0m| 19/50 [00:36<00:58,  1.88s/it]                                                         Episode 20	 reward: -11.60	 makespan: 1148.00	 Mean_loss: 0.22623393,  training time: 1.86
progress:  38%|[34m      [0m| 19/50 [00:38<00:58,  1.88s/it]progress:  40%|[34m      [0m| 20/50 [00:38<00:56,  1.87s/it]                                                         Episode 21	 reward: -11.06	 makespan: 1095.00	 Mean_loss: 0.14932652,  training time: 1.85
progress:  40%|[34m      [0m| 20/50 [00:40<00:56,  1.87s/it]progress:  42%|[34m     [0m| 21/50 [00:40<00:54,  1.87s/it]                                                         Episode 22	 reward: -10.81	 makespan: 1070.25	 Mean_loss: 0.17077965,  training time: 1.87
progress:  42%|[34m     [0m| 21/50 [00:42<00:54,  1.87s/it]progress:  44%|[34m     [0m| 22/50 [00:42<00:52,  1.87s/it]                                                         Episode 23	 reward: -11.34	 makespan: 1122.25	 Mean_loss: 0.16532031,  training time: 1.87
progress:  44%|[34m     [0m| 22/50 [00:44<00:52,  1.87s/it]progress:  46%|[34m     [0m| 23/50 [00:44<00:50,  1.87s/it]                                                         Episode 24	 reward: -10.97	 makespan: 1086.00	 Mean_loss: 0.16206977,  training time: 1.84
progress:  46%|[34m     [0m| 23/50 [00:46<00:50,  1.87s/it]progress:  48%|[34m     [0m| 24/50 [00:46<00:48,  1.86s/it]                                                         Episode 25	 reward: -10.28	 makespan: 1017.25	 Mean_loss: 0.11104266,  training time: 1.86
progress:  48%|[34m     [0m| 24/50 [00:47<00:48,  1.86s/it]progress:  50%|[34m     [0m| 25/50 [00:47<00:46,  1.86s/it]                                                         Episode 26	 reward: -10.17	 makespan: 1007.25	 Mean_loss: 0.19102302,  training time: 1.86
progress:  50%|[34m     [0m| 25/50 [00:49<00:46,  1.86s/it]progress:  52%|[34m    [0m| 26/50 [00:49<00:44,  1.86s/it]                                                         Episode 27	 reward: -10.62	 makespan: 1051.50	 Mean_loss: 0.09832960,  training time: 1.84
progress:  52%|[34m    [0m| 26/50 [00:51<00:44,  1.86s/it]progress:  54%|[34m    [0m| 27/50 [00:51<00:42,  1.85s/it]                                                         Episode 28	 reward: -10.52	 makespan: 1041.00	 Mean_loss: 0.13844672,  training time: 1.84
progress:  54%|[34m    [0m| 27/50 [00:53<00:42,  1.85s/it]progress:  56%|[34m    [0m| 28/50 [00:53<00:40,  1.85s/it]                                                         Episode 29	 reward: -10.70	 makespan: 1059.00	 Mean_loss: 0.10070188,  training time: 1.86
progress:  56%|[34m    [0m| 28/50 [00:55<00:40,  1.85s/it]progress:  58%|[34m    [0m| 29/50 [00:55<00:38,  1.85s/it]                                                         Episode 30	 reward: -10.56	 makespan: 1045.25	 Mean_loss: 0.14094570,  training time: 1.86
progress:  58%|[34m    [0m| 29/50 [00:57<00:38,  1.85s/it]progress:  60%|[34m    [0m| 30/50 [00:57<00:37,  1.86s/it]                                                         Episode 31	 reward: -10.47	 makespan: 1037.00	 Mean_loss: 0.16015354,  training time: 1.89
progress:  60%|[34m    [0m| 30/50 [00:59<00:37,  1.86s/it]progress:  62%|[34m   [0m| 31/50 [00:59<00:35,  1.87s/it]                                                         Episode 32	 reward: -10.71	 makespan: 1060.75	 Mean_loss: 0.09147610,  training time: 1.86
progress:  62%|[34m   [0m| 31/50 [01:00<00:35,  1.87s/it]progress:  64%|[34m   [0m| 32/50 [01:00<00:33,  1.87s/it]                                                         Episode 33	 reward: -10.44	 makespan: 1033.25	 Mean_loss: 0.15030891,  training time: 1.85
progress:  64%|[34m   [0m| 32/50 [01:02<00:33,  1.87s/it]progress:  66%|[34m   [0m| 33/50 [01:02<00:31,  1.86s/it]                                                         Episode 34	 reward: -10.37	 makespan: 1026.75	 Mean_loss: 0.10029949,  training time: 1.83
progress:  66%|[34m   [0m| 33/50 [01:04<00:31,  1.86s/it]progress:  68%|[34m   [0m| 34/50 [01:04<00:29,  1.85s/it]                                                         Episode 35	 reward: -10.80	 makespan: 1069.50	 Mean_loss: 0.10111272,  training time: 1.85
progress:  68%|[34m   [0m| 34/50 [01:06<00:29,  1.85s/it]progress:  70%|[34m   [0m| 35/50 [01:06<00:27,  1.85s/it]                                                         Episode 36	 reward: -10.53	 makespan: 1042.00	 Mean_loss: 0.07589729,  training time: 1.83
progress:  70%|[34m   [0m| 35/50 [01:08<00:27,  1.85s/it]progress:  72%|[34m  [0m| 36/50 [01:08<00:25,  1.84s/it]                                                         Episode 37	 reward: -10.48	 makespan: 1037.75	 Mean_loss: 0.08421920,  training time: 1.86
progress:  72%|[34m  [0m| 36/50 [01:10<00:25,  1.84s/it]progress:  74%|[34m  [0m| 37/50 [01:10<00:24,  1.85s/it]                                                         Episode 38	 reward: -10.00	 makespan: 990.25	 Mean_loss: 0.07263841,  training time: 1.88
progress:  74%|[34m  [0m| 37/50 [01:11<00:24,  1.85s/it]progress:  76%|[34m  [0m| 38/50 [01:11<00:22,  1.86s/it]                                                         Episode 39	 reward: -10.05	 makespan: 994.50	 Mean_loss: 0.06389543,  training time: 1.85
progress:  76%|[34m  [0m| 38/50 [01:13<00:22,  1.86s/it]progress:  78%|[34m  [0m| 39/50 [01:13<00:20,  1.86s/it]                                                         Episode 40	 reward: -10.44	 makespan: 1033.50	 Mean_loss: 0.08719338,  training time: 1.86
progress:  78%|[34m  [0m| 39/50 [01:15<00:20,  1.86s/it]progress:  80%|[34m  [0m| 40/50 [01:15<00:18,  1.86s/it]                                                         Episode 41	 reward: -9.91	 makespan: 980.75	 Mean_loss: 0.08742075,  training time: 1.86
progress:  80%|[34m  [0m| 40/50 [01:17<00:18,  1.86s/it]progress:  82%|[34m [0m| 41/50 [01:17<00:16,  1.86s/it]                                                         Episode 42	 reward: -9.91	 makespan: 980.75	 Mean_loss: 0.09601817,  training time: 1.84
progress:  82%|[34m [0m| 41/50 [01:19<00:16,  1.86s/it]progress:  84%|[34m [0m| 42/50 [01:19<00:14,  1.85s/it]                                                         Episode 43	 reward: -10.24	 makespan: 1014.25	 Mean_loss: 0.08517693,  training time: 1.83
progress:  84%|[34m [0m| 42/50 [01:21<00:14,  1.85s/it]progress:  86%|[34m [0m| 43/50 [01:21<00:12,  1.85s/it]                                                         Episode 44	 reward: -9.99	 makespan: 989.50	 Mean_loss: 0.06158029,  training time: 1.87
progress:  86%|[34m [0m| 43/50 [01:23<00:12,  1.85s/it]progress:  88%|[34m [0m| 44/50 [01:23<00:11,  1.85s/it]                                                         Episode 45	 reward: -9.84	 makespan: 974.00	 Mean_loss: 0.08881705,  training time: 1.85
progress:  88%|[34m [0m| 44/50 [01:24<00:11,  1.85s/it]progress:  90%|[34m [0m| 45/50 [01:24<00:09,  1.85s/it]                                                         Episode 46	 reward: -9.87	 makespan: 977.25	 Mean_loss: 0.07946995,  training time: 1.82
progress:  90%|[34m [0m| 45/50 [01:26<00:09,  1.85s/it]progress:  92%|[34m[0m| 46/50 [01:26<00:07,  1.84s/it]                                                         Episode 47	 reward: -10.12	 makespan: 1001.75	 Mean_loss: 0.13409020,  training time: 1.88
progress:  92%|[34m[0m| 46/50 [01:28<00:07,  1.84s/it]progress:  94%|[34m[0m| 47/50 [01:28<00:05,  1.85s/it]                                                         Episode 48	 reward: -10.39	 makespan: 1029.00	 Mean_loss: 0.13857357,  training time: 1.84
progress:  94%|[34m[0m| 47/50 [01:30<00:05,  1.85s/it]progress:  96%|[34m[0m| 48/50 [01:30<00:03,  1.85s/it]                                                         Episode 49	 reward: -9.90	 makespan: 979.75	 Mean_loss: 0.06793080,  training time: 1.85
progress:  96%|[34m[0m| 48/50 [01:32<00:03,  1.85s/it]progress:  98%|[34m[0m| 49/50 [01:32<00:01,  1.85s/it]                                                         Episode 50	 reward: -9.81	 makespan: 971.00	 Mean_loss: 0.07524553,  training time: 1.87
progress:  98%|[34m[0m| 49/50 [01:34<00:01,  1.85s/it]progress: 100%|[34m[0m| 50/50 [01:34<00:00,  1.86s/it]progress: 100%|[34m[0m| 50/50 [01:34<00:00,  1.88s/it]

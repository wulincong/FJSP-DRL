+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 61105 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ TEST_DIR=./test_script
+ exp=exp15
+ echo exp15
exp15
+ cat
op_per_job+MAML
DAN.pyop_per_job_options,baseline
 
MAML
MAML

+ op_per_job_options='4 6 8 10 12'
+ logdir=./runs/exp15
+ hidden_dim_actor=64
+ hidden_dim_critic=64
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ n_j=15
+ n_m=5
+ data_source=SD2
+ logdir_dan=./runs/exp15/DAN
+ options=($op_per_job_options)
+ max_updates_finetune=50
+ lr=0.003
+ first_model_name=15x5+mix+SD2_operjob4
+ last_model_name=15x5+mix+SD2_operjob12
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]4.0
4.0
4.0
4.0
                                                Episode 1	 reward: -6.02	 makespan: 596.25	 Mean_loss: 0.17205724,  training time: 5.24
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:17,  5.25s/it]                                                        Episode 2	 reward: -5.54	 makespan: 548.50	 Mean_loss: 0.13062888,  training time: 1.07
progress:   2%|[34m         [0m| 1/50 [00:06<04:17,  5.25s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:14,  2.81s/it]                                                        Episode 3	 reward: -6.01	 makespan: 594.50	 Mean_loss: 0.16776052,  training time: 1.10
progress:   4%|[34m         [0m| 2/50 [00:07<02:14,  2.81s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:35,  2.03s/it]                                                        Episode 4	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.06164024,  training time: 1.12
progress:   6%|[34m         [0m| 3/50 [00:08<01:35,  2.03s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:16,  1.67s/it]                                                        Episode 5	 reward: -5.90	 makespan: 584.50	 Mean_loss: 0.11240564,  training time: 1.06
progress:   8%|[34m         [0m| 4/50 [00:09<01:16,  1.67s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:05,  1.45s/it]                                                        Episode 6	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.09120351,  training time: 1.10
progress:  10%|[34m         [0m| 5/50 [00:10<01:05,  1.45s/it]progress:  12%|[34m        [0m| 6/50 [00:10<00:58,  1.33s/it]                                                        Episode 7	 reward: -5.27	 makespan: 522.00	 Mean_loss: 0.05723163,  training time: 1.09
progress:  12%|[34m        [0m| 6/50 [00:11<00:58,  1.33s/it]progress:  14%|[34m        [0m| 7/50 [00:11<00:53,  1.25s/it]                                                        Episode 8	 reward: -5.66	 makespan: 560.25	 Mean_loss: 0.04413353,  training time: 1.07
progress:  14%|[34m        [0m| 7/50 [00:12<00:53,  1.25s/it]progress:  16%|[34m        [0m| 8/50 [00:12<00:50,  1.19s/it]                                                        Episode 9	 reward: -5.63	 makespan: 557.00	 Mean_loss: 0.04919597,  training time: 1.04
progress:  16%|[34m        [0m| 8/50 [00:13<00:50,  1.19s/it]progress:  18%|[34m        [0m| 9/50 [00:13<00:47,  1.15s/it]                                                        Episode 10	 reward: -6.15	 makespan: 608.75	 Mean_loss: 0.08049262,  training time: 1.02
progress:  18%|[34m        [0m| 9/50 [00:14<00:47,  1.15s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:44,  1.11s/it]                                                         Episode 11	 reward: -5.63	 makespan: 557.50	 Mean_loss: 0.05345550,  training time: 1.09
progress:  20%|[34m        [0m| 10/50 [00:16<00:44,  1.11s/it]progress:  22%|[34m       [0m| 11/50 [00:16<00:43,  1.11s/it]                                                         Episode 12	 reward: -5.39	 makespan: 534.00	 Mean_loss: 0.05932495,  training time: 2.39
progress:  22%|[34m       [0m| 11/50 [00:18<00:43,  1.11s/it]progress:  24%|[34m       [0m| 12/50 [00:18<00:56,  1.50s/it]                                                         Episode 13	 reward: -5.50	 makespan: 544.75	 Mean_loss: 0.09443978,  training time: 1.05
progress:  24%|[34m       [0m| 12/50 [00:19<00:56,  1.50s/it]progress:  26%|[34m       [0m| 13/50 [00:19<00:50,  1.36s/it]                                                         Episode 14	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.09046520,  training time: 1.09
progress:  26%|[34m       [0m| 13/50 [00:20<00:50,  1.36s/it]progress:  28%|[34m       [0m| 14/50 [00:20<00:46,  1.28s/it]                                                         Episode 15	 reward: -5.85	 makespan: 578.75	 Mean_loss: 0.13103028,  training time: 1.06
progress:  28%|[34m       [0m| 14/50 [00:21<00:46,  1.28s/it]progress:  30%|[34m       [0m| 15/50 [00:21<00:42,  1.22s/it]                                                         Episode 16	 reward: -5.61	 makespan: 555.50	 Mean_loss: 0.04712956,  training time: 1.05
progress:  30%|[34m       [0m| 15/50 [00:22<00:42,  1.22s/it]progress:  32%|[34m      [0m| 16/50 [00:22<00:39,  1.17s/it]                                                         Episode 17	 reward: -5.33	 makespan: 527.25	 Mean_loss: 0.06680810,  training time: 1.07
progress:  32%|[34m      [0m| 16/50 [00:23<00:39,  1.17s/it]progress:  34%|[34m      [0m| 17/50 [00:23<00:37,  1.14s/it]                                                         Episode 18	 reward: -5.29	 makespan: 523.25	 Mean_loss: 0.03370211,  training time: 1.13
progress:  34%|[34m      [0m| 17/50 [00:24<00:37,  1.14s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:36,  1.14s/it]                                                         Episode 19	 reward: -5.42	 makespan: 536.50	 Mean_loss: 0.05554204,  training time: 1.12
progress:  36%|[34m      [0m| 18/50 [00:26<00:36,  1.14s/it]progress:  38%|[34m      [0m| 19/50 [00:26<00:35,  1.13s/it]                                                         Episode 20	 reward: -5.49	 makespan: 543.75	 Mean_loss: 0.05584563,  training time: 1.05
progress:  38%|[34m      [0m| 19/50 [00:27<00:35,  1.13s/it]progress:  40%|[34m      [0m| 20/50 [00:27<00:33,  1.11s/it]                                                         Episode 21	 reward: -5.26	 makespan: 520.25	 Mean_loss: 0.03132141,  training time: 1.08
progress:  40%|[34m      [0m| 20/50 [00:28<00:33,  1.11s/it]progress:  42%|[34m     [0m| 21/50 [00:28<00:31,  1.10s/it]                                                         Episode 22	 reward: -5.59	 makespan: 553.00	 Mean_loss: 0.03794253,  training time: 1.09
progress:  42%|[34m     [0m| 21/50 [00:29<00:31,  1.10s/it]progress:  44%|[34m     [0m| 22/50 [00:29<00:30,  1.10s/it]                                                         Episode 23	 reward: -5.27	 makespan: 521.50	 Mean_loss: 0.09618896,  training time: 1.07
progress:  44%|[34m     [0m| 22/50 [00:30<00:30,  1.10s/it]progress:  46%|[34m     [0m| 23/50 [00:30<00:29,  1.09s/it]                                                         Episode 24	 reward: -5.54	 makespan: 548.75	 Mean_loss: 0.08793078,  training time: 1.08
progress:  46%|[34m     [0m| 23/50 [00:31<00:29,  1.09s/it]progress:  48%|[34m     [0m| 24/50 [00:31<00:28,  1.09s/it]                                                         Episode 25	 reward: -5.58	 makespan: 552.00	 Mean_loss: 0.06011203,  training time: 1.06
progress:  48%|[34m     [0m| 24/50 [00:32<00:28,  1.09s/it]progress:  50%|[34m     [0m| 25/50 [00:32<00:27,  1.08s/it]                                                         Episode 26	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.05850246,  training time: 1.08
progress:  50%|[34m     [0m| 25/50 [00:33<00:27,  1.08s/it]progress:  52%|[34m    [0m| 26/50 [00:33<00:25,  1.08s/it]                                                         Episode 27	 reward: -6.09	 makespan: 602.50	 Mean_loss: 0.14792521,  training time: 1.12
progress:  52%|[34m    [0m| 26/50 [00:34<00:25,  1.08s/it]progress:  54%|[34m    [0m| 27/50 [00:34<00:25,  1.09s/it]                                                         Episode 28	 reward: -5.45	 makespan: 539.50	 Mean_loss: 0.10249288,  training time: 1.08
progress:  54%|[34m    [0m| 27/50 [00:35<00:25,  1.09s/it]progress:  56%|[34m    [0m| 28/50 [00:35<00:23,  1.09s/it]                                                         Episode 29	 reward: -5.74	 makespan: 568.75	 Mean_loss: 0.06624703,  training time: 1.07
progress:  56%|[34m    [0m| 28/50 [00:36<00:23,  1.09s/it]progress:  58%|[34m    [0m| 29/50 [00:36<00:22,  1.08s/it]                                                         Episode 30	 reward: -5.76	 makespan: 570.00	 Mean_loss: 0.06625570,  training time: 1.07
progress:  58%|[34m    [0m| 29/50 [00:37<00:22,  1.08s/it]progress:  60%|[34m    [0m| 30/50 [00:37<00:21,  1.08s/it]                                                         Episode 31	 reward: -5.73	 makespan: 567.00	 Mean_loss: 0.07812956,  training time: 1.07
progress:  60%|[34m    [0m| 30/50 [00:38<00:21,  1.08s/it]progress:  62%|[34m   [0m| 31/50 [00:38<00:20,  1.08s/it]                                                         Episode 32	 reward: -5.59	 makespan: 553.50	 Mean_loss: 0.05929932,  training time: 1.05
progress:  62%|[34m   [0m| 31/50 [00:40<00:20,  1.08s/it]progress:  64%|[34m   [0m| 32/50 [00:40<00:19,  1.07s/it]                                                         Episode 33	 reward: -5.72	 makespan: 566.75	 Mean_loss: 0.07690233,  training time: 1.06
progress:  64%|[34m   [0m| 32/50 [00:41<00:19,  1.07s/it]progress:  66%|[34m   [0m| 33/50 [00:41<00:18,  1.07s/it]                                                         Episode 34	 reward: -5.84	 makespan: 578.50	 Mean_loss: 0.04414837,  training time: 1.05
progress:  66%|[34m   [0m| 33/50 [00:42<00:18,  1.07s/it]progress:  68%|[34m   [0m| 34/50 [00:42<00:17,  1.06s/it]                                                         Episode 35	 reward: -6.15	 makespan: 608.50	 Mean_loss: 0.11838974,  training time: 1.05
progress:  68%|[34m   [0m| 34/50 [00:43<00:17,  1.06s/it]progress:  70%|[34m   [0m| 35/50 [00:43<00:15,  1.06s/it]                                                         Episode 36	 reward: -5.92	 makespan: 586.00	 Mean_loss: 0.07431645,  training time: 1.07
progress:  70%|[34m   [0m| 35/50 [00:44<00:15,  1.06s/it]progress:  72%|[34m  [0m| 36/50 [00:44<00:14,  1.06s/it]                                                         Episode 37	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.07301570,  training time: 1.06
progress:  72%|[34m  [0m| 36/50 [00:45<00:14,  1.06s/it]progress:  74%|[34m  [0m| 37/50 [00:45<00:13,  1.06s/it]                                                         Episode 38	 reward: -5.71	 makespan: 565.75	 Mean_loss: 0.03973913,  training time: 1.05
progress:  74%|[34m  [0m| 37/50 [00:46<00:13,  1.06s/it]progress:  76%|[34m  [0m| 38/50 [00:46<00:12,  1.06s/it]                                                         Episode 39	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.05181265,  training time: 1.05
progress:  76%|[34m  [0m| 38/50 [00:47<00:12,  1.06s/it]progress:  78%|[34m  [0m| 39/50 [00:47<00:11,  1.06s/it]                                                         Episode 40	 reward: -5.38	 makespan: 533.00	 Mean_loss: 0.04166520,  training time: 1.06
progress:  78%|[34m  [0m| 39/50 [00:48<00:11,  1.06s/it]progress:  80%|[34m  [0m| 40/50 [00:48<00:10,  1.06s/it]                                                         Episode 41	 reward: -5.65	 makespan: 559.00	 Mean_loss: 0.03730486,  training time: 1.16
progress:  80%|[34m  [0m| 40/50 [00:49<00:10,  1.06s/it]progress:  82%|[34m [0m| 41/50 [00:49<00:09,  1.09s/it]                                                         Episode 42	 reward: -5.48	 makespan: 542.75	 Mean_loss: 0.06181527,  training time: 1.04
progress:  82%|[34m [0m| 41/50 [00:50<00:09,  1.09s/it]progress:  84%|[34m [0m| 42/50 [00:50<00:08,  1.08s/it]                                                         Episode 43	 reward: -5.26	 makespan: 520.50	 Mean_loss: 0.05335324,  training time: 0.98
progress:  84%|[34m [0m| 42/50 [00:51<00:08,  1.08s/it]progress:  86%|[34m [0m| 43/50 [00:51<00:07,  1.05s/it]                                                         Episode 44	 reward: -5.34	 makespan: 528.25	 Mean_loss: 0.02356841,  training time: 1.03
progress:  86%|[34m [0m| 43/50 [00:52<00:07,  1.05s/it]progress:  88%|[34m [0m| 44/50 [00:52<00:06,  1.04s/it]                                                         Episode 45	 reward: -5.54	 makespan: 548.25	 Mean_loss: 0.05601873,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:53<00:06,  1.04s/it]progress:  90%|[34m [0m| 45/50 [00:53<00:05,  1.04s/it]                                                         Episode 46	 reward: -5.29	 makespan: 524.00	 Mean_loss: 0.06004142,  training time: 1.03
progress:  90%|[34m [0m| 45/50 [00:54<00:05,  1.04s/it]progress:  92%|[34m[0m| 46/50 [00:54<00:04,  1.04s/it]                                                         Episode 47	 reward: -5.25	 makespan: 519.50	 Mean_loss: 0.07969148,  training time: 1.03
progress:  92%|[34m[0m| 46/50 [00:55<00:04,  1.04s/it]progress:  94%|[34m[0m| 47/50 [00:55<00:03,  1.04s/it]                                                         Episode 48	 reward: -5.51	 makespan: 545.25	 Mean_loss: 0.04790946,  training time: 1.04
progress:  94%|[34m[0m| 47/50 [00:56<00:03,  1.04s/it]progress:  96%|[34m[0m| 48/50 [00:56<00:02,  1.04s/it]                                                         Episode 49	 reward: -5.68	 makespan: 562.50	 Mean_loss: 0.04564339,  training time: 1.03
progress:  96%|[34m[0m| 48/50 [00:57<00:02,  1.04s/it]progress:  98%|[34m[0m| 49/50 [00:57<00:01,  1.04s/it]                                                         Episode 50	 reward: -5.66	 makespan: 560.25	 Mean_loss: 0.06098047,  training time: 1.02
progress:  98%|[34m[0m| 49/50 [00:58<00:01,  1.04s/it]progress: 100%|[34m[0m| 50/50 [00:58<00:00,  1.03s/it]progress: 100%|[34m[0m| 50/50 [00:58<00:00,  1.18s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 6 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]6.0
6.0
6.0
6.0
                                                Episode 1	 reward: -7.71	 makespan: 763.25	 Mean_loss: 0.18096516,  training time: 5.21
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:15,  5.22s/it]                                                        Episode 2	 reward: -7.54	 makespan: 746.00	 Mean_loss: 0.23099348,  training time: 1.58
progress:   2%|[34m         [0m| 1/50 [00:06<04:15,  5.22s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:28,  3.10s/it]                                                        Episode 3	 reward: -7.28	 makespan: 720.75	 Mean_loss: 0.16231549,  training time: 1.50
progress:   4%|[34m         [0m| 2/50 [00:08<02:28,  3.10s/it]progress:   6%|[34m         [0m| 3/50 [00:08<01:51,  2.37s/it]                                                        Episode 4	 reward: -7.45	 makespan: 738.00	 Mean_loss: 0.16703263,  training time: 1.49
progress:   6%|[34m         [0m| 3/50 [00:09<01:51,  2.37s/it]progress:   8%|[34m         [0m| 4/50 [00:09<01:33,  2.02s/it]                                                        Episode 5	 reward: -7.34	 makespan: 726.25	 Mean_loss: 0.10523577,  training time: 1.48
progress:   8%|[34m         [0m| 4/50 [00:11<01:33,  2.02s/it]progress:  10%|[34m         [0m| 5/50 [00:11<01:22,  1.83s/it]                                                        Episode 6	 reward: -7.49	 makespan: 742.00	 Mean_loss: 0.10426156,  training time: 1.50
progress:  10%|[34m         [0m| 5/50 [00:12<01:22,  1.83s/it]progress:  12%|[34m        [0m| 6/50 [00:12<01:15,  1.72s/it]                                                        Episode 7	 reward: -7.21	 makespan: 714.00	 Mean_loss: 0.13870661,  training time: 1.49
progress:  12%|[34m        [0m| 6/50 [00:14<01:15,  1.72s/it]progress:  14%|[34m        [0m| 7/50 [00:14<01:10,  1.64s/it]                                                        Episode 8	 reward: -6.66	 makespan: 659.75	 Mean_loss: 0.09636939,  training time: 1.53
progress:  14%|[34m        [0m| 7/50 [00:15<01:10,  1.64s/it]progress:  16%|[34m        [0m| 8/50 [00:15<01:07,  1.61s/it]                                                        Episode 9	 reward: -6.82	 makespan: 675.00	 Mean_loss: 0.05600648,  training time: 1.58
progress:  16%|[34m        [0m| 8/50 [00:17<01:07,  1.61s/it]progress:  18%|[34m        [0m| 9/50 [00:17<01:05,  1.60s/it]                                                        Episode 10	 reward: -7.42	 makespan: 735.00	 Mean_loss: 0.10905924,  training time: 1.54
progress:  18%|[34m        [0m| 9/50 [00:18<01:05,  1.60s/it]progress:  20%|[34m        [0m| 10/50 [00:18<01:03,  1.58s/it]                                                         Episode 11	 reward: -7.11	 makespan: 703.75	 Mean_loss: 0.12090957,  training time: 1.54
progress:  20%|[34m        [0m| 10/50 [00:20<01:03,  1.58s/it]progress:  22%|[34m       [0m| 11/50 [00:20<01:01,  1.57s/it]                                                         Episode 12	 reward: -7.21	 makespan: 714.00	 Mean_loss: 0.12823461,  training time: 1.54
progress:  22%|[34m       [0m| 11/50 [00:22<01:01,  1.57s/it]progress:  24%|[34m       [0m| 12/50 [00:22<00:59,  1.56s/it]                                                         Episode 13	 reward: -7.30	 makespan: 722.25	 Mean_loss: 0.10052733,  training time: 1.50
progress:  24%|[34m       [0m| 12/50 [00:23<00:59,  1.56s/it]progress:  26%|[34m       [0m| 13/50 [00:23<00:57,  1.54s/it]                                                         Episode 14	 reward: -7.40	 makespan: 733.00	 Mean_loss: 0.07657519,  training time: 1.46
progress:  26%|[34m       [0m| 13/50 [00:24<00:57,  1.54s/it]progress:  28%|[34m       [0m| 14/50 [00:24<00:54,  1.52s/it]                                                         Episode 15	 reward: -7.04	 makespan: 696.75	 Mean_loss: 0.10254677,  training time: 1.45
progress:  28%|[34m       [0m| 14/50 [00:26<00:54,  1.52s/it]progress:  30%|[34m       [0m| 15/50 [00:26<00:52,  1.50s/it]                                                         Episode 16	 reward: -7.00	 makespan: 693.00	 Mean_loss: 0.06308471,  training time: 1.48
progress:  30%|[34m       [0m| 15/50 [00:27<00:52,  1.50s/it]progress:  32%|[34m      [0m| 16/50 [00:27<00:50,  1.49s/it]                                                         Episode 17	 reward: -7.08	 makespan: 700.50	 Mean_loss: 0.09232862,  training time: 2.68
progress:  32%|[34m      [0m| 16/50 [00:30<00:50,  1.49s/it]progress:  34%|[34m      [0m| 17/50 [00:30<01:01,  1.85s/it]                                                         Episode 18	 reward: -6.92	 makespan: 685.00	 Mean_loss: 0.05752144,  training time: 1.53
progress:  34%|[34m      [0m| 17/50 [00:32<01:01,  1.85s/it]progress:  36%|[34m      [0m| 18/50 [00:32<00:56,  1.76s/it]                                                         Episode 19	 reward: -6.98	 makespan: 691.25	 Mean_loss: 0.09417517,  training time: 1.46
progress:  36%|[34m      [0m| 18/50 [00:33<00:56,  1.76s/it]progress:  38%|[34m      [0m| 19/50 [00:33<00:51,  1.67s/it]                                                         Episode 20	 reward: -6.67	 makespan: 660.00	 Mean_loss: 0.07404810,  training time: 1.45
progress:  38%|[34m      [0m| 19/50 [00:35<00:51,  1.67s/it]progress:  40%|[34m      [0m| 20/50 [00:35<00:48,  1.60s/it]                                                         Episode 21	 reward: -6.92	 makespan: 684.75	 Mean_loss: 0.11100701,  training time: 1.45
progress:  40%|[34m      [0m| 20/50 [00:36<00:48,  1.60s/it]progress:  42%|[34m     [0m| 21/50 [00:36<00:45,  1.56s/it]                                                         Episode 22	 reward: -7.20	 makespan: 713.00	 Mean_loss: 0.09641194,  training time: 1.46
progress:  42%|[34m     [0m| 21/50 [00:37<00:45,  1.56s/it]progress:  44%|[34m     [0m| 22/50 [00:37<00:42,  1.53s/it]                                                         Episode 23	 reward: -7.07	 makespan: 700.00	 Mean_loss: 0.12224165,  training time: 1.45
progress:  44%|[34m     [0m| 22/50 [00:39<00:42,  1.53s/it]progress:  46%|[34m     [0m| 23/50 [00:39<00:40,  1.50s/it]                                                         Episode 24	 reward: -7.03	 makespan: 696.00	 Mean_loss: 0.05214412,  training time: 1.45
progress:  46%|[34m     [0m| 23/50 [00:40<00:40,  1.50s/it]progress:  48%|[34m     [0m| 24/50 [00:40<00:38,  1.49s/it]                                                         Episode 25	 reward: -6.82	 makespan: 675.50	 Mean_loss: 0.05333503,  training time: 1.46
progress:  48%|[34m     [0m| 24/50 [00:42<00:38,  1.49s/it]progress:  50%|[34m     [0m| 25/50 [00:42<00:37,  1.48s/it]                                                         Episode 26	 reward: -7.17	 makespan: 709.50	 Mean_loss: 0.09441330,  training time: 1.44
progress:  50%|[34m     [0m| 25/50 [00:43<00:37,  1.48s/it]progress:  52%|[34m    [0m| 26/50 [00:43<00:35,  1.47s/it]                                                         Episode 27	 reward: -7.03	 makespan: 695.50	 Mean_loss: 0.06566924,  training time: 1.46
progress:  52%|[34m    [0m| 26/50 [00:45<00:35,  1.47s/it]progress:  54%|[34m    [0m| 27/50 [00:45<00:33,  1.47s/it]                                                         Episode 28	 reward: -6.74	 makespan: 667.25	 Mean_loss: 0.05909235,  training time: 1.50
progress:  54%|[34m    [0m| 27/50 [00:46<00:33,  1.47s/it]progress:  56%|[34m    [0m| 28/50 [00:46<00:32,  1.48s/it]                                                         Episode 29	 reward: -6.76	 makespan: 669.25	 Mean_loss: 0.06171655,  training time: 1.46
progress:  56%|[34m    [0m| 28/50 [00:48<00:32,  1.48s/it]progress:  58%|[34m    [0m| 29/50 [00:48<00:30,  1.47s/it]                                                         Episode 30	 reward: -6.92	 makespan: 684.75	 Mean_loss: 0.03150268,  training time: 1.50
progress:  58%|[34m    [0m| 29/50 [00:49<00:30,  1.47s/it]progress:  60%|[34m    [0m| 30/50 [00:49<00:29,  1.48s/it]                                                         Episode 31	 reward: -6.80	 makespan: 673.25	 Mean_loss: 0.04718480,  training time: 1.47
progress:  60%|[34m    [0m| 30/50 [00:51<00:29,  1.48s/it]progress:  62%|[34m   [0m| 31/50 [00:51<00:28,  1.48s/it]                                                         Episode 32	 reward: -6.71	 makespan: 664.75	 Mean_loss: 0.03937565,  training time: 1.45
progress:  62%|[34m   [0m| 31/50 [00:52<00:28,  1.48s/it]progress:  64%|[34m   [0m| 32/50 [00:52<00:26,  1.47s/it]                                                         Episode 33	 reward: -6.60	 makespan: 653.25	 Mean_loss: 0.03808518,  training time: 1.51
progress:  64%|[34m   [0m| 32/50 [00:54<00:26,  1.47s/it]progress:  66%|[34m   [0m| 33/50 [00:54<00:25,  1.48s/it]                                                         Episode 34	 reward: -6.71	 makespan: 664.75	 Mean_loss: 0.03926671,  training time: 1.49
progress:  66%|[34m   [0m| 33/50 [00:55<00:25,  1.48s/it]progress:  68%|[34m   [0m| 34/50 [00:55<00:23,  1.49s/it]                                                         Episode 35	 reward: -6.60	 makespan: 653.50	 Mean_loss: 0.02034853,  training time: 1.46
progress:  68%|[34m   [0m| 34/50 [00:57<00:23,  1.49s/it]progress:  70%|[34m   [0m| 35/50 [00:57<00:22,  1.48s/it]                                                         Episode 36	 reward: -6.57	 makespan: 650.50	 Mean_loss: 0.05391796,  training time: 1.47
progress:  70%|[34m   [0m| 35/50 [00:58<00:22,  1.48s/it]progress:  72%|[34m  [0m| 36/50 [00:58<00:20,  1.48s/it]                                                         Episode 37	 reward: -6.58	 makespan: 651.75	 Mean_loss: 0.04041741,  training time: 1.52
progress:  72%|[34m  [0m| 36/50 [01:00<00:20,  1.48s/it]progress:  74%|[34m  [0m| 37/50 [01:00<00:19,  1.49s/it]                                                         Episode 38	 reward: -6.52	 makespan: 645.00	 Mean_loss: 0.02490477,  training time: 1.50
progress:  74%|[34m  [0m| 37/50 [01:01<00:19,  1.49s/it]progress:  76%|[34m  [0m| 38/50 [01:01<00:17,  1.49s/it]                                                         Episode 39	 reward: -6.43	 makespan: 637.00	 Mean_loss: 0.02454560,  training time: 1.46
progress:  76%|[34m  [0m| 38/50 [01:03<00:17,  1.49s/it]progress:  78%|[34m  [0m| 39/50 [01:03<00:16,  1.48s/it]                                                         Episode 40	 reward: -6.69	 makespan: 662.25	 Mean_loss: 0.03371179,  training time: 1.48
progress:  78%|[34m  [0m| 39/50 [01:04<00:16,  1.48s/it]progress:  80%|[34m  [0m| 40/50 [01:04<00:14,  1.48s/it]                                                         Episode 41	 reward: -6.47	 makespan: 641.00	 Mean_loss: 0.04703856,  training time: 1.51
progress:  80%|[34m  [0m| 40/50 [01:06<00:14,  1.48s/it]progress:  82%|[34m [0m| 41/50 [01:06<00:13,  1.49s/it]                                                         Episode 42	 reward: -6.53	 makespan: 646.75	 Mean_loss: 0.03368272,  training time: 1.51
progress:  82%|[34m [0m| 41/50 [01:07<00:13,  1.49s/it]progress:  84%|[34m [0m| 42/50 [01:07<00:11,  1.50s/it]                                                         Episode 43	 reward: -6.53	 makespan: 646.75	 Mean_loss: 0.02569704,  training time: 1.47
progress:  84%|[34m [0m| 42/50 [01:09<00:11,  1.50s/it]progress:  86%|[34m [0m| 43/50 [01:09<00:10,  1.49s/it]                                                         Episode 44	 reward: -6.16	 makespan: 610.00	 Mean_loss: 0.02630111,  training time: 1.47
progress:  86%|[34m [0m| 43/50 [01:10<00:10,  1.49s/it]progress:  88%|[34m [0m| 44/50 [01:10<00:08,  1.48s/it]                                                         Episode 45	 reward: -6.60	 makespan: 653.75	 Mean_loss: 0.03570601,  training time: 1.48
progress:  88%|[34m [0m| 44/50 [01:11<00:08,  1.48s/it]progress:  90%|[34m [0m| 45/50 [01:11<00:07,  1.48s/it]                                                         Episode 46	 reward: -6.69	 makespan: 662.50	 Mean_loss: 0.02724695,  training time: 1.46
progress:  90%|[34m [0m| 45/50 [01:13<00:07,  1.48s/it]progress:  92%|[34m[0m| 46/50 [01:13<00:05,  1.48s/it]                                                         Episode 47	 reward: -6.90	 makespan: 682.75	 Mean_loss: 0.03990386,  training time: 1.46
progress:  92%|[34m[0m| 46/50 [01:14<00:05,  1.48s/it]progress:  94%|[34m[0m| 47/50 [01:14<00:04,  1.47s/it]                                                         Episode 48	 reward: -6.69	 makespan: 662.75	 Mean_loss: 0.03102998,  training time: 1.47
progress:  94%|[34m[0m| 47/50 [01:16<00:04,  1.47s/it]progress:  96%|[34m[0m| 48/50 [01:16<00:02,  1.47s/it]                                                         Episode 49	 reward: -6.61	 makespan: 654.50	 Mean_loss: 0.03060877,  training time: 1.47
progress:  96%|[34m[0m| 48/50 [01:17<00:02,  1.47s/it]progress:  98%|[34m[0m| 49/50 [01:17<00:01,  1.47s/it]                                                         Episode 50	 reward: -6.59	 makespan: 652.50	 Mean_loss: 0.02196265,  training time: 1.47
progress:  98%|[34m[0m| 49/50 [01:19<00:01,  1.47s/it]progress: 100%|[34m[0m| 50/50 [01:19<00:00,  1.47s/it]progress: 100%|[34m[0m| 50/50 [01:19<00:00,  1.59s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 8 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]8.0
8.0
8.0
8.0
                                                Episode 1	 reward: -10.43	 makespan: 1032.25	 Mean_loss: 0.57430375,  training time: 5.82
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:45,  5.83s/it]                                                        Episode 2	 reward: -10.49	 makespan: 1038.50	 Mean_loss: 0.64040720,  training time: 1.94
progress:   2%|[34m         [0m| 1/50 [00:07<04:45,  5.83s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:50,  3.55s/it]                                                        Episode 3	 reward: -11.00	 makespan: 1089.25	 Mean_loss: 0.60448897,  training time: 1.98
progress:   4%|[34m         [0m| 2/50 [00:09<02:50,  3.55s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:13,  2.83s/it]                                                        Episode 4	 reward: -11.05	 makespan: 1093.50	 Mean_loss: 0.76100534,  training time: 1.91
progress:   6%|[34m         [0m| 3/50 [00:11<02:13,  2.83s/it]progress:   8%|[34m         [0m| 4/50 [00:11<01:53,  2.47s/it]                                                        Episode 5	 reward: -11.75	 makespan: 1163.00	 Mean_loss: 0.64563620,  training time: 1.92
progress:   8%|[34m         [0m| 4/50 [00:13<01:53,  2.47s/it]progress:  10%|[34m         [0m| 5/50 [00:13<01:42,  2.27s/it]                                                        Episode 6	 reward: -11.28	 makespan: 1116.25	 Mean_loss: 0.63582265,  training time: 1.98
progress:  10%|[34m         [0m| 5/50 [00:15<01:42,  2.27s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:35,  2.17s/it]                                                        Episode 7	 reward: -10.94	 makespan: 1083.50	 Mean_loss: 0.74101996,  training time: 1.89
progress:  12%|[34m        [0m| 6/50 [00:17<01:35,  2.17s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:29,  2.08s/it]                                                        Episode 8	 reward: -10.74	 makespan: 1063.50	 Mean_loss: 0.42329156,  training time: 1.99
progress:  14%|[34m        [0m| 7/50 [00:19<01:29,  2.08s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:26,  2.05s/it]                                                        Episode 9	 reward: -10.39	 makespan: 1028.50	 Mean_loss: 0.44260156,  training time: 1.93
progress:  16%|[34m        [0m| 8/50 [00:21<01:26,  2.05s/it]progress:  18%|[34m        [0m| 9/50 [00:21<01:22,  2.01s/it]                                                        Episode 10	 reward: -10.14	 makespan: 1003.50	 Mean_loss: 0.32043758,  training time: 1.90
progress:  18%|[34m        [0m| 9/50 [00:23<01:22,  2.01s/it]progress:  20%|[34m        [0m| 10/50 [00:23<01:19,  1.98s/it]                                                         Episode 11	 reward: -10.11	 makespan: 1000.75	 Mean_loss: 0.28892589,  training time: 1.89
progress:  20%|[34m        [0m| 10/50 [00:25<01:19,  1.98s/it]progress:  22%|[34m       [0m| 11/50 [00:25<01:16,  1.95s/it]                                                         Episode 12	 reward: -10.29	 makespan: 1018.75	 Mean_loss: 0.16882430,  training time: 2.61
progress:  22%|[34m       [0m| 11/50 [00:27<01:16,  1.95s/it]progress:  24%|[34m       [0m| 12/50 [00:27<01:21,  2.15s/it]                                                         Episode 13	 reward: -11.09	 makespan: 1098.25	 Mean_loss: 0.38638574,  training time: 1.92
progress:  24%|[34m       [0m| 12/50 [00:29<01:21,  2.15s/it]progress:  26%|[34m       [0m| 13/50 [00:29<01:17,  2.08s/it]                                                         Episode 14	 reward: -10.81	 makespan: 1070.50	 Mean_loss: 0.32417542,  training time: 1.89
progress:  26%|[34m       [0m| 13/50 [00:31<01:17,  2.08s/it]progress:  28%|[34m       [0m| 14/50 [00:31<01:12,  2.03s/it]                                                         Episode 15	 reward: -10.22	 makespan: 1011.75	 Mean_loss: 0.34333006,  training time: 1.88
progress:  28%|[34m       [0m| 14/50 [00:33<01:12,  2.03s/it]progress:  30%|[34m       [0m| 15/50 [00:33<01:09,  1.98s/it]                                                         Episode 16	 reward: -10.20	 makespan: 1010.00	 Mean_loss: 0.17343855,  training time: 1.90
progress:  30%|[34m       [0m| 15/50 [00:35<01:09,  1.98s/it]progress:  32%|[34m      [0m| 16/50 [00:35<01:06,  1.96s/it]                                                         Episode 17	 reward: -10.21	 makespan: 1010.50	 Mean_loss: 0.17778040,  training time: 1.91
progress:  32%|[34m      [0m| 16/50 [00:37<01:06,  1.96s/it]progress:  34%|[34m      [0m| 17/50 [00:37<01:04,  1.94s/it]                                                         Episode 18	 reward: -10.25	 makespan: 1014.50	 Mean_loss: 0.21528889,  training time: 1.91
progress:  34%|[34m      [0m| 17/50 [00:39<01:04,  1.94s/it]progress:  36%|[34m      [0m| 18/50 [00:39<01:01,  1.94s/it]                                                         Episode 19	 reward: -10.31	 makespan: 1020.25	 Mean_loss: 0.23990993,  training time: 1.92
progress:  36%|[34m      [0m| 18/50 [00:41<01:01,  1.94s/it]progress:  38%|[34m      [0m| 19/50 [00:41<00:59,  1.93s/it]                                                         Episode 20	 reward: -9.77	 makespan: 966.75	 Mean_loss: 0.14446470,  training time: 1.91
progress:  38%|[34m      [0m| 19/50 [00:43<00:59,  1.93s/it]progress:  40%|[34m      [0m| 20/50 [00:43<00:57,  1.92s/it]                                                         Episode 21	 reward: -9.93	 makespan: 982.75	 Mean_loss: 0.16002145,  training time: 1.90
progress:  40%|[34m      [0m| 20/50 [00:44<00:57,  1.92s/it]progress:  42%|[34m     [0m| 21/50 [00:44<00:55,  1.92s/it]                                                         Episode 22	 reward: -10.20	 makespan: 1010.00	 Mean_loss: 0.14688708,  training time: 1.91
progress:  42%|[34m     [0m| 21/50 [00:46<00:55,  1.92s/it]progress:  44%|[34m     [0m| 22/50 [00:46<00:53,  1.92s/it]                                                         Episode 23	 reward: -10.20	 makespan: 1009.75	 Mean_loss: 0.10735171,  training time: 1.89
progress:  44%|[34m     [0m| 22/50 [00:48<00:53,  1.92s/it]progress:  46%|[34m     [0m| 23/50 [00:48<00:51,  1.91s/it]                                                         Episode 24	 reward: -10.09	 makespan: 999.00	 Mean_loss: 0.18807229,  training time: 1.89
progress:  46%|[34m     [0m| 23/50 [00:50<00:51,  1.91s/it]progress:  48%|[34m     [0m| 24/50 [00:50<00:49,  1.90s/it]                                                         Episode 25	 reward: -10.12	 makespan: 1002.25	 Mean_loss: 0.10660325,  training time: 1.89
progress:  48%|[34m     [0m| 24/50 [00:52<00:49,  1.90s/it]progress:  50%|[34m     [0m| 25/50 [00:52<00:47,  1.90s/it]                                                         Episode 26	 reward: -10.01	 makespan: 991.00	 Mean_loss: 0.09948727,  training time: 1.92
progress:  50%|[34m     [0m| 25/50 [00:54<00:47,  1.90s/it]progress:  52%|[34m    [0m| 26/50 [00:54<00:45,  1.91s/it]                                                         Episode 27	 reward: -10.42	 makespan: 1032.00	 Mean_loss: 0.09746353,  training time: 1.87
progress:  52%|[34m    [0m| 26/50 [00:56<00:45,  1.91s/it]progress:  54%|[34m    [0m| 27/50 [00:56<00:43,  1.90s/it]                                                         Episode 28	 reward: -10.23	 makespan: 1013.00	 Mean_loss: 0.06733276,  training time: 1.89
progress:  54%|[34m    [0m| 27/50 [00:58<00:43,  1.90s/it]progress:  56%|[34m    [0m| 28/50 [00:58<00:41,  1.89s/it]                                                         Episode 29	 reward: -10.23	 makespan: 1012.75	 Mean_loss: 0.11491215,  training time: 1.91
progress:  56%|[34m    [0m| 28/50 [01:00<00:41,  1.89s/it]progress:  58%|[34m    [0m| 29/50 [01:00<00:39,  1.90s/it]                                                         Episode 30	 reward: -10.03	 makespan: 993.25	 Mean_loss: 0.10040794,  training time: 1.91
progress:  58%|[34m    [0m| 29/50 [01:02<00:39,  1.90s/it]progress:  60%|[34m    [0m| 30/50 [01:02<00:38,  1.90s/it]                                                         Episode 31	 reward: -10.15	 makespan: 1005.25	 Mean_loss: 0.06792340,  training time: 1.90
progress:  60%|[34m    [0m| 30/50 [01:03<00:38,  1.90s/it]progress:  62%|[34m   [0m| 31/50 [01:03<00:36,  1.90s/it]                                                         Episode 32	 reward: -10.24	 makespan: 1013.50	 Mean_loss: 0.09035271,  training time: 1.89
progress:  62%|[34m   [0m| 31/50 [01:05<00:36,  1.90s/it]progress:  64%|[34m   [0m| 32/50 [01:05<00:34,  1.90s/it]                                                         Episode 33	 reward: -10.09	 makespan: 998.75	 Mean_loss: 0.07548625,  training time: 1.89
progress:  64%|[34m   [0m| 32/50 [01:07<00:34,  1.90s/it]progress:  66%|[34m   [0m| 33/50 [01:07<00:32,  1.90s/it]                                                         Episode 34	 reward: -10.04	 makespan: 994.25	 Mean_loss: 0.08537921,  training time: 1.90
progress:  66%|[34m   [0m| 33/50 [01:09<00:32,  1.90s/it]progress:  68%|[34m   [0m| 34/50 [01:09<00:30,  1.90s/it]                                                         Episode 35	 reward: -9.77	 makespan: 967.50	 Mean_loss: 0.09700590,  training time: 1.88
progress:  68%|[34m   [0m| 34/50 [01:11<00:30,  1.90s/it]progress:  70%|[34m   [0m| 35/50 [01:11<00:28,  1.89s/it]                                                         Episode 36	 reward: -9.99	 makespan: 988.75	 Mean_loss: 0.07822286,  training time: 1.89
progress:  70%|[34m   [0m| 35/50 [01:13<00:28,  1.89s/it]progress:  72%|[34m  [0m| 36/50 [01:13<00:26,  1.89s/it]                                                         Episode 37	 reward: -9.82	 makespan: 972.50	 Mean_loss: 0.06419536,  training time: 1.84
progress:  72%|[34m  [0m| 36/50 [01:15<00:26,  1.89s/it]progress:  74%|[34m  [0m| 37/50 [01:15<00:24,  1.88s/it]                                                         Episode 38	 reward: -10.20	 makespan: 1009.50	 Mean_loss: 0.07530066,  training time: 1.88
progress:  74%|[34m  [0m| 37/50 [01:17<00:24,  1.88s/it]progress:  76%|[34m  [0m| 38/50 [01:17<00:22,  1.88s/it]                                                         Episode 39	 reward: -10.18	 makespan: 1008.00	 Mean_loss: 0.07480509,  training time: 1.89
progress:  76%|[34m  [0m| 38/50 [01:19<00:22,  1.88s/it]progress:  78%|[34m  [0m| 39/50 [01:19<00:20,  1.88s/it]                                                         Episode 40	 reward: -9.77	 makespan: 966.75	 Mean_loss: 0.06804299,  training time: 1.89
progress:  78%|[34m  [0m| 39/50 [01:20<00:20,  1.88s/it]progress:  80%|[34m  [0m| 40/50 [01:20<00:18,  1.88s/it]                                                         Episode 41	 reward: -10.12	 makespan: 1001.75	 Mean_loss: 0.09626580,  training time: 1.88
progress:  80%|[34m  [0m| 40/50 [01:22<00:18,  1.88s/it]progress:  82%|[34m [0m| 41/50 [01:22<00:16,  1.88s/it]                                                         Episode 42	 reward: -10.29	 makespan: 1018.75	 Mean_loss: 0.08675922,  training time: 1.88
progress:  82%|[34m [0m| 41/50 [01:24<00:16,  1.88s/it]progress:  84%|[34m [0m| 42/50 [01:24<00:15,  1.88s/it]                                                         Episode 43	 reward: -9.86	 makespan: 976.50	 Mean_loss: 0.06501541,  training time: 1.84
progress:  84%|[34m [0m| 42/50 [01:26<00:15,  1.88s/it]progress:  86%|[34m [0m| 43/50 [01:26<00:13,  1.87s/it]                                                         Episode 44	 reward: -9.80	 makespan: 970.25	 Mean_loss: 0.06969584,  training time: 1.87
progress:  86%|[34m [0m| 43/50 [01:28<00:13,  1.87s/it]progress:  88%|[34m [0m| 44/50 [01:28<00:11,  1.87s/it]                                                         Episode 45	 reward: -9.86	 makespan: 976.00	 Mean_loss: 0.05171095,  training time: 1.86
progress:  88%|[34m [0m| 44/50 [01:30<00:11,  1.87s/it]progress:  90%|[34m [0m| 45/50 [01:30<00:09,  1.87s/it]                                                         Episode 46	 reward: -9.92	 makespan: 982.00	 Mean_loss: 0.07158769,  training time: 1.86
progress:  90%|[34m [0m| 45/50 [01:32<00:09,  1.87s/it]progress:  92%|[34m[0m| 46/50 [01:32<00:07,  1.87s/it]                                                         Episode 47	 reward: -9.67	 makespan: 957.50	 Mean_loss: 0.05218819,  training time: 1.86
progress:  92%|[34m[0m| 46/50 [01:33<00:07,  1.87s/it]progress:  94%|[34m[0m| 47/50 [01:33<00:05,  1.86s/it]                                                         Episode 48	 reward: -9.74	 makespan: 964.00	 Mean_loss: 0.06439115,  training time: 1.89
progress:  94%|[34m[0m| 47/50 [01:35<00:05,  1.86s/it]progress:  96%|[34m[0m| 48/50 [01:35<00:03,  1.87s/it]                                                         Episode 49	 reward: -9.51	 makespan: 941.50	 Mean_loss: 0.04845935,  training time: 1.88
progress:  96%|[34m[0m| 48/50 [01:37<00:03,  1.87s/it]progress:  98%|[34m[0m| 49/50 [01:37<00:01,  1.87s/it]                                                         Episode 50	 reward: -10.03	 makespan: 992.75	 Mean_loss: 0.05703067,  training time: 1.89
progress:  98%|[34m[0m| 49/50 [01:39<00:01,  1.87s/it]progress: 100%|[34m[0m| 50/50 [01:39<00:00,  1.88s/it]progress: 100%|[34m[0m| 50/50 [01:39<00:00,  1.99s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 10 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]10.0
10.0
10.0
10.0
                                                Episode 1	 reward: -13.04	 makespan: 1290.50	 Mean_loss: 0.79220515,  training time: 4.78
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:54,  4.79s/it]                                                        Episode 2	 reward: -13.69	 makespan: 1355.75	 Mean_loss: 1.22929049,  training time: 2.56
progress:   2%|[34m         [0m| 1/50 [00:07<03:54,  4.79s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:47,  3.48s/it]                                                        Episode 3	 reward: -13.46	 makespan: 1332.75	 Mean_loss: 1.24627793,  training time: 2.47
progress:   4%|[34m         [0m| 2/50 [00:09<02:47,  3.48s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:22,  3.02s/it]                                                        Episode 4	 reward: -15.08	 makespan: 1493.00	 Mean_loss: 1.25799155,  training time: 2.53
progress:   6%|[34m         [0m| 3/50 [00:12<02:22,  3.02s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:10,  2.83s/it]                                                        Episode 5	 reward: -14.40	 makespan: 1425.50	 Mean_loss: 1.26045537,  training time: 2.41
progress:   8%|[34m         [0m| 4/50 [00:14<02:10,  2.83s/it]progress:  10%|[34m         [0m| 5/50 [00:14<02:00,  2.68s/it]                                                        Episode 6	 reward: -14.71	 makespan: 1456.50	 Mean_loss: 1.27378082,  training time: 2.55
progress:  10%|[34m         [0m| 5/50 [00:17<02:00,  2.68s/it]progress:  12%|[34m        [0m| 6/50 [00:17<01:55,  2.64s/it]                                                        Episode 7	 reward: -14.04	 makespan: 1390.00	 Mean_loss: 0.96400863,  training time: 2.38
progress:  12%|[34m        [0m| 6/50 [00:19<01:55,  2.64s/it]progress:  14%|[34m        [0m| 7/50 [00:19<01:49,  2.55s/it]                                                        Episode 8	 reward: -13.56	 makespan: 1342.50	 Mean_loss: 0.77477545,  training time: 2.39
progress:  14%|[34m        [0m| 7/50 [00:22<01:49,  2.55s/it]progress:  16%|[34m        [0m| 8/50 [00:22<01:45,  2.50s/it]                                                        Episode 9	 reward: -13.10	 makespan: 1297.25	 Mean_loss: 0.53193384,  training time: 2.34
progress:  16%|[34m        [0m| 8/50 [00:24<01:45,  2.50s/it]progress:  18%|[34m        [0m| 9/50 [00:24<01:40,  2.45s/it]                                                        Episode 10	 reward: -12.90	 makespan: 1277.00	 Mean_loss: 0.48754039,  training time: 2.39
progress:  18%|[34m        [0m| 9/50 [00:26<01:40,  2.45s/it]progress:  20%|[34m        [0m| 10/50 [00:26<01:37,  2.43s/it]                                                         Episode 11	 reward: -13.26	 makespan: 1312.25	 Mean_loss: 0.48227900,  training time: 2.36
progress:  20%|[34m        [0m| 10/50 [00:29<01:37,  2.43s/it]progress:  22%|[34m       [0m| 11/50 [00:29<01:34,  2.41s/it]                                                         Episode 12	 reward: -13.30	 makespan: 1316.25	 Mean_loss: 0.38302386,  training time: 2.36
progress:  22%|[34m       [0m| 11/50 [00:31<01:34,  2.41s/it]progress:  24%|[34m       [0m| 12/50 [00:31<01:31,  2.40s/it]                                                         Episode 13	 reward: -12.80	 makespan: 1266.75	 Mean_loss: 0.39888614,  training time: 2.37
progress:  24%|[34m       [0m| 12/50 [00:33<01:31,  2.40s/it]progress:  26%|[34m       [0m| 13/50 [00:33<01:28,  2.39s/it]                                                         Episode 14	 reward: -12.98	 makespan: 1284.75	 Mean_loss: 0.35969245,  training time: 2.36
progress:  26%|[34m       [0m| 13/50 [00:36<01:28,  2.39s/it]progress:  28%|[34m       [0m| 14/50 [00:36<01:25,  2.38s/it]                                                         Episode 15	 reward: -13.14	 makespan: 1300.75	 Mean_loss: 0.30469337,  training time: 2.37
progress:  28%|[34m       [0m| 14/50 [00:38<01:25,  2.38s/it]progress:  30%|[34m       [0m| 15/50 [00:38<01:23,  2.38s/it]                                                         Episode 16	 reward: -13.82	 makespan: 1367.75	 Mean_loss: 0.35045505,  training time: 2.36
progress:  30%|[34m       [0m| 15/50 [00:41<01:23,  2.38s/it]progress:  32%|[34m      [0m| 16/50 [00:41<01:20,  2.37s/it]                                                         Episode 17	 reward: -13.12	 makespan: 1298.75	 Mean_loss: 0.18641330,  training time: 2.35
progress:  32%|[34m      [0m| 16/50 [00:43<01:20,  2.37s/it]progress:  34%|[34m      [0m| 17/50 [00:43<01:18,  2.37s/it]                                                         Episode 18	 reward: -12.88	 makespan: 1274.75	 Mean_loss: 0.28673062,  training time: 2.32
progress:  34%|[34m      [0m| 17/50 [00:45<01:18,  2.37s/it]progress:  36%|[34m      [0m| 18/50 [00:45<01:15,  2.35s/it]                                                         Episode 19	 reward: -12.91	 makespan: 1278.50	 Mean_loss: 0.32274443,  training time: 2.32
progress:  36%|[34m      [0m| 18/50 [00:48<01:15,  2.35s/it]progress:  38%|[34m      [0m| 19/50 [00:48<01:12,  2.34s/it]                                                         Episode 20	 reward: -13.09	 makespan: 1295.50	 Mean_loss: 0.29993945,  training time: 2.34
progress:  38%|[34m      [0m| 19/50 [00:50<01:12,  2.34s/it]progress:  40%|[34m      [0m| 20/50 [00:50<01:10,  2.35s/it]                                                         Episode 21	 reward: -13.07	 makespan: 1293.75	 Mean_loss: 0.40691927,  training time: 2.32
progress:  40%|[34m      [0m| 20/50 [00:52<01:10,  2.35s/it]progress:  42%|[34m     [0m| 21/50 [00:52<01:07,  2.34s/it]                                                         Episode 22	 reward: -13.09	 makespan: 1295.50	 Mean_loss: 0.18382898,  training time: 2.32
progress:  42%|[34m     [0m| 21/50 [00:55<01:07,  2.34s/it]progress:  44%|[34m     [0m| 22/50 [00:55<01:05,  2.33s/it]                                                         Episode 23	 reward: -12.96	 makespan: 1282.75	 Mean_loss: 0.25422192,  training time: 2.41
progress:  44%|[34m     [0m| 22/50 [00:57<01:05,  2.33s/it]progress:  46%|[34m     [0m| 23/50 [00:57<01:03,  2.36s/it]                                                         Episode 24	 reward: -12.64	 makespan: 1251.75	 Mean_loss: 0.21033439,  training time: 2.35
progress:  46%|[34m     [0m| 23/50 [00:59<01:03,  2.36s/it]progress:  48%|[34m     [0m| 24/50 [00:59<01:01,  2.35s/it]                                                         Episode 25	 reward: -12.40	 makespan: 1227.50	 Mean_loss: 0.19859037,  training time: 2.35
progress:  48%|[34m     [0m| 24/50 [01:02<01:01,  2.35s/it]progress:  50%|[34m     [0m| 25/50 [01:02<00:58,  2.35s/it]                                                         Episode 26	 reward: -12.16	 makespan: 1204.25	 Mean_loss: 0.30736560,  training time: 2.33
progress:  50%|[34m     [0m| 25/50 [01:04<00:58,  2.35s/it]progress:  52%|[34m    [0m| 26/50 [01:04<00:56,  2.35s/it]                                                         Episode 27	 reward: -12.00	 makespan: 1188.00	 Mean_loss: 0.16384041,  training time: 2.32
progress:  52%|[34m    [0m| 26/50 [01:06<00:56,  2.35s/it]progress:  54%|[34m    [0m| 27/50 [01:06<00:53,  2.34s/it]                                                         Episode 28	 reward: -12.15	 makespan: 1203.00	 Mean_loss: 0.18346238,  training time: 2.33
progress:  54%|[34m    [0m| 27/50 [01:09<00:53,  2.34s/it]progress:  56%|[34m    [0m| 28/50 [01:09<00:51,  2.34s/it]                                                         Episode 29	 reward: -12.19	 makespan: 1207.00	 Mean_loss: 0.24431615,  training time: 2.35
progress:  56%|[34m    [0m| 28/50 [01:11<00:51,  2.34s/it]progress:  58%|[34m    [0m| 29/50 [01:11<00:49,  2.34s/it]                                                         Episode 30	 reward: -11.96	 makespan: 1184.25	 Mean_loss: 0.14805135,  training time: 2.33
progress:  58%|[34m    [0m| 29/50 [01:13<00:49,  2.34s/it]progress:  60%|[34m    [0m| 30/50 [01:13<00:46,  2.34s/it]                                                         Episode 31	 reward: -12.05	 makespan: 1193.00	 Mean_loss: 0.14118218,  training time: 2.35
progress:  60%|[34m    [0m| 30/50 [01:16<00:46,  2.34s/it]progress:  62%|[34m   [0m| 31/50 [01:16<00:44,  2.34s/it]                                                         Episode 32	 reward: -12.09	 makespan: 1197.00	 Mean_loss: 0.20352085,  training time: 2.34
progress:  62%|[34m   [0m| 31/50 [01:18<00:44,  2.34s/it]progress:  64%|[34m   [0m| 32/50 [01:18<00:42,  2.34s/it]                                                         Episode 33	 reward: -11.74	 makespan: 1162.25	 Mean_loss: 0.12014954,  training time: 2.34
progress:  64%|[34m   [0m| 32/50 [01:20<00:42,  2.34s/it]progress:  66%|[34m   [0m| 33/50 [01:20<00:39,  2.34s/it]                                                         Episode 34	 reward: -11.93	 makespan: 1181.00	 Mean_loss: 0.10396688,  training time: 2.37
progress:  66%|[34m   [0m| 33/50 [01:23<00:39,  2.34s/it]progress:  68%|[34m   [0m| 34/50 [01:23<00:37,  2.35s/it]                                                         Episode 35	 reward: -12.53	 makespan: 1240.00	 Mean_loss: 0.13660486,  training time: 2.45
progress:  68%|[34m   [0m| 34/50 [01:25<00:37,  2.35s/it]progress:  70%|[34m   [0m| 35/50 [01:25<00:35,  2.38s/it]                                                         Episode 36	 reward: -12.03	 makespan: 1191.25	 Mean_loss: 0.12109318,  training time: 2.34
progress:  70%|[34m   [0m| 35/50 [01:27<00:35,  2.38s/it]progress:  72%|[34m  [0m| 36/50 [01:27<00:33,  2.37s/it]                                                         Episode 37	 reward: -12.16	 makespan: 1204.25	 Mean_loss: 0.10838794,  training time: 2.36
progress:  72%|[34m  [0m| 36/50 [01:30<00:33,  2.37s/it]progress:  74%|[34m  [0m| 37/50 [01:30<00:30,  2.37s/it]                                                         Episode 38	 reward: -11.73	 makespan: 1161.00	 Mean_loss: 0.08541195,  training time: 2.33
progress:  74%|[34m  [0m| 37/50 [01:32<00:30,  2.37s/it]progress:  76%|[34m  [0m| 38/50 [01:32<00:28,  2.36s/it]                                                         Episode 39	 reward: -12.28	 makespan: 1215.50	 Mean_loss: 0.09454558,  training time: 2.39
progress:  76%|[34m  [0m| 38/50 [01:35<00:28,  2.36s/it]progress:  78%|[34m  [0m| 39/50 [01:35<00:26,  2.37s/it]                                                         Episode 40	 reward: -11.82	 makespan: 1169.75	 Mean_loss: 0.12305247,  training time: 2.34
progress:  78%|[34m  [0m| 39/50 [01:37<00:26,  2.37s/it]progress:  80%|[34m  [0m| 40/50 [01:37<00:23,  2.36s/it]                                                         Episode 41	 reward: -11.47	 makespan: 1135.75	 Mean_loss: 0.10038243,  training time: 2.51
progress:  80%|[34m  [0m| 40/50 [01:39<00:23,  2.36s/it]progress:  82%|[34m [0m| 41/50 [01:39<00:21,  2.40s/it]                                                         Episode 42	 reward: -12.23	 makespan: 1210.50	 Mean_loss: 0.11099435,  training time: 2.35
progress:  82%|[34m [0m| 41/50 [01:42<00:21,  2.40s/it]progress:  84%|[34m [0m| 42/50 [01:42<00:19,  2.39s/it]                                                         Episode 43	 reward: -12.02	 makespan: 1190.00	 Mean_loss: 0.12279079,  training time: 2.34
progress:  84%|[34m [0m| 42/50 [01:44<00:19,  2.39s/it]progress:  86%|[34m [0m| 43/50 [01:44<00:16,  2.37s/it]                                                         Episode 44	 reward: -11.52	 makespan: 1140.25	 Mean_loss: 0.10999306,  training time: 2.34
progress:  86%|[34m [0m| 43/50 [01:46<00:16,  2.37s/it]progress:  88%|[34m [0m| 44/50 [01:46<00:14,  2.36s/it]                                                         Episode 45	 reward: -12.12	 makespan: 1199.50	 Mean_loss: 0.12355604,  training time: 2.34
progress:  88%|[34m [0m| 44/50 [01:49<00:14,  2.36s/it]progress:  90%|[34m [0m| 45/50 [01:49<00:11,  2.36s/it]                                                         Episode 46	 reward: -12.11	 makespan: 1198.75	 Mean_loss: 0.11135077,  training time: 2.34
progress:  90%|[34m [0m| 45/50 [01:51<00:11,  2.36s/it]progress:  92%|[34m[0m| 46/50 [01:51<00:09,  2.35s/it]                                                         Episode 47	 reward: -11.73	 makespan: 1161.25	 Mean_loss: 0.07017787,  training time: 2.33
progress:  92%|[34m[0m| 46/50 [01:53<00:09,  2.35s/it]progress:  94%|[34m[0m| 47/50 [01:53<00:07,  2.35s/it]                                                         Episode 48	 reward: -12.12	 makespan: 1200.00	 Mean_loss: 0.08943923,  training time: 2.35
progress:  94%|[34m[0m| 47/50 [01:56<00:07,  2.35s/it]progress:  96%|[34m[0m| 48/50 [01:56<00:04,  2.35s/it]                                                         Episode 49	 reward: -12.14	 makespan: 1201.50	 Mean_loss: 0.09101088,  training time: 2.33
progress:  96%|[34m[0m| 48/50 [01:58<00:04,  2.35s/it]progress:  98%|[34m[0m| 49/50 [01:58<00:02,  2.34s/it]                                                         Episode 50	 reward: -11.86	 makespan: 1174.50	 Mean_loss: 0.04756789,  training time: 2.33
progress:  98%|[34m[0m| 49/50 [02:00<00:02,  2.34s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.34s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.42s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob4/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob4 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 12 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]12.0
12.0
12.0
12.0
                                                Episode 1	 reward: -16.24	 makespan: 1607.50	 Mean_loss: 0.99348873,  training time: 5.73
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:41,  5.74s/it]                                                        Episode 2	 reward: -16.03	 makespan: 1586.75	 Mean_loss: 1.29865074,  training time: 2.89
progress:   2%|[34m         [0m| 1/50 [00:08<04:41,  5.74s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:15,  4.07s/it]                                                        Episode 3	 reward: -15.62	 makespan: 1546.75	 Mean_loss: 1.25265360,  training time: 2.78
progress:   4%|[34m         [0m| 2/50 [00:11<03:15,  4.07s/it]progress:   6%|[34m         [0m| 3/50 [00:11<02:43,  3.48s/it]                                                        Episode 4	 reward: -16.29	 makespan: 1612.50	 Mean_loss: 1.53607368,  training time: 2.88
progress:   6%|[34m         [0m| 3/50 [00:14<02:43,  3.48s/it]progress:   8%|[34m         [0m| 4/50 [00:14<02:29,  3.24s/it]                                                        Episode 5	 reward: -14.97	 makespan: 1481.75	 Mean_loss: 1.21166337,  training time: 2.95
progress:   8%|[34m         [0m| 4/50 [00:17<02:29,  3.24s/it]progress:  10%|[34m         [0m| 5/50 [00:17<02:21,  3.14s/it]                                                        Episode 6	 reward: -15.11	 makespan: 1495.75	 Mean_loss: 1.11795700,  training time: 2.80
progress:  10%|[34m         [0m| 5/50 [00:20<02:21,  3.14s/it]progress:  12%|[34m        [0m| 6/50 [00:20<02:13,  3.02s/it]                                                        Episode 7	 reward: -15.49	 makespan: 1533.75	 Mean_loss: 0.95756280,  training time: 2.79
progress:  12%|[34m        [0m| 6/50 [00:22<02:13,  3.02s/it]progress:  14%|[34m        [0m| 7/50 [00:22<02:06,  2.95s/it]                                                        Episode 8	 reward: -15.13	 makespan: 1498.25	 Mean_loss: 0.77246112,  training time: 2.76
progress:  14%|[34m        [0m| 7/50 [00:25<02:06,  2.95s/it]progress:  16%|[34m        [0m| 8/50 [00:25<02:01,  2.89s/it]                                                        Episode 9	 reward: -14.81	 makespan: 1466.25	 Mean_loss: 0.64308918,  training time: 2.78
progress:  16%|[34m        [0m| 8/50 [00:28<02:01,  2.89s/it]progress:  18%|[34m        [0m| 9/50 [00:28<01:57,  2.85s/it]                                                        Episode 10	 reward: -14.73	 makespan: 1458.50	 Mean_loss: 0.60248011,  training time: 2.80
progress:  18%|[34m        [0m| 9/50 [00:31<01:57,  2.85s/it]progress:  20%|[34m        [0m| 10/50 [00:31<01:53,  2.84s/it]                                                         Episode 11	 reward: -14.45	 makespan: 1430.75	 Mean_loss: 0.56246549,  training time: 2.77
progress:  20%|[34m        [0m| 10/50 [00:33<01:53,  2.84s/it]progress:  22%|[34m       [0m| 11/50 [00:33<01:49,  2.82s/it]                                                         Episode 12	 reward: -14.90	 makespan: 1475.00	 Mean_loss: 0.51783139,  training time: 2.77
progress:  22%|[34m       [0m| 11/50 [00:36<01:49,  2.82s/it]progress:  24%|[34m       [0m| 12/50 [00:36<01:46,  2.80s/it]                                                         Episode 13	 reward: -14.72	 makespan: 1457.25	 Mean_loss: 0.56678391,  training time: 2.78
progress:  24%|[34m       [0m| 12/50 [00:39<01:46,  2.80s/it]progress:  26%|[34m       [0m| 13/50 [00:39<01:43,  2.80s/it]                                                         Episode 14	 reward: -14.68	 makespan: 1453.25	 Mean_loss: 0.47044846,  training time: 2.78
progress:  26%|[34m       [0m| 13/50 [00:42<01:43,  2.80s/it]progress:  28%|[34m       [0m| 14/50 [00:42<01:40,  2.79s/it]                                                         Episode 15	 reward: -14.84	 makespan: 1469.50	 Mean_loss: 0.36667714,  training time: 2.75
progress:  28%|[34m       [0m| 14/50 [00:45<01:40,  2.79s/it]progress:  30%|[34m       [0m| 15/50 [00:45<01:37,  2.78s/it]                                                         Episode 16	 reward: -15.38	 makespan: 1523.00	 Mean_loss: 0.55213732,  training time: 2.76
progress:  30%|[34m       [0m| 15/50 [00:47<01:37,  2.78s/it]progress:  32%|[34m      [0m| 16/50 [00:47<01:34,  2.78s/it]                                                         Episode 17	 reward: -15.31	 makespan: 1515.75	 Mean_loss: 0.47061926,  training time: 2.78
progress:  32%|[34m      [0m| 16/50 [00:50<01:34,  2.78s/it]progress:  34%|[34m      [0m| 17/50 [00:50<01:31,  2.78s/it]                                                         Episode 18	 reward: -14.57	 makespan: 1442.75	 Mean_loss: 0.24231547,  training time: 2.77
progress:  34%|[34m      [0m| 17/50 [00:53<01:31,  2.78s/it]progress:  36%|[34m      [0m| 18/50 [00:53<01:28,  2.78s/it]                                                         Episode 19	 reward: -14.82	 makespan: 1467.25	 Mean_loss: 0.33415589,  training time: 2.75
progress:  36%|[34m      [0m| 18/50 [00:56<01:28,  2.78s/it]progress:  38%|[34m      [0m| 19/50 [00:56<01:25,  2.77s/it]                                                         Episode 20	 reward: -14.79	 makespan: 1464.25	 Mean_loss: 0.27195987,  training time: 2.74
progress:  38%|[34m      [0m| 19/50 [00:58<01:25,  2.77s/it]progress:  40%|[34m      [0m| 20/50 [00:58<01:22,  2.76s/it]                                                         Episode 21	 reward: -15.00	 makespan: 1485.25	 Mean_loss: 0.20520625,  training time: 2.71
progress:  40%|[34m      [0m| 20/50 [01:01<01:22,  2.76s/it]progress:  42%|[34m     [0m| 21/50 [01:01<01:19,  2.75s/it]                                                         Episode 22	 reward: -13.91	 makespan: 1377.50	 Mean_loss: 0.26534772,  training time: 2.73
progress:  42%|[34m     [0m| 21/50 [01:04<01:19,  2.75s/it]progress:  44%|[34m     [0m| 22/50 [01:04<01:16,  2.74s/it]                                                         Episode 23	 reward: -14.40	 makespan: 1425.75	 Mean_loss: 0.18883878,  training time: 2.73
progress:  44%|[34m     [0m| 22/50 [01:07<01:16,  2.74s/it]progress:  46%|[34m     [0m| 23/50 [01:07<01:13,  2.74s/it]                                                         Episode 24	 reward: -14.02	 makespan: 1387.50	 Mean_loss: 0.16531400,  training time: 2.75
progress:  46%|[34m     [0m| 23/50 [01:09<01:13,  2.74s/it]progress:  48%|[34m     [0m| 24/50 [01:09<01:11,  2.74s/it]                                                         Episode 25	 reward: -14.18	 makespan: 1404.25	 Mean_loss: 0.11172105,  training time: 2.77
progress:  48%|[34m     [0m| 24/50 [01:12<01:11,  2.74s/it]progress:  50%|[34m     [0m| 25/50 [01:12<01:08,  2.75s/it]                                                         Episode 26	 reward: -13.46	 makespan: 1332.25	 Mean_loss: 0.11825327,  training time: 2.72
progress:  50%|[34m     [0m| 25/50 [01:15<01:08,  2.75s/it]progress:  52%|[34m    [0m| 26/50 [01:15<01:05,  2.74s/it]                                                         Episode 27	 reward: -14.37	 makespan: 1423.00	 Mean_loss: 0.13180360,  training time: 2.76
progress:  52%|[34m    [0m| 26/50 [01:18<01:05,  2.74s/it]progress:  54%|[34m    [0m| 27/50 [01:18<01:03,  2.75s/it]                                                         Episode 28	 reward: -14.34	 makespan: 1419.25	 Mean_loss: 0.09768063,  training time: 2.74
progress:  54%|[34m    [0m| 27/50 [01:20<01:03,  2.75s/it]progress:  56%|[34m    [0m| 28/50 [01:20<01:00,  2.75s/it]                                                         Episode 29	 reward: -14.26	 makespan: 1411.25	 Mean_loss: 0.11675748,  training time: 2.72
progress:  56%|[34m    [0m| 28/50 [01:23<01:00,  2.75s/it]progress:  58%|[34m    [0m| 29/50 [01:23<00:57,  2.74s/it]                                                         Episode 30	 reward: -13.78	 makespan: 1363.75	 Mean_loss: 0.10191780,  training time: 2.75
progress:  58%|[34m    [0m| 29/50 [01:26<00:57,  2.74s/it]progress:  60%|[34m    [0m| 30/50 [01:26<00:54,  2.74s/it]                                                         Episode 31	 reward: -13.75	 makespan: 1361.50	 Mean_loss: 0.09157749,  training time: 2.73
progress:  60%|[34m    [0m| 30/50 [01:28<00:54,  2.74s/it]progress:  62%|[34m   [0m| 31/50 [01:28<00:52,  2.74s/it]                                                         Episode 32	 reward: -13.63	 makespan: 1349.75	 Mean_loss: 0.06588678,  training time: 2.74
progress:  62%|[34m   [0m| 31/50 [01:31<00:52,  2.74s/it]progress:  64%|[34m   [0m| 32/50 [01:31<00:49,  2.74s/it]                                                         Episode 33	 reward: -14.32	 makespan: 1417.50	 Mean_loss: 0.09102564,  training time: 2.77
progress:  64%|[34m   [0m| 32/50 [01:34<00:49,  2.74s/it]progress:  66%|[34m   [0m| 33/50 [01:34<00:46,  2.75s/it]                                                         Episode 34	 reward: -14.30	 makespan: 1415.25	 Mean_loss: 0.10819445,  training time: 2.77
progress:  66%|[34m   [0m| 33/50 [01:37<00:46,  2.75s/it]progress:  68%|[34m   [0m| 34/50 [01:37<00:44,  2.76s/it]                                                         Episode 35	 reward: -14.14	 makespan: 1399.50	 Mean_loss: 0.08805476,  training time: 2.78
progress:  68%|[34m   [0m| 34/50 [01:40<00:44,  2.76s/it]progress:  70%|[34m   [0m| 35/50 [01:40<00:41,  2.76s/it]                                                         Episode 36	 reward: -14.21	 makespan: 1406.75	 Mean_loss: 0.08659638,  training time: 2.76
progress:  70%|[34m   [0m| 35/50 [01:42<00:41,  2.76s/it]progress:  72%|[34m  [0m| 36/50 [01:42<00:38,  2.76s/it]                                                         Episode 37	 reward: -14.37	 makespan: 1422.75	 Mean_loss: 0.08248169,  training time: 2.77
progress:  72%|[34m  [0m| 36/50 [01:45<00:38,  2.76s/it]progress:  74%|[34m  [0m| 37/50 [01:45<00:35,  2.76s/it]                                                         Episode 38	 reward: -14.58	 makespan: 1443.75	 Mean_loss: 0.14187813,  training time: 2.76
progress:  74%|[34m  [0m| 37/50 [01:48<00:35,  2.76s/it]progress:  76%|[34m  [0m| 38/50 [01:48<00:33,  2.76s/it]                                                         Episode 39	 reward: -14.03	 makespan: 1389.25	 Mean_loss: 0.08882020,  training time: 2.77
progress:  76%|[34m  [0m| 38/50 [01:51<00:33,  2.76s/it]progress:  78%|[34m  [0m| 39/50 [01:51<00:30,  2.76s/it]                                                         Episode 40	 reward: -14.57	 makespan: 1442.50	 Mean_loss: 0.08710708,  training time: 2.74
progress:  78%|[34m  [0m| 39/50 [01:53<00:30,  2.76s/it]progress:  80%|[34m  [0m| 40/50 [01:53<00:27,  2.76s/it]                                                         Episode 41	 reward: -14.11	 makespan: 1397.25	 Mean_loss: 0.11218803,  training time: 2.75
progress:  80%|[34m  [0m| 40/50 [01:56<00:27,  2.76s/it]progress:  82%|[34m [0m| 41/50 [01:56<00:24,  2.76s/it]                                                         Episode 42	 reward: -14.18	 makespan: 1403.50	 Mean_loss: 0.08568881,  training time: 2.75
progress:  82%|[34m [0m| 41/50 [01:59<00:24,  2.76s/it]progress:  84%|[34m [0m| 42/50 [01:59<00:22,  2.75s/it]                                                         Episode 43	 reward: -15.06	 makespan: 1490.50	 Mean_loss: 0.09036255,  training time: 2.79
progress:  84%|[34m [0m| 42/50 [02:02<00:22,  2.75s/it]progress:  86%|[34m [0m| 43/50 [02:02<00:19,  2.77s/it]                                                         Episode 44	 reward: -14.40	 makespan: 1425.50	 Mean_loss: 0.06069512,  training time: 2.78
progress:  86%|[34m [0m| 43/50 [02:04<00:19,  2.77s/it]progress:  88%|[34m [0m| 44/50 [02:04<00:16,  2.77s/it]                                                         Episode 45	 reward: -14.34	 makespan: 1419.75	 Mean_loss: 0.06739751,  training time: 2.80
progress:  88%|[34m [0m| 44/50 [02:07<00:16,  2.77s/it]progress:  90%|[34m [0m| 45/50 [02:07<00:13,  2.78s/it]                                                         Episode 46	 reward: -14.19	 makespan: 1404.50	 Mean_loss: 0.06288792,  training time: 2.82
progress:  90%|[34m [0m| 45/50 [02:10<00:13,  2.78s/it]progress:  92%|[34m[0m| 46/50 [02:10<00:11,  2.79s/it]                                                         Episode 47	 reward: -13.98	 makespan: 1383.75	 Mean_loss: 0.07858978,  training time: 2.78
progress:  92%|[34m[0m| 46/50 [02:13<00:11,  2.79s/it]progress:  94%|[34m[0m| 47/50 [02:13<00:08,  2.79s/it]                                                         Episode 48	 reward: -14.14	 makespan: 1400.00	 Mean_loss: 0.05771669,  training time: 2.80
progress:  94%|[34m[0m| 47/50 [02:16<00:08,  2.79s/it]progress:  96%|[34m[0m| 48/50 [02:16<00:05,  2.79s/it]                                                         Episode 49	 reward: -14.33	 makespan: 1418.25	 Mean_loss: 0.04874559,  training time: 2.78
progress:  96%|[34m[0m| 48/50 [02:18<00:05,  2.79s/it]progress:  98%|[34m[0m| 49/50 [02:18<00:02,  2.79s/it]                                                         Episode 50	 reward: -14.43	 makespan: 1428.75	 Mean_loss: 0.05990018,  training time: 2.80
progress:  98%|[34m[0m| 49/50 [02:21<00:02,  2.79s/it]progress: 100%|[34m[0m| 50/50 [02:21<00:00,  2.79s/it]progress: 100%|[34m[0m| 50/50 [02:21<00:00,  2.83s/it]
+ for model in '$first_model_name' '$last_model_name'
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job4 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 4 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]4.0
4.0
4.0
4.0
                                                Episode 1	 reward: -6.22	 makespan: 616.25	 Mean_loss: 2.87520337,  training time: 4.84
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:57,  4.85s/it]                                                        Episode 2	 reward: -5.82	 makespan: 576.00	 Mean_loss: 1.15271974,  training time: 1.10
progress:   2%|[34m         [0m| 1/50 [00:05<03:57,  4.85s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:07,  2.66s/it]                                                        Episode 3	 reward: -6.16	 makespan: 609.50	 Mean_loss: 0.50282061,  training time: 1.06
progress:   4%|[34m         [0m| 2/50 [00:07<02:07,  2.66s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:30,  1.93s/it]                                                        Episode 4	 reward: -6.03	 makespan: 597.00	 Mean_loss: 0.26574308,  training time: 1.15
progress:   6%|[34m         [0m| 3/50 [00:08<01:30,  1.93s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:14,  1.62s/it]                                                        Episode 5	 reward: -7.09	 makespan: 702.25	 Mean_loss: 0.32308492,  training time: 1.13
progress:   8%|[34m         [0m| 4/50 [00:09<01:14,  1.62s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:05,  1.45s/it]                                                        Episode 6	 reward: -6.59	 makespan: 652.50	 Mean_loss: 0.33705378,  training time: 1.06
progress:  10%|[34m         [0m| 5/50 [00:10<01:05,  1.45s/it]progress:  12%|[34m        [0m| 6/50 [00:10<00:57,  1.32s/it]                                                        Episode 7	 reward: -6.57	 makespan: 650.50	 Mean_loss: 0.24000625,  training time: 1.03
progress:  12%|[34m        [0m| 6/50 [00:11<00:57,  1.32s/it]progress:  14%|[34m        [0m| 7/50 [00:11<00:52,  1.22s/it]                                                        Episode 8	 reward: -6.77	 makespan: 670.50	 Mean_loss: 0.15929820,  training time: 1.06
progress:  14%|[34m        [0m| 7/50 [00:12<00:52,  1.22s/it]progress:  16%|[34m        [0m| 8/50 [00:12<00:49,  1.17s/it]                                                        Episode 9	 reward: -6.40	 makespan: 633.75	 Mean_loss: 0.15453571,  training time: 1.06
progress:  16%|[34m        [0m| 8/50 [00:13<00:49,  1.17s/it]progress:  18%|[34m        [0m| 9/50 [00:13<00:46,  1.14s/it]                                                        Episode 10	 reward: -6.13	 makespan: 606.50	 Mean_loss: 0.12028593,  training time: 1.11
progress:  18%|[34m        [0m| 9/50 [00:14<00:46,  1.14s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:45,  1.13s/it]                                                         Episode 11	 reward: -6.54	 makespan: 647.50	 Mean_loss: 0.19611970,  training time: 1.08
progress:  20%|[34m        [0m| 10/50 [00:15<00:45,  1.13s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:43,  1.11s/it]                                                         Episode 12	 reward: -6.25	 makespan: 619.00	 Mean_loss: 0.13075432,  training time: 1.66
progress:  22%|[34m       [0m| 11/50 [00:17<00:43,  1.11s/it]progress:  24%|[34m       [0m| 12/50 [00:17<00:48,  1.28s/it]                                                         Episode 13	 reward: -6.75	 makespan: 668.25	 Mean_loss: 0.16067722,  training time: 1.11
progress:  24%|[34m       [0m| 12/50 [00:18<00:48,  1.28s/it]progress:  26%|[34m       [0m| 13/50 [00:18<00:45,  1.23s/it]                                                         Episode 14	 reward: -6.74	 makespan: 667.75	 Mean_loss: 0.12305248,  training time: 1.13
progress:  26%|[34m       [0m| 13/50 [00:19<00:45,  1.23s/it]progress:  28%|[34m       [0m| 14/50 [00:19<00:43,  1.20s/it]                                                         Episode 15	 reward: -6.11	 makespan: 604.50	 Mean_loss: 0.10042624,  training time: 1.09
progress:  28%|[34m       [0m| 14/50 [00:20<00:43,  1.20s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:40,  1.17s/it]                                                         Episode 16	 reward: -6.32	 makespan: 625.50	 Mean_loss: 0.10922652,  training time: 1.04
progress:  30%|[34m       [0m| 15/50 [00:21<00:40,  1.17s/it]progress:  32%|[34m      [0m| 16/50 [00:21<00:38,  1.13s/it]                                                         Episode 17	 reward: -6.21	 makespan: 614.50	 Mean_loss: 0.13326937,  training time: 1.04
progress:  32%|[34m      [0m| 16/50 [00:22<00:38,  1.13s/it]progress:  34%|[34m      [0m| 17/50 [00:22<00:36,  1.10s/it]                                                         Episode 18	 reward: -6.58	 makespan: 651.25	 Mean_loss: 0.08588675,  training time: 1.02
progress:  34%|[34m      [0m| 17/50 [00:23<00:36,  1.10s/it]progress:  36%|[34m      [0m| 18/50 [00:23<00:34,  1.08s/it]                                                         Episode 19	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.18982482,  training time: 0.98
progress:  36%|[34m      [0m| 18/50 [00:24<00:34,  1.08s/it]progress:  38%|[34m      [0m| 19/50 [00:24<00:32,  1.05s/it]                                                         Episode 20	 reward: -6.16	 makespan: 610.00	 Mean_loss: 0.18282749,  training time: 1.01
progress:  38%|[34m      [0m| 19/50 [00:25<00:32,  1.05s/it]progress:  40%|[34m      [0m| 20/50 [00:25<00:31,  1.04s/it]                                                         Episode 21	 reward: -6.37	 makespan: 630.25	 Mean_loss: 0.12614334,  training time: 1.00
progress:  40%|[34m      [0m| 20/50 [00:26<00:31,  1.04s/it]progress:  42%|[34m     [0m| 21/50 [00:26<00:29,  1.03s/it]                                                         Episode 22	 reward: -5.68	 makespan: 562.25	 Mean_loss: 0.06919801,  training time: 1.05
progress:  42%|[34m     [0m| 21/50 [00:27<00:29,  1.03s/it]progress:  44%|[34m     [0m| 22/50 [00:27<00:28,  1.03s/it]                                                         Episode 23	 reward: -6.50	 makespan: 643.50	 Mean_loss: 0.12713563,  training time: 1.05
progress:  44%|[34m     [0m| 22/50 [00:28<00:28,  1.03s/it]progress:  46%|[34m     [0m| 23/50 [00:28<00:28,  1.04s/it]                                                         Episode 24	 reward: -5.66	 makespan: 560.00	 Mean_loss: 0.15611814,  training time: 1.06
progress:  46%|[34m     [0m| 23/50 [00:29<00:28,  1.04s/it]progress:  48%|[34m     [0m| 24/50 [00:29<00:27,  1.04s/it]                                                         Episode 25	 reward: -6.41	 makespan: 634.25	 Mean_loss: 0.14642900,  training time: 1.06
progress:  48%|[34m     [0m| 24/50 [00:31<00:27,  1.04s/it]progress:  50%|[34m     [0m| 25/50 [00:31<00:26,  1.05s/it]                                                         Episode 26	 reward: -6.17	 makespan: 610.75	 Mean_loss: 0.06555866,  training time: 1.02
progress:  50%|[34m     [0m| 25/50 [00:32<00:26,  1.05s/it]progress:  52%|[34m    [0m| 26/50 [00:32<00:24,  1.04s/it]                                                         Episode 27	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.10384929,  training time: 1.06
progress:  52%|[34m    [0m| 26/50 [00:33<00:24,  1.04s/it]progress:  54%|[34m    [0m| 27/50 [00:33<00:24,  1.05s/it]                                                         Episode 28	 reward: -6.40	 makespan: 633.25	 Mean_loss: 0.14736341,  training time: 1.06
progress:  54%|[34m    [0m| 27/50 [00:34<00:24,  1.05s/it]progress:  56%|[34m    [0m| 28/50 [00:34<00:23,  1.05s/it]                                                         Episode 29	 reward: -6.57	 makespan: 650.50	 Mean_loss: 0.07748929,  training time: 1.08
progress:  56%|[34m    [0m| 28/50 [00:35<00:23,  1.05s/it]progress:  58%|[34m    [0m| 29/50 [00:35<00:22,  1.06s/it]                                                         Episode 30	 reward: -6.12	 makespan: 606.00	 Mean_loss: 0.12413366,  training time: 1.05
progress:  58%|[34m    [0m| 29/50 [00:36<00:22,  1.06s/it]progress:  60%|[34m    [0m| 30/50 [00:36<00:21,  1.06s/it]                                                         Episode 31	 reward: -6.31	 makespan: 624.75	 Mean_loss: 0.15978600,  training time: 1.04
progress:  60%|[34m    [0m| 30/50 [00:37<00:21,  1.06s/it]progress:  62%|[34m   [0m| 31/50 [00:37<00:20,  1.05s/it]                                                         Episode 32	 reward: -5.70	 makespan: 564.75	 Mean_loss: 0.08069512,  training time: 1.04
progress:  62%|[34m   [0m| 31/50 [00:38<00:20,  1.05s/it]progress:  64%|[34m   [0m| 32/50 [00:38<00:18,  1.05s/it]                                                         Episode 33	 reward: -5.86	 makespan: 580.00	 Mean_loss: 0.07573104,  training time: 1.04
progress:  64%|[34m   [0m| 32/50 [00:39<00:18,  1.05s/it]progress:  66%|[34m   [0m| 33/50 [00:39<00:17,  1.05s/it]                                                         Episode 34	 reward: -5.57	 makespan: 551.00	 Mean_loss: 0.05608904,  training time: 1.06
progress:  66%|[34m   [0m| 33/50 [00:40<00:17,  1.05s/it]progress:  68%|[34m   [0m| 34/50 [00:40<00:16,  1.05s/it]                                                         Episode 35	 reward: -6.38	 makespan: 631.75	 Mean_loss: 0.11079784,  training time: 1.05
progress:  68%|[34m   [0m| 34/50 [00:41<00:16,  1.05s/it]progress:  70%|[34m   [0m| 35/50 [00:41<00:15,  1.05s/it]                                                         Episode 36	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.11683448,  training time: 1.07
progress:  70%|[34m   [0m| 35/50 [00:42<00:15,  1.05s/it]progress:  72%|[34m  [0m| 36/50 [00:42<00:14,  1.06s/it]                                                         Episode 37	 reward: -5.71	 makespan: 565.00	 Mean_loss: 0.09219617,  training time: 1.05
progress:  72%|[34m  [0m| 36/50 [00:43<00:14,  1.06s/it]progress:  74%|[34m  [0m| 37/50 [00:43<00:13,  1.05s/it]                                                         Episode 38	 reward: -5.74	 makespan: 568.75	 Mean_loss: 0.06454451,  training time: 1.05
progress:  74%|[34m  [0m| 37/50 [00:44<00:13,  1.05s/it]progress:  76%|[34m  [0m| 38/50 [00:44<00:12,  1.05s/it]                                                         Episode 39	 reward: -5.85	 makespan: 579.25	 Mean_loss: 0.04906267,  training time: 1.04
progress:  76%|[34m  [0m| 38/50 [00:45<00:12,  1.05s/it]progress:  78%|[34m  [0m| 39/50 [00:45<00:11,  1.05s/it]                                                         Episode 40	 reward: -5.59	 makespan: 553.50	 Mean_loss: 0.04290821,  training time: 1.05
progress:  78%|[34m  [0m| 39/50 [00:46<00:11,  1.05s/it]progress:  80%|[34m  [0m| 40/50 [00:46<00:10,  1.05s/it]                                                         Episode 41	 reward: -5.51	 makespan: 545.25	 Mean_loss: 0.08245926,  training time: 1.06
progress:  80%|[34m  [0m| 40/50 [00:47<00:10,  1.05s/it]progress:  82%|[34m [0m| 41/50 [00:47<00:09,  1.06s/it]                                                         Episode 42	 reward: -5.10	 makespan: 505.00	 Mean_loss: 0.03406460,  training time: 1.05
progress:  82%|[34m [0m| 41/50 [00:48<00:09,  1.06s/it]progress:  84%|[34m [0m| 42/50 [00:48<00:08,  1.05s/it]                                                         Episode 43	 reward: -5.22	 makespan: 516.50	 Mean_loss: 0.03334414,  training time: 1.03
progress:  84%|[34m [0m| 42/50 [00:49<00:08,  1.05s/it]progress:  86%|[34m [0m| 43/50 [00:49<00:07,  1.05s/it]                                                         Episode 44	 reward: -4.91	 makespan: 486.50	 Mean_loss: 0.05575156,  training time: 1.01
progress:  86%|[34m [0m| 43/50 [00:50<00:07,  1.05s/it]progress:  88%|[34m [0m| 44/50 [00:50<00:06,  1.04s/it]                                                         Episode 45	 reward: -5.13	 makespan: 508.25	 Mean_loss: 0.05967157,  training time: 1.03
progress:  88%|[34m [0m| 44/50 [00:51<00:06,  1.04s/it]progress:  90%|[34m [0m| 45/50 [00:51<00:05,  1.04s/it]                                                         Episode 46	 reward: -5.36	 makespan: 531.00	 Mean_loss: 0.03222146,  training time: 1.10
progress:  90%|[34m [0m| 45/50 [00:53<00:05,  1.04s/it]progress:  92%|[34m[0m| 46/50 [00:53<00:04,  1.06s/it]                                                         Episode 47	 reward: -5.28	 makespan: 522.50	 Mean_loss: 0.06481440,  training time: 1.07
progress:  92%|[34m[0m| 46/50 [00:54<00:04,  1.06s/it]progress:  94%|[34m[0m| 47/50 [00:54<00:03,  1.06s/it]                                                         Episode 48	 reward: -5.72	 makespan: 566.00	 Mean_loss: 0.06217759,  training time: 1.06
progress:  94%|[34m[0m| 47/50 [00:55<00:03,  1.06s/it]progress:  96%|[34m[0m| 48/50 [00:55<00:02,  1.06s/it]                                                         Episode 49	 reward: -5.22	 makespan: 517.00	 Mean_loss: 0.05238783,  training time: 1.05
progress:  96%|[34m[0m| 48/50 [00:56<00:02,  1.06s/it]progress:  98%|[34m[0m| 49/50 [00:56<00:01,  1.06s/it]                                                         Episode 50	 reward: -5.12	 makespan: 506.75	 Mean_loss: 0.04544616,  training time: 1.02
progress:  98%|[34m[0m| 49/50 [00:57<00:01,  1.06s/it]progress: 100%|[34m[0m| 50/50 [00:57<00:00,  1.05s/it]progress: 100%|[34m[0m| 50/50 [00:57<00:00,  1.15s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job6 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 6 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]6.0
6.0
6.0
6.0
                                                Episode 1	 reward: -8.89	 makespan: 880.25	 Mean_loss: 2.32966948,  training time: 3.86
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:09,  3.87s/it]                                                        Episode 2	 reward: -7.62	 makespan: 754.75	 Mean_loss: 1.40274882,  training time: 1.52
progress:   2%|[34m         [0m| 1/50 [00:05<03:09,  3.87s/it]progress:   4%|[34m         [0m| 2/50 [00:05<01:59,  2.49s/it]                                                        Episode 3	 reward: -7.68	 makespan: 760.50	 Mean_loss: 0.64778459,  training time: 1.48
progress:   4%|[34m         [0m| 2/50 [00:06<01:59,  2.49s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:35,  2.03s/it]                                                        Episode 4	 reward: -7.83	 makespan: 774.75	 Mean_loss: 0.34940082,  training time: 1.46
progress:   6%|[34m         [0m| 3/50 [00:08<01:35,  2.03s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:23,  1.81s/it]                                                        Episode 5	 reward: -7.37	 makespan: 729.75	 Mean_loss: 0.14803775,  training time: 1.64
progress:   8%|[34m         [0m| 4/50 [00:09<01:23,  1.81s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:18,  1.75s/it]                                                        Episode 6	 reward: -7.50	 makespan: 742.25	 Mean_loss: 0.14798091,  training time: 1.48
progress:  10%|[34m         [0m| 5/50 [00:11<01:18,  1.75s/it]progress:  12%|[34m        [0m| 6/50 [00:11<01:12,  1.66s/it]                                                        Episode 7	 reward: -7.69	 makespan: 761.25	 Mean_loss: 0.19798863,  training time: 1.48
progress:  12%|[34m        [0m| 6/50 [00:12<01:12,  1.66s/it]progress:  14%|[34m        [0m| 7/50 [00:12<01:08,  1.60s/it]                                                        Episode 8	 reward: -7.54	 makespan: 746.75	 Mean_loss: 0.13117725,  training time: 1.50
progress:  14%|[34m        [0m| 7/50 [00:14<01:08,  1.60s/it]progress:  16%|[34m        [0m| 8/50 [00:14<01:05,  1.57s/it]                                                        Episode 9	 reward: -7.46	 makespan: 738.25	 Mean_loss: 0.11547669,  training time: 1.46
progress:  16%|[34m        [0m| 8/50 [00:15<01:05,  1.57s/it]progress:  18%|[34m        [0m| 9/50 [00:15<01:02,  1.53s/it]                                                        Episode 10	 reward: -7.23	 makespan: 715.75	 Mean_loss: 0.09973365,  training time: 1.46
progress:  18%|[34m        [0m| 9/50 [00:17<01:02,  1.53s/it]progress:  20%|[34m        [0m| 10/50 [00:17<01:00,  1.51s/it]                                                         Episode 11	 reward: -7.75	 makespan: 767.25	 Mean_loss: 0.16477354,  training time: 1.46
progress:  20%|[34m        [0m| 10/50 [00:18<01:00,  1.51s/it]progress:  22%|[34m       [0m| 11/50 [00:18<00:58,  1.49s/it]                                                         Episode 12	 reward: -6.94	 makespan: 686.75	 Mean_loss: 0.12246575,  training time: 1.46
progress:  22%|[34m       [0m| 11/50 [00:20<00:58,  1.49s/it]progress:  24%|[34m       [0m| 12/50 [00:20<00:56,  1.49s/it]                                                         Episode 13	 reward: -7.19	 makespan: 712.25	 Mean_loss: 0.10144956,  training time: 1.48
progress:  24%|[34m       [0m| 12/50 [00:21<00:56,  1.49s/it]progress:  26%|[34m       [0m| 13/50 [00:21<00:55,  1.49s/it]                                                         Episode 14	 reward: -7.61	 makespan: 753.00	 Mean_loss: 0.09646730,  training time: 1.45
progress:  26%|[34m       [0m| 13/50 [00:23<00:55,  1.49s/it]progress:  28%|[34m       [0m| 14/50 [00:23<00:53,  1.48s/it]                                                         Episode 15	 reward: -7.36	 makespan: 728.75	 Mean_loss: 0.12519462,  training time: 1.46
progress:  28%|[34m       [0m| 14/50 [00:24<00:53,  1.48s/it]progress:  30%|[34m       [0m| 15/50 [00:24<00:51,  1.47s/it]                                                         Episode 16	 reward: -7.23	 makespan: 716.00	 Mean_loss: 0.09699574,  training time: 1.44
progress:  30%|[34m       [0m| 15/50 [00:26<00:51,  1.47s/it]progress:  32%|[34m      [0m| 16/50 [00:26<00:49,  1.46s/it]                                                         Episode 17	 reward: -7.11	 makespan: 704.00	 Mean_loss: 0.08799763,  training time: 1.60
progress:  32%|[34m      [0m| 16/50 [00:27<00:49,  1.46s/it]progress:  34%|[34m      [0m| 17/50 [00:27<00:49,  1.50s/it]                                                         Episode 18	 reward: -7.36	 makespan: 728.50	 Mean_loss: 0.08893868,  training time: 1.44
progress:  34%|[34m      [0m| 17/50 [00:29<00:49,  1.50s/it]progress:  36%|[34m      [0m| 18/50 [00:29<00:47,  1.49s/it]                                                         Episode 19	 reward: -7.48	 makespan: 741.00	 Mean_loss: 0.09538110,  training time: 1.48
progress:  36%|[34m      [0m| 18/50 [00:30<00:47,  1.49s/it]progress:  38%|[34m      [0m| 19/50 [00:30<00:45,  1.48s/it]                                                         Episode 20	 reward: -7.71	 makespan: 763.00	 Mean_loss: 0.15097308,  training time: 1.46
progress:  38%|[34m      [0m| 19/50 [00:32<00:45,  1.48s/it]progress:  40%|[34m      [0m| 20/50 [00:32<00:44,  1.48s/it]                                                         Episode 21	 reward: -6.98	 makespan: 691.00	 Mean_loss: 0.10907214,  training time: 1.44
progress:  40%|[34m      [0m| 20/50 [00:33<00:44,  1.48s/it]progress:  42%|[34m     [0m| 21/50 [00:33<00:42,  1.46s/it]                                                         Episode 22	 reward: -7.67	 makespan: 759.25	 Mean_loss: 0.11453631,  training time: 1.49
progress:  42%|[34m     [0m| 21/50 [00:35<00:42,  1.46s/it]progress:  44%|[34m     [0m| 22/50 [00:35<00:41,  1.47s/it]                                                         Episode 23	 reward: -7.34	 makespan: 726.25	 Mean_loss: 0.10824247,  training time: 1.45
progress:  44%|[34m     [0m| 22/50 [00:36<00:41,  1.47s/it]progress:  46%|[34m     [0m| 23/50 [00:36<00:39,  1.47s/it]                                                         Episode 24	 reward: -7.05	 makespan: 697.50	 Mean_loss: 0.10522097,  training time: 1.45
progress:  46%|[34m     [0m| 23/50 [00:37<00:39,  1.47s/it]progress:  48%|[34m     [0m| 24/50 [00:37<00:38,  1.46s/it]                                                         Episode 25	 reward: -6.80	 makespan: 672.75	 Mean_loss: 0.08828866,  training time: 1.46
progress:  48%|[34m     [0m| 24/50 [00:39<00:38,  1.46s/it]progress:  50%|[34m     [0m| 25/50 [00:39<00:36,  1.46s/it]                                                         Episode 26	 reward: -7.20	 makespan: 712.75	 Mean_loss: 0.05749113,  training time: 1.46
progress:  50%|[34m     [0m| 25/50 [00:40<00:36,  1.46s/it]progress:  52%|[34m    [0m| 26/50 [00:40<00:35,  1.46s/it]                                                         Episode 27	 reward: -7.05	 makespan: 698.00	 Mean_loss: 0.06672115,  training time: 1.48
progress:  52%|[34m    [0m| 26/50 [00:42<00:35,  1.46s/it]progress:  54%|[34m    [0m| 27/50 [00:42<00:33,  1.47s/it]                                                         Episode 28	 reward: -7.03	 makespan: 696.25	 Mean_loss: 0.06244790,  training time: 1.48
progress:  54%|[34m    [0m| 27/50 [00:43<00:33,  1.47s/it]progress:  56%|[34m    [0m| 28/50 [00:43<00:32,  1.47s/it]                                                         Episode 29	 reward: -7.04	 makespan: 696.75	 Mean_loss: 0.03846617,  training time: 1.46
progress:  56%|[34m    [0m| 28/50 [00:45<00:32,  1.47s/it]progress:  58%|[34m    [0m| 29/50 [00:45<00:30,  1.47s/it]                                                         Episode 30	 reward: -6.87	 makespan: 680.25	 Mean_loss: 0.05671817,  training time: 1.44
progress:  58%|[34m    [0m| 29/50 [00:46<00:30,  1.47s/it]progress:  60%|[34m    [0m| 30/50 [00:46<00:29,  1.46s/it]                                                         Episode 31	 reward: -7.09	 makespan: 701.75	 Mean_loss: 0.07058687,  training time: 1.45
progress:  60%|[34m    [0m| 30/50 [00:48<00:29,  1.46s/it]progress:  62%|[34m   [0m| 31/50 [00:48<00:27,  1.46s/it]                                                         Episode 32	 reward: -6.99	 makespan: 692.00	 Mean_loss: 0.04342761,  training time: 1.45
progress:  62%|[34m   [0m| 31/50 [00:49<00:27,  1.46s/it]progress:  64%|[34m   [0m| 32/50 [00:49<00:26,  1.46s/it]                                                         Episode 33	 reward: -6.97	 makespan: 690.50	 Mean_loss: 0.03777295,  training time: 1.45
progress:  64%|[34m   [0m| 32/50 [00:51<00:26,  1.46s/it]progress:  66%|[34m   [0m| 33/50 [00:51<00:24,  1.45s/it]                                                         Episode 34	 reward: -6.69	 makespan: 662.00	 Mean_loss: 0.03590114,  training time: 1.45
progress:  66%|[34m   [0m| 33/50 [00:52<00:24,  1.45s/it]progress:  68%|[34m   [0m| 34/50 [00:52<00:23,  1.45s/it]                                                         Episode 35	 reward: -7.00	 makespan: 693.25	 Mean_loss: 0.03796722,  training time: 1.44
progress:  68%|[34m   [0m| 34/50 [00:53<00:23,  1.45s/it]progress:  70%|[34m   [0m| 35/50 [00:53<00:21,  1.45s/it]                                                         Episode 36	 reward: -6.86	 makespan: 679.25	 Mean_loss: 0.02725072,  training time: 1.46
progress:  70%|[34m   [0m| 35/50 [00:55<00:21,  1.45s/it]progress:  72%|[34m  [0m| 36/50 [00:55<00:20,  1.45s/it]                                                         Episode 37	 reward: -6.93	 makespan: 685.75	 Mean_loss: 0.04498957,  training time: 1.44
progress:  72%|[34m  [0m| 36/50 [00:56<00:20,  1.45s/it]progress:  74%|[34m  [0m| 37/50 [00:56<00:18,  1.45s/it]                                                         Episode 38	 reward: -7.33	 makespan: 725.25	 Mean_loss: 0.06744547,  training time: 1.47
progress:  74%|[34m  [0m| 37/50 [00:58<00:18,  1.45s/it]progress:  76%|[34m  [0m| 38/50 [00:58<00:17,  1.46s/it]                                                         Episode 39	 reward: -6.82	 makespan: 675.50	 Mean_loss: 0.05837170,  training time: 1.48
progress:  76%|[34m  [0m| 38/50 [00:59<00:17,  1.46s/it]progress:  78%|[34m  [0m| 39/50 [00:59<00:16,  1.46s/it]                                                         Episode 40	 reward: -6.62	 makespan: 655.25	 Mean_loss: 0.05481594,  training time: 1.46
progress:  78%|[34m  [0m| 39/50 [01:01<00:16,  1.46s/it]progress:  80%|[34m  [0m| 40/50 [01:01<00:14,  1.46s/it]                                                         Episode 41	 reward: -6.83	 makespan: 676.00	 Mean_loss: 0.06164116,  training time: 1.49
progress:  80%|[34m  [0m| 40/50 [01:02<00:14,  1.46s/it]progress:  82%|[34m [0m| 41/50 [01:02<00:13,  1.47s/it]                                                         Episode 42	 reward: -7.03	 makespan: 695.75	 Mean_loss: 0.03487180,  training time: 1.48
progress:  82%|[34m [0m| 41/50 [01:04<00:13,  1.47s/it]progress:  84%|[34m [0m| 42/50 [01:04<00:11,  1.48s/it]                                                         Episode 43	 reward: -6.87	 makespan: 680.50	 Mean_loss: 0.03641590,  training time: 1.40
progress:  84%|[34m [0m| 42/50 [01:05<00:11,  1.48s/it]progress:  86%|[34m [0m| 43/50 [01:05<00:10,  1.45s/it]                                                         Episode 44	 reward: -6.74	 makespan: 667.25	 Mean_loss: 0.02863616,  training time: 1.46
progress:  86%|[34m [0m| 43/50 [01:07<00:10,  1.45s/it]progress:  88%|[34m [0m| 44/50 [01:07<00:08,  1.46s/it]                                                         Episode 45	 reward: -6.67	 makespan: 660.75	 Mean_loss: 0.03832066,  training time: 1.43
progress:  88%|[34m [0m| 44/50 [01:08<00:08,  1.46s/it]progress:  90%|[34m [0m| 45/50 [01:08<00:07,  1.45s/it]                                                         Episode 46	 reward: -6.68	 makespan: 661.25	 Mean_loss: 0.03766675,  training time: 1.45
progress:  90%|[34m [0m| 45/50 [01:10<00:07,  1.45s/it]progress:  92%|[34m[0m| 46/50 [01:10<00:05,  1.45s/it]                                                         Episode 47	 reward: -6.78	 makespan: 671.50	 Mean_loss: 0.04123304,  training time: 1.46
progress:  92%|[34m[0m| 46/50 [01:11<00:05,  1.45s/it]progress:  94%|[34m[0m| 47/50 [01:11<00:04,  1.45s/it]                                                         Episode 48	 reward: -6.94	 makespan: 686.75	 Mean_loss: 0.05792337,  training time: 1.49
progress:  94%|[34m[0m| 47/50 [01:12<00:04,  1.45s/it]progress:  96%|[34m[0m| 48/50 [01:12<00:02,  1.46s/it]                                                         Episode 49	 reward: -6.97	 makespan: 689.75	 Mean_loss: 0.07002941,  training time: 1.51
progress:  96%|[34m[0m| 48/50 [01:14<00:02,  1.46s/it]progress:  98%|[34m[0m| 49/50 [01:14<00:01,  1.48s/it]                                                         Episode 50	 reward: -6.64	 makespan: 657.25	 Mean_loss: 0.04494260,  training time: 1.52
progress:  98%|[34m[0m| 49/50 [01:15<00:01,  1.48s/it]progress: 100%|[34m[0m| 50/50 [01:15<00:00,  1.49s/it]progress: 100%|[34m[0m| 50/50 [01:15<00:00,  1.52s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job8 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 8 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]8.0
8.0
8.0
8.0
                                                Episode 1	 reward: -11.79	 makespan: 1167.50	 Mean_loss: 1.95495236,  training time: 3.62
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:57,  3.62s/it]                                                        Episode 2	 reward: -10.73	 makespan: 1062.25	 Mean_loss: 1.11287296,  training time: 1.93
progress:   2%|[34m         [0m| 1/50 [00:05<02:57,  3.62s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:05,  2.62s/it]                                                        Episode 3	 reward: -11.65	 makespan: 1153.50	 Mean_loss: 0.50253689,  training time: 2.01
progress:   4%|[34m         [0m| 2/50 [00:07<02:05,  2.62s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:50,  2.34s/it]                                                        Episode 4	 reward: -11.52	 makespan: 1140.00	 Mean_loss: 0.31944242,  training time: 1.89
progress:   6%|[34m         [0m| 3/50 [00:09<01:50,  2.34s/it]progress:   8%|[34m         [0m| 4/50 [00:09<01:39,  2.17s/it]                                                        Episode 5	 reward: -11.73	 makespan: 1161.25	 Mean_loss: 0.26541448,  training time: 1.93
progress:   8%|[34m         [0m| 4/50 [00:11<01:39,  2.17s/it]progress:  10%|[34m         [0m| 5/50 [00:11<01:33,  2.08s/it]                                                        Episode 6	 reward: -10.89	 makespan: 1078.50	 Mean_loss: 0.19150506,  training time: 1.86
progress:  10%|[34m         [0m| 5/50 [00:13<01:33,  2.08s/it]progress:  12%|[34m        [0m| 6/50 [00:13<01:28,  2.01s/it]                                                        Episode 7	 reward: -10.98	 makespan: 1087.50	 Mean_loss: 0.19915834,  training time: 1.89
progress:  12%|[34m        [0m| 6/50 [00:15<01:28,  2.01s/it]progress:  14%|[34m        [0m| 7/50 [00:15<01:24,  1.97s/it]                                                        Episode 8	 reward: -10.57	 makespan: 1046.00	 Mean_loss: 0.11417170,  training time: 1.87
progress:  14%|[34m        [0m| 7/50 [00:17<01:24,  1.97s/it]progress:  16%|[34m        [0m| 8/50 [00:17<01:21,  1.94s/it]                                                        Episode 9	 reward: -11.13	 makespan: 1102.00	 Mean_loss: 0.15858468,  training time: 1.88
progress:  16%|[34m        [0m| 8/50 [00:18<01:21,  1.94s/it]progress:  18%|[34m        [0m| 9/50 [00:18<01:18,  1.92s/it]                                                        Episode 10	 reward: -10.66	 makespan: 1055.75	 Mean_loss: 0.12899750,  training time: 1.87
progress:  18%|[34m        [0m| 9/50 [00:20<01:18,  1.92s/it]progress:  20%|[34m        [0m| 10/50 [00:20<01:16,  1.91s/it]                                                         Episode 11	 reward: -10.42	 makespan: 1031.25	 Mean_loss: 0.15048364,  training time: 1.90
progress:  20%|[34m        [0m| 10/50 [00:22<01:16,  1.91s/it]progress:  22%|[34m       [0m| 11/50 [00:22<01:14,  1.90s/it]                                                         Episode 12	 reward: -10.53	 makespan: 1042.00	 Mean_loss: 0.10900642,  training time: 1.96
progress:  22%|[34m       [0m| 11/50 [00:24<01:14,  1.90s/it]progress:  24%|[34m       [0m| 12/50 [00:24<01:13,  1.92s/it]                                                         Episode 13	 reward: -11.17	 makespan: 1106.00	 Mean_loss: 0.18374816,  training time: 1.85
progress:  24%|[34m       [0m| 12/50 [00:26<01:13,  1.92s/it]progress:  26%|[34m       [0m| 13/50 [00:26<01:10,  1.90s/it]                                                         Episode 14	 reward: -10.99	 makespan: 1088.50	 Mean_loss: 0.18158887,  training time: 1.90
progress:  26%|[34m       [0m| 13/50 [00:28<01:10,  1.90s/it]progress:  28%|[34m       [0m| 14/50 [00:28<01:08,  1.90s/it]                                                         Episode 15	 reward: -11.05	 makespan: 1094.25	 Mean_loss: 0.24251148,  training time: 1.88
progress:  28%|[34m       [0m| 14/50 [00:30<01:08,  1.90s/it]progress:  30%|[34m       [0m| 15/50 [00:30<01:06,  1.89s/it]                                                         Episode 16	 reward: -10.26	 makespan: 1015.50	 Mean_loss: 0.15080366,  training time: 1.89
progress:  30%|[34m       [0m| 15/50 [00:32<01:06,  1.89s/it]progress:  32%|[34m      [0m| 16/50 [00:32<01:04,  1.89s/it]                                                         Episode 17	 reward: -10.08	 makespan: 997.75	 Mean_loss: 0.17306945,  training time: 1.90
progress:  32%|[34m      [0m| 16/50 [00:34<01:04,  1.89s/it]progress:  34%|[34m      [0m| 17/50 [00:34<01:02,  1.89s/it]                                                         Episode 18	 reward: -9.84	 makespan: 974.25	 Mean_loss: 0.16571562,  training time: 1.89
progress:  34%|[34m      [0m| 17/50 [00:35<01:02,  1.89s/it]progress:  36%|[34m      [0m| 18/50 [00:35<01:00,  1.89s/it]                                                         Episode 19	 reward: -10.28	 makespan: 1018.00	 Mean_loss: 0.12164795,  training time: 1.89
progress:  36%|[34m      [0m| 18/50 [00:37<01:00,  1.89s/it]progress:  38%|[34m      [0m| 19/50 [00:37<00:58,  1.89s/it]                                                         Episode 20	 reward: -9.58	 makespan: 948.75	 Mean_loss: 0.11379463,  training time: 1.88
progress:  38%|[34m      [0m| 19/50 [00:39<00:58,  1.89s/it]progress:  40%|[34m      [0m| 20/50 [00:39<00:56,  1.89s/it]                                                         Episode 21	 reward: -9.91	 makespan: 981.00	 Mean_loss: 0.10290559,  training time: 1.90
progress:  40%|[34m      [0m| 20/50 [00:41<00:56,  1.89s/it]progress:  42%|[34m     [0m| 21/50 [00:41<00:54,  1.89s/it]                                                         Episode 22	 reward: -9.87	 makespan: 976.75	 Mean_loss: 0.09631858,  training time: 1.87
progress:  42%|[34m     [0m| 21/50 [00:43<00:54,  1.89s/it]progress:  44%|[34m     [0m| 22/50 [00:43<00:52,  1.89s/it]                                                         Episode 23	 reward: -9.79	 makespan: 968.75	 Mean_loss: 0.08680613,  training time: 1.89
progress:  44%|[34m     [0m| 22/50 [00:45<00:52,  1.89s/it]progress:  46%|[34m     [0m| 23/50 [00:45<00:50,  1.89s/it]                                                         Episode 24	 reward: -9.25	 makespan: 916.00	 Mean_loss: 0.07530897,  training time: 1.87
progress:  46%|[34m     [0m| 23/50 [00:47<00:50,  1.89s/it]progress:  48%|[34m     [0m| 24/50 [00:47<00:48,  1.88s/it]                                                         Episode 25	 reward: -9.57	 makespan: 947.75	 Mean_loss: 0.07200366,  training time: 1.89
progress:  48%|[34m     [0m| 24/50 [00:49<00:48,  1.88s/it]progress:  50%|[34m     [0m| 25/50 [00:49<00:47,  1.89s/it]                                                         Episode 26	 reward: -9.45	 makespan: 935.50	 Mean_loss: 0.05963828,  training time: 1.89
progress:  50%|[34m     [0m| 25/50 [00:51<00:47,  1.89s/it]progress:  52%|[34m    [0m| 26/50 [00:51<00:45,  1.89s/it]                                                         Episode 27	 reward: -9.53	 makespan: 943.75	 Mean_loss: 0.06241372,  training time: 1.89
progress:  52%|[34m    [0m| 26/50 [00:52<00:45,  1.89s/it]progress:  54%|[34m    [0m| 27/50 [00:52<00:43,  1.89s/it]                                                         Episode 28	 reward: -9.37	 makespan: 927.50	 Mean_loss: 0.06469700,  training time: 1.91
progress:  54%|[34m    [0m| 27/50 [00:54<00:43,  1.89s/it]progress:  56%|[34m    [0m| 28/50 [00:54<00:41,  1.90s/it]                                                         Episode 29	 reward: -9.84	 makespan: 974.25	 Mean_loss: 0.09227890,  training time: 1.87
progress:  56%|[34m    [0m| 28/50 [00:56<00:41,  1.90s/it]progress:  58%|[34m    [0m| 29/50 [00:56<00:39,  1.89s/it]                                                         Episode 30	 reward: -9.57	 makespan: 947.75	 Mean_loss: 0.06968362,  training time: 1.87
progress:  58%|[34m    [0m| 29/50 [00:58<00:39,  1.89s/it]progress:  60%|[34m    [0m| 30/50 [00:58<00:37,  1.88s/it]                                                         Episode 31	 reward: -9.49	 makespan: 939.75	 Mean_loss: 0.06295982,  training time: 1.86
progress:  60%|[34m    [0m| 30/50 [01:00<00:37,  1.88s/it]progress:  62%|[34m   [0m| 31/50 [01:00<00:35,  1.88s/it]                                                         Episode 32	 reward: -9.58	 makespan: 948.75	 Mean_loss: 0.04264220,  training time: 1.86
progress:  62%|[34m   [0m| 31/50 [01:02<00:35,  1.88s/it]progress:  64%|[34m   [0m| 32/50 [01:02<00:33,  1.87s/it]                                                         Episode 33	 reward: -9.74	 makespan: 964.50	 Mean_loss: 0.05006284,  training time: 1.88
progress:  64%|[34m   [0m| 32/50 [01:04<00:33,  1.87s/it]progress:  66%|[34m   [0m| 33/50 [01:04<00:31,  1.88s/it]                                                         Episode 34	 reward: -9.56	 makespan: 946.50	 Mean_loss: 0.07130813,  training time: 1.87
progress:  66%|[34m   [0m| 33/50 [01:06<00:31,  1.88s/it]progress:  68%|[34m   [0m| 34/50 [01:06<00:30,  1.88s/it]                                                         Episode 35	 reward: -9.33	 makespan: 924.00	 Mean_loss: 0.07489558,  training time: 1.84
progress:  68%|[34m   [0m| 34/50 [01:07<00:30,  1.88s/it]progress:  70%|[34m   [0m| 35/50 [01:07<00:27,  1.86s/it]                                                         Episode 36	 reward: -9.65	 makespan: 955.00	 Mean_loss: 0.08021320,  training time: 1.88
progress:  70%|[34m   [0m| 35/50 [01:09<00:27,  1.86s/it]progress:  72%|[34m  [0m| 36/50 [01:09<00:26,  1.87s/it]                                                         Episode 37	 reward: -9.85	 makespan: 975.00	 Mean_loss: 0.05602217,  training time: 1.88
progress:  72%|[34m  [0m| 36/50 [01:11<00:26,  1.87s/it]progress:  74%|[34m  [0m| 37/50 [01:11<00:24,  1.87s/it]                                                         Episode 38	 reward: -9.48	 makespan: 938.75	 Mean_loss: 0.05822167,  training time: 1.86
progress:  74%|[34m  [0m| 37/50 [01:13<00:24,  1.87s/it]progress:  76%|[34m  [0m| 38/50 [01:13<00:22,  1.87s/it]                                                         Episode 39	 reward: -9.50	 makespan: 940.25	 Mean_loss: 0.05529805,  training time: 1.88
progress:  76%|[34m  [0m| 38/50 [01:15<00:22,  1.87s/it]progress:  78%|[34m  [0m| 39/50 [01:15<00:20,  1.87s/it]                                                         Episode 40	 reward: -9.39	 makespan: 929.75	 Mean_loss: 0.05206505,  training time: 1.89
progress:  78%|[34m  [0m| 39/50 [01:17<00:20,  1.87s/it]progress:  80%|[34m  [0m| 40/50 [01:17<00:18,  1.88s/it]                                                         Episode 41	 reward: -9.44	 makespan: 934.50	 Mean_loss: 0.04679491,  training time: 1.94
progress:  80%|[34m  [0m| 40/50 [01:19<00:18,  1.88s/it]progress:  82%|[34m [0m| 41/50 [01:19<00:17,  1.90s/it]                                                         Episode 42	 reward: -9.85	 makespan: 975.25	 Mean_loss: 0.08229263,  training time: 1.87
progress:  82%|[34m [0m| 41/50 [01:21<00:17,  1.90s/it]progress:  84%|[34m [0m| 42/50 [01:21<00:15,  1.89s/it]                                                         Episode 43	 reward: -9.49	 makespan: 940.00	 Mean_loss: 0.05758870,  training time: 1.86
progress:  84%|[34m [0m| 42/50 [01:22<00:15,  1.89s/it]progress:  86%|[34m [0m| 43/50 [01:22<00:13,  1.88s/it]                                                         Episode 44	 reward: -9.21	 makespan: 912.00	 Mean_loss: 0.04905966,  training time: 1.88
progress:  86%|[34m [0m| 43/50 [01:24<00:13,  1.88s/it]progress:  88%|[34m [0m| 44/50 [01:24<00:11,  1.88s/it]                                                         Episode 45	 reward: -8.90	 makespan: 881.50	 Mean_loss: 0.05012519,  training time: 1.86
progress:  88%|[34m [0m| 44/50 [01:26<00:11,  1.88s/it]progress:  90%|[34m [0m| 45/50 [01:26<00:09,  1.87s/it]                                                         Episode 46	 reward: -8.92	 makespan: 883.50	 Mean_loss: 0.03763993,  training time: 1.88
progress:  90%|[34m [0m| 45/50 [01:28<00:09,  1.87s/it]progress:  92%|[34m[0m| 46/50 [01:28<00:07,  1.88s/it]                                                         Episode 47	 reward: -8.90	 makespan: 881.50	 Mean_loss: 0.03500928,  training time: 1.90
progress:  92%|[34m[0m| 46/50 [01:30<00:07,  1.88s/it]progress:  94%|[34m[0m| 47/50 [01:30<00:05,  1.88s/it]                                                         Episode 48	 reward: -8.98	 makespan: 889.50	 Mean_loss: 0.06429949,  training time: 1.88
progress:  94%|[34m[0m| 47/50 [01:32<00:05,  1.88s/it]progress:  96%|[34m[0m| 48/50 [01:32<00:03,  1.88s/it]                                                         Episode 49	 reward: -9.28	 makespan: 919.00	 Mean_loss: 0.05485543,  training time: 1.88
progress:  96%|[34m[0m| 48/50 [01:34<00:03,  1.88s/it]progress:  98%|[34m[0m| 49/50 [01:34<00:01,  1.88s/it]                                                         Episode 50	 reward: -8.91	 makespan: 882.00	 Mean_loss: 0.03605704,  training time: 1.86
progress:  98%|[34m[0m| 49/50 [01:36<00:01,  1.88s/it]progress: 100%|[34m[0m| 50/50 [01:36<00:00,  1.88s/it]progress: 100%|[34m[0m| 50/50 [01:36<00:00,  1.92s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job10 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 10 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]10.0
10.0
10.0
10.0
                                                Episode 1	 reward: -13.42	 makespan: 1329.00	 Mean_loss: 2.11710930,  training time: 5.95
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:51,  5.96s/it]                                                        Episode 2	 reward: -13.40	 makespan: 1326.50	 Mean_loss: 1.05942321,  training time: 2.56
progress:   2%|[34m         [0m| 1/50 [00:08<04:51,  5.96s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:10,  3.97s/it]                                                        Episode 3	 reward: -13.30	 makespan: 1316.25	 Mean_loss: 0.54409409,  training time: 2.40
progress:   4%|[34m         [0m| 2/50 [00:10<03:10,  3.97s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:33,  3.26s/it]                                                        Episode 4	 reward: -12.94	 makespan: 1281.25	 Mean_loss: 0.45959708,  training time: 2.38
progress:   6%|[34m         [0m| 3/50 [00:13<02:33,  3.26s/it]progress:   8%|[34m         [0m| 4/50 [00:13<02:13,  2.91s/it]                                                        Episode 5	 reward: -13.40	 makespan: 1326.25	 Mean_loss: 0.30825284,  training time: 2.40
progress:   8%|[34m         [0m| 4/50 [00:15<02:13,  2.91s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:02,  2.73s/it]                                                        Episode 6	 reward: -12.82	 makespan: 1268.75	 Mean_loss: 0.15924689,  training time: 2.99
progress:  10%|[34m         [0m| 5/50 [00:18<02:02,  2.73s/it]progress:  12%|[34m        [0m| 6/50 [00:18<02:04,  2.82s/it]                                                        Episode 7	 reward: -13.80	 makespan: 1366.25	 Mean_loss: 0.23631844,  training time: 2.36
progress:  12%|[34m        [0m| 6/50 [00:21<02:04,  2.82s/it]progress:  14%|[34m        [0m| 7/50 [00:21<01:54,  2.67s/it]                                                        Episode 8	 reward: -12.88	 makespan: 1275.00	 Mean_loss: 0.23376410,  training time: 2.38
progress:  14%|[34m        [0m| 7/50 [00:23<01:54,  2.67s/it]progress:  16%|[34m        [0m| 8/50 [00:23<01:48,  2.58s/it]                                                        Episode 9	 reward: -13.59	 makespan: 1345.50	 Mean_loss: 0.25457472,  training time: 2.35
progress:  16%|[34m        [0m| 8/50 [00:25<01:48,  2.58s/it]progress:  18%|[34m        [0m| 9/50 [00:25<01:42,  2.51s/it]                                                        Episode 10	 reward: -14.03	 makespan: 1388.50	 Mean_loss: 0.26982975,  training time: 2.38
progress:  18%|[34m        [0m| 9/50 [00:28<01:42,  2.51s/it]progress:  20%|[34m        [0m| 10/50 [00:28<01:38,  2.47s/it]                                                         Episode 11	 reward: -13.61	 makespan: 1347.75	 Mean_loss: 0.28875506,  training time: 2.34
progress:  20%|[34m        [0m| 10/50 [00:30<01:38,  2.47s/it]progress:  22%|[34m       [0m| 11/50 [00:30<01:34,  2.43s/it]                                                         Episode 12	 reward: -14.37	 makespan: 1422.50	 Mean_loss: 0.27982673,  training time: 2.33
progress:  22%|[34m       [0m| 11/50 [00:32<01:34,  2.43s/it]progress:  24%|[34m       [0m| 12/50 [00:32<01:31,  2.40s/it]                                                         Episode 13	 reward: -14.23	 makespan: 1409.00	 Mean_loss: 0.31908062,  training time: 2.34
progress:  24%|[34m       [0m| 12/50 [00:35<01:31,  2.40s/it]progress:  26%|[34m       [0m| 13/50 [00:35<01:28,  2.38s/it]                                                         Episode 14	 reward: -13.62	 makespan: 1348.25	 Mean_loss: 0.27326670,  training time: 2.34
progress:  26%|[34m       [0m| 13/50 [00:37<01:28,  2.38s/it]progress:  28%|[34m       [0m| 14/50 [00:37<01:25,  2.37s/it]                                                         Episode 15	 reward: -13.58	 makespan: 1344.25	 Mean_loss: 0.20993981,  training time: 2.36
progress:  28%|[34m       [0m| 14/50 [00:39<01:25,  2.37s/it]progress:  30%|[34m       [0m| 15/50 [00:39<01:22,  2.37s/it]                                                         Episode 16	 reward: -13.76	 makespan: 1361.75	 Mean_loss: 0.17609726,  training time: 2.37
progress:  30%|[34m       [0m| 15/50 [00:42<01:22,  2.37s/it]progress:  32%|[34m      [0m| 16/50 [00:42<01:20,  2.37s/it]                                                         Episode 17	 reward: -13.70	 makespan: 1356.75	 Mean_loss: 0.19456640,  training time: 2.34
progress:  32%|[34m      [0m| 16/50 [00:44<01:20,  2.37s/it]progress:  34%|[34m      [0m| 17/50 [00:44<01:17,  2.36s/it]                                                         Episode 18	 reward: -13.51	 makespan: 1337.75	 Mean_loss: 0.20043708,  training time: 2.36
progress:  34%|[34m      [0m| 17/50 [00:46<01:17,  2.36s/it]progress:  36%|[34m      [0m| 18/50 [00:46<01:15,  2.36s/it]                                                         Episode 19	 reward: -13.28	 makespan: 1315.00	 Mean_loss: 0.19052932,  training time: 2.34
progress:  36%|[34m      [0m| 18/50 [00:49<01:15,  2.36s/it]progress:  38%|[34m      [0m| 19/50 [00:49<01:13,  2.36s/it]                                                         Episode 20	 reward: -13.39	 makespan: 1325.75	 Mean_loss: 0.21397421,  training time: 2.34
progress:  38%|[34m      [0m| 19/50 [00:51<01:13,  2.36s/it]progress:  40%|[34m      [0m| 20/50 [00:51<01:10,  2.35s/it]                                                         Episode 21	 reward: -13.69	 makespan: 1355.25	 Mean_loss: 0.20356545,  training time: 2.33
progress:  40%|[34m      [0m| 20/50 [00:54<01:10,  2.35s/it]progress:  42%|[34m     [0m| 21/50 [00:54<01:08,  2.35s/it]                                                         Episode 22	 reward: -13.20	 makespan: 1307.00	 Mean_loss: 0.26225954,  training time: 2.33
progress:  42%|[34m     [0m| 21/50 [00:56<01:08,  2.35s/it]progress:  44%|[34m     [0m| 22/50 [00:56<01:05,  2.34s/it]                                                         Episode 23	 reward: -13.36	 makespan: 1322.25	 Mean_loss: 0.24677157,  training time: 2.32
progress:  44%|[34m     [0m| 22/50 [00:58<01:05,  2.34s/it]progress:  46%|[34m     [0m| 23/50 [00:58<01:03,  2.34s/it]                                                         Episode 24	 reward: -13.51	 makespan: 1337.50	 Mean_loss: 0.16524385,  training time: 2.33
progress:  46%|[34m     [0m| 23/50 [01:00<01:03,  2.34s/it]progress:  48%|[34m     [0m| 24/50 [01:00<01:00,  2.34s/it]                                                         Episode 25	 reward: -13.50	 makespan: 1336.25	 Mean_loss: 0.13167354,  training time: 2.33
progress:  48%|[34m     [0m| 24/50 [01:03<01:00,  2.34s/it]progress:  50%|[34m     [0m| 25/50 [01:03<00:58,  2.34s/it]                                                         Episode 26	 reward: -12.75	 makespan: 1262.50	 Mean_loss: 0.23784959,  training time: 2.34
progress:  50%|[34m     [0m| 25/50 [01:05<00:58,  2.34s/it]progress:  52%|[34m    [0m| 26/50 [01:05<00:56,  2.34s/it]                                                         Episode 27	 reward: -13.35	 makespan: 1321.75	 Mean_loss: 0.22621161,  training time: 2.35
progress:  52%|[34m    [0m| 26/50 [01:08<00:56,  2.34s/it]progress:  54%|[34m    [0m| 27/50 [01:08<00:53,  2.34s/it]                                                         Episode 28	 reward: -12.71	 makespan: 1258.75	 Mean_loss: 0.14627720,  training time: 2.35
progress:  54%|[34m    [0m| 27/50 [01:10<00:53,  2.34s/it]progress:  56%|[34m    [0m| 28/50 [01:10<00:51,  2.34s/it]                                                         Episode 29	 reward: -12.35	 makespan: 1223.00	 Mean_loss: 0.18692918,  training time: 2.38
progress:  56%|[34m    [0m| 28/50 [01:12<00:51,  2.34s/it]progress:  58%|[34m    [0m| 29/50 [01:12<00:49,  2.35s/it]                                                         Episode 30	 reward: -13.05	 makespan: 1292.25	 Mean_loss: 0.17308414,  training time: 2.35
progress:  58%|[34m    [0m| 29/50 [01:15<00:49,  2.35s/it]progress:  60%|[34m    [0m| 30/50 [01:15<00:47,  2.36s/it]                                                         Episode 31	 reward: -13.62	 makespan: 1348.75	 Mean_loss: 0.17765293,  training time: 2.37
progress:  60%|[34m    [0m| 30/50 [01:17<00:47,  2.36s/it]progress:  62%|[34m   [0m| 31/50 [01:17<00:44,  2.36s/it]                                                         Episode 32	 reward: -12.90	 makespan: 1276.75	 Mean_loss: 0.19641250,  training time: 2.34
progress:  62%|[34m   [0m| 31/50 [01:19<00:44,  2.36s/it]progress:  64%|[34m   [0m| 32/50 [01:19<00:42,  2.36s/it]                                                         Episode 33	 reward: -13.23	 makespan: 1309.75	 Mean_loss: 0.19353797,  training time: 2.35
progress:  64%|[34m   [0m| 32/50 [01:22<00:42,  2.36s/it]progress:  66%|[34m   [0m| 33/50 [01:22<00:40,  2.35s/it]                                                         Episode 34	 reward: -13.73	 makespan: 1359.00	 Mean_loss: 0.13372687,  training time: 2.31
progress:  66%|[34m   [0m| 33/50 [01:24<00:40,  2.35s/it]progress:  68%|[34m   [0m| 34/50 [01:24<00:37,  2.34s/it]                                                         Episode 35	 reward: -13.02	 makespan: 1289.00	 Mean_loss: 0.17123204,  training time: 2.32
progress:  68%|[34m   [0m| 34/50 [01:26<00:37,  2.34s/it]progress:  70%|[34m   [0m| 35/50 [01:26<00:35,  2.34s/it]                                                         Episode 36	 reward: -13.65	 makespan: 1351.75	 Mean_loss: 0.23894466,  training time: 2.33
progress:  70%|[34m   [0m| 35/50 [01:29<00:35,  2.34s/it]progress:  72%|[34m  [0m| 36/50 [01:29<00:32,  2.33s/it]                                                         Episode 37	 reward: -13.23	 makespan: 1310.25	 Mean_loss: 0.16495703,  training time: 2.36
progress:  72%|[34m  [0m| 36/50 [01:31<00:32,  2.33s/it]progress:  74%|[34m  [0m| 37/50 [01:31<00:30,  2.34s/it]                                                         Episode 38	 reward: -12.52	 makespan: 1239.25	 Mean_loss: 0.14805228,  training time: 2.33
progress:  74%|[34m  [0m| 37/50 [01:33<00:30,  2.34s/it]progress:  76%|[34m  [0m| 38/50 [01:33<00:28,  2.34s/it]                                                         Episode 39	 reward: -13.42	 makespan: 1328.50	 Mean_loss: 0.18451333,  training time: 2.35
progress:  76%|[34m  [0m| 38/50 [01:36<00:28,  2.34s/it]progress:  78%|[34m  [0m| 39/50 [01:36<00:25,  2.34s/it]                                                         Episode 40	 reward: -12.83	 makespan: 1270.25	 Mean_loss: 0.14949195,  training time: 2.34
progress:  78%|[34m  [0m| 39/50 [01:38<00:25,  2.34s/it]progress:  80%|[34m  [0m| 40/50 [01:38<00:23,  2.34s/it]                                                         Episode 41	 reward: -13.24	 makespan: 1311.25	 Mean_loss: 0.11395666,  training time: 2.35
progress:  80%|[34m  [0m| 40/50 [01:40<00:23,  2.34s/it]progress:  82%|[34m [0m| 41/50 [01:40<00:21,  2.34s/it]                                                         Episode 42	 reward: -12.89	 makespan: 1276.25	 Mean_loss: 0.14072731,  training time: 2.34
progress:  82%|[34m [0m| 41/50 [01:43<00:21,  2.34s/it]progress:  84%|[34m [0m| 42/50 [01:43<00:18,  2.34s/it]                                                         Episode 43	 reward: -13.40	 makespan: 1327.00	 Mean_loss: 0.12112957,  training time: 2.36
progress:  84%|[34m [0m| 42/50 [01:45<00:18,  2.34s/it]progress:  86%|[34m [0m| 43/50 [01:45<00:16,  2.35s/it]                                                         Episode 44	 reward: -12.52	 makespan: 1239.00	 Mean_loss: 0.14430009,  training time: 2.37
progress:  86%|[34m [0m| 43/50 [01:47<00:16,  2.35s/it]progress:  88%|[34m [0m| 44/50 [01:47<00:14,  2.35s/it]                                                         Episode 45	 reward: -12.65	 makespan: 1252.50	 Mean_loss: 0.10754051,  training time: 2.35
progress:  88%|[34m [0m| 44/50 [01:50<00:14,  2.35s/it]progress:  90%|[34m [0m| 45/50 [01:50<00:11,  2.35s/it]                                                         Episode 46	 reward: -12.55	 makespan: 1242.75	 Mean_loss: 0.09465806,  training time: 2.36
progress:  90%|[34m [0m| 45/50 [01:52<00:11,  2.35s/it]progress:  92%|[34m[0m| 46/50 [01:52<00:09,  2.36s/it]                                                         Episode 47	 reward: -12.48	 makespan: 1235.75	 Mean_loss: 0.11119907,  training time: 2.37
progress:  92%|[34m[0m| 46/50 [01:55<00:09,  2.36s/it]progress:  94%|[34m[0m| 47/50 [01:55<00:07,  2.36s/it]                                                         Episode 48	 reward: -12.24	 makespan: 1211.75	 Mean_loss: 0.10886963,  training time: 2.34
progress:  94%|[34m[0m| 47/50 [01:57<00:07,  2.36s/it]progress:  96%|[34m[0m| 48/50 [01:57<00:04,  2.35s/it]                                                         Episode 49	 reward: -12.07	 makespan: 1194.50	 Mean_loss: 0.11842024,  training time: 2.32
progress:  96%|[34m[0m| 48/50 [01:59<00:04,  2.35s/it]progress:  98%|[34m[0m| 49/50 [01:59<00:02,  2.34s/it]                                                         Episode 50	 reward: -12.60	 makespan: 1247.00	 Mean_loss: 0.11765459,  training time: 2.35
progress:  98%|[34m[0m| 49/50 [02:02<00:02,  2.34s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.35s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.44s/it]
+ for op_per_job in '"${options[@]}"'
+ python ./train/DAN_finetuning.py --logdir ./runs/exp15/DAN/transfer15x5+mix+SD2_operjob12/op_per_job12 --model_suffix free --finetuning_model 15x5+mix+SD2_operjob12 --max_updates 50 --n_j 15 --n_m 5 --num_envs 4 --op_per_job 12 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_operjob12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_operjob12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]12.0
12.0
12.0
12.0
                                                Episode 1	 reward: -16.77	 makespan: 1660.50	 Mean_loss: 2.00645447,  training time: 6.50
progress:   0%|[34m          [0m| 0/50 [00:06<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:06<05:18,  6.50s/it]                                                        Episode 2	 reward: -17.72	 makespan: 1754.00	 Mean_loss: 1.20425129,  training time: 2.83
progress:   2%|[34m         [0m| 1/50 [00:09<05:18,  6.50s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:29,  4.36s/it]                                                        Episode 3	 reward: -18.26	 makespan: 1807.50	 Mean_loss: 0.88477218,  training time: 2.81
progress:   4%|[34m         [0m| 2/50 [00:12<03:29,  4.36s/it]progress:   6%|[34m         [0m| 3/50 [00:12<02:51,  3.65s/it]                                                        Episode 4	 reward: -17.53	 makespan: 1735.25	 Mean_loss: 0.72531980,  training time: 2.74
progress:   6%|[34m         [0m| 3/50 [00:14<02:51,  3.65s/it]progress:   8%|[34m         [0m| 4/50 [00:14<02:31,  3.29s/it]                                                        Episode 5	 reward: -16.97	 makespan: 1680.50	 Mean_loss: 0.88020611,  training time: 3.07
progress:   8%|[34m         [0m| 4/50 [00:17<02:31,  3.29s/it]progress:  10%|[34m         [0m| 5/50 [00:17<02:24,  3.21s/it]                                                        Episode 6	 reward: -17.42	 makespan: 1725.00	 Mean_loss: 0.62052727,  training time: 2.77
progress:  10%|[34m         [0m| 5/50 [00:20<02:24,  3.21s/it]progress:  12%|[34m        [0m| 6/50 [00:20<02:14,  3.06s/it]                                                        Episode 7	 reward: -16.38	 makespan: 1622.00	 Mean_loss: 0.61644793,  training time: 2.87
progress:  12%|[34m        [0m| 6/50 [00:23<02:14,  3.06s/it]progress:  14%|[34m        [0m| 7/50 [00:23<02:09,  3.00s/it]                                                        Episode 8	 reward: -16.69	 makespan: 1652.75	 Mean_loss: 0.37931615,  training time: 2.81
progress:  14%|[34m        [0m| 7/50 [00:26<02:09,  3.00s/it]progress:  16%|[34m        [0m| 8/50 [00:26<02:03,  2.94s/it]                                                        Episode 9	 reward: -15.99	 makespan: 1583.00	 Mean_loss: 0.24702090,  training time: 2.79
progress:  16%|[34m        [0m| 8/50 [00:29<02:03,  2.94s/it]progress:  18%|[34m        [0m| 9/50 [00:29<01:58,  2.90s/it]                                                        Episode 10	 reward: -14.99	 makespan: 1483.75	 Mean_loss: 0.37312630,  training time: 2.72
progress:  18%|[34m        [0m| 9/50 [00:31<01:58,  2.90s/it]progress:  20%|[34m        [0m| 10/50 [00:31<01:53,  2.84s/it]                                                         Episode 11	 reward: -15.01	 makespan: 1486.25	 Mean_loss: 0.39164120,  training time: 2.73
progress:  20%|[34m        [0m| 10/50 [00:34<01:53,  2.84s/it]progress:  22%|[34m       [0m| 11/50 [00:34<01:49,  2.81s/it]                                                         Episode 12	 reward: -16.36	 makespan: 1619.50	 Mean_loss: 0.40961909,  training time: 2.73
progress:  22%|[34m       [0m| 11/50 [00:37<01:49,  2.81s/it]progress:  24%|[34m       [0m| 12/50 [00:37<01:45,  2.79s/it]                                                         Episode 13	 reward: -15.34	 makespan: 1518.50	 Mean_loss: 0.29919320,  training time: 2.74
progress:  24%|[34m       [0m| 12/50 [00:40<01:45,  2.79s/it]progress:  26%|[34m       [0m| 13/50 [00:40<01:42,  2.77s/it]                                                         Episode 14	 reward: -14.98	 makespan: 1483.50	 Mean_loss: 0.19715689,  training time: 2.71
progress:  26%|[34m       [0m| 13/50 [00:42<01:42,  2.77s/it]progress:  28%|[34m       [0m| 14/50 [00:42<01:39,  2.76s/it]                                                         Episode 15	 reward: -14.16	 makespan: 1401.75	 Mean_loss: 0.21212132,  training time: 2.76
progress:  28%|[34m       [0m| 14/50 [00:45<01:39,  2.76s/it]progress:  30%|[34m       [0m| 15/50 [00:45<01:36,  2.76s/it]                                                         Episode 16	 reward: -15.55	 makespan: 1539.50	 Mean_loss: 0.18868279,  training time: 2.74
progress:  30%|[34m       [0m| 15/50 [00:48<01:36,  2.76s/it]progress:  32%|[34m      [0m| 16/50 [00:48<01:33,  2.75s/it]                                                         Episode 17	 reward: -15.11	 makespan: 1495.50	 Mean_loss: 0.19103715,  training time: 2.73
progress:  32%|[34m      [0m| 16/50 [00:51<01:33,  2.75s/it]progress:  34%|[34m      [0m| 17/50 [00:51<01:30,  2.75s/it]                                                         Episode 18	 reward: -14.53	 makespan: 1438.50	 Mean_loss: 0.14880438,  training time: 2.72
progress:  34%|[34m      [0m| 17/50 [00:53<01:30,  2.75s/it]progress:  36%|[34m      [0m| 18/50 [00:53<01:27,  2.74s/it]                                                         Episode 19	 reward: -15.15	 makespan: 1499.50	 Mean_loss: 0.21718280,  training time: 2.73
progress:  36%|[34m      [0m| 18/50 [00:56<01:27,  2.74s/it]progress:  38%|[34m      [0m| 19/50 [00:56<01:24,  2.74s/it]                                                         Episode 20	 reward: -15.86	 makespan: 1570.25	 Mean_loss: 0.21524586,  training time: 2.74
progress:  38%|[34m      [0m| 19/50 [00:59<01:24,  2.74s/it]progress:  40%|[34m      [0m| 20/50 [00:59<01:22,  2.74s/it]                                                         Episode 21	 reward: -15.45	 makespan: 1529.50	 Mean_loss: 0.25912544,  training time: 2.74
progress:  40%|[34m      [0m| 20/50 [01:02<01:22,  2.74s/it]progress:  42%|[34m     [0m| 21/50 [01:02<01:19,  2.74s/it]                                                         Episode 22	 reward: -14.43	 makespan: 1428.25	 Mean_loss: 0.18247679,  training time: 2.72
progress:  42%|[34m     [0m| 21/50 [01:04<01:19,  2.74s/it]progress:  44%|[34m     [0m| 22/50 [01:04<01:16,  2.73s/it]                                                         Episode 23	 reward: -14.02	 makespan: 1387.50	 Mean_loss: 0.16252723,  training time: 2.73
progress:  44%|[34m     [0m| 22/50 [01:07<01:16,  2.73s/it]progress:  46%|[34m     [0m| 23/50 [01:07<01:13,  2.73s/it]                                                         Episode 24	 reward: -14.17	 makespan: 1402.75	 Mean_loss: 0.13055402,  training time: 2.74
progress:  46%|[34m     [0m| 23/50 [01:10<01:13,  2.73s/it]progress:  48%|[34m     [0m| 24/50 [01:10<01:11,  2.74s/it]                                                         Episode 25	 reward: -14.24	 makespan: 1409.75	 Mean_loss: 0.12345014,  training time: 2.75
progress:  48%|[34m     [0m| 24/50 [01:12<01:11,  2.74s/it]progress:  50%|[34m     [0m| 25/50 [01:12<01:08,  2.74s/it]                                                         Episode 26	 reward: -14.59	 makespan: 1444.00	 Mean_loss: 0.19013727,  training time: 2.72
progress:  50%|[34m     [0m| 25/50 [01:15<01:08,  2.74s/it]progress:  52%|[34m    [0m| 26/50 [01:15<01:05,  2.73s/it]                                                         Episode 27	 reward: -14.31	 makespan: 1416.50	 Mean_loss: 0.13525656,  training time: 2.72
progress:  52%|[34m    [0m| 26/50 [01:18<01:05,  2.73s/it]progress:  54%|[34m    [0m| 27/50 [01:18<01:02,  2.73s/it]                                                         Episode 28	 reward: -14.28	 makespan: 1414.00	 Mean_loss: 0.10232298,  training time: 2.74
progress:  54%|[34m    [0m| 27/50 [01:21<01:02,  2.73s/it]progress:  56%|[34m    [0m| 28/50 [01:21<01:00,  2.74s/it]                                                         Episode 29	 reward: -13.93	 makespan: 1379.25	 Mean_loss: 0.10817920,  training time: 2.74
progress:  56%|[34m    [0m| 28/50 [01:23<01:00,  2.74s/it]progress:  58%|[34m    [0m| 29/50 [01:23<00:57,  2.74s/it]                                                         Episode 30	 reward: -13.94	 makespan: 1380.50	 Mean_loss: 0.07870091,  training time: 2.73
progress:  58%|[34m    [0m| 29/50 [01:26<00:57,  2.74s/it]progress:  60%|[34m    [0m| 30/50 [01:26<00:54,  2.74s/it]                                                         Episode 31	 reward: -14.40	 makespan: 1425.75	 Mean_loss: 0.10164815,  training time: 2.75
progress:  60%|[34m    [0m| 30/50 [01:29<00:54,  2.74s/it]progress:  62%|[34m   [0m| 31/50 [01:29<00:52,  2.74s/it]                                                         Episode 32	 reward: -14.70	 makespan: 1455.00	 Mean_loss: 0.11083183,  training time: 2.75
progress:  62%|[34m   [0m| 31/50 [01:32<00:52,  2.74s/it]progress:  64%|[34m   [0m| 32/50 [01:32<00:49,  2.74s/it]                                                         Episode 33	 reward: -15.19	 makespan: 1504.25	 Mean_loss: 0.15020309,  training time: 2.73
progress:  64%|[34m   [0m| 32/50 [01:34<00:49,  2.74s/it]progress:  66%|[34m   [0m| 33/50 [01:34<00:46,  2.74s/it]                                                         Episode 34	 reward: -14.71	 makespan: 1456.00	 Mean_loss: 0.14068094,  training time: 2.75
progress:  66%|[34m   [0m| 33/50 [01:37<00:46,  2.74s/it]progress:  68%|[34m   [0m| 34/50 [01:37<00:43,  2.74s/it]                                                         Episode 35	 reward: -15.70	 makespan: 1554.50	 Mean_loss: 0.21130863,  training time: 2.78
progress:  68%|[34m   [0m| 34/50 [01:40<00:43,  2.74s/it]progress:  70%|[34m   [0m| 35/50 [01:40<00:41,  2.75s/it]                                                         Episode 36	 reward: -15.40	 makespan: 1524.75	 Mean_loss: 0.16313416,  training time: 2.77
progress:  70%|[34m   [0m| 35/50 [01:43<00:41,  2.75s/it]progress:  72%|[34m  [0m| 36/50 [01:43<00:38,  2.76s/it]                                                         Episode 37	 reward: -14.87	 makespan: 1472.50	 Mean_loss: 0.14511317,  training time: 2.76
progress:  72%|[34m  [0m| 36/50 [01:45<00:38,  2.76s/it]progress:  74%|[34m  [0m| 37/50 [01:45<00:35,  2.76s/it]                                                         Episode 38	 reward: -15.09	 makespan: 1493.50	 Mean_loss: 0.13450244,  training time: 2.76
progress:  74%|[34m  [0m| 37/50 [01:48<00:35,  2.76s/it]progress:  76%|[34m  [0m| 38/50 [01:48<00:33,  2.76s/it]                                                         Episode 39	 reward: -16.01	 makespan: 1585.00	 Mean_loss: 0.18799029,  training time: 2.78
progress:  76%|[34m  [0m| 38/50 [01:51<00:33,  2.76s/it]progress:  78%|[34m  [0m| 39/50 [01:51<00:30,  2.77s/it]                                                         Episode 40	 reward: -16.07	 makespan: 1590.50	 Mean_loss: 0.20266972,  training time: 2.75
progress:  78%|[34m  [0m| 39/50 [01:54<00:30,  2.77s/it]progress:  80%|[34m  [0m| 40/50 [01:54<00:27,  2.76s/it]                                                         Episode 41	 reward: -15.24	 makespan: 1509.00	 Mean_loss: 0.12512697,  training time: 2.72
progress:  80%|[34m  [0m| 40/50 [01:56<00:27,  2.76s/it]progress:  82%|[34m [0m| 41/50 [01:56<00:24,  2.75s/it]                                                         Episode 42	 reward: -14.48	 makespan: 1434.00	 Mean_loss: 0.13174787,  training time: 2.77
progress:  82%|[34m [0m| 41/50 [01:59<00:24,  2.75s/it]progress:  84%|[34m [0m| 42/50 [01:59<00:22,  2.75s/it]                                                         Episode 43	 reward: -14.87	 makespan: 1472.50	 Mean_loss: 0.18248358,  training time: 2.76
progress:  84%|[34m [0m| 42/50 [02:02<00:22,  2.75s/it]progress:  86%|[34m [0m| 43/50 [02:02<00:19,  2.76s/it]                                                         Episode 44	 reward: -14.20	 makespan: 1405.50	 Mean_loss: 0.16523236,  training time: 2.75
progress:  86%|[34m [0m| 43/50 [02:05<00:19,  2.76s/it]progress:  88%|[34m [0m| 44/50 [02:05<00:16,  2.76s/it]                                                         Episode 45	 reward: -14.27	 makespan: 1412.50	 Mean_loss: 0.12797680,  training time: 2.75
progress:  88%|[34m [0m| 44/50 [02:08<00:16,  2.76s/it]progress:  90%|[34m [0m| 45/50 [02:08<00:13,  2.76s/it]                                                         Episode 46	 reward: -14.21	 makespan: 1407.25	 Mean_loss: 0.13016121,  training time: 2.76
progress:  90%|[34m [0m| 45/50 [02:10<00:13,  2.76s/it]progress:  92%|[34m[0m| 46/50 [02:10<00:11,  2.76s/it]                                                         Episode 47	 reward: -14.40	 makespan: 1425.25	 Mean_loss: 0.12880602,  training time: 2.74
progress:  92%|[34m[0m| 46/50 [02:13<00:11,  2.76s/it]progress:  94%|[34m[0m| 47/50 [02:13<00:08,  2.75s/it]                                                         Episode 48	 reward: -13.83	 makespan: 1369.50	 Mean_loss: 0.08969561,  training time: 2.75
progress:  94%|[34m[0m| 47/50 [02:16<00:08,  2.75s/it]progress:  96%|[34m[0m| 48/50 [02:16<00:05,  2.75s/it]                                                         Episode 49	 reward: -13.94	 makespan: 1380.50	 Mean_loss: 0.10132831,  training time: 2.73
progress:  96%|[34m[0m| 48/50 [02:18<00:05,  2.75s/it]progress:  98%|[34m[0m| 49/50 [02:18<00:02,  2.74s/it]                                                         Episode 50	 reward: -14.28	 makespan: 1413.50	 Mean_loss: 0.11903066,  training time: 2.74
progress:  98%|[34m[0m| 49/50 [02:21<00:02,  2.74s/it]progress: 100%|[34m[0m| 50/50 [02:21<00:00,  2.74s/it]progress: 100%|[34m[0m| 50/50 [02:21<00:00,  2.83s/it]
+ meta_iterations=1000
+ max_updates_maml=1000
+ model_suffix=exp15_1000_64_3
+ num_tasks=4
+ logdir_maml=./runs/exp15/maml
+ python train/multi_task_maml_exp15.py --logdir ./runs/exp15/maml --model_suffix exp15_1000_64_3 --maml_model True --meta_iterations 1000 --num_envs 4 --hidden_dim_actor 64 --hidden_dim_critic 64 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --op_per_job_options 4 6 8 10 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
slurmstepd: error: *** JOB 5289903 ON e09r03 CANCELLED AT 2023-12-26T16:51:03 ***

+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/check.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/check.sh
++++ export CHECK_HOME=/opt/hpc/setfreq/
++++ CHECK_HOME=/opt/hpc/setfreq/
++++ export PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 12009 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ exp=exp17_1
+ echo exp17_1
exp17_1
+ cat

->  op_per_job ->
+ n_j_options='15 15 15 15'
+ n_m_options='13 10 7 5'
+ op_per_job_options='4 7 10 12'
+ logdir=./runs/exp17_1
+ hidden_dim_actor=512
+ hidden_dim_critic=512
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ meta_iterations=500
+ max_updates_maml=500
+ num_tasks=4
+ max_updates_finetune=50
+ lr=0.003
+ data='13,4 10,7 7,10 5,12'
+ logdir_dan=./runs/exp17_1/DAN
+ python train/DAN.py --n_j 15 --n_m 13 --op_per_job 4 --data_source SD2 --model_suffix SD2 --logdir ./runs/exp17_1/DAN/train_model/15x13x4 --max_updates 500
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+SD2
-------------------------Training Setting-------------------------
source : SD2
model name :15x13+mix+SD2
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/500 [00:00<?, ?it/s]                                                 Episode 1	 reward: -3.61	 makespan: 357.60	 Mean_loss: 0.95955282,  training time: 5.05
progress:   0%|[34m          [0m| 0/500 [00:05<?, ?it/s]progress:   0%|[34m          [0m| 1/500 [00:05<41:58,  5.05s/it]                                                         Episode 2	 reward: -3.64	 makespan: 360.05	 Mean_loss: 0.62375832,  training time: 1.35
progress:   0%|[34m          [0m| 1/500 [00:06<41:58,  5.05s/it]progress:   0%|[34m          [0m| 2/500 [00:06<23:51,  2.88s/it]                                                         Episode 3	 reward: -3.47	 makespan: 343.75	 Mean_loss: 0.50179309,  training time: 1.34
progress:   0%|[34m          [0m| 2/500 [00:07<23:51,  2.88s/it]progress:   1%|[34m          [0m| 3/500 [00:07<17:59,  2.17s/it]                                                         Episode 4	 reward: -3.50	 makespan: 346.50	 Mean_loss: 0.35481498,  training time: 1.34
progress:   1%|[34m          [0m| 3/500 [00:09<17:59,  2.17s/it]progress:   1%|[34m          [0m| 4/500 [00:09<15:14,  1.84s/it]                                                         Episode 5	 reward: -3.43	 makespan: 339.90	 Mean_loss: 0.30524015,  training time: 1.34
progress:   1%|[34m          [0m| 4/500 [00:10<15:14,  1.84s/it]progress:   1%|[34m          [0m| 5/500 [00:10<13:42,  1.66s/it]                                                         Episode 6	 reward: -3.41	 makespan: 337.80	 Mean_loss: 0.13913848,  training time: 1.35
progress:   1%|[34m          [0m| 5/500 [00:11<13:42,  1.66s/it]progress:   1%|[34m          [0m| 6/500 [00:11<12:48,  1.55s/it]                                                         Episode 7	 reward: -3.52	 makespan: 348.15	 Mean_loss: 0.24050924,  training time: 1.35
progress:   1%|[34m          [0m| 6/500 [00:13<12:48,  1.55s/it]progress:   1%|[34m         [0m| 7/500 [00:13<12:13,  1.49s/it]                                                         Episode 8	 reward: -3.66	 makespan: 362.55	 Mean_loss: 0.27238366,  training time: 1.34
progress:   1%|[34m         [0m| 7/500 [00:14<12:13,  1.49s/it]progress:   2%|[34m         [0m| 8/500 [00:14<11:49,  1.44s/it]                                                         Episode 9	 reward: -3.38	 makespan: 334.35	 Mean_loss: 0.22307643,  training time: 1.36
progress:   2%|[34m         [0m| 8/500 [00:15<11:49,  1.44s/it]progress:   2%|[34m         [0m| 9/500 [00:15<11:34,  1.42s/it]                                                         Episode 10	 reward: -3.37	 makespan: 333.15	 Mean_loss: 0.20387480,  training time: 1.41
progress:   2%|[34m         [0m| 9/500 [00:17<11:34,  1.42s/it]progress:   2%|[34m         [0m| 10/500 [00:17<11:32,  1.41s/it]                                                          Episode 11	 reward: -3.43	 makespan: 339.35	 Mean_loss: 0.17419621,  training time: 1.35
progress:   2%|[34m         [0m| 10/500 [00:18<11:32,  1.41s/it]progress:   2%|[34m         [0m| 11/500 [00:18<11:21,  1.39s/it]                                                          Episode 12	 reward: -3.40	 makespan: 336.65	 Mean_loss: 0.18290867,  training time: 1.34
progress:   2%|[34m         [0m| 11/500 [00:19<11:21,  1.39s/it]progress:   2%|[34m         [0m| 12/500 [00:19<11:12,  1.38s/it]                                                          Episode 13	 reward: -3.26	 makespan: 322.55	 Mean_loss: 0.13800067,  training time: 1.43
progress:   2%|[34m         [0m| 12/500 [00:21<11:12,  1.38s/it]progress:   3%|[34m         [0m| 13/500 [00:21<11:19,  1.40s/it]                                                          Episode 14	 reward: -3.57	 makespan: 353.35	 Mean_loss: 0.20803483,  training time: 1.37
progress:   3%|[34m         [0m| 13/500 [00:22<11:19,  1.40s/it]progress:   3%|[34m         [0m| 14/500 [00:22<11:14,  1.39s/it]                                                          Episode 15	 reward: -3.34	 makespan: 331.15	 Mean_loss: 0.19233620,  training time: 1.35
progress:   3%|[34m         [0m| 14/500 [00:24<11:14,  1.39s/it]progress:   3%|[34m         [0m| 15/500 [00:24<11:08,  1.38s/it]                                                          Episode 16	 reward: -3.56	 makespan: 352.40	 Mean_loss: 0.18100300,  training time: 1.36
progress:   3%|[34m         [0m| 15/500 [00:25<11:08,  1.38s/it]progress:   3%|[34m         [0m| 16/500 [00:25<11:03,  1.37s/it]                                                          Episode 17	 reward: -3.35	 makespan: 331.45	 Mean_loss: 0.20565188,  training time: 1.38
progress:   3%|[34m         [0m| 16/500 [00:26<11:03,  1.37s/it]progress:   3%|[34m         [0m| 17/500 [00:26<11:04,  1.37s/it]                                                          Episode 18	 reward: -3.49	 makespan: 345.60	 Mean_loss: 0.18188913,  training time: 1.40
progress:   3%|[34m         [0m| 17/500 [00:28<11:04,  1.37s/it]progress:   4%|[34m         [0m| 18/500 [00:28<11:05,  1.38s/it]                                                          Episode 19	 reward: -3.25	 makespan: 321.45	 Mean_loss: 0.12075894,  training time: 1.36
progress:   4%|[34m         [0m| 18/500 [00:29<11:05,  1.38s/it]progress:   4%|[34m         [0m| 19/500 [00:29<11:01,  1.38s/it]                                                          Episode 20	 reward: -3.34	 makespan: 330.70	 Mean_loss: 0.10441932,  training time: 1.43
progress:   4%|[34m         [0m| 19/500 [00:31<11:01,  1.38s/it]progress:   4%|[34m         [0m| 20/500 [00:31<11:08,  1.39s/it]                                                          Episode 21	 reward: -3.29	 makespan: 325.70	 Mean_loss: 0.10025205,  training time: 1.45
progress:   4%|[34m         [0m| 20/500 [00:32<11:08,  1.39s/it]progress:   4%|[34m         [0m| 21/500 [00:32<11:15,  1.41s/it]                                                          Episode 22	 reward: -3.34	 makespan: 330.70	 Mean_loss: 0.07646488,  training time: 1.41
progress:   4%|[34m         [0m| 21/500 [00:33<11:15,  1.41s/it]progress:   4%|[34m         [0m| 22/500 [00:33<11:14,  1.41s/it]                                                          Episode 23	 reward: -3.32	 makespan: 328.80	 Mean_loss: 0.08844374,  training time: 1.39
progress:   4%|[34m         [0m| 22/500 [00:35<11:14,  1.41s/it]progress:   5%|[34m         [0m| 23/500 [00:35<11:10,  1.41s/it]                                                          Episode 24	 reward: -3.24	 makespan: 320.85	 Mean_loss: 0.11243626,  training time: 1.34
progress:   5%|[34m         [0m| 23/500 [00:36<11:10,  1.41s/it]progress:   5%|[34m         [0m| 24/500 [00:36<11:00,  1.39s/it]                                                          Episode 25	 reward: -3.42	 makespan: 338.25	 Mean_loss: 0.09256323,  training time: 1.33
progress:   5%|[34m         [0m| 24/500 [00:37<11:00,  1.39s/it]progress:   5%|[34m         [0m| 25/500 [00:37<10:51,  1.37s/it]                                                          Episode 26	 reward: -3.22	 makespan: 319.10	 Mean_loss: 0.06850513,  training time: 1.37
progress:   5%|[34m         [0m| 25/500 [00:39<10:51,  1.37s/it]progress:   5%|[34m         [0m| 26/500 [00:39<10:49,  1.37s/it]                                                          Episode 27	 reward: -3.22	 makespan: 318.60	 Mean_loss: 0.07100213,  training time: 1.34
progress:   5%|[34m         [0m| 26/500 [00:40<10:49,  1.37s/it]progress:   5%|[34m         [0m| 27/500 [00:40<10:43,  1.36s/it]                                                          Episode 28	 reward: -3.21	 makespan: 317.55	 Mean_loss: 0.08480144,  training time: 1.38
progress:   5%|[34m         [0m| 27/500 [00:42<10:43,  1.36s/it]progress:   6%|[34m         [0m| 28/500 [00:42<10:44,  1.37s/it]                                                          Episode 29	 reward: -3.21	 makespan: 317.65	 Mean_loss: 0.07951297,  training time: 1.35
progress:   6%|[34m         [0m| 28/500 [00:43<10:44,  1.37s/it]progress:   6%|[34m         [0m| 29/500 [00:43<10:41,  1.36s/it]                                                          Episode 30	 reward: -3.18	 makespan: 314.60	 Mean_loss: 0.04466092,  training time: 1.37
progress:   6%|[34m         [0m| 29/500 [00:44<10:41,  1.36s/it]progress:   6%|[34m         [0m| 30/500 [00:44<10:42,  1.37s/it]                                                          Episode 31	 reward: -2.97	 makespan: 294.25	 Mean_loss: 0.04886863,  training time: 1.35
progress:   6%|[34m         [0m| 30/500 [00:46<10:42,  1.37s/it]progress:   6%|[34m         [0m| 31/500 [00:46<10:38,  1.36s/it]                                                          Episode 32	 reward: -2.99	 makespan: 296.40	 Mean_loss: 0.07251833,  training time: 1.34
progress:   6%|[34m         [0m| 31/500 [00:47<10:38,  1.36s/it]progress:   6%|[34m         [0m| 32/500 [00:47<10:33,  1.35s/it]                                                          Episode 33	 reward: -3.18	 makespan: 315.25	 Mean_loss: 0.08253554,  training time: 1.36
progress:   6%|[34m         [0m| 32/500 [00:48<10:33,  1.35s/it]progress:   7%|[34m         [0m| 33/500 [00:48<10:32,  1.36s/it]                                                          Episode 34	 reward: -3.02	 makespan: 298.75	 Mean_loss: 0.06131842,  training time: 1.45
progress:   7%|[34m         [0m| 33/500 [00:50<10:32,  1.36s/it]progress:   7%|[34m         [0m| 34/500 [00:50<10:44,  1.38s/it]                                                          Episode 35	 reward: -3.09	 makespan: 306.00	 Mean_loss: 0.06592875,  training time: 1.35
progress:   7%|[34m         [0m| 34/500 [00:51<10:44,  1.38s/it]progress:   7%|[34m         [0m| 35/500 [00:51<10:38,  1.37s/it]                                                          Episode 36	 reward: -3.08	 makespan: 304.60	 Mean_loss: 0.07424355,  training time: 1.35
progress:   7%|[34m         [0m| 35/500 [00:52<10:38,  1.37s/it]progress:   7%|[34m         [0m| 36/500 [00:52<10:33,  1.37s/it]                                                          Episode 37	 reward: -3.11	 makespan: 308.05	 Mean_loss: 0.12938684,  training time: 1.36
progress:   7%|[34m         [0m| 36/500 [00:54<10:33,  1.37s/it]progress:   7%|[34m         [0m| 37/500 [00:54<10:32,  1.37s/it]                                                          Episode 38	 reward: -3.11	 makespan: 307.75	 Mean_loss: 0.04903817,  training time: 1.37
progress:   7%|[34m         [0m| 37/500 [00:55<10:32,  1.37s/it]progress:   8%|[34m         [0m| 38/500 [00:55<10:31,  1.37s/it]                                                          Episode 39	 reward: -3.25	 makespan: 322.00	 Mean_loss: 0.05150907,  training time: 1.36
progress:   8%|[34m         [0m| 38/500 [00:57<10:31,  1.37s/it]progress:   8%|[34m         [0m| 39/500 [00:57<10:28,  1.36s/it]                                                          Episode 40	 reward: -3.04	 makespan: 301.30	 Mean_loss: 0.04583213,  training time: 1.34
progress:   8%|[34m         [0m| 39/500 [00:58<10:28,  1.36s/it]progress:   8%|[34m         [0m| 40/500 [00:58<10:24,  1.36s/it]                                                          Episode 41	 reward: -2.86	 makespan: 282.85	 Mean_loss: 0.07284497,  training time: 1.39
progress:   8%|[34m         [0m| 40/500 [00:59<10:24,  1.36s/it]progress:   8%|[34m         [0m| 41/500 [00:59<10:27,  1.37s/it]                                                          Episode 42	 reward: -2.69	 makespan: 266.80	 Mean_loss: 0.02353624,  training time: 1.34
progress:   8%|[34m         [0m| 41/500 [01:01<10:27,  1.37s/it]progress:   8%|[34m         [0m| 42/500 [01:01<10:22,  1.36s/it]                                                          Episode 43	 reward: -2.72	 makespan: 269.15	 Mean_loss: 0.03318983,  training time: 1.34
progress:   8%|[34m         [0m| 42/500 [01:02<10:22,  1.36s/it]progress:   9%|[34m         [0m| 43/500 [01:02<10:17,  1.35s/it]                                                          Episode 44	 reward: -2.68	 makespan: 265.75	 Mean_loss: 0.05054331,  training time: 1.35
progress:   9%|[34m         [0m| 43/500 [01:03<10:17,  1.35s/it]progress:   9%|[34m         [0m| 44/500 [01:03<10:16,  1.35s/it]                                                          Episode 45	 reward: -2.69	 makespan: 266.40	 Mean_loss: 0.05920937,  training time: 1.34
progress:   9%|[34m         [0m| 44/500 [01:05<10:16,  1.35s/it]progress:   9%|[34m         [0m| 45/500 [01:05<10:13,  1.35s/it]                                                          Episode 46	 reward: -2.63	 makespan: 260.45	 Mean_loss: 0.03668442,  training time: 1.34
progress:   9%|[34m         [0m| 45/500 [01:06<10:13,  1.35s/it]progress:   9%|[34m         [0m| 46/500 [01:06<10:11,  1.35s/it]                                                          Episode 47	 reward: -2.64	 makespan: 261.60	 Mean_loss: 0.03548801,  training time: 1.42
progress:   9%|[34m         [0m| 46/500 [01:07<10:11,  1.35s/it]progress:   9%|[34m         [0m| 47/500 [01:07<10:20,  1.37s/it]                                                          Episode 48	 reward: -2.64	 makespan: 261.65	 Mean_loss: 0.08060664,  training time: 1.39
progress:   9%|[34m         [0m| 47/500 [01:09<10:20,  1.37s/it]progress:  10%|[34m         [0m| 48/500 [01:09<10:22,  1.38s/it]                                                          Episode 49	 reward: -2.65	 makespan: 262.60	 Mean_loss: 0.01877845,  training time: 1.37
progress:  10%|[34m         [0m| 48/500 [01:10<10:22,  1.38s/it]progress:  10%|[34m         [0m| 49/500 [01:10<10:20,  1.37s/it]                                                          Episode 50	 reward: -2.58	 makespan: 255.00	 Mean_loss: 0.03587904,  training time: 1.40
progress:  10%|[34m         [0m| 49/500 [01:12<10:20,  1.37s/it]progress:  10%|[34m         [0m| 50/500 [01:12<10:22,  1.38s/it]                                                          Episode 51	 reward: -2.68	 makespan: 265.75	 Mean_loss: 0.04345326,  training time: 1.38
progress:  10%|[34m         [0m| 50/500 [01:13<10:22,  1.38s/it]progress:  10%|[34m         [0m| 51/500 [01:13<10:20,  1.38s/it]                                                          Episode 52	 reward: -2.67	 makespan: 264.80	 Mean_loss: 0.04267742,  training time: 1.36
progress:  10%|[34m         [0m| 51/500 [01:14<10:20,  1.38s/it]progress:  10%|[34m         [0m| 52/500 [01:14<10:16,  1.38s/it]                                                          Episode 53	 reward: -2.64	 makespan: 261.55	 Mean_loss: 0.03507437,  training time: 1.36
progress:  10%|[34m         [0m| 52/500 [01:16<10:16,  1.38s/it]progress:  11%|[34m         [0m| 53/500 [01:16<10:12,  1.37s/it]                                                          Episode 54	 reward: -2.63	 makespan: 260.45	 Mean_loss: 0.04698932,  training time: 1.37
progress:  11%|[34m         [0m| 53/500 [01:17<10:12,  1.37s/it]progress:  11%|[34m         [0m| 54/500 [01:17<10:11,  1.37s/it]                                                          Episode 55	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.04065934,  training time: 1.37
progress:  11%|[34m         [0m| 54/500 [01:18<10:11,  1.37s/it]progress:  11%|[34m         [0m| 55/500 [01:18<10:10,  1.37s/it]                                                          Episode 56	 reward: -2.62	 makespan: 259.35	 Mean_loss: 0.02798653,  training time: 1.35
progress:  11%|[34m         [0m| 55/500 [01:20<10:10,  1.37s/it]progress:  11%|[34m         [0m| 56/500 [01:20<10:06,  1.37s/it]                                                          Episode 57	 reward: -2.65	 makespan: 262.55	 Mean_loss: 0.00872720,  training time: 1.36
progress:  11%|[34m         [0m| 56/500 [01:21<10:06,  1.37s/it]progress:  11%|[34m        [0m| 57/500 [01:21<10:04,  1.36s/it]                                                          Episode 58	 reward: -2.61	 makespan: 258.40	 Mean_loss: 0.05567545,  training time: 1.39
progress:  11%|[34m        [0m| 57/500 [01:23<10:04,  1.36s/it]progress:  12%|[34m        [0m| 58/500 [01:23<10:06,  1.37s/it]                                                          Episode 59	 reward: -2.60	 makespan: 257.85	 Mean_loss: 0.04814290,  training time: 1.37
progress:  12%|[34m        [0m| 58/500 [01:24<10:06,  1.37s/it]progress:  12%|[34m        [0m| 59/500 [01:24<10:04,  1.37s/it]                                                          Episode 60	 reward: -2.55	 makespan: 252.55	 Mean_loss: 0.06040491,  training time: 1.36
progress:  12%|[34m        [0m| 59/500 [01:25<10:04,  1.37s/it]progress:  12%|[34m        [0m| 60/500 [01:25<10:02,  1.37s/it]                                                          Episode 61	 reward: -2.71	 makespan: 268.65	 Mean_loss: 0.02142158,  training time: 1.39
progress:  12%|[34m        [0m| 60/500 [01:27<10:02,  1.37s/it]progress:  12%|[34m        [0m| 61/500 [01:27<10:04,  1.38s/it]                                                          Episode 62	 reward: -2.63	 makespan: 260.25	 Mean_loss: 0.07015228,  training time: 1.36
progress:  12%|[34m        [0m| 61/500 [01:28<10:04,  1.38s/it]progress:  12%|[34m        [0m| 62/500 [01:28<10:00,  1.37s/it]                                                          Episode 63	 reward: -2.66	 makespan: 263.75	 Mean_loss: 0.05079038,  training time: 1.39
progress:  12%|[34m        [0m| 62/500 [01:29<10:00,  1.37s/it]progress:  13%|[34m        [0m| 63/500 [01:29<10:02,  1.38s/it]                                                          Episode 64	 reward: -2.65	 makespan: 261.95	 Mean_loss: 0.03438309,  training time: 1.57
progress:  13%|[34m        [0m| 63/500 [01:31<10:02,  1.38s/it]progress:  13%|[34m        [0m| 64/500 [01:31<10:25,  1.44s/it]                                                          Episode 65	 reward: -2.65	 makespan: 262.65	 Mean_loss: 0.03343712,  training time: 1.42
progress:  13%|[34m        [0m| 64/500 [01:32<10:25,  1.44s/it]progress:  13%|[34m        [0m| 65/500 [01:32<10:22,  1.43s/it]                                                          Episode 66	 reward: -2.79	 makespan: 276.55	 Mean_loss: 0.06180704,  training time: 1.32
progress:  13%|[34m        [0m| 65/500 [01:34<10:22,  1.43s/it]progress:  13%|[34m        [0m| 66/500 [01:34<10:07,  1.40s/it]                                                          Episode 67	 reward: -2.65	 makespan: 262.00	 Mean_loss: 0.03699914,  training time: 1.34
progress:  13%|[34m        [0m| 66/500 [01:35<10:07,  1.40s/it]progress:  13%|[34m        [0m| 67/500 [01:35<09:57,  1.38s/it]                                                          Episode 68	 reward: -2.67	 makespan: 264.45	 Mean_loss: 0.02807174,  training time: 1.34
progress:  13%|[34m        [0m| 67/500 [01:36<09:57,  1.38s/it]progress:  14%|[34m        [0m| 68/500 [01:36<09:50,  1.37s/it]                                                          Episode 69	 reward: -2.62	 makespan: 259.10	 Mean_loss: 0.04463895,  training time: 1.38
progress:  14%|[34m        [0m| 68/500 [01:38<09:50,  1.37s/it]progress:  14%|[34m        [0m| 69/500 [01:38<09:51,  1.37s/it]                                                          Episode 70	 reward: -2.78	 makespan: 275.20	 Mean_loss: 0.06520356,  training time: 1.38
progress:  14%|[34m        [0m| 69/500 [01:39<09:51,  1.37s/it]progress:  14%|[34m        [0m| 70/500 [01:39<09:51,  1.38s/it]                                                          Episode 71	 reward: -2.64	 makespan: 261.70	 Mean_loss: 0.05129148,  training time: 1.33
progress:  14%|[34m        [0m| 70/500 [01:40<09:51,  1.38s/it]progress:  14%|[34m        [0m| 71/500 [01:40<09:44,  1.36s/it]                                                          Episode 72	 reward: -2.72	 makespan: 269.30	 Mean_loss: 0.06533995,  training time: 1.33
progress:  14%|[34m        [0m| 71/500 [01:42<09:44,  1.36s/it]progress:  14%|[34m        [0m| 72/500 [01:42<09:38,  1.35s/it]                                                          Episode 73	 reward: -2.69	 makespan: 266.00	 Mean_loss: 0.04274300,  training time: 1.33
progress:  14%|[34m        [0m| 72/500 [01:43<09:38,  1.35s/it]progress:  15%|[34m        [0m| 73/500 [01:43<09:34,  1.34s/it]                                                          Episode 74	 reward: -2.68	 makespan: 265.00	 Mean_loss: 0.04328836,  training time: 1.33
progress:  15%|[34m        [0m| 73/500 [01:44<09:34,  1.34s/it]progress:  15%|[34m        [0m| 74/500 [01:44<09:31,  1.34s/it]                                                          Episode 75	 reward: -2.63	 makespan: 260.40	 Mean_loss: 0.07669490,  training time: 1.36
progress:  15%|[34m        [0m| 74/500 [01:46<09:31,  1.34s/it]progress:  15%|[34m        [0m| 75/500 [01:46<09:32,  1.35s/it]                                                          Episode 76	 reward: -2.73	 makespan: 270.20	 Mean_loss: 0.02238702,  training time: 1.33
progress:  15%|[34m        [0m| 75/500 [01:47<09:32,  1.35s/it]progress:  15%|[34m        [0m| 76/500 [01:47<09:29,  1.34s/it]                                                          Episode 77	 reward: -2.73	 makespan: 270.40	 Mean_loss: 0.03447800,  training time: 1.32
progress:  15%|[34m        [0m| 76/500 [01:48<09:29,  1.34s/it]progress:  15%|[34m        [0m| 77/500 [01:48<09:24,  1.34s/it]                                                          Episode 78	 reward: -2.66	 makespan: 263.25	 Mean_loss: 0.04145316,  training time: 1.37
progress:  15%|[34m        [0m| 77/500 [01:50<09:24,  1.34s/it]progress:  16%|[34m        [0m| 78/500 [01:50<09:27,  1.35s/it]                                                          Episode 79	 reward: -2.63	 makespan: 259.90	 Mean_loss: 0.05206434,  training time: 1.34
progress:  16%|[34m        [0m| 78/500 [01:51<09:27,  1.35s/it]progress:  16%|[34m        [0m| 79/500 [01:51<09:26,  1.35s/it]                                                          Episode 80	 reward: -2.66	 makespan: 263.15	 Mean_loss: 0.06138218,  training time: 1.34
progress:  16%|[34m        [0m| 79/500 [01:53<09:26,  1.35s/it]progress:  16%|[34m        [0m| 80/500 [01:53<09:24,  1.35s/it]                                                          Episode 81	 reward: -2.55	 makespan: 252.75	 Mean_loss: 0.05490259,  training time: 1.40
progress:  16%|[34m        [0m| 80/500 [01:54<09:24,  1.35s/it]progress:  16%|[34m        [0m| 81/500 [01:54<09:30,  1.36s/it]                                                          Episode 82	 reward: -2.46	 makespan: 243.25	 Mean_loss: 0.05356460,  training time: 1.37
progress:  16%|[34m        [0m| 81/500 [01:55<09:30,  1.36s/it]progress:  16%|[34m        [0m| 82/500 [01:55<09:30,  1.36s/it]                                                          Episode 83	 reward: -2.49	 makespan: 246.15	 Mean_loss: 0.01500893,  training time: 1.36
progress:  16%|[34m        [0m| 82/500 [01:57<09:30,  1.36s/it]progress:  17%|[34m        [0m| 83/500 [01:57<09:28,  1.36s/it]                                                          Episode 84	 reward: -2.53	 makespan: 250.20	 Mean_loss: 0.00420692,  training time: 1.34
progress:  17%|[34m        [0m| 83/500 [01:58<09:28,  1.36s/it]progress:  17%|[34m        [0m| 84/500 [01:58<09:24,  1.36s/it]                                                          Episode 85	 reward: -2.46	 makespan: 243.40	 Mean_loss: 0.02664773,  training time: 1.32
progress:  17%|[34m        [0m| 84/500 [01:59<09:24,  1.36s/it]progress:  17%|[34m        [0m| 85/500 [01:59<09:19,  1.35s/it]                                                          Episode 86	 reward: -2.50	 makespan: 247.05	 Mean_loss: 0.01862443,  training time: 1.32
progress:  17%|[34m        [0m| 85/500 [02:01<09:19,  1.35s/it]progress:  17%|[34m        [0m| 86/500 [02:01<09:14,  1.34s/it]                                                          Episode 87	 reward: -2.51	 makespan: 248.70	 Mean_loss: 0.02709227,  training time: 1.32
progress:  17%|[34m        [0m| 86/500 [02:02<09:14,  1.34s/it]progress:  17%|[34m        [0m| 87/500 [02:02<09:10,  1.33s/it]                                                          Episode 88	 reward: -2.49	 makespan: 246.65	 Mean_loss: -0.00839851,  training time: 1.34
progress:  17%|[34m        [0m| 87/500 [02:03<09:10,  1.33s/it]progress:  18%|[34m        [0m| 88/500 [02:03<09:09,  1.33s/it]                                                          Episode 89	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.01546784,  training time: 1.32
progress:  18%|[34m        [0m| 88/500 [02:05<09:09,  1.33s/it]progress:  18%|[34m        [0m| 89/500 [02:05<09:06,  1.33s/it]                                                          Episode 90	 reward: -2.53	 makespan: 250.15	 Mean_loss: 0.01288094,  training time: 1.35
progress:  18%|[34m        [0m| 89/500 [02:06<09:06,  1.33s/it]progress:  18%|[34m        [0m| 90/500 [02:06<09:07,  1.34s/it]                                                          Episode 91	 reward: -2.48	 makespan: 245.20	 Mean_loss: 0.02797861,  training time: 1.33
progress:  18%|[34m        [0m| 90/500 [02:07<09:07,  1.34s/it]progress:  18%|[34m        [0m| 91/500 [02:07<09:05,  1.33s/it]                                                          Episode 92	 reward: -2.44	 makespan: 241.10	 Mean_loss: 0.00027161,  training time: 1.39
progress:  18%|[34m        [0m| 91/500 [02:09<09:05,  1.33s/it]progress:  18%|[34m        [0m| 92/500 [02:09<09:11,  1.35s/it]                                                          Episode 93	 reward: -2.43	 makespan: 240.10	 Mean_loss: 0.02319459,  training time: 1.33
progress:  18%|[34m        [0m| 92/500 [02:10<09:11,  1.35s/it]progress:  19%|[34m        [0m| 93/500 [02:10<09:07,  1.34s/it]                                                          Episode 94	 reward: -2.43	 makespan: 240.35	 Mean_loss: 0.04407641,  training time: 1.39
progress:  19%|[34m        [0m| 93/500 [02:11<09:07,  1.34s/it]progress:  19%|[34m        [0m| 94/500 [02:11<09:12,  1.36s/it]                                                          Episode 95	 reward: -2.51	 makespan: 248.15	 Mean_loss: -0.00821995,  training time: 1.33
progress:  19%|[34m        [0m| 94/500 [02:13<09:12,  1.36s/it]progress:  19%|[34m        [0m| 95/500 [02:13<09:06,  1.35s/it]                                                          Episode 96	 reward: -2.46	 makespan: 243.60	 Mean_loss: 0.00741367,  training time: 1.32
progress:  19%|[34m        [0m| 95/500 [02:14<09:06,  1.35s/it]progress:  19%|[34m        [0m| 96/500 [02:14<09:01,  1.34s/it]                                                          Episode 97	 reward: -2.54	 makespan: 251.60	 Mean_loss: 0.00486153,  training time: 1.32
progress:  19%|[34m        [0m| 96/500 [02:15<09:01,  1.34s/it]progress:  19%|[34m        [0m| 97/500 [02:15<08:57,  1.33s/it]                                                          Episode 98	 reward: -2.45	 makespan: 242.30	 Mean_loss: 0.02421039,  training time: 1.35
progress:  19%|[34m        [0m| 97/500 [02:17<08:57,  1.33s/it]progress:  20%|[34m        [0m| 98/500 [02:17<08:59,  1.34s/it]                                                          Episode 99	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.00621744,  training time: 1.42
progress:  20%|[34m        [0m| 98/500 [02:18<08:59,  1.34s/it]progress:  20%|[34m        [0m| 99/500 [02:18<09:07,  1.37s/it]                                                          Episode 100	 reward: -2.54	 makespan: 251.40	 Mean_loss: 0.02066853,  training time: 1.38
progress:  20%|[34m        [0m| 99/500 [02:20<09:07,  1.37s/it]progress:  20%|[34m        [0m| 100/500 [02:20<09:08,  1.37s/it]                                                           Episode 101	 reward: -2.66	 makespan: 263.30	 Mean_loss: 0.04131294,  training time: 1.40
progress:  20%|[34m        [0m| 100/500 [02:21<09:08,  1.37s/it]progress:  20%|[34m        [0m| 101/500 [02:21<09:10,  1.38s/it]                                                           Episode 102	 reward: -2.59	 makespan: 256.85	 Mean_loss: 0.00757650,  training time: 1.33
progress:  20%|[34m        [0m| 101/500 [02:22<09:10,  1.38s/it]progress:  20%|[34m        [0m| 102/500 [02:22<09:02,  1.36s/it]                                                           Episode 103	 reward: -2.68	 makespan: 265.65	 Mean_loss: 0.04958989,  training time: 1.41
progress:  20%|[34m        [0m| 102/500 [02:24<09:02,  1.36s/it]progress:  21%|[34m        [0m| 103/500 [02:24<09:07,  1.38s/it]                                                           Episode 104	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.01482266,  training time: 1.34
progress:  21%|[34m        [0m| 103/500 [02:25<09:07,  1.38s/it]progress:  21%|[34m        [0m| 104/500 [02:25<09:01,  1.37s/it]                                                           Episode 105	 reward: -2.65	 makespan: 262.80	 Mean_loss: 0.03663265,  training time: 1.33
progress:  21%|[34m        [0m| 104/500 [02:26<09:01,  1.37s/it]progress:  21%|[34m        [0m| 105/500 [02:26<08:55,  1.36s/it]                                                           Episode 106	 reward: -2.66	 makespan: 263.55	 Mean_loss: 0.07786853,  training time: 1.35
progress:  21%|[34m        [0m| 105/500 [02:28<08:55,  1.36s/it]progress:  21%|[34m        [0m| 106/500 [02:28<08:53,  1.35s/it]                                                           Episode 107	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.04375427,  training time: 1.33
progress:  21%|[34m        [0m| 106/500 [02:29<08:53,  1.35s/it]progress:  21%|[34m       [0m| 107/500 [02:29<08:49,  1.35s/it]                                                           Episode 108	 reward: -2.54	 makespan: 251.70	 Mean_loss: 0.01236334,  training time: 1.34
progress:  21%|[34m       [0m| 107/500 [02:30<08:49,  1.35s/it]progress:  22%|[34m       [0m| 108/500 [02:30<08:47,  1.35s/it]                                                           Episode 109	 reward: -2.63	 makespan: 259.95	 Mean_loss: 0.03296545,  training time: 1.29
progress:  22%|[34m       [0m| 108/500 [02:32<08:47,  1.35s/it]progress:  22%|[34m       [0m| 109/500 [02:32<08:39,  1.33s/it]                                                           Episode 110	 reward: -2.69	 makespan: 266.45	 Mean_loss: 0.03374705,  training time: 1.34
progress:  22%|[34m       [0m| 109/500 [02:33<08:39,  1.33s/it]progress:  22%|[34m       [0m| 110/500 [02:33<08:39,  1.33s/it]                                                           Episode 111	 reward: -2.60	 makespan: 257.15	 Mean_loss: 0.03847938,  training time: 1.32
progress:  22%|[34m       [0m| 110/500 [02:34<08:39,  1.33s/it]progress:  22%|[34m       [0m| 111/500 [02:34<08:37,  1.33s/it]                                                           Episode 112	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.03020280,  training time: 1.34
progress:  22%|[34m       [0m| 111/500 [02:36<08:37,  1.33s/it]progress:  22%|[34m       [0m| 112/500 [02:36<08:37,  1.33s/it]                                                           Episode 113	 reward: -2.53	 makespan: 250.35	 Mean_loss: 0.02401002,  training time: 1.34
progress:  22%|[34m       [0m| 112/500 [02:37<08:37,  1.33s/it]progress:  23%|[34m       [0m| 113/500 [02:37<08:37,  1.34s/it]                                                           Episode 114	 reward: -2.67	 makespan: 264.55	 Mean_loss: 0.06069526,  training time: 1.33
progress:  23%|[34m       [0m| 113/500 [02:38<08:37,  1.34s/it]progress:  23%|[34m       [0m| 114/500 [02:38<08:35,  1.34s/it]                                                           Episode 115	 reward: -2.57	 makespan: 254.10	 Mean_loss: 0.03002219,  training time: 1.34
progress:  23%|[34m       [0m| 114/500 [02:40<08:35,  1.34s/it]progress:  23%|[34m       [0m| 115/500 [02:40<08:34,  1.34s/it]                                                           Episode 116	 reward: -2.65	 makespan: 262.10	 Mean_loss: 0.02044510,  training time: 1.34
progress:  23%|[34m       [0m| 115/500 [02:41<08:34,  1.34s/it]progress:  23%|[34m       [0m| 116/500 [02:41<08:33,  1.34s/it]                                                           Episode 117	 reward: -2.60	 makespan: 257.45	 Mean_loss: 0.02103843,  training time: 1.36
progress:  23%|[34m       [0m| 116/500 [02:42<08:33,  1.34s/it]progress:  23%|[34m       [0m| 117/500 [02:42<08:35,  1.35s/it]                                                           Episode 118	 reward: -2.54	 makespan: 251.80	 Mean_loss: 0.01490104,  training time: 1.34
progress:  23%|[34m       [0m| 117/500 [02:44<08:35,  1.35s/it]progress:  24%|[34m       [0m| 118/500 [02:44<08:32,  1.34s/it]                                                           Episode 119	 reward: -2.66	 makespan: 263.40	 Mean_loss: 0.04904776,  training time: 1.33
progress:  24%|[34m       [0m| 118/500 [02:45<08:32,  1.34s/it]progress:  24%|[34m       [0m| 119/500 [02:45<08:29,  1.34s/it]                                                           Episode 120	 reward: -2.65	 makespan: 262.25	 Mean_loss: 0.02965258,  training time: 1.35
progress:  24%|[34m       [0m| 119/500 [02:46<08:29,  1.34s/it]progress:  24%|[34m       [0m| 120/500 [02:46<08:29,  1.34s/it]                                                           Episode 121	 reward: -2.55	 makespan: 252.65	 Mean_loss: 0.04114680,  training time: 1.38
progress:  24%|[34m       [0m| 120/500 [02:48<08:29,  1.34s/it]progress:  24%|[34m       [0m| 121/500 [02:48<08:32,  1.35s/it]                                                           Episode 122	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.02850017,  training time: 1.33
progress:  24%|[34m       [0m| 121/500 [02:49<08:32,  1.35s/it]progress:  24%|[34m       [0m| 122/500 [02:49<08:29,  1.35s/it]                                                           Episode 123	 reward: -2.53	 makespan: 250.50	 Mean_loss: 0.03597239,  training time: 1.33
progress:  24%|[34m       [0m| 122/500 [02:50<08:29,  1.35s/it]progress:  25%|[34m       [0m| 123/500 [02:50<08:25,  1.34s/it]                                                           Episode 124	 reward: -2.56	 makespan: 253.00	 Mean_loss: 0.02972440,  training time: 1.34
progress:  25%|[34m       [0m| 123/500 [02:52<08:25,  1.34s/it]progress:  25%|[34m       [0m| 124/500 [02:52<08:23,  1.34s/it]                                                           Episode 125	 reward: -2.48	 makespan: 246.00	 Mean_loss: 0.01667690,  training time: 1.34
progress:  25%|[34m       [0m| 124/500 [02:53<08:23,  1.34s/it]progress:  25%|[34m       [0m| 125/500 [02:53<08:22,  1.34s/it]                                                           Episode 126	 reward: -2.48	 makespan: 245.40	 Mean_loss: 0.02109066,  training time: 1.41
progress:  25%|[34m       [0m| 125/500 [02:55<08:22,  1.34s/it]progress:  25%|[34m       [0m| 126/500 [02:55<08:29,  1.36s/it]                                                           Episode 127	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.01541509,  training time: 1.37
progress:  25%|[34m       [0m| 126/500 [02:56<08:29,  1.36s/it]progress:  25%|[34m       [0m| 127/500 [02:56<08:28,  1.36s/it]                                                           Episode 128	 reward: -2.45	 makespan: 242.55	 Mean_loss: 0.00866467,  training time: 1.33
progress:  25%|[34m       [0m| 127/500 [02:57<08:28,  1.36s/it]progress:  26%|[34m       [0m| 128/500 [02:57<08:23,  1.35s/it]                                                           Episode 129	 reward: -2.60	 makespan: 257.00	 Mean_loss: 0.01943521,  training time: 1.32
progress:  26%|[34m       [0m| 128/500 [02:59<08:23,  1.35s/it]progress:  26%|[34m       [0m| 129/500 [02:59<08:18,  1.34s/it]                                                           Episode 130	 reward: -2.42	 makespan: 239.90	 Mean_loss: 0.02509215,  training time: 1.33
progress:  26%|[34m       [0m| 129/500 [03:00<08:18,  1.34s/it]progress:  26%|[34m       [0m| 130/500 [03:00<08:16,  1.34s/it]                                                           Episode 131	 reward: -2.42	 makespan: 240.05	 Mean_loss: 0.00318590,  training time: 1.33
progress:  26%|[34m       [0m| 130/500 [03:01<08:16,  1.34s/it]progress:  26%|[34m       [0m| 131/500 [03:01<08:13,  1.34s/it]                                                           Episode 132	 reward: -2.37	 makespan: 235.05	 Mean_loss: 0.01026925,  training time: 1.34
progress:  26%|[34m       [0m| 131/500 [03:03<08:13,  1.34s/it]progress:  26%|[34m       [0m| 132/500 [03:03<08:12,  1.34s/it]                                                           Episode 133	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.03000362,  training time: 1.40
progress:  26%|[34m       [0m| 132/500 [03:04<08:12,  1.34s/it]progress:  27%|[34m       [0m| 133/500 [03:04<08:17,  1.36s/it]                                                           Episode 134	 reward: -2.51	 makespan: 248.70	 Mean_loss: 0.00735780,  training time: 1.33
progress:  27%|[34m       [0m| 133/500 [03:05<08:17,  1.36s/it]progress:  27%|[34m       [0m| 134/500 [03:05<08:13,  1.35s/it]                                                           Episode 135	 reward: -2.46	 makespan: 243.45	 Mean_loss: -0.00508457,  training time: 1.32
progress:  27%|[34m       [0m| 134/500 [03:07<08:13,  1.35s/it]progress:  27%|[34m       [0m| 135/500 [03:07<08:09,  1.34s/it]                                                           Episode 136	 reward: -2.53	 makespan: 250.00	 Mean_loss: 0.03034483,  training time: 1.39
progress:  27%|[34m       [0m| 135/500 [03:08<08:09,  1.34s/it]progress:  27%|[34m       [0m| 136/500 [03:08<08:14,  1.36s/it]                                                           Episode 137	 reward: -2.44	 makespan: 241.10	 Mean_loss: -0.00310464,  training time: 1.37
progress:  27%|[34m       [0m| 136/500 [03:09<08:14,  1.36s/it]progress:  27%|[34m       [0m| 137/500 [03:09<08:13,  1.36s/it]                                                           Episode 138	 reward: -2.55	 makespan: 252.30	 Mean_loss: 0.03239258,  training time: 1.34
progress:  27%|[34m       [0m| 137/500 [03:11<08:13,  1.36s/it]progress:  28%|[34m       [0m| 138/500 [03:11<08:10,  1.35s/it]                                                           Episode 139	 reward: -2.44	 makespan: 241.30	 Mean_loss: 0.02393154,  training time: 1.33
progress:  28%|[34m       [0m| 138/500 [03:12<08:10,  1.35s/it]progress:  28%|[34m       [0m| 139/500 [03:12<08:06,  1.35s/it]                                                           Episode 140	 reward: -2.34	 makespan: 231.25	 Mean_loss: 0.00542906,  training time: 1.40
progress:  28%|[34m       [0m| 139/500 [03:13<08:06,  1.35s/it]progress:  28%|[34m       [0m| 140/500 [03:13<08:10,  1.36s/it]                                                           Episode 141	 reward: -2.50	 makespan: 247.30	 Mean_loss: 0.04179476,  training time: 1.36
progress:  28%|[34m       [0m| 140/500 [03:15<08:10,  1.36s/it]progress:  28%|[34m       [0m| 141/500 [03:15<08:08,  1.36s/it]                                                           Episode 142	 reward: -2.63	 makespan: 260.05	 Mean_loss: 0.04342607,  training time: 1.34
progress:  28%|[34m       [0m| 141/500 [03:16<08:08,  1.36s/it]progress:  28%|[34m       [0m| 142/500 [03:16<08:04,  1.35s/it]                                                           Episode 143	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.01952088,  training time: 1.34
progress:  28%|[34m       [0m| 142/500 [03:18<08:04,  1.35s/it]progress:  29%|[34m       [0m| 143/500 [03:18<08:02,  1.35s/it]                                                           Episode 144	 reward: -2.65	 makespan: 262.35	 Mean_loss: 0.03214633,  training time: 1.33
progress:  29%|[34m       [0m| 143/500 [03:19<08:02,  1.35s/it]progress:  29%|[34m       [0m| 144/500 [03:19<07:59,  1.35s/it]                                                           Episode 145	 reward: -2.47	 makespan: 244.50	 Mean_loss: 0.02162845,  training time: 1.34
progress:  29%|[34m       [0m| 144/500 [03:20<07:59,  1.35s/it]progress:  29%|[34m       [0m| 145/500 [03:20<07:57,  1.35s/it]                                                           Episode 146	 reward: -2.58	 makespan: 255.70	 Mean_loss: 0.04755019,  training time: 1.34
progress:  29%|[34m       [0m| 145/500 [03:22<07:57,  1.35s/it]progress:  29%|[34m       [0m| 146/500 [03:22<07:56,  1.34s/it]                                                           Episode 147	 reward: -2.51	 makespan: 248.15	 Mean_loss: 0.02291643,  training time: 1.36
progress:  29%|[34m       [0m| 146/500 [03:23<07:56,  1.34s/it]progress:  29%|[34m       [0m| 147/500 [03:23<07:56,  1.35s/it]                                                           Episode 148	 reward: -2.66	 makespan: 262.85	 Mean_loss: 0.04384731,  training time: 1.35
progress:  29%|[34m       [0m| 147/500 [03:24<07:56,  1.35s/it]progress:  30%|[34m       [0m| 148/500 [03:24<07:55,  1.35s/it]                                                           Episode 149	 reward: -2.56	 makespan: 253.55	 Mean_loss: 0.05523135,  training time: 1.36
progress:  30%|[34m       [0m| 148/500 [03:26<07:55,  1.35s/it]progress:  30%|[34m       [0m| 149/500 [03:26<07:55,  1.35s/it]                                                           Episode 150	 reward: -2.55	 makespan: 252.30	 Mean_loss: 0.02277700,  training time: 1.54
progress:  30%|[34m       [0m| 149/500 [03:27<07:55,  1.35s/it]progress:  30%|[34m       [0m| 150/500 [03:27<08:13,  1.41s/it]                                                           Episode 151	 reward: -2.50	 makespan: 247.80	 Mean_loss: 0.00632597,  training time: 1.37
progress:  30%|[34m       [0m| 150/500 [03:29<08:13,  1.41s/it]progress:  30%|[34m       [0m| 151/500 [03:29<08:08,  1.40s/it]                                                           Episode 152	 reward: -2.51	 makespan: 248.50	 Mean_loss: 0.03325059,  training time: 1.31
progress:  30%|[34m       [0m| 151/500 [03:30<08:08,  1.40s/it]progress:  30%|[34m       [0m| 152/500 [03:30<07:57,  1.37s/it]                                                           Episode 153	 reward: -2.46	 makespan: 243.50	 Mean_loss: 0.01998041,  training time: 1.37
progress:  30%|[34m       [0m| 152/500 [03:31<07:57,  1.37s/it]progress:  31%|[34m       [0m| 153/500 [03:31<07:56,  1.37s/it]                                                           Episode 154	 reward: -2.64	 makespan: 261.60	 Mean_loss: 0.02027257,  training time: 1.33
progress:  31%|[34m       [0m| 153/500 [03:33<07:56,  1.37s/it]progress:  31%|[34m       [0m| 154/500 [03:33<07:50,  1.36s/it]                                                           Episode 155	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.00577648,  training time: 1.35
progress:  31%|[34m       [0m| 154/500 [03:34<07:50,  1.36s/it]progress:  31%|[34m       [0m| 155/500 [03:34<07:48,  1.36s/it]                                                           Episode 156	 reward: -2.61	 makespan: 258.80	 Mean_loss: 0.03158560,  training time: 1.36
progress:  31%|[34m       [0m| 155/500 [03:35<07:48,  1.36s/it]progress:  31%|[34m       [0m| 156/500 [03:35<07:47,  1.36s/it]                                                           Episode 157	 reward: -2.50	 makespan: 247.05	 Mean_loss: 0.00800874,  training time: 1.36
progress:  31%|[34m       [0m| 156/500 [03:37<07:47,  1.36s/it]progress:  31%|[34m      [0m| 157/500 [03:37<07:46,  1.36s/it]                                                           Episode 158	 reward: -2.54	 makespan: 251.15	 Mean_loss: 0.01866103,  training time: 1.36
progress:  31%|[34m      [0m| 157/500 [03:38<07:46,  1.36s/it]progress:  32%|[34m      [0m| 158/500 [03:38<07:45,  1.36s/it]                                                           Episode 159	 reward: -2.54	 makespan: 251.05	 Mean_loss: 0.00517610,  training time: 1.36
progress:  32%|[34m      [0m| 158/500 [03:39<07:45,  1.36s/it]progress:  32%|[34m      [0m| 159/500 [03:39<07:44,  1.36s/it]                                                           Episode 160	 reward: -2.55	 makespan: 252.45	 Mean_loss: 0.00259418,  training time: 1.36
progress:  32%|[34m      [0m| 159/500 [03:41<07:44,  1.36s/it]progress:  32%|[34m      [0m| 160/500 [03:41<07:42,  1.36s/it]                                                           Episode 161	 reward: -2.54	 makespan: 251.60	 Mean_loss: 0.03198572,  training time: 1.40
progress:  32%|[34m      [0m| 160/500 [03:42<07:42,  1.36s/it]progress:  32%|[34m      [0m| 161/500 [03:42<07:45,  1.37s/it]                                                           Episode 162	 reward: -2.43	 makespan: 240.65	 Mean_loss: 0.04964688,  training time: 1.35
progress:  32%|[34m      [0m| 161/500 [03:43<07:45,  1.37s/it]progress:  32%|[34m      [0m| 162/500 [03:43<07:41,  1.37s/it]                                                           Episode 163	 reward: -2.45	 makespan: 242.95	 Mean_loss: 0.03221859,  training time: 1.39
progress:  32%|[34m      [0m| 162/500 [03:45<07:41,  1.37s/it]progress:  33%|[34m      [0m| 163/500 [03:45<07:43,  1.37s/it]                                                           Episode 164	 reward: -2.56	 makespan: 253.65	 Mean_loss: 0.03421230,  training time: 1.34
progress:  33%|[34m      [0m| 163/500 [03:46<07:43,  1.37s/it]progress:  33%|[34m      [0m| 164/500 [03:46<07:38,  1.36s/it]                                                           Episode 165	 reward: -2.48	 makespan: 245.10	 Mean_loss: 0.06269146,  training time: 1.35
progress:  33%|[34m      [0m| 164/500 [03:48<07:38,  1.36s/it]progress:  33%|[34m      [0m| 165/500 [03:48<07:36,  1.36s/it]                                                           Episode 166	 reward: -2.43	 makespan: 240.15	 Mean_loss: 0.02082050,  training time: 1.41
progress:  33%|[34m      [0m| 165/500 [03:49<07:36,  1.36s/it]progress:  33%|[34m      [0m| 166/500 [03:49<07:39,  1.38s/it]                                                           Episode 167	 reward: -2.54	 makespan: 251.40	 Mean_loss: 0.05621774,  training time: 1.36
progress:  33%|[34m      [0m| 166/500 [03:50<07:39,  1.38s/it]progress:  33%|[34m      [0m| 167/500 [03:50<07:36,  1.37s/it]                                                           Episode 168	 reward: -2.45	 makespan: 243.00	 Mean_loss: 0.04967865,  training time: 1.32
progress:  33%|[34m      [0m| 167/500 [03:52<07:36,  1.37s/it]progress:  34%|[34m      [0m| 168/500 [03:52<07:30,  1.36s/it]                                                           Episode 169	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.02415628,  training time: 1.34
progress:  34%|[34m      [0m| 168/500 [03:53<07:30,  1.36s/it]progress:  34%|[34m      [0m| 169/500 [03:53<07:27,  1.35s/it]                                                           Episode 170	 reward: -2.48	 makespan: 245.50	 Mean_loss: 0.04923182,  training time: 1.34
progress:  34%|[34m      [0m| 169/500 [03:54<07:27,  1.35s/it]progress:  34%|[34m      [0m| 170/500 [03:54<07:25,  1.35s/it]                                                           Episode 171	 reward: -2.57	 makespan: 254.90	 Mean_loss: 0.03489024,  training time: 1.32
progress:  34%|[34m      [0m| 170/500 [03:56<07:25,  1.35s/it]progress:  34%|[34m      [0m| 171/500 [03:56<07:21,  1.34s/it]                                                           Episode 172	 reward: -2.63	 makespan: 260.50	 Mean_loss: 0.05393575,  training time: 1.34
progress:  34%|[34m      [0m| 171/500 [03:57<07:21,  1.34s/it]progress:  34%|[34m      [0m| 172/500 [03:57<07:19,  1.34s/it]                                                           Episode 173	 reward: -2.57	 makespan: 254.05	 Mean_loss: 0.04511121,  training time: 1.34
progress:  34%|[34m      [0m| 172/500 [03:58<07:19,  1.34s/it]progress:  35%|[34m      [0m| 173/500 [03:58<07:18,  1.34s/it]                                                           Episode 174	 reward: -2.62	 makespan: 259.15	 Mean_loss: 0.01954490,  training time: 1.34
progress:  35%|[34m      [0m| 173/500 [04:00<07:18,  1.34s/it]progress:  35%|[34m      [0m| 174/500 [04:00<07:16,  1.34s/it]                                                           Episode 175	 reward: -2.59	 makespan: 256.70	 Mean_loss: 0.02456307,  training time: 1.31
progress:  35%|[34m      [0m| 174/500 [04:01<07:16,  1.34s/it]progress:  35%|[34m      [0m| 175/500 [04:01<07:12,  1.33s/it]                                                           Episode 176	 reward: -2.53	 makespan: 250.40	 Mean_loss: 0.03490429,  training time: 1.34
progress:  35%|[34m      [0m| 175/500 [04:02<07:12,  1.33s/it]progress:  35%|[34m      [0m| 176/500 [04:02<07:11,  1.33s/it]                                                           Episode 177	 reward: -2.55	 makespan: 252.10	 Mean_loss: 0.03684031,  training time: 1.33
progress:  35%|[34m      [0m| 176/500 [04:04<07:11,  1.33s/it]progress:  35%|[34m      [0m| 177/500 [04:04<07:09,  1.33s/it]                                                           Episode 178	 reward: -2.53	 makespan: 250.70	 Mean_loss: 0.04279566,  training time: 1.29
progress:  35%|[34m      [0m| 177/500 [04:05<07:09,  1.33s/it]progress:  36%|[34m      [0m| 178/500 [04:05<07:05,  1.32s/it]                                                           Episode 179	 reward: -2.56	 makespan: 253.70	 Mean_loss: 0.05609414,  training time: 1.31
progress:  36%|[34m      [0m| 178/500 [04:06<07:05,  1.32s/it]progress:  36%|[34m      [0m| 179/500 [04:06<07:03,  1.32s/it]                                                           Episode 180	 reward: -2.47	 makespan: 244.65	 Mean_loss: 0.04571059,  training time: 1.34
progress:  36%|[34m      [0m| 179/500 [04:08<07:03,  1.32s/it]progress:  36%|[34m      [0m| 180/500 [04:08<07:03,  1.32s/it]                                                           Episode 181	 reward: -2.55	 makespan: 252.90	 Mean_loss: 0.04182199,  training time: 1.34
progress:  36%|[34m      [0m| 180/500 [04:09<07:03,  1.32s/it]progress:  36%|[34m      [0m| 181/500 [04:09<07:03,  1.33s/it]                                                           Episode 182	 reward: -2.56	 makespan: 253.25	 Mean_loss: 0.01976470,  training time: 1.35
progress:  36%|[34m      [0m| 181/500 [04:10<07:03,  1.33s/it]progress:  36%|[34m      [0m| 182/500 [04:10<07:04,  1.34s/it]                                                           Episode 183	 reward: -2.66	 makespan: 263.10	 Mean_loss: 0.06702111,  training time: 1.33
progress:  36%|[34m      [0m| 182/500 [04:12<07:04,  1.34s/it]progress:  37%|[34m      [0m| 183/500 [04:12<07:03,  1.33s/it]                                                           Episode 184	 reward: -2.61	 makespan: 258.15	 Mean_loss: 0.03364063,  training time: 1.34
progress:  37%|[34m      [0m| 183/500 [04:13<07:03,  1.33s/it]progress:  37%|[34m      [0m| 184/500 [04:13<07:02,  1.34s/it]                                                           Episode 185	 reward: -2.62	 makespan: 259.20	 Mean_loss: 0.04950052,  training time: 1.33
progress:  37%|[34m      [0m| 184/500 [04:14<07:02,  1.34s/it]progress:  37%|[34m      [0m| 185/500 [04:14<07:01,  1.34s/it]                                                           Episode 186	 reward: -2.62	 makespan: 259.45	 Mean_loss: 0.02496651,  training time: 1.32
progress:  37%|[34m      [0m| 185/500 [04:16<07:01,  1.34s/it]progress:  37%|[34m      [0m| 186/500 [04:16<06:58,  1.33s/it]                                                           Episode 187	 reward: -2.66	 makespan: 263.80	 Mean_loss: 0.04508608,  training time: 1.34
progress:  37%|[34m      [0m| 186/500 [04:17<06:58,  1.33s/it]progress:  37%|[34m      [0m| 187/500 [04:17<06:57,  1.33s/it]                                                           Episode 188	 reward: -2.59	 makespan: 256.10	 Mean_loss: 0.05054632,  training time: 1.31
progress:  37%|[34m      [0m| 187/500 [04:18<06:57,  1.33s/it]progress:  38%|[34m      [0m| 188/500 [04:18<06:54,  1.33s/it]                                                           Episode 189	 reward: -2.58	 makespan: 255.35	 Mean_loss: 0.02430965,  training time: 1.30
progress:  38%|[34m      [0m| 188/500 [04:20<06:54,  1.33s/it]progress:  38%|[34m      [0m| 189/500 [04:20<06:50,  1.32s/it]                                                           Episode 190	 reward: -2.67	 makespan: 264.45	 Mean_loss: 0.04213835,  training time: 1.35
progress:  38%|[34m      [0m| 189/500 [04:21<06:50,  1.32s/it]progress:  38%|[34m      [0m| 190/500 [04:21<06:51,  1.33s/it]                                                           Episode 191	 reward: -2.65	 makespan: 262.15	 Mean_loss: 0.01555605,  training time: 1.35
progress:  38%|[34m      [0m| 190/500 [04:22<06:51,  1.33s/it]progress:  38%|[34m      [0m| 191/500 [04:22<06:52,  1.33s/it]                                                           Episode 192	 reward: -2.65	 makespan: 262.45	 Mean_loss: 0.03487076,  training time: 1.32
progress:  38%|[34m      [0m| 191/500 [04:24<06:52,  1.33s/it]progress:  38%|[34m      [0m| 192/500 [04:24<06:50,  1.33s/it]                                                           Episode 193	 reward: -2.59	 makespan: 256.85	 Mean_loss: 0.02612035,  training time: 1.32
progress:  38%|[34m      [0m| 192/500 [04:25<06:50,  1.33s/it]progress:  39%|[34m      [0m| 193/500 [04:25<06:48,  1.33s/it]                                                           Episode 194	 reward: -2.58	 makespan: 255.30	 Mean_loss: 0.04873649,  training time: 1.30
progress:  39%|[34m      [0m| 193/500 [04:26<06:48,  1.33s/it]progress:  39%|[34m      [0m| 194/500 [04:26<06:44,  1.32s/it]                                                           Episode 195	 reward: -2.58	 makespan: 255.30	 Mean_loss: 0.04043835,  training time: 1.34
progress:  39%|[34m      [0m| 194/500 [04:28<06:44,  1.32s/it]progress:  39%|[34m      [0m| 195/500 [04:28<06:44,  1.33s/it]                                                           Episode 196	 reward: -2.59	 makespan: 256.65	 Mean_loss: 0.03454080,  training time: 1.32
progress:  39%|[34m      [0m| 195/500 [04:29<06:44,  1.33s/it]progress:  39%|[34m      [0m| 196/500 [04:29<06:42,  1.32s/it]                                                           Episode 197	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.05865373,  training time: 1.34
progress:  39%|[34m      [0m| 196/500 [04:30<06:42,  1.32s/it]progress:  39%|[34m      [0m| 197/500 [04:30<06:42,  1.33s/it]                                                           Episode 198	 reward: -2.54	 makespan: 251.30	 Mean_loss: 0.03117134,  training time: 1.31
progress:  39%|[34m      [0m| 197/500 [04:32<06:42,  1.33s/it]progress:  40%|[34m      [0m| 198/500 [04:32<06:40,  1.32s/it]                                                           Episode 199	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.02038156,  training time: 1.35
progress:  40%|[34m      [0m| 198/500 [04:33<06:40,  1.32s/it]progress:  40%|[34m      [0m| 199/500 [04:33<06:40,  1.33s/it]                                                           Episode 200	 reward: -2.63	 makespan: 260.70	 Mean_loss: 0.01719381,  training time: 1.40
progress:  40%|[34m      [0m| 199/500 [04:34<06:40,  1.33s/it]progress:  40%|[34m      [0m| 200/500 [04:34<06:46,  1.35s/it]                                                           Episode 201	 reward: -2.63	 makespan: 260.00	 Mean_loss: 0.00246385,  training time: 1.37
progress:  40%|[34m      [0m| 200/500 [04:36<06:46,  1.35s/it]progress:  40%|[34m      [0m| 201/500 [04:36<06:46,  1.36s/it]                                                           Episode 202	 reward: -2.61	 makespan: 258.00	 Mean_loss: 0.02925555,  training time: 1.37
progress:  40%|[34m      [0m| 201/500 [04:37<06:46,  1.36s/it]progress:  40%|[34m      [0m| 202/500 [04:37<06:46,  1.36s/it]                                                           Episode 203	 reward: -2.59	 makespan: 256.25	 Mean_loss: 0.00789190,  training time: 1.35
progress:  40%|[34m      [0m| 202/500 [04:38<06:46,  1.36s/it]progress:  41%|[34m      [0m| 203/500 [04:38<06:44,  1.36s/it]                                                           Episode 204	 reward: -2.65	 makespan: 262.80	 Mean_loss: 0.00268585,  training time: 1.36
progress:  41%|[34m      [0m| 203/500 [04:40<06:44,  1.36s/it]progress:  41%|[34m      [0m| 204/500 [04:40<06:42,  1.36s/it]                                                           Episode 205	 reward: -2.59	 makespan: 256.50	 Mean_loss: 0.00084127,  training time: 1.35
progress:  41%|[34m      [0m| 204/500 [04:41<06:42,  1.36s/it]progress:  41%|[34m      [0m| 205/500 [04:41<06:40,  1.36s/it]                                                           Episode 206	 reward: -2.58	 makespan: 255.45	 Mean_loss: 0.01888653,  training time: 1.38
progress:  41%|[34m      [0m| 205/500 [04:42<06:40,  1.36s/it]progress:  41%|[34m      [0m| 206/500 [04:42<06:41,  1.37s/it]                                                           Episode 207	 reward: -2.59	 makespan: 256.40	 Mean_loss: 0.00748037,  training time: 1.34
progress:  41%|[34m      [0m| 206/500 [04:44<06:41,  1.37s/it]progress:  41%|[34m     [0m| 207/500 [04:44<06:37,  1.36s/it]                                                           Episode 208	 reward: -2.60	 makespan: 257.20	 Mean_loss: 0.00915488,  training time: 1.35
progress:  41%|[34m     [0m| 207/500 [04:45<06:37,  1.36s/it]progress:  42%|[34m     [0m| 208/500 [04:45<06:35,  1.35s/it]                                                           Episode 209	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.00106964,  training time: 1.35
progress:  42%|[34m     [0m| 208/500 [04:47<06:35,  1.35s/it]progress:  42%|[34m     [0m| 209/500 [04:47<06:33,  1.35s/it]                                                           Episode 210	 reward: -2.55	 makespan: 252.70	 Mean_loss: 0.00813984,  training time: 1.36
progress:  42%|[34m     [0m| 209/500 [04:48<06:33,  1.35s/it]progress:  42%|[34m     [0m| 210/500 [04:48<06:32,  1.35s/it]                                                           Episode 211	 reward: -2.66	 makespan: 263.65	 Mean_loss: 0.02650536,  training time: 1.34
progress:  42%|[34m     [0m| 210/500 [04:49<06:32,  1.35s/it]progress:  42%|[34m     [0m| 211/500 [04:49<06:30,  1.35s/it]                                                           Episode 212	 reward: -2.58	 makespan: 255.35	 Mean_loss: 0.00902877,  training time: 1.32
progress:  42%|[34m     [0m| 211/500 [04:51<06:30,  1.35s/it]progress:  42%|[34m     [0m| 212/500 [04:51<06:26,  1.34s/it]                                                           Episode 213	 reward: -2.58	 makespan: 255.10	 Mean_loss: -0.01163743,  training time: 1.34
progress:  42%|[34m     [0m| 212/500 [04:52<06:26,  1.34s/it]progress:  43%|[34m     [0m| 213/500 [04:52<06:25,  1.34s/it]                                                           Episode 214	 reward: -2.55	 makespan: 252.05	 Mean_loss: 0.01607708,  training time: 1.33
progress:  43%|[34m     [0m| 213/500 [04:53<06:25,  1.34s/it]progress:  43%|[34m     [0m| 214/500 [04:53<06:23,  1.34s/it]                                                           Episode 215	 reward: -2.57	 makespan: 254.55	 Mean_loss: 0.01602826,  training time: 1.33
progress:  43%|[34m     [0m| 214/500 [04:55<06:23,  1.34s/it]progress:  43%|[34m     [0m| 215/500 [04:55<06:21,  1.34s/it]                                                           Episode 216	 reward: -2.54	 makespan: 251.65	 Mean_loss: -0.01204816,  training time: 1.34
progress:  43%|[34m     [0m| 215/500 [04:56<06:21,  1.34s/it]progress:  43%|[34m     [0m| 216/500 [04:56<06:20,  1.34s/it]                                                           Episode 217	 reward: -2.67	 makespan: 264.20	 Mean_loss: 0.02773223,  training time: 1.40
progress:  43%|[34m     [0m| 216/500 [04:57<06:20,  1.34s/it]progress:  43%|[34m     [0m| 217/500 [04:57<06:23,  1.36s/it]                                                           Episode 218	 reward: -2.67	 makespan: 264.20	 Mean_loss: 0.01486000,  training time: 1.33
progress:  43%|[34m     [0m| 217/500 [04:59<06:23,  1.36s/it]progress:  44%|[34m     [0m| 218/500 [04:59<06:20,  1.35s/it]                                                           Episode 219	 reward: -2.62	 makespan: 259.05	 Mean_loss: 0.00035482,  training time: 1.34
progress:  44%|[34m     [0m| 218/500 [05:00<06:20,  1.35s/it]progress:  44%|[34m     [0m| 219/500 [05:00<06:18,  1.35s/it]                                                           Episode 220	 reward: -2.58	 makespan: 255.55	 Mean_loss: 0.00321651,  training time: 1.34
progress:  44%|[34m     [0m| 219/500 [05:01<06:18,  1.35s/it]progress:  44%|[34m     [0m| 220/500 [05:01<06:16,  1.34s/it]                                                           Episode 221	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.02797823,  training time: 1.38
progress:  44%|[34m     [0m| 220/500 [05:03<06:16,  1.34s/it]progress:  44%|[34m     [0m| 221/500 [05:03<06:17,  1.35s/it]                                                           Episode 222	 reward: -2.46	 makespan: 243.65	 Mean_loss: 0.05330762,  training time: 1.32
progress:  44%|[34m     [0m| 221/500 [05:04<06:17,  1.35s/it]progress:  44%|[34m     [0m| 222/500 [05:04<06:13,  1.34s/it]                                                           Episode 223	 reward: -2.50	 makespan: 247.35	 Mean_loss: 0.00536965,  training time: 1.30
progress:  44%|[34m     [0m| 222/500 [05:05<06:13,  1.34s/it]progress:  45%|[34m     [0m| 223/500 [05:05<06:08,  1.33s/it]                                                           Episode 224	 reward: -2.58	 makespan: 255.15	 Mean_loss: 0.03866633,  training time: 1.34
progress:  45%|[34m     [0m| 223/500 [05:07<06:08,  1.33s/it]progress:  45%|[34m     [0m| 224/500 [05:07<06:07,  1.33s/it]                                                           Episode 225	 reward: -2.49	 makespan: 246.10	 Mean_loss: 0.01999679,  training time: 1.38
progress:  45%|[34m     [0m| 224/500 [05:08<06:07,  1.33s/it]progress:  45%|[34m     [0m| 225/500 [05:08<06:10,  1.35s/it]                                                           Episode 226	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.01089951,  training time: 1.33
progress:  45%|[34m     [0m| 225/500 [05:09<06:10,  1.35s/it]progress:  45%|[34m     [0m| 226/500 [05:09<06:08,  1.34s/it]                                                           Episode 227	 reward: -2.57	 makespan: 254.75	 Mean_loss: 0.01918116,  training time: 1.31
progress:  45%|[34m     [0m| 226/500 [05:11<06:08,  1.34s/it]progress:  45%|[34m     [0m| 227/500 [05:11<06:04,  1.33s/it]                                                           Episode 228	 reward: -2.44	 makespan: 241.50	 Mean_loss: -0.00022220,  training time: 1.32
progress:  45%|[34m     [0m| 227/500 [05:12<06:04,  1.33s/it]progress:  46%|[34m     [0m| 228/500 [05:12<06:01,  1.33s/it]                                                           Episode 229	 reward: -2.44	 makespan: 241.15	 Mean_loss: 0.02643627,  training time: 1.31
progress:  46%|[34m     [0m| 228/500 [05:13<06:01,  1.33s/it]progress:  46%|[34m     [0m| 229/500 [05:13<05:58,  1.32s/it]                                                           Episode 230	 reward: -2.52	 makespan: 249.20	 Mean_loss: 0.02928683,  training time: 1.33
progress:  46%|[34m     [0m| 229/500 [05:15<05:58,  1.32s/it]progress:  46%|[34m     [0m| 230/500 [05:15<05:58,  1.33s/it]                                                           Episode 231	 reward: -2.55	 makespan: 252.90	 Mean_loss: 0.02157064,  training time: 1.33
progress:  46%|[34m     [0m| 230/500 [05:16<05:58,  1.33s/it]progress:  46%|[34m     [0m| 231/500 [05:16<05:57,  1.33s/it]                                                           Episode 232	 reward: -2.46	 makespan: 243.05	 Mean_loss: -0.00610451,  training time: 1.32
progress:  46%|[34m     [0m| 231/500 [05:17<05:57,  1.33s/it]progress:  46%|[34m     [0m| 232/500 [05:17<05:55,  1.33s/it]                                                           Episode 233	 reward: -2.49	 makespan: 246.90	 Mean_loss: -0.00325976,  training time: 1.32
progress:  46%|[34m     [0m| 232/500 [05:19<05:55,  1.33s/it]progress:  47%|[34m     [0m| 233/500 [05:19<05:53,  1.32s/it]                                                           Episode 234	 reward: -2.39	 makespan: 236.70	 Mean_loss: 0.02926390,  training time: 1.30
progress:  47%|[34m     [0m| 233/500 [05:20<05:53,  1.32s/it]progress:  47%|[34m     [0m| 234/500 [05:20<05:50,  1.32s/it]                                                           Episode 235	 reward: -2.56	 makespan: 253.15	 Mean_loss: 0.04821572,  training time: 1.32
progress:  47%|[34m     [0m| 234/500 [05:21<05:50,  1.32s/it]progress:  47%|[34m     [0m| 235/500 [05:21<05:48,  1.32s/it]                                                           Episode 236	 reward: -2.41	 makespan: 238.95	 Mean_loss: 0.00996284,  training time: 1.34
progress:  47%|[34m     [0m| 235/500 [05:23<05:48,  1.32s/it]progress:  47%|[34m     [0m| 236/500 [05:23<05:49,  1.32s/it]                                                           Episode 237	 reward: -2.52	 makespan: 249.90	 Mean_loss: 0.02144324,  training time: 1.33
progress:  47%|[34m     [0m| 236/500 [05:24<05:49,  1.32s/it]progress:  47%|[34m     [0m| 237/500 [05:24<05:48,  1.33s/it]                                                           Episode 238	 reward: -2.51	 makespan: 248.80	 Mean_loss: 0.04336273,  training time: 1.31
progress:  47%|[34m     [0m| 237/500 [05:25<05:48,  1.33s/it]progress:  48%|[34m     [0m| 238/500 [05:25<05:46,  1.32s/it]                                                           Episode 239	 reward: -2.36	 makespan: 233.60	 Mean_loss: 0.01177412,  training time: 1.34
progress:  48%|[34m     [0m| 238/500 [05:27<05:46,  1.32s/it]progress:  48%|[34m     [0m| 239/500 [05:27<05:46,  1.33s/it]                                                           Episode 240	 reward: -2.46	 makespan: 243.55	 Mean_loss: 0.04243231,  training time: 1.33
progress:  48%|[34m     [0m| 239/500 [05:28<05:46,  1.33s/it]progress:  48%|[34m     [0m| 240/500 [05:28<05:45,  1.33s/it]                                                           Episode 241	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.03818158,  training time: 1.37
progress:  48%|[34m     [0m| 240/500 [05:29<05:45,  1.33s/it]progress:  48%|[34m     [0m| 241/500 [05:29<05:47,  1.34s/it]                                                           Episode 242	 reward: -2.45	 makespan: 242.15	 Mean_loss: 0.03884682,  training time: 1.33
progress:  48%|[34m     [0m| 241/500 [05:31<05:47,  1.34s/it]progress:  48%|[34m     [0m| 242/500 [05:31<05:45,  1.34s/it]                                                           Episode 243	 reward: -2.46	 makespan: 244.00	 Mean_loss: 0.03095153,  training time: 1.35
progress:  48%|[34m     [0m| 242/500 [05:32<05:45,  1.34s/it]progress:  49%|[34m     [0m| 243/500 [05:32<05:44,  1.34s/it]                                                           Episode 244	 reward: -2.45	 makespan: 242.20	 Mean_loss: 0.02504858,  training time: 1.32
progress:  49%|[34m     [0m| 243/500 [05:33<05:44,  1.34s/it]progress:  49%|[34m     [0m| 244/500 [05:33<05:41,  1.34s/it]                                                           Episode 245	 reward: -2.51	 makespan: 248.05	 Mean_loss: 0.02030797,  training time: 1.32
progress:  49%|[34m     [0m| 244/500 [05:35<05:41,  1.34s/it]progress:  49%|[34m     [0m| 245/500 [05:35<05:39,  1.33s/it]                                                           Episode 246	 reward: -2.45	 makespan: 242.30	 Mean_loss: 0.02574945,  training time: 1.32
progress:  49%|[34m     [0m| 245/500 [05:36<05:39,  1.33s/it]progress:  49%|[34m     [0m| 246/500 [05:36<05:37,  1.33s/it]                                                           Episode 247	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.01909608,  training time: 1.31
progress:  49%|[34m     [0m| 246/500 [05:37<05:37,  1.33s/it]progress:  49%|[34m     [0m| 247/500 [05:37<05:34,  1.32s/it]                                                           Episode 248	 reward: -2.45	 makespan: 242.75	 Mean_loss: 0.01732831,  training time: 1.31
progress:  49%|[34m     [0m| 247/500 [05:38<05:34,  1.32s/it]progress:  50%|[34m     [0m| 248/500 [05:38<05:32,  1.32s/it]                                                           Episode 249	 reward: -2.54	 makespan: 251.00	 Mean_loss: 0.02697007,  training time: 1.30
progress:  50%|[34m     [0m| 248/500 [05:40<05:32,  1.32s/it]progress:  50%|[34m     [0m| 249/500 [05:40<05:29,  1.31s/it]                                                           Episode 250	 reward: -2.47	 makespan: 244.85	 Mean_loss: 0.02229749,  training time: 1.33
progress:  50%|[34m     [0m| 249/500 [05:41<05:29,  1.31s/it]progress:  50%|[34m     [0m| 250/500 [05:41<05:29,  1.32s/it]                                                           Episode 251	 reward: -2.60	 makespan: 257.80	 Mean_loss: 0.01907813,  training time: 1.27
progress:  50%|[34m     [0m| 250/500 [05:42<05:29,  1.32s/it]progress:  50%|[34m     [0m| 251/500 [05:42<05:24,  1.30s/it]                                                           Episode 252	 reward: -2.48	 makespan: 245.40	 Mean_loss: 0.02124176,  training time: 1.27
progress:  50%|[34m     [0m| 251/500 [05:44<05:24,  1.30s/it]progress:  50%|[34m     [0m| 252/500 [05:44<05:20,  1.29s/it]                                                           Episode 253	 reward: -2.49	 makespan: 246.75	 Mean_loss: 0.01047661,  training time: 1.34
progress:  50%|[34m     [0m| 252/500 [05:45<05:20,  1.29s/it]progress:  51%|[34m     [0m| 253/500 [05:45<05:23,  1.31s/it]                                                           Episode 254	 reward: -2.45	 makespan: 242.50	 Mean_loss: 0.03678476,  training time: 1.38
progress:  51%|[34m     [0m| 253/500 [05:46<05:23,  1.31s/it]progress:  51%|[34m     [0m| 254/500 [05:46<05:27,  1.33s/it]                                                           Episode 255	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.03761500,  training time: 1.29
progress:  51%|[34m     [0m| 254/500 [05:48<05:27,  1.33s/it]progress:  51%|[34m     [0m| 255/500 [05:48<05:22,  1.32s/it]                                                           Episode 256	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.01464200,  training time: 1.41
progress:  51%|[34m     [0m| 255/500 [05:49<05:22,  1.32s/it]progress:  51%|[34m     [0m| 256/500 [05:49<05:28,  1.35s/it]                                                           Episode 257	 reward: -2.47	 makespan: 244.60	 Mean_loss: 0.01860620,  training time: 1.40
progress:  51%|[34m     [0m| 256/500 [05:50<05:28,  1.35s/it]progress:  51%|[34m    [0m| 257/500 [05:50<05:31,  1.36s/it]                                                           Episode 258	 reward: -2.53	 makespan: 250.15	 Mean_loss: 0.03294506,  training time: 1.32
progress:  51%|[34m    [0m| 257/500 [05:52<05:31,  1.36s/it]progress:  52%|[34m    [0m| 258/500 [05:52<05:27,  1.35s/it]                                                           Episode 259	 reward: -2.50	 makespan: 247.65	 Mean_loss: 0.01786495,  training time: 1.29
progress:  52%|[34m    [0m| 258/500 [05:53<05:27,  1.35s/it]progress:  52%|[34m    [0m| 259/500 [05:53<05:21,  1.33s/it]                                                           Episode 260	 reward: -2.41	 makespan: 239.05	 Mean_loss: -0.00734694,  training time: 1.29
progress:  52%|[34m    [0m| 259/500 [05:54<05:21,  1.33s/it]progress:  52%|[34m    [0m| 260/500 [05:54<05:16,  1.32s/it]                                                           Episode 261	 reward: -2.48	 makespan: 245.05	 Mean_loss: 0.05856788,  training time: 1.34
progress:  52%|[34m    [0m| 260/500 [05:56<05:16,  1.32s/it]progress:  52%|[34m    [0m| 261/500 [05:56<05:17,  1.33s/it]                                                           Episode 262	 reward: -2.56	 makespan: 253.90	 Mean_loss: 0.03622349,  training time: 1.30
progress:  52%|[34m    [0m| 261/500 [05:57<05:17,  1.33s/it]progress:  52%|[34m    [0m| 262/500 [05:57<05:14,  1.32s/it]                                                           Episode 263	 reward: -2.54	 makespan: 251.50	 Mean_loss: 0.02144111,  training time: 1.28
progress:  52%|[34m    [0m| 262/500 [05:58<05:14,  1.32s/it]progress:  53%|[34m    [0m| 263/500 [05:58<05:10,  1.31s/it]                                                           Episode 264	 reward: -2.57	 makespan: 254.20	 Mean_loss: 0.07936625,  training time: 1.32
progress:  53%|[34m    [0m| 263/500 [06:00<05:10,  1.31s/it]progress:  53%|[34m    [0m| 264/500 [06:00<05:10,  1.31s/it]                                                           Episode 265	 reward: -2.49	 makespan: 246.60	 Mean_loss: 0.02824869,  training time: 1.30
progress:  53%|[34m    [0m| 264/500 [06:01<05:10,  1.31s/it]progress:  53%|[34m    [0m| 265/500 [06:01<05:07,  1.31s/it]                                                           Episode 266	 reward: -2.58	 makespan: 255.70	 Mean_loss: 0.04467317,  training time: 1.34
progress:  53%|[34m    [0m| 265/500 [06:02<05:07,  1.31s/it]progress:  53%|[34m    [0m| 266/500 [06:02<05:08,  1.32s/it]                                                           Episode 267	 reward: -2.58	 makespan: 255.90	 Mean_loss: 0.04048063,  training time: 1.32
progress:  53%|[34m    [0m| 266/500 [06:04<05:08,  1.32s/it]progress:  53%|[34m    [0m| 267/500 [06:04<05:07,  1.32s/it]                                                           Episode 268	 reward: -2.54	 makespan: 251.00	 Mean_loss: 0.05316020,  training time: 1.31
progress:  53%|[34m    [0m| 267/500 [06:05<05:07,  1.32s/it]progress:  54%|[34m    [0m| 268/500 [06:05<05:05,  1.32s/it]                                                           Episode 269	 reward: -2.61	 makespan: 258.30	 Mean_loss: 0.03830019,  training time: 1.27
progress:  54%|[34m    [0m| 268/500 [06:06<05:05,  1.32s/it]progress:  54%|[34m    [0m| 269/500 [06:06<05:00,  1.30s/it]                                                           Episode 270	 reward: -2.49	 makespan: 246.15	 Mean_loss: 0.03927302,  training time: 1.33
progress:  54%|[34m    [0m| 269/500 [06:08<05:00,  1.30s/it]progress:  54%|[34m    [0m| 270/500 [06:08<05:01,  1.31s/it]                                                           Episode 271	 reward: -2.47	 makespan: 244.80	 Mean_loss: 0.02767701,  training time: 1.33
progress:  54%|[34m    [0m| 270/500 [06:09<05:01,  1.31s/it]progress:  54%|[34m    [0m| 271/500 [06:09<05:01,  1.32s/it]                                                           Episode 272	 reward: -2.53	 makespan: 250.10	 Mean_loss: 0.04221074,  training time: 1.29
progress:  54%|[34m    [0m| 271/500 [06:10<05:01,  1.32s/it]progress:  54%|[34m    [0m| 272/500 [06:10<04:58,  1.31s/it]                                                           Episode 273	 reward: -2.41	 makespan: 238.80	 Mean_loss: 0.04648020,  training time: 1.35
progress:  54%|[34m    [0m| 272/500 [06:12<04:58,  1.31s/it]progress:  55%|[34m    [0m| 273/500 [06:12<05:00,  1.32s/it]                                                           Episode 274	 reward: -2.51	 makespan: 248.75	 Mean_loss: 0.08274285,  training time: 1.30
progress:  55%|[34m    [0m| 273/500 [06:13<05:00,  1.32s/it]progress:  55%|[34m    [0m| 274/500 [06:13<04:57,  1.32s/it]                                                           Episode 275	 reward: -2.54	 makespan: 251.50	 Mean_loss: 0.04893445,  training time: 1.29
progress:  55%|[34m    [0m| 274/500 [06:14<04:57,  1.32s/it]progress:  55%|[34m    [0m| 275/500 [06:14<04:54,  1.31s/it]                                                           Episode 276	 reward: -2.60	 makespan: 257.15	 Mean_loss: 0.05724899,  training time: 1.29
progress:  55%|[34m    [0m| 275/500 [06:15<04:54,  1.31s/it]progress:  55%|[34m    [0m| 276/500 [06:15<04:52,  1.30s/it]                                                           Episode 277	 reward: -2.49	 makespan: 246.95	 Mean_loss: 0.06563666,  training time: 1.28
progress:  55%|[34m    [0m| 276/500 [06:17<04:52,  1.30s/it]progress:  55%|[34m    [0m| 277/500 [06:17<04:49,  1.30s/it]                                                           Episode 278	 reward: -2.57	 makespan: 254.25	 Mean_loss: 0.03102925,  training time: 1.28
progress:  55%|[34m    [0m| 277/500 [06:18<04:49,  1.30s/it]progress:  56%|[34m    [0m| 278/500 [06:18<04:47,  1.29s/it]                                                           Episode 279	 reward: -2.58	 makespan: 255.10	 Mean_loss: 0.06142269,  training time: 1.31
progress:  56%|[34m    [0m| 278/500 [06:19<04:47,  1.29s/it]progress:  56%|[34m    [0m| 279/500 [06:19<04:47,  1.30s/it]                                                           Episode 280	 reward: -2.49	 makespan: 246.10	 Mean_loss: 0.03221605,  training time: 1.28
progress:  56%|[34m    [0m| 279/500 [06:21<04:47,  1.30s/it]progress:  56%|[34m    [0m| 280/500 [06:21<04:44,  1.29s/it]                                                           Episode 281	 reward: -2.54	 makespan: 251.80	 Mean_loss: 0.03753761,  training time: 1.33
progress:  56%|[34m    [0m| 280/500 [06:22<04:44,  1.29s/it]progress:  56%|[34m    [0m| 281/500 [06:22<04:46,  1.31s/it]                                                           Episode 282	 reward: -2.59	 makespan: 256.30	 Mean_loss: 0.04272883,  training time: 1.27
progress:  56%|[34m    [0m| 281/500 [06:23<04:46,  1.31s/it]progress:  56%|[34m    [0m| 282/500 [06:23<04:42,  1.30s/it]                                                           Episode 283	 reward: -2.66	 makespan: 263.20	 Mean_loss: 0.05472729,  training time: 1.31
progress:  56%|[34m    [0m| 282/500 [06:24<04:42,  1.30s/it]progress:  57%|[34m    [0m| 283/500 [06:24<04:42,  1.30s/it]                                                           Episode 284	 reward: -2.50	 makespan: 247.30	 Mean_loss: 0.01671523,  training time: 1.31
progress:  57%|[34m    [0m| 283/500 [06:26<04:42,  1.30s/it]progress:  57%|[34m    [0m| 284/500 [06:26<04:41,  1.30s/it]                                                           Episode 285	 reward: -2.54	 makespan: 251.15	 Mean_loss: 0.03505917,  training time: 1.28
progress:  57%|[34m    [0m| 284/500 [06:27<04:41,  1.30s/it]progress:  57%|[34m    [0m| 285/500 [06:27<04:38,  1.30s/it]                                                           Episode 286	 reward: -2.57	 makespan: 254.85	 Mean_loss: 0.06321464,  training time: 1.29
progress:  57%|[34m    [0m| 285/500 [06:28<04:38,  1.30s/it]progress:  57%|[34m    [0m| 286/500 [06:28<04:37,  1.30s/it]                                                           Episode 287	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.04128942,  training time: 1.31
progress:  57%|[34m    [0m| 286/500 [06:30<04:37,  1.30s/it]progress:  57%|[34m    [0m| 287/500 [06:30<04:36,  1.30s/it]                                                           Episode 288	 reward: -2.61	 makespan: 258.35	 Mean_loss: 0.04819540,  training time: 1.27
progress:  57%|[34m    [0m| 287/500 [06:31<04:36,  1.30s/it]progress:  58%|[34m    [0m| 288/500 [06:31<04:33,  1.29s/it]                                                           Episode 289	 reward: -2.65	 makespan: 261.95	 Mean_loss: 0.01669517,  training time: 1.28
progress:  58%|[34m    [0m| 288/500 [06:32<04:33,  1.29s/it]progress:  58%|[34m    [0m| 289/500 [06:32<04:31,  1.29s/it]                                                           Episode 290	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.03821478,  training time: 1.30
progress:  58%|[34m    [0m| 289/500 [06:34<04:31,  1.29s/it]progress:  58%|[34m    [0m| 290/500 [06:34<04:31,  1.29s/it]                                                           Episode 291	 reward: -2.55	 makespan: 252.10	 Mean_loss: 0.02562712,  training time: 1.31
progress:  58%|[34m    [0m| 290/500 [06:35<04:31,  1.29s/it]progress:  58%|[34m    [0m| 291/500 [06:35<04:31,  1.30s/it]                                                           Episode 292	 reward: -2.54	 makespan: 251.20	 Mean_loss: 0.05634262,  training time: 1.34
progress:  58%|[34m    [0m| 291/500 [06:36<04:31,  1.30s/it]progress:  58%|[34m    [0m| 292/500 [06:36<04:32,  1.31s/it]                                                           Episode 293	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.02848350,  training time: 1.32
progress:  58%|[34m    [0m| 292/500 [06:37<04:32,  1.31s/it]progress:  59%|[34m    [0m| 293/500 [06:37<04:31,  1.31s/it]                                                           Episode 294	 reward: -2.52	 makespan: 249.50	 Mean_loss: 0.01589919,  training time: 1.32
progress:  59%|[34m    [0m| 293/500 [06:39<04:31,  1.31s/it]progress:  59%|[34m    [0m| 294/500 [06:39<04:30,  1.31s/it]                                                           Episode 295	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.05491237,  training time: 1.36
progress:  59%|[34m    [0m| 294/500 [06:40<04:30,  1.31s/it]progress:  59%|[34m    [0m| 295/500 [06:40<04:32,  1.33s/it]                                                           Episode 296	 reward: -2.60	 makespan: 257.50	 Mean_loss: 0.03517814,  training time: 1.32
progress:  59%|[34m    [0m| 295/500 [06:41<04:32,  1.33s/it]progress:  59%|[34m    [0m| 296/500 [06:41<04:30,  1.33s/it]                                                           Episode 297	 reward: -2.74	 makespan: 270.80	 Mean_loss: 0.02636559,  training time: 1.31
progress:  59%|[34m    [0m| 296/500 [06:43<04:30,  1.33s/it]progress:  59%|[34m    [0m| 297/500 [06:43<04:28,  1.32s/it]                                                           Episode 298	 reward: -2.60	 makespan: 257.75	 Mean_loss: 0.05046508,  training time: 1.35
progress:  59%|[34m    [0m| 297/500 [06:44<04:28,  1.32s/it]progress:  60%|[34m    [0m| 298/500 [06:44<04:28,  1.33s/it]                                                           Episode 299	 reward: -2.65	 makespan: 262.25	 Mean_loss: 0.01526794,  training time: 1.37
progress:  60%|[34m    [0m| 298/500 [06:46<04:28,  1.33s/it]progress:  60%|[34m    [0m| 299/500 [06:46<04:29,  1.34s/it]                                                           Episode 300	 reward: -2.65	 makespan: 262.40	 Mean_loss: 0.05679302,  training time: 1.37
progress:  60%|[34m    [0m| 299/500 [06:47<04:29,  1.34s/it]progress:  60%|[34m    [0m| 300/500 [06:47<04:30,  1.35s/it]                                                           Episode 301	 reward: -2.55	 makespan: 252.25	 Mean_loss: 0.05579840,  training time: 1.38
progress:  60%|[34m    [0m| 300/500 [06:48<04:30,  1.35s/it]progress:  60%|[34m    [0m| 301/500 [06:48<04:30,  1.36s/it]                                                           Episode 302	 reward: -2.52	 makespan: 249.00	 Mean_loss: 0.02089373,  training time: 1.33
progress:  60%|[34m    [0m| 301/500 [06:50<04:30,  1.36s/it]progress:  60%|[34m    [0m| 302/500 [06:50<04:27,  1.35s/it]                                                           Episode 303	 reward: -2.56	 makespan: 253.45	 Mean_loss: 0.04925321,  training time: 1.28
progress:  60%|[34m    [0m| 302/500 [06:51<04:27,  1.35s/it]progress:  61%|[34m    [0m| 303/500 [06:51<04:22,  1.33s/it]                                                           Episode 304	 reward: -2.50	 makespan: 247.25	 Mean_loss: 0.04715963,  training time: 1.33
progress:  61%|[34m    [0m| 303/500 [06:52<04:22,  1.33s/it]progress:  61%|[34m    [0m| 304/500 [06:52<04:20,  1.33s/it]                                                           Episode 305	 reward: -2.50	 makespan: 247.45	 Mean_loss: 0.05359538,  training time: 1.34
progress:  61%|[34m    [0m| 304/500 [06:54<04:20,  1.33s/it]progress:  61%|[34m    [0m| 305/500 [06:54<04:19,  1.33s/it]                                                           Episode 306	 reward: -2.61	 makespan: 258.40	 Mean_loss: 0.04193128,  training time: 1.30
progress:  61%|[34m    [0m| 305/500 [06:55<04:19,  1.33s/it]progress:  61%|[34m    [0m| 306/500 [06:55<04:16,  1.32s/it]                                                           Episode 307	 reward: -2.57	 makespan: 254.30	 Mean_loss: 0.06080026,  training time: 1.32
progress:  61%|[34m    [0m| 306/500 [06:56<04:16,  1.32s/it]progress:  61%|[34m   [0m| 307/500 [06:56<04:15,  1.32s/it]                                                           Episode 308	 reward: -2.57	 makespan: 254.60	 Mean_loss: 0.04616440,  training time: 1.33
progress:  61%|[34m   [0m| 307/500 [06:58<04:15,  1.32s/it]progress:  62%|[34m   [0m| 308/500 [06:58<04:14,  1.33s/it]                                                           Episode 309	 reward: -2.50	 makespan: 247.15	 Mean_loss: 0.04010132,  training time: 1.30
progress:  62%|[34m   [0m| 308/500 [06:59<04:14,  1.33s/it]progress:  62%|[34m   [0m| 309/500 [06:59<04:11,  1.32s/it]                                                           Episode 310	 reward: -2.55	 makespan: 252.25	 Mean_loss: 0.03393889,  training time: 1.31
progress:  62%|[34m   [0m| 309/500 [07:00<04:11,  1.32s/it]progress:  62%|[34m   [0m| 310/500 [07:00<04:10,  1.32s/it]                                                           Episode 311	 reward: -2.50	 makespan: 247.95	 Mean_loss: 0.04220558,  training time: 1.35
progress:  62%|[34m   [0m| 310/500 [07:01<04:10,  1.32s/it]progress:  62%|[34m   [0m| 311/500 [07:01<04:10,  1.33s/it]                                                           Episode 312	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.05380271,  training time: 1.30
progress:  62%|[34m   [0m| 311/500 [07:03<04:10,  1.33s/it]progress:  62%|[34m   [0m| 312/500 [07:03<04:08,  1.32s/it]                                                           Episode 313	 reward: -2.60	 makespan: 257.40	 Mean_loss: 0.09499431,  training time: 1.33
progress:  62%|[34m   [0m| 312/500 [07:04<04:08,  1.32s/it]progress:  63%|[34m   [0m| 313/500 [07:04<04:07,  1.32s/it]                                                           Episode 314	 reward: -2.53	 makespan: 250.55	 Mean_loss: 0.04148857,  training time: 1.35
progress:  63%|[34m   [0m| 313/500 [07:05<04:07,  1.32s/it]progress:  63%|[34m   [0m| 314/500 [07:05<04:07,  1.33s/it]                                                           Episode 315	 reward: -2.58	 makespan: 255.25	 Mean_loss: 0.04771848,  training time: 1.33
progress:  63%|[34m   [0m| 314/500 [07:07<04:07,  1.33s/it]progress:  63%|[34m   [0m| 315/500 [07:07<04:06,  1.33s/it]                                                           Episode 316	 reward: -2.48	 makespan: 245.45	 Mean_loss: 0.02955317,  training time: 1.29
progress:  63%|[34m   [0m| 315/500 [07:08<04:06,  1.33s/it]progress:  63%|[34m   [0m| 316/500 [07:08<04:02,  1.32s/it]                                                           Episode 317	 reward: -2.66	 makespan: 263.00	 Mean_loss: 0.06016114,  training time: 1.32
progress:  63%|[34m   [0m| 316/500 [07:09<04:02,  1.32s/it]progress:  63%|[34m   [0m| 317/500 [07:09<04:01,  1.32s/it]                                                           Episode 318	 reward: -2.56	 makespan: 253.90	 Mean_loss: 0.04208894,  training time: 1.37
progress:  63%|[34m   [0m| 317/500 [07:11<04:01,  1.32s/it]progress:  64%|[34m   [0m| 318/500 [07:11<04:02,  1.33s/it]                                                           Episode 319	 reward: -2.57	 makespan: 254.30	 Mean_loss: 0.04413547,  training time: 1.30
progress:  64%|[34m   [0m| 318/500 [07:12<04:02,  1.33s/it]progress:  64%|[34m   [0m| 319/500 [07:12<03:59,  1.32s/it]                                                           Episode 320	 reward: -2.51	 makespan: 248.90	 Mean_loss: 0.03547379,  training time: 1.29
progress:  64%|[34m   [0m| 319/500 [07:13<03:59,  1.32s/it]progress:  64%|[34m   [0m| 320/500 [07:13<03:56,  1.32s/it]                                                           Episode 321	 reward: -2.54	 makespan: 251.25	 Mean_loss: 0.01235584,  training time: 1.40
progress:  64%|[34m   [0m| 320/500 [07:15<03:56,  1.32s/it]progress:  64%|[34m   [0m| 321/500 [07:15<03:59,  1.34s/it]                                                           Episode 322	 reward: -2.65	 makespan: 262.00	 Mean_loss: 0.02311059,  training time: 1.37
progress:  64%|[34m   [0m| 321/500 [07:16<03:59,  1.34s/it]progress:  64%|[34m   [0m| 322/500 [07:16<04:00,  1.35s/it]                                                           Episode 323	 reward: -2.57	 makespan: 254.45	 Mean_loss: 0.01437109,  training time: 1.37
progress:  64%|[34m   [0m| 322/500 [07:18<04:00,  1.35s/it]progress:  65%|[34m   [0m| 323/500 [07:18<03:59,  1.36s/it]                                                           Episode 324	 reward: -2.68	 makespan: 265.35	 Mean_loss: 0.00323304,  training time: 1.39
progress:  65%|[34m   [0m| 323/500 [07:19<03:59,  1.36s/it]progress:  65%|[34m   [0m| 324/500 [07:19<04:00,  1.36s/it]                                                           Episode 325	 reward: -2.62	 makespan: 258.90	 Mean_loss: 0.00009568,  training time: 1.38
progress:  65%|[34m   [0m| 324/500 [07:20<04:00,  1.36s/it]progress:  65%|[34m   [0m| 325/500 [07:20<03:59,  1.37s/it]                                                           Episode 326	 reward: -2.60	 makespan: 257.80	 Mean_loss: 0.01427521,  training time: 1.37
progress:  65%|[34m   [0m| 325/500 [07:22<03:59,  1.37s/it]progress:  65%|[34m   [0m| 326/500 [07:22<03:58,  1.37s/it]                                                           Episode 327	 reward: -2.52	 makespan: 249.60	 Mean_loss: 0.02740700,  training time: 1.35
progress:  65%|[34m   [0m| 326/500 [07:23<03:58,  1.37s/it]progress:  65%|[34m   [0m| 327/500 [07:23<03:55,  1.36s/it]                                                           Episode 328	 reward: -2.58	 makespan: 255.85	 Mean_loss: 0.03000471,  training time: 1.37
progress:  65%|[34m   [0m| 327/500 [07:24<03:55,  1.36s/it]progress:  66%|[34m   [0m| 328/500 [07:24<03:54,  1.36s/it]                                                           Episode 329	 reward: -2.64	 makespan: 261.75	 Mean_loss: 0.05133165,  training time: 1.35
progress:  66%|[34m   [0m| 328/500 [07:26<03:54,  1.36s/it]progress:  66%|[34m   [0m| 329/500 [07:26<03:52,  1.36s/it]                                                           Episode 330	 reward: -2.62	 makespan: 259.35	 Mean_loss: 0.00757989,  training time: 1.53
progress:  66%|[34m   [0m| 329/500 [07:27<03:52,  1.36s/it]progress:  66%|[34m   [0m| 330/500 [07:27<03:59,  1.41s/it]                                                           Episode 331	 reward: -2.62	 makespan: 259.00	 Mean_loss: 0.02712953,  training time: 1.34
progress:  66%|[34m   [0m| 330/500 [07:29<03:59,  1.41s/it]progress:  66%|[34m   [0m| 331/500 [07:29<03:54,  1.39s/it]                                                           Episode 332	 reward: -2.60	 makespan: 257.70	 Mean_loss: 0.01613462,  training time: 1.31
progress:  66%|[34m   [0m| 331/500 [07:30<03:54,  1.39s/it]progress:  66%|[34m   [0m| 332/500 [07:30<03:49,  1.37s/it]                                                           Episode 333	 reward: -2.59	 makespan: 256.15	 Mean_loss: 0.00062654,  training time: 1.32
progress:  66%|[34m   [0m| 332/500 [07:31<03:49,  1.37s/it]progress:  67%|[34m   [0m| 333/500 [07:31<03:45,  1.35s/it]                                                           Episode 334	 reward: -2.55	 makespan: 252.05	 Mean_loss: 0.00688444,  training time: 1.34
progress:  67%|[34m   [0m| 333/500 [07:33<03:45,  1.35s/it]progress:  67%|[34m   [0m| 334/500 [07:33<03:43,  1.35s/it]                                                           Episode 335	 reward: -2.55	 makespan: 252.20	 Mean_loss: 0.02559494,  training time: 1.30
progress:  67%|[34m   [0m| 334/500 [07:34<03:43,  1.35s/it]progress:  67%|[34m   [0m| 335/500 [07:34<03:40,  1.34s/it]                                                           Episode 336	 reward: -2.59	 makespan: 256.10	 Mean_loss: 0.00781035,  training time: 1.28
progress:  67%|[34m   [0m| 335/500 [07:35<03:40,  1.34s/it]progress:  67%|[34m   [0m| 336/500 [07:35<03:36,  1.32s/it]                                                           Episode 337	 reward: -2.56	 makespan: 253.30	 Mean_loss: -0.02094160,  training time: 1.30
progress:  67%|[34m   [0m| 336/500 [07:36<03:36,  1.32s/it]progress:  67%|[34m   [0m| 337/500 [07:36<03:34,  1.31s/it]                                                           Episode 338	 reward: -2.61	 makespan: 258.60	 Mean_loss: 0.02276140,  training time: 1.33
progress:  67%|[34m   [0m| 337/500 [07:38<03:34,  1.31s/it]progress:  68%|[34m   [0m| 338/500 [07:38<03:33,  1.32s/it]                                                           Episode 339	 reward: -2.53	 makespan: 250.80	 Mean_loss: 0.01029717,  training time: 1.29
progress:  68%|[34m   [0m| 338/500 [07:39<03:33,  1.32s/it]progress:  68%|[34m   [0m| 339/500 [07:39<03:31,  1.31s/it]                                                           Episode 340	 reward: -2.60	 makespan: 257.50	 Mean_loss: -0.00050398,  training time: 1.34
progress:  68%|[34m   [0m| 339/500 [07:40<03:31,  1.31s/it]progress:  68%|[34m   [0m| 340/500 [07:40<03:31,  1.32s/it]                                                           Episode 341	 reward: -2.57	 makespan: 254.85	 Mean_loss: 0.00946636,  training time: 1.35
progress:  68%|[34m   [0m| 340/500 [07:42<03:31,  1.32s/it]progress:  68%|[34m   [0m| 341/500 [07:42<03:31,  1.33s/it]                                                           Episode 342	 reward: -2.57	 makespan: 254.15	 Mean_loss: -0.01497545,  training time: 1.32
progress:  68%|[34m   [0m| 341/500 [07:43<03:31,  1.33s/it]progress:  68%|[34m   [0m| 342/500 [07:43<03:29,  1.33s/it]                                                           Episode 343	 reward: -2.49	 makespan: 246.60	 Mean_loss: 0.01497096,  training time: 1.31
progress:  68%|[34m   [0m| 342/500 [07:44<03:29,  1.33s/it]progress:  69%|[34m   [0m| 343/500 [07:44<03:27,  1.32s/it]                                                           Episode 344	 reward: -2.50	 makespan: 247.85	 Mean_loss: 0.01888790,  training time: 1.32
progress:  69%|[34m   [0m| 343/500 [07:46<03:27,  1.32s/it]progress:  69%|[34m   [0m| 344/500 [07:46<03:26,  1.32s/it]                                                           Episode 345	 reward: -2.55	 makespan: 252.00	 Mean_loss: 0.01378855,  training time: 1.33
progress:  69%|[34m   [0m| 344/500 [07:47<03:26,  1.32s/it]progress:  69%|[34m   [0m| 345/500 [07:47<03:25,  1.33s/it]                                                           Episode 346	 reward: -2.54	 makespan: 251.10	 Mean_loss: 0.01688859,  training time: 1.30
progress:  69%|[34m   [0m| 345/500 [07:48<03:25,  1.33s/it]progress:  69%|[34m   [0m| 346/500 [07:48<03:23,  1.32s/it]                                                           Episode 347	 reward: -2.56	 makespan: 253.75	 Mean_loss: 0.00746931,  training time: 1.36
progress:  69%|[34m   [0m| 346/500 [07:50<03:23,  1.32s/it]progress:  69%|[34m   [0m| 347/500 [07:50<03:23,  1.33s/it]                                                           Episode 348	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.02724702,  training time: 1.34
progress:  69%|[34m   [0m| 347/500 [07:51<03:23,  1.33s/it]progress:  70%|[34m   [0m| 348/500 [07:51<03:22,  1.33s/it]                                                           Episode 349	 reward: -2.52	 makespan: 249.05	 Mean_loss: -0.00695844,  training time: 1.29
progress:  70%|[34m   [0m| 348/500 [07:52<03:22,  1.33s/it]progress:  70%|[34m   [0m| 349/500 [07:52<03:19,  1.32s/it]                                                           Episode 350	 reward: -2.53	 makespan: 250.00	 Mean_loss: 0.01016921,  training time: 1.33
progress:  70%|[34m   [0m| 349/500 [07:54<03:19,  1.32s/it]progress:  70%|[34m   [0m| 350/500 [07:54<03:18,  1.32s/it]                                                           Episode 351	 reward: -2.60	 makespan: 257.20	 Mean_loss: 0.00442322,  training time: 1.33
progress:  70%|[34m   [0m| 350/500 [07:55<03:18,  1.32s/it]progress:  70%|[34m   [0m| 351/500 [07:55<03:17,  1.33s/it]                                                           Episode 352	 reward: -2.47	 makespan: 244.75	 Mean_loss: 0.03114724,  training time: 1.28
progress:  70%|[34m   [0m| 351/500 [07:56<03:17,  1.33s/it]progress:  70%|[34m   [0m| 352/500 [07:56<03:14,  1.31s/it]                                                           Episode 353	 reward: -2.48	 makespan: 245.75	 Mean_loss: 0.01218226,  training time: 1.32
progress:  70%|[34m   [0m| 352/500 [07:58<03:14,  1.31s/it]progress:  71%|[34m   [0m| 353/500 [07:58<03:13,  1.31s/it]                                                           Episode 354	 reward: -2.47	 makespan: 244.60	 Mean_loss: 0.00273117,  training time: 1.32
progress:  71%|[34m   [0m| 353/500 [07:59<03:13,  1.31s/it]progress:  71%|[34m   [0m| 354/500 [07:59<03:12,  1.32s/it]                                                           Episode 355	 reward: -2.54	 makespan: 251.65	 Mean_loss: 0.04696299,  training time: 1.29
progress:  71%|[34m   [0m| 354/500 [08:00<03:12,  1.32s/it]progress:  71%|[34m   [0m| 355/500 [08:00<03:09,  1.31s/it]                                                           Episode 356	 reward: -2.50	 makespan: 247.70	 Mean_loss: -0.00600488,  training time: 1.36
progress:  71%|[34m   [0m| 355/500 [08:02<03:09,  1.31s/it]progress:  71%|[34m   [0m| 356/500 [08:02<03:10,  1.32s/it]                                                           Episode 357	 reward: -2.49	 makespan: 246.25	 Mean_loss: 0.00831591,  training time: 1.30
progress:  71%|[34m   [0m| 356/500 [08:03<03:10,  1.32s/it]progress:  71%|[34m  [0m| 357/500 [08:03<03:08,  1.32s/it]                                                           Episode 358	 reward: -2.49	 makespan: 246.40	 Mean_loss: 0.04950007,  training time: 1.33
progress:  71%|[34m  [0m| 357/500 [08:04<03:08,  1.32s/it]progress:  72%|[34m  [0m| 358/500 [08:04<03:07,  1.32s/it]                                                           Episode 359	 reward: -2.54	 makespan: 251.30	 Mean_loss: -0.00363296,  training time: 1.31
progress:  72%|[34m  [0m| 358/500 [08:05<03:07,  1.32s/it]progress:  72%|[34m  [0m| 359/500 [08:05<03:05,  1.32s/it]                                                           Episode 360	 reward: -2.58	 makespan: 255.85	 Mean_loss: 0.01617949,  training time: 1.31
progress:  72%|[34m  [0m| 359/500 [08:07<03:05,  1.32s/it]progress:  72%|[34m  [0m| 360/500 [08:07<03:04,  1.31s/it]                                                           Episode 361	 reward: -2.65	 makespan: 262.55	 Mean_loss: 0.01286876,  training time: 1.33
progress:  72%|[34m  [0m| 360/500 [08:08<03:04,  1.31s/it]progress:  72%|[34m  [0m| 361/500 [08:08<03:03,  1.32s/it]                                                           Episode 362	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.02004661,  training time: 1.33
progress:  72%|[34m  [0m| 361/500 [08:09<03:03,  1.32s/it]progress:  72%|[34m  [0m| 362/500 [08:09<03:02,  1.32s/it]                                                           Episode 363	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.02965395,  training time: 1.33
progress:  72%|[34m  [0m| 362/500 [08:11<03:02,  1.32s/it]progress:  73%|[34m  [0m| 363/500 [08:11<03:01,  1.33s/it]                                                           Episode 364	 reward: -2.60	 makespan: 257.00	 Mean_loss: 0.02786738,  training time: 1.30
progress:  73%|[34m  [0m| 363/500 [08:12<03:01,  1.33s/it]progress:  73%|[34m  [0m| 364/500 [08:12<02:59,  1.32s/it]                                                           Episode 365	 reward: -2.60	 makespan: 257.85	 Mean_loss: 0.03821360,  training time: 1.32
progress:  73%|[34m  [0m| 364/500 [08:13<02:59,  1.32s/it]progress:  73%|[34m  [0m| 365/500 [08:13<02:58,  1.32s/it]                                                           Episode 366	 reward: -2.48	 makespan: 245.70	 Mean_loss: 0.00760858,  training time: 1.42
progress:  73%|[34m  [0m| 365/500 [08:15<02:58,  1.32s/it]progress:  73%|[34m  [0m| 366/500 [08:15<03:01,  1.35s/it]                                                           Episode 367	 reward: -2.58	 makespan: 255.55	 Mean_loss: 0.01704510,  training time: 1.35
progress:  73%|[34m  [0m| 366/500 [08:16<03:01,  1.35s/it]progress:  73%|[34m  [0m| 367/500 [08:16<02:59,  1.35s/it]                                                           Episode 368	 reward: -2.47	 makespan: 244.40	 Mean_loss: 0.00134107,  training time: 1.35
progress:  73%|[34m  [0m| 367/500 [08:18<02:59,  1.35s/it]progress:  74%|[34m  [0m| 368/500 [08:18<02:58,  1.35s/it]                                                           Episode 369	 reward: -2.50	 makespan: 247.95	 Mean_loss: 0.02030958,  training time: 1.30
progress:  74%|[34m  [0m| 368/500 [08:19<02:58,  1.35s/it]progress:  74%|[34m  [0m| 369/500 [08:19<02:55,  1.34s/it]                                                           Episode 370	 reward: -2.52	 makespan: 249.20	 Mean_loss: 0.02823051,  training time: 1.32
progress:  74%|[34m  [0m| 369/500 [08:20<02:55,  1.34s/it]progress:  74%|[34m  [0m| 370/500 [08:20<02:53,  1.33s/it]                                                           Episode 371	 reward: -2.58	 makespan: 255.90	 Mean_loss: 0.00678361,  training time: 1.33
progress:  74%|[34m  [0m| 370/500 [08:22<02:53,  1.33s/it]progress:  74%|[34m  [0m| 371/500 [08:22<02:51,  1.33s/it]                                                           Episode 372	 reward: -2.53	 makespan: 250.05	 Mean_loss: -0.01018300,  training time: 1.32
progress:  74%|[34m  [0m| 371/500 [08:23<02:51,  1.33s/it]progress:  74%|[34m  [0m| 372/500 [08:23<02:49,  1.33s/it]                                                           Episode 373	 reward: -2.55	 makespan: 252.90	 Mean_loss: 0.00682113,  training time: 1.30
progress:  74%|[34m  [0m| 372/500 [08:24<02:49,  1.33s/it]progress:  75%|[34m  [0m| 373/500 [08:24<02:47,  1.32s/it]                                                           Episode 374	 reward: -2.57	 makespan: 254.05	 Mean_loss: 0.01972808,  training time: 1.43
progress:  75%|[34m  [0m| 373/500 [08:26<02:47,  1.32s/it]progress:  75%|[34m  [0m| 374/500 [08:26<02:50,  1.35s/it]                                                           Episode 375	 reward: -2.61	 makespan: 258.35	 Mean_loss: 0.00333551,  training time: 1.32
progress:  75%|[34m  [0m| 374/500 [08:27<02:50,  1.35s/it]progress:  75%|[34m  [0m| 375/500 [08:27<02:47,  1.34s/it]                                                           Episode 376	 reward: -2.52	 makespan: 249.90	 Mean_loss: -0.00246565,  training time: 1.28
progress:  75%|[34m  [0m| 375/500 [08:28<02:47,  1.34s/it]progress:  75%|[34m  [0m| 376/500 [08:28<02:44,  1.32s/it]                                                           Episode 377	 reward: -2.50	 makespan: 247.15	 Mean_loss: 0.01620536,  training time: 1.28
progress:  75%|[34m  [0m| 376/500 [08:29<02:44,  1.32s/it]progress:  75%|[34m  [0m| 377/500 [08:29<02:41,  1.31s/it]                                                           Episode 378	 reward: -2.51	 makespan: 248.15	 Mean_loss: 0.00677763,  training time: 1.33
progress:  75%|[34m  [0m| 377/500 [08:31<02:41,  1.31s/it]progress:  76%|[34m  [0m| 378/500 [08:31<02:40,  1.32s/it]                                                           Episode 379	 reward: -2.58	 makespan: 255.70	 Mean_loss: 0.00848538,  training time: 1.30
progress:  76%|[34m  [0m| 378/500 [08:32<02:40,  1.32s/it]progress:  76%|[34m  [0m| 379/500 [08:32<02:38,  1.31s/it]                                                           Episode 380	 reward: -2.51	 makespan: 248.10	 Mean_loss: -0.00627999,  training time: 1.33
progress:  76%|[34m  [0m| 379/500 [08:33<02:38,  1.31s/it]progress:  76%|[34m  [0m| 380/500 [08:33<02:38,  1.32s/it]                                                           Episode 381	 reward: -2.51	 makespan: 248.70	 Mean_loss: 0.02648784,  training time: 1.35
progress:  76%|[34m  [0m| 380/500 [08:35<02:38,  1.32s/it]progress:  76%|[34m  [0m| 381/500 [08:35<02:38,  1.33s/it]                                                           Episode 382	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.02814126,  training time: 1.33
progress:  76%|[34m  [0m| 381/500 [08:36<02:38,  1.33s/it]progress:  76%|[34m  [0m| 382/500 [08:36<02:36,  1.33s/it]                                                           Episode 383	 reward: -2.54	 makespan: 251.25	 Mean_loss: 0.02337152,  training time: 1.32
progress:  76%|[34m  [0m| 382/500 [08:37<02:36,  1.33s/it]progress:  77%|[34m  [0m| 383/500 [08:37<02:35,  1.33s/it]                                                           Episode 384	 reward: -2.54	 makespan: 251.75	 Mean_loss: 0.02672255,  training time: 1.32
progress:  77%|[34m  [0m| 383/500 [08:39<02:35,  1.33s/it]progress:  77%|[34m  [0m| 384/500 [08:39<02:33,  1.33s/it]                                                           Episode 385	 reward: -2.53	 makespan: 250.10	 Mean_loss: 0.01557794,  training time: 1.31
progress:  77%|[34m  [0m| 384/500 [08:40<02:33,  1.33s/it]progress:  77%|[34m  [0m| 385/500 [08:40<02:31,  1.32s/it]                                                           Episode 386	 reward: -2.50	 makespan: 247.30	 Mean_loss: 0.01476944,  training time: 1.31
progress:  77%|[34m  [0m| 385/500 [08:41<02:31,  1.32s/it]progress:  77%|[34m  [0m| 386/500 [08:41<02:30,  1.32s/it]                                                           Episode 387	 reward: -2.58	 makespan: 255.65	 Mean_loss: 0.03230891,  training time: 1.35
progress:  77%|[34m  [0m| 386/500 [08:43<02:30,  1.32s/it]progress:  77%|[34m  [0m| 387/500 [08:43<02:30,  1.33s/it]                                                           Episode 388	 reward: -2.41	 makespan: 238.20	 Mean_loss: 0.00463324,  training time: 1.29
progress:  77%|[34m  [0m| 387/500 [08:44<02:30,  1.33s/it]progress:  78%|[34m  [0m| 388/500 [08:44<02:27,  1.32s/it]                                                           Episode 389	 reward: -2.49	 makespan: 246.90	 Mean_loss: 0.02922988,  training time: 1.31
progress:  78%|[34m  [0m| 388/500 [08:45<02:27,  1.32s/it]progress:  78%|[34m  [0m| 389/500 [08:45<02:25,  1.31s/it]                                                           Episode 390	 reward: -2.49	 makespan: 246.45	 Mean_loss: 0.02644131,  training time: 1.32
progress:  78%|[34m  [0m| 389/500 [08:47<02:25,  1.31s/it]progress:  78%|[34m  [0m| 390/500 [08:47<02:24,  1.32s/it]                                                           Episode 391	 reward: -2.41	 makespan: 238.80	 Mean_loss: 0.01688313,  training time: 1.32
progress:  78%|[34m  [0m| 390/500 [08:48<02:24,  1.32s/it]progress:  78%|[34m  [0m| 391/500 [08:48<02:23,  1.32s/it]                                                           Episode 392	 reward: -2.47	 makespan: 244.10	 Mean_loss: 0.02059222,  training time: 1.28
progress:  78%|[34m  [0m| 391/500 [08:49<02:23,  1.32s/it]progress:  78%|[34m  [0m| 392/500 [08:49<02:21,  1.31s/it]                                                           Episode 393	 reward: -2.52	 makespan: 249.65	 Mean_loss: 0.03415782,  training time: 1.32
progress:  78%|[34m  [0m| 392/500 [08:51<02:21,  1.31s/it]progress:  79%|[34m  [0m| 393/500 [08:51<02:20,  1.31s/it]                                                           Episode 394	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.03220768,  training time: 1.33
progress:  79%|[34m  [0m| 393/500 [08:52<02:20,  1.31s/it]progress:  79%|[34m  [0m| 394/500 [08:52<02:19,  1.32s/it]                                                           Episode 395	 reward: -2.52	 makespan: 249.60	 Mean_loss: 0.05546879,  training time: 1.36
progress:  79%|[34m  [0m| 394/500 [08:53<02:19,  1.32s/it]progress:  79%|[34m  [0m| 395/500 [08:53<02:19,  1.33s/it]                                                           Episode 396	 reward: -2.47	 makespan: 244.10	 Mean_loss: 0.02075672,  training time: 1.35
progress:  79%|[34m  [0m| 395/500 [08:55<02:19,  1.33s/it]progress:  79%|[34m  [0m| 396/500 [08:55<02:19,  1.34s/it]                                                           Episode 397	 reward: -2.48	 makespan: 245.20	 Mean_loss: 0.02195950,  training time: 1.36
progress:  79%|[34m  [0m| 396/500 [08:56<02:19,  1.34s/it]progress:  79%|[34m  [0m| 397/500 [08:56<02:18,  1.34s/it]                                                           Episode 398	 reward: -2.51	 makespan: 248.85	 Mean_loss: 0.03154739,  training time: 1.36
progress:  79%|[34m  [0m| 397/500 [08:57<02:18,  1.34s/it]progress:  80%|[34m  [0m| 398/500 [08:57<02:17,  1.35s/it]                                                           Episode 399	 reward: -2.53	 makespan: 250.20	 Mean_loss: 0.02022332,  training time: 1.38
progress:  80%|[34m  [0m| 398/500 [08:59<02:17,  1.35s/it]progress:  80%|[34m  [0m| 399/500 [08:59<02:17,  1.36s/it]                                                           Episode 400	 reward: -2.45	 makespan: 242.95	 Mean_loss: 0.01550782,  training time: 1.37
progress:  80%|[34m  [0m| 399/500 [09:00<02:17,  1.36s/it]progress:  80%|[34m  [0m| 400/500 [09:00<02:16,  1.36s/it]                                                           Episode 401	 reward: -2.58	 makespan: 255.10	 Mean_loss: 0.02153682,  training time: 1.39
progress:  80%|[34m  [0m| 400/500 [09:01<02:16,  1.36s/it]progress:  80%|[34m  [0m| 401/500 [09:01<02:15,  1.37s/it]                                                           Episode 402	 reward: -2.51	 makespan: 248.60	 Mean_loss: 0.00466056,  training time: 1.36
progress:  80%|[34m  [0m| 401/500 [09:03<02:15,  1.37s/it]progress:  80%|[34m  [0m| 402/500 [09:03<02:13,  1.37s/it]                                                           Episode 403	 reward: -2.43	 makespan: 240.95	 Mean_loss: -0.00079477,  training time: 1.37
progress:  80%|[34m  [0m| 402/500 [09:04<02:13,  1.37s/it]progress:  81%|[34m  [0m| 403/500 [09:04<02:12,  1.37s/it]                                                           Episode 404	 reward: -2.53	 makespan: 250.20	 Mean_loss: 0.00859369,  training time: 1.37
progress:  81%|[34m  [0m| 403/500 [09:06<02:12,  1.37s/it]progress:  81%|[34m  [0m| 404/500 [09:06<02:11,  1.37s/it]                                                           Episode 405	 reward: -2.53	 makespan: 250.90	 Mean_loss: 0.02075568,  training time: 1.35
progress:  81%|[34m  [0m| 404/500 [09:07<02:11,  1.37s/it]progress:  81%|[34m  [0m| 405/500 [09:07<02:09,  1.37s/it]                                                           Episode 406	 reward: -2.53	 makespan: 250.60	 Mean_loss: -0.01561231,  training time: 1.36
progress:  81%|[34m  [0m| 405/500 [09:08<02:09,  1.37s/it]progress:  81%|[34m  [0m| 406/500 [09:08<02:08,  1.37s/it]                                                           Episode 407	 reward: -2.54	 makespan: 251.30	 Mean_loss: -0.01107266,  training time: 1.34
progress:  81%|[34m  [0m| 406/500 [09:10<02:08,  1.37s/it]progress:  81%|[34m [0m| 407/500 [09:10<02:06,  1.36s/it]                                                           Episode 408	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.01763504,  training time: 1.35
progress:  81%|[34m [0m| 407/500 [09:11<02:06,  1.36s/it]progress:  82%|[34m [0m| 408/500 [09:11<02:04,  1.35s/it]                                                           Episode 409	 reward: -2.48	 makespan: 245.55	 Mean_loss: 0.00271996,  training time: 1.35
progress:  82%|[34m [0m| 408/500 [09:12<02:04,  1.35s/it]progress:  82%|[34m [0m| 409/500 [09:12<02:03,  1.35s/it]                                                           Episode 410	 reward: -2.36	 makespan: 233.95	 Mean_loss: 0.00433972,  training time: 1.37
progress:  82%|[34m [0m| 409/500 [09:14<02:03,  1.35s/it]progress:  82%|[34m [0m| 410/500 [09:14<02:02,  1.36s/it]                                                           Episode 411	 reward: -2.45	 makespan: 242.35	 Mean_loss: 0.00241443,  training time: 1.35
progress:  82%|[34m [0m| 410/500 [09:15<02:02,  1.36s/it]progress:  82%|[34m [0m| 411/500 [09:15<02:00,  1.36s/it]                                                           Episode 412	 reward: -2.42	 makespan: 239.20	 Mean_loss: -0.01219517,  training time: 1.38
progress:  82%|[34m [0m| 411/500 [09:16<02:00,  1.36s/it]progress:  82%|[34m [0m| 412/500 [09:16<01:59,  1.36s/it]                                                           Episode 413	 reward: -2.50	 makespan: 247.40	 Mean_loss: -0.00161970,  training time: 1.33
progress:  82%|[34m [0m| 412/500 [09:18<01:59,  1.36s/it]progress:  83%|[34m [0m| 413/500 [09:18<01:57,  1.35s/it]                                                           Episode 414	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.01121576,  training time: 1.33
progress:  83%|[34m [0m| 413/500 [09:19<01:57,  1.35s/it]progress:  83%|[34m [0m| 414/500 [09:19<01:56,  1.35s/it]                                                           Episode 415	 reward: -2.55	 makespan: 252.75	 Mean_loss: 0.01592536,  training time: 1.35
progress:  83%|[34m [0m| 414/500 [09:20<01:56,  1.35s/it]progress:  83%|[34m [0m| 415/500 [09:20<01:54,  1.35s/it]                                                           Episode 416	 reward: -2.47	 makespan: 244.30	 Mean_loss: 0.00250303,  training time: 1.37
progress:  83%|[34m [0m| 415/500 [09:22<01:54,  1.35s/it]progress:  83%|[34m [0m| 416/500 [09:22<01:53,  1.36s/it]                                                           Episode 417	 reward: -2.46	 makespan: 243.75	 Mean_loss: 0.01369242,  training time: 1.40
progress:  83%|[34m [0m| 416/500 [09:23<01:53,  1.36s/it]progress:  83%|[34m [0m| 417/500 [09:23<01:53,  1.37s/it]                                                           Episode 418	 reward: -2.45	 makespan: 242.60	 Mean_loss: 0.00878956,  training time: 1.35
progress:  83%|[34m [0m| 417/500 [09:25<01:53,  1.37s/it]progress:  84%|[34m [0m| 418/500 [09:25<01:51,  1.36s/it]                                                           Episode 419	 reward: -2.49	 makespan: 246.45	 Mean_loss: 0.03988633,  training time: 1.31
progress:  84%|[34m [0m| 418/500 [09:26<01:51,  1.36s/it]progress:  84%|[34m [0m| 419/500 [09:26<01:49,  1.35s/it]                                                           Episode 420	 reward: -2.57	 makespan: 254.85	 Mean_loss: 0.00296061,  training time: 1.35
progress:  84%|[34m [0m| 419/500 [09:27<01:49,  1.35s/it]progress:  84%|[34m [0m| 420/500 [09:27<01:47,  1.35s/it]                                                           Episode 421	 reward: -2.69	 makespan: 265.85	 Mean_loss: 0.01798979,  training time: 1.38
progress:  84%|[34m [0m| 420/500 [09:29<01:47,  1.35s/it]progress:  84%|[34m [0m| 421/500 [09:29<01:47,  1.36s/it]                                                           Episode 422	 reward: -2.61	 makespan: 257.95	 Mean_loss: 0.03751440,  training time: 1.33
progress:  84%|[34m [0m| 421/500 [09:30<01:47,  1.36s/it]progress:  84%|[34m [0m| 422/500 [09:30<01:45,  1.35s/it]                                                           Episode 423	 reward: -2.53	 makespan: 250.90	 Mean_loss: 0.02609602,  training time: 1.32
progress:  84%|[34m [0m| 422/500 [09:31<01:45,  1.35s/it]progress:  85%|[34m [0m| 423/500 [09:31<01:43,  1.34s/it]                                                           Episode 424	 reward: -2.61	 makespan: 258.30	 Mean_loss: 0.01863904,  training time: 1.33
progress:  85%|[34m [0m| 423/500 [09:33<01:43,  1.34s/it]progress:  85%|[34m [0m| 424/500 [09:33<01:41,  1.34s/it]                                                           Episode 425	 reward: -2.55	 makespan: 252.55	 Mean_loss: 0.03722986,  training time: 1.32
progress:  85%|[34m [0m| 424/500 [09:34<01:41,  1.34s/it]progress:  85%|[34m [0m| 425/500 [09:34<01:40,  1.33s/it]                                                           Episode 426	 reward: -2.52	 makespan: 249.35	 Mean_loss: 0.05234474,  training time: 1.31
progress:  85%|[34m [0m| 425/500 [09:35<01:40,  1.33s/it]progress:  85%|[34m [0m| 426/500 [09:35<01:38,  1.33s/it]                                                           Episode 427	 reward: -2.64	 makespan: 261.40	 Mean_loss: 0.02056454,  training time: 1.35
progress:  85%|[34m [0m| 426/500 [09:37<01:38,  1.33s/it]progress:  85%|[34m [0m| 427/500 [09:37<01:37,  1.33s/it]                                                           Episode 428	 reward: -2.60	 makespan: 257.10	 Mean_loss: 0.00801761,  training time: 1.32
progress:  85%|[34m [0m| 427/500 [09:38<01:37,  1.33s/it]progress:  86%|[34m [0m| 428/500 [09:38<01:35,  1.33s/it]                                                           Episode 429	 reward: -2.65	 makespan: 262.10	 Mean_loss: 0.03131838,  training time: 1.34
progress:  86%|[34m [0m| 428/500 [09:39<01:35,  1.33s/it]progress:  86%|[34m [0m| 429/500 [09:39<01:34,  1.33s/it]                                                           Episode 430	 reward: -2.63	 makespan: 260.20	 Mean_loss: 0.03021485,  training time: 1.34
progress:  86%|[34m [0m| 429/500 [09:41<01:34,  1.33s/it]progress:  86%|[34m [0m| 430/500 [09:41<01:33,  1.34s/it]                                                           Episode 431	 reward: -2.56	 makespan: 253.55	 Mean_loss: 0.01796741,  training time: 1.33
progress:  86%|[34m [0m| 430/500 [09:42<01:33,  1.34s/it]progress:  86%|[34m [0m| 431/500 [09:42<01:31,  1.33s/it]                                                           Episode 432	 reward: -2.59	 makespan: 256.20	 Mean_loss: 0.03787073,  training time: 1.32
progress:  86%|[34m [0m| 431/500 [09:43<01:31,  1.33s/it]progress:  86%|[34m [0m| 432/500 [09:43<01:30,  1.33s/it]                                                           Episode 433	 reward: -2.57	 makespan: 254.60	 Mean_loss: 0.01583581,  training time: 1.32
progress:  86%|[34m [0m| 432/500 [09:45<01:30,  1.33s/it]progress:  87%|[34m [0m| 433/500 [09:45<01:28,  1.33s/it]                                                           Episode 434	 reward: -2.64	 makespan: 261.30	 Mean_loss: 0.02953520,  training time: 1.33
progress:  87%|[34m [0m| 433/500 [09:46<01:28,  1.33s/it]progress:  87%|[34m [0m| 434/500 [09:46<01:27,  1.33s/it]                                                           Episode 435	 reward: -2.56	 makespan: 252.95	 Mean_loss: 0.03546594,  training time: 1.32
progress:  87%|[34m [0m| 434/500 [09:47<01:27,  1.33s/it]progress:  87%|[34m [0m| 435/500 [09:47<01:26,  1.33s/it]                                                           Episode 436	 reward: -2.57	 makespan: 254.75	 Mean_loss: 0.01115587,  training time: 1.32
progress:  87%|[34m [0m| 435/500 [09:49<01:26,  1.33s/it]progress:  87%|[34m [0m| 436/500 [09:49<01:24,  1.33s/it]                                                           Episode 437	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.04535114,  training time: 1.32
progress:  87%|[34m [0m| 436/500 [09:50<01:24,  1.33s/it]progress:  87%|[34m [0m| 437/500 [09:50<01:23,  1.32s/it]                                                           Episode 438	 reward: -2.47	 makespan: 244.85	 Mean_loss: 0.01928223,  training time: 1.32
progress:  87%|[34m [0m| 437/500 [09:51<01:23,  1.32s/it]progress:  88%|[34m [0m| 438/500 [09:51<01:21,  1.32s/it]                                                           Episode 439	 reward: -2.52	 makespan: 249.90	 Mean_loss: 0.04759726,  training time: 1.33
progress:  88%|[34m [0m| 438/500 [09:52<01:21,  1.32s/it]progress:  88%|[34m [0m| 439/500 [09:52<01:20,  1.32s/it]                                                           Episode 440	 reward: -2.58	 makespan: 255.40	 Mean_loss: 0.04871816,  training time: 1.33
progress:  88%|[34m [0m| 439/500 [09:54<01:20,  1.32s/it]progress:  88%|[34m [0m| 440/500 [09:54<01:19,  1.33s/it]                                                           Episode 441	 reward: -2.51	 makespan: 248.60	 Mean_loss: 0.04689848,  training time: 1.36
progress:  88%|[34m [0m| 440/500 [09:55<01:19,  1.33s/it]progress:  88%|[34m [0m| 441/500 [09:55<01:18,  1.34s/it]                                                           Episode 442	 reward: -2.54	 makespan: 251.90	 Mean_loss: 0.04132256,  training time: 1.32
progress:  88%|[34m [0m| 441/500 [09:56<01:18,  1.34s/it]progress:  88%|[34m [0m| 442/500 [09:56<01:17,  1.33s/it]                                                           Episode 443	 reward: -2.52	 makespan: 249.70	 Mean_loss: 0.03537798,  training time: 1.32
progress:  88%|[34m [0m| 442/500 [09:58<01:17,  1.33s/it]progress:  89%|[34m [0m| 443/500 [09:58<01:15,  1.33s/it]                                                           Episode 444	 reward: -2.55	 makespan: 252.35	 Mean_loss: 0.03766757,  training time: 1.36
progress:  89%|[34m [0m| 443/500 [09:59<01:15,  1.33s/it]progress:  89%|[34m [0m| 444/500 [09:59<01:14,  1.34s/it]                                                           Episode 445	 reward: -2.44	 makespan: 241.75	 Mean_loss: 0.04058346,  training time: 1.32
progress:  89%|[34m [0m| 444/500 [10:00<01:14,  1.34s/it]progress:  89%|[34m [0m| 445/500 [10:00<01:13,  1.33s/it]                                                           Episode 446	 reward: -2.43	 makespan: 240.35	 Mean_loss: 0.03325907,  training time: 1.32
progress:  89%|[34m [0m| 445/500 [10:02<01:13,  1.33s/it]progress:  89%|[34m [0m| 446/500 [10:02<01:11,  1.33s/it]                                                           Episode 447	 reward: -2.54	 makespan: 251.65	 Mean_loss: 0.04299637,  training time: 1.32
progress:  89%|[34m [0m| 446/500 [10:03<01:11,  1.33s/it]progress:  89%|[34m [0m| 447/500 [10:03<01:10,  1.33s/it]                                                           Episode 448	 reward: -2.46	 makespan: 243.35	 Mean_loss: 0.03114241,  training time: 1.33
progress:  89%|[34m [0m| 447/500 [10:04<01:10,  1.33s/it]progress:  90%|[34m [0m| 448/500 [10:04<01:09,  1.33s/it]                                                           Episode 449	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.03733972,  training time: 1.33
progress:  90%|[34m [0m| 448/500 [10:06<01:09,  1.33s/it]progress:  90%|[34m [0m| 449/500 [10:06<01:07,  1.33s/it]                                                           Episode 450	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.02836648,  training time: 1.35
progress:  90%|[34m [0m| 449/500 [10:07<01:07,  1.33s/it]progress:  90%|[34m [0m| 450/500 [10:07<01:06,  1.33s/it]                                                           Episode 451	 reward: -2.48	 makespan: 245.35	 Mean_loss: 0.03831767,  training time: 1.35
progress:  90%|[34m [0m| 450/500 [10:08<01:06,  1.33s/it]progress:  90%|[34m [0m| 451/500 [10:08<01:05,  1.34s/it]                                                           Episode 452	 reward: -2.47	 makespan: 244.15	 Mean_loss: 0.03831690,  training time: 1.35
progress:  90%|[34m [0m| 451/500 [10:10<01:05,  1.34s/it]progress:  90%|[34m [0m| 452/500 [10:10<01:04,  1.34s/it]                                                           Episode 453	 reward: -2.56	 makespan: 253.70	 Mean_loss: 0.03895153,  training time: 1.33
progress:  90%|[34m [0m| 452/500 [10:11<01:04,  1.34s/it]progress:  91%|[34m [0m| 453/500 [10:11<01:03,  1.34s/it]                                                           Episode 454	 reward: -2.56	 makespan: 253.55	 Mean_loss: 0.03521550,  training time: 1.33
progress:  91%|[34m [0m| 453/500 [10:13<01:03,  1.34s/it]progress:  91%|[34m [0m| 454/500 [10:13<01:01,  1.34s/it]                                                           Episode 455	 reward: -2.50	 makespan: 247.40	 Mean_loss: 0.03777758,  training time: 1.32
progress:  91%|[34m [0m| 454/500 [10:14<01:01,  1.34s/it]progress:  91%|[34m [0m| 455/500 [10:14<01:00,  1.33s/it]                                                           Episode 456	 reward: -2.53	 makespan: 250.60	 Mean_loss: 0.03766508,  training time: 1.34
progress:  91%|[34m [0m| 455/500 [10:15<01:00,  1.33s/it]progress:  91%|[34m [0m| 456/500 [10:15<00:58,  1.33s/it]                                                           Episode 457	 reward: -2.55	 makespan: 252.25	 Mean_loss: 0.03970353,  training time: 1.33
progress:  91%|[34m [0m| 456/500 [10:16<00:58,  1.33s/it]progress:  91%|[34m[0m| 457/500 [10:16<00:57,  1.33s/it]                                                           Episode 458	 reward: -2.42	 makespan: 239.70	 Mean_loss: 0.02975161,  training time: 1.33
progress:  91%|[34m[0m| 457/500 [10:18<00:57,  1.33s/it]progress:  92%|[34m[0m| 458/500 [10:18<00:55,  1.33s/it]                                                           Episode 459	 reward: -2.49	 makespan: 246.55	 Mean_loss: 0.04674879,  training time: 1.32
progress:  92%|[34m[0m| 458/500 [10:19<00:55,  1.33s/it]progress:  92%|[34m[0m| 459/500 [10:19<00:54,  1.33s/it]                                                           Episode 460	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.04010978,  training time: 1.33
progress:  92%|[34m[0m| 459/500 [10:20<00:54,  1.33s/it]progress:  92%|[34m[0m| 460/500 [10:20<00:53,  1.33s/it]                                                           Episode 461	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.03576816,  training time: 1.38
progress:  92%|[34m[0m| 460/500 [10:22<00:53,  1.33s/it]progress:  92%|[34m[0m| 461/500 [10:22<00:52,  1.34s/it]                                                           Episode 462	 reward: -2.41	 makespan: 238.25	 Mean_loss: 0.03604522,  training time: 1.33
progress:  92%|[34m[0m| 461/500 [10:23<00:52,  1.34s/it]progress:  92%|[34m[0m| 462/500 [10:23<00:50,  1.34s/it]                                                           Episode 463	 reward: -2.49	 makespan: 246.20	 Mean_loss: 0.01994525,  training time: 1.33
progress:  92%|[34m[0m| 462/500 [10:25<00:50,  1.34s/it]progress:  93%|[34m[0m| 463/500 [10:25<00:49,  1.34s/it]                                                           Episode 464	 reward: -2.48	 makespan: 245.80	 Mean_loss: 0.03388738,  training time: 1.32
progress:  93%|[34m[0m| 463/500 [10:26<00:49,  1.34s/it]progress:  93%|[34m[0m| 464/500 [10:26<00:48,  1.33s/it]                                                           Episode 465	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.04663769,  training time: 1.32
progress:  93%|[34m[0m| 464/500 [10:27<00:48,  1.33s/it]progress:  93%|[34m[0m| 465/500 [10:27<00:46,  1.33s/it]                                                           Episode 466	 reward: -2.38	 makespan: 235.90	 Mean_loss: 0.04698323,  training time: 1.32
progress:  93%|[34m[0m| 465/500 [10:28<00:46,  1.33s/it]progress:  93%|[34m[0m| 466/500 [10:28<00:45,  1.33s/it]                                                           Episode 467	 reward: -2.53	 makespan: 250.80	 Mean_loss: 0.08219634,  training time: 1.33
progress:  93%|[34m[0m| 466/500 [10:30<00:45,  1.33s/it]progress:  93%|[34m[0m| 467/500 [10:30<00:43,  1.33s/it]                                                           Episode 468	 reward: -2.50	 makespan: 247.85	 Mean_loss: 0.04359234,  training time: 1.33
progress:  93%|[34m[0m| 467/500 [10:31<00:43,  1.33s/it]progress:  94%|[34m[0m| 468/500 [10:31<00:42,  1.33s/it]                                                           Episode 469	 reward: -2.45	 makespan: 242.90	 Mean_loss: 0.03109326,  training time: 1.34
progress:  94%|[34m[0m| 468/500 [10:32<00:42,  1.33s/it]progress:  94%|[34m[0m| 469/500 [10:32<00:41,  1.33s/it]                                                           Episode 470	 reward: -2.45	 makespan: 242.45	 Mean_loss: 0.04110709,  training time: 1.34
progress:  94%|[34m[0m| 469/500 [10:34<00:41,  1.33s/it]progress:  94%|[34m[0m| 470/500 [10:34<00:40,  1.34s/it]                                                           Episode 471	 reward: -2.46	 makespan: 243.55	 Mean_loss: 0.04670990,  training time: 1.33
progress:  94%|[34m[0m| 470/500 [10:35<00:40,  1.34s/it]progress:  94%|[34m[0m| 471/500 [10:35<00:38,  1.34s/it]                                                           Episode 472	 reward: -2.50	 makespan: 247.15	 Mean_loss: 0.03961786,  training time: 1.37
progress:  94%|[34m[0m| 471/500 [10:37<00:38,  1.34s/it]progress:  94%|[34m[0m| 472/500 [10:37<00:37,  1.35s/it]                                                           Episode 473	 reward: -2.42	 makespan: 239.95	 Mean_loss: 0.02676997,  training time: 1.36
progress:  94%|[34m[0m| 472/500 [10:38<00:37,  1.35s/it]progress:  95%|[34m[0m| 473/500 [10:38<00:36,  1.35s/it]                                                           Episode 474	 reward: -2.40	 makespan: 237.45	 Mean_loss: 0.03344859,  training time: 1.45
progress:  95%|[34m[0m| 473/500 [10:39<00:36,  1.35s/it]progress:  95%|[34m[0m| 474/500 [10:39<00:35,  1.38s/it]                                                           Episode 475	 reward: -2.41	 makespan: 238.60	 Mean_loss: 0.04340456,  training time: 1.36
progress:  95%|[34m[0m| 474/500 [10:41<00:35,  1.38s/it]progress:  95%|[34m[0m| 475/500 [10:41<00:34,  1.38s/it]                                                           Episode 476	 reward: -2.47	 makespan: 244.85	 Mean_loss: 0.04372597,  training time: 1.33
progress:  95%|[34m[0m| 475/500 [10:42<00:34,  1.38s/it]progress:  95%|[34m[0m| 476/500 [10:42<00:32,  1.36s/it]                                                           Episode 477	 reward: -2.52	 makespan: 249.85	 Mean_loss: 0.04082259,  training time: 1.35
progress:  95%|[34m[0m| 476/500 [10:43<00:32,  1.36s/it]progress:  95%|[34m[0m| 477/500 [10:43<00:31,  1.36s/it]                                                           Episode 478	 reward: -2.41	 makespan: 238.75	 Mean_loss: 0.02526976,  training time: 1.34
progress:  95%|[34m[0m| 477/500 [10:45<00:31,  1.36s/it]progress:  96%|[34m[0m| 478/500 [10:45<00:29,  1.35s/it]                                                           Episode 479	 reward: -2.41	 makespan: 238.85	 Mean_loss: 0.03647431,  training time: 1.33
progress:  96%|[34m[0m| 478/500 [10:46<00:29,  1.35s/it]progress:  96%|[34m[0m| 479/500 [10:46<00:28,  1.35s/it]                                                           Episode 480	 reward: -2.51	 makespan: 248.40	 Mean_loss: 0.04182678,  training time: 1.35
progress:  96%|[34m[0m| 479/500 [10:47<00:28,  1.35s/it]progress:  96%|[34m[0m| 480/500 [10:47<00:26,  1.35s/it]                                                           Episode 481	 reward: -2.52	 makespan: 249.00	 Mean_loss: 0.00873251,  training time: 1.37
progress:  96%|[34m[0m| 480/500 [10:49<00:26,  1.35s/it]progress:  96%|[34m[0m| 481/500 [10:49<00:25,  1.35s/it]                                                           Episode 482	 reward: -2.57	 makespan: 254.55	 Mean_loss: 0.02095320,  training time: 1.32
progress:  96%|[34m[0m| 481/500 [10:50<00:25,  1.35s/it]progress:  96%|[34m[0m| 482/500 [10:50<00:24,  1.34s/it]                                                           Episode 483	 reward: -2.63	 makespan: 260.05	 Mean_loss: 0.02056502,  training time: 1.33
progress:  96%|[34m[0m| 482/500 [10:51<00:24,  1.34s/it]progress:  97%|[34m[0m| 483/500 [10:51<00:22,  1.34s/it]                                                           Episode 484	 reward: -2.56	 makespan: 253.10	 Mean_loss: 0.03748225,  training time: 1.33
progress:  97%|[34m[0m| 483/500 [10:53<00:22,  1.34s/it]progress:  97%|[34m[0m| 484/500 [10:53<00:21,  1.34s/it]                                                           Episode 485	 reward: -2.56	 makespan: 253.00	 Mean_loss: 0.01342740,  training time: 1.34
progress:  97%|[34m[0m| 484/500 [10:54<00:21,  1.34s/it]progress:  97%|[34m[0m| 485/500 [10:54<00:20,  1.34s/it]                                                           Episode 486	 reward: -2.58	 makespan: 255.80	 Mean_loss: 0.00874490,  training time: 1.32
progress:  97%|[34m[0m| 485/500 [10:55<00:20,  1.34s/it]progress:  97%|[34m[0m| 486/500 [10:55<00:18,  1.33s/it]                                                           Episode 487	 reward: -2.50	 makespan: 247.95	 Mean_loss: 0.01179700,  training time: 1.33
progress:  97%|[34m[0m| 486/500 [10:57<00:18,  1.33s/it]progress:  97%|[34m[0m| 487/500 [10:57<00:17,  1.33s/it]                                                           Episode 488	 reward: -2.56	 makespan: 253.45	 Mean_loss: 0.01463685,  training time: 1.33
progress:  97%|[34m[0m| 487/500 [10:58<00:17,  1.33s/it]progress:  98%|[34m[0m| 488/500 [10:58<00:15,  1.33s/it]                                                           Episode 489	 reward: -2.58	 makespan: 255.45	 Mean_loss: 0.03352007,  training time: 1.33
progress:  98%|[34m[0m| 488/500 [10:59<00:15,  1.33s/it]progress:  98%|[34m[0m| 489/500 [10:59<00:14,  1.33s/it]                                                           Episode 490	 reward: -2.51	 makespan: 248.10	 Mean_loss: 0.03013224,  training time: 1.36
progress:  98%|[34m[0m| 489/500 [11:01<00:14,  1.33s/it]progress:  98%|[34m[0m| 490/500 [11:01<00:13,  1.34s/it]                                                           Episode 491	 reward: -2.41	 makespan: 238.70	 Mean_loss: 0.02661033,  training time: 1.33
progress:  98%|[34m[0m| 490/500 [11:02<00:13,  1.34s/it]progress:  98%|[34m[0m| 491/500 [11:02<00:12,  1.34s/it]                                                           Episode 492	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.03022098,  training time: 1.32
progress:  98%|[34m[0m| 491/500 [11:03<00:12,  1.34s/it]progress:  98%|[34m[0m| 492/500 [11:03<00:10,  1.33s/it]                                                           Episode 493	 reward: -2.53	 makespan: 250.05	 Mean_loss: 0.01962597,  training time: 1.32
progress:  98%|[34m[0m| 492/500 [11:05<00:10,  1.33s/it]progress:  99%|[34m[0m| 493/500 [11:05<00:09,  1.33s/it]                                                           Episode 494	 reward: -2.57	 makespan: 254.90	 Mean_loss: 0.00693090,  training time: 1.33
progress:  99%|[34m[0m| 493/500 [11:06<00:09,  1.33s/it]progress:  99%|[34m[0m| 494/500 [11:06<00:07,  1.33s/it]                                                           Episode 495	 reward: -2.55	 makespan: 252.80	 Mean_loss: 0.01660121,  training time: 1.40
progress:  99%|[34m[0m| 494/500 [11:08<00:07,  1.33s/it]progress:  99%|[34m[0m| 495/500 [11:08<00:06,  1.35s/it]                                                           Episode 496	 reward: -2.48	 makespan: 245.45	 Mean_loss: 0.02283676,  training time: 1.33
progress:  99%|[34m[0m| 495/500 [11:09<00:06,  1.35s/it]progress:  99%|[34m[0m| 496/500 [11:09<00:05,  1.34s/it]                                                           Episode 497	 reward: -2.57	 makespan: 254.40	 Mean_loss: 0.00845782,  training time: 1.34
progress:  99%|[34m[0m| 496/500 [11:10<00:05,  1.34s/it]progress:  99%|[34m[0m| 497/500 [11:10<00:04,  1.34s/it]                                                           Episode 498	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.01682262,  training time: 1.32
progress:  99%|[34m[0m| 497/500 [11:11<00:04,  1.34s/it]progress: 100%|[34m[0m| 498/500 [11:11<00:02,  1.34s/it]                                                           Episode 499	 reward: -2.51	 makespan: 248.10	 Mean_loss: 0.01875906,  training time: 1.37
progress: 100%|[34m[0m| 498/500 [11:13<00:02,  1.34s/it]progress: 100%|[34m[0m| 499/500 [11:13<00:01,  1.35s/it]                                                           Episode 500	 reward: -2.59	 makespan: 255.95	 Mean_loss: 0.01315088,  training time: 1.33
progress: 100%|[34m[0m| 499/500 [11:14<00:01,  1.35s/it]progress: 100%|[34m[0m| 500/500 [11:14<00:00,  1.34s/it]progress: 100%|[34m[0m| 500/500 [11:14<00:00,  1.35s/it]
+ python train/DAN.py --n_j 15 --n_m 5 --op_per_job 12 --data_source SD2 --model_suffix SD2 --logdir ./runs/exp17_1/DAN/train_model/15x5x12 --max_updates 500
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/500 [00:00<?, ?it/s]                                                 Episode 1	 reward: -20.43	 makespan: 2022.80	 Mean_loss: 22.64959717,  training time: 4.94
progress:   0%|[34m          [0m| 0/500 [00:04<?, ?it/s]progress:   0%|[34m          [0m| 1/500 [00:04<41:03,  4.94s/it]                                                         Episode 2	 reward: -19.52	 makespan: 1932.20	 Mean_loss: 18.76117897,  training time: 3.78
progress:   0%|[34m          [0m| 1/500 [00:08<41:03,  4.94s/it]progress:   0%|[34m          [0m| 2/500 [00:08<35:20,  4.26s/it]                                                         Episode 3	 reward: -19.07	 makespan: 1887.65	 Mean_loss: 15.47761917,  training time: 3.84
progress:   0%|[34m          [0m| 2/500 [00:12<35:20,  4.26s/it]progress:   1%|[34m          [0m| 3/500 [00:12<33:40,  4.07s/it]                                                         Episode 4	 reward: -18.78	 makespan: 1858.95	 Mean_loss: 11.35195351,  training time: 3.81
progress:   1%|[34m          [0m| 3/500 [00:16<33:40,  4.07s/it]progress:   1%|[34m          [0m| 4/500 [00:16<32:46,  3.97s/it]                                                         Episode 5	 reward: -19.17	 makespan: 1897.80	 Mean_loss: 10.63013554,  training time: 4.02
progress:   1%|[34m          [0m| 4/500 [00:20<32:46,  3.97s/it]progress:   1%|[34m          [0m| 5/500 [00:20<32:52,  3.99s/it]                                                         Episode 6	 reward: -20.00	 makespan: 1980.15	 Mean_loss: 12.30818462,  training time: 3.81
progress:   1%|[34m          [0m| 5/500 [00:24<32:52,  3.99s/it]progress:   1%|[34m          [0m| 6/500 [00:24<32:19,  3.93s/it]                                                         Episode 7	 reward: -19.46	 makespan: 1926.85	 Mean_loss: 14.01500511,  training time: 3.78
progress:   1%|[34m          [0m| 6/500 [00:27<32:19,  3.93s/it]progress:   1%|[34m         [0m| 7/500 [00:27<31:53,  3.88s/it]                                                         Episode 8	 reward: -19.45	 makespan: 1925.50	 Mean_loss: 14.72734642,  training time: 3.77
progress:   1%|[34m         [0m| 7/500 [00:31<31:53,  3.88s/it]progress:   2%|[34m         [0m| 8/500 [00:31<31:32,  3.85s/it]                                                         Episode 9	 reward: -20.14	 makespan: 1993.65	 Mean_loss: 15.80562878,  training time: 3.76
progress:   2%|[34m         [0m| 8/500 [00:35<31:32,  3.85s/it]progress:   2%|[34m         [0m| 9/500 [00:35<31:15,  3.82s/it]                                                         Episode 10	 reward: -20.25	 makespan: 2004.90	 Mean_loss: 16.86549377,  training time: 3.87
progress:   2%|[34m         [0m| 9/500 [00:39<31:15,  3.82s/it]progress:   2%|[34m         [0m| 10/500 [00:39<31:18,  3.83s/it]                                                          Episode 11	 reward: -19.97	 makespan: 1976.55	 Mean_loss: 17.59708023,  training time: 3.83
progress:   2%|[34m         [0m| 10/500 [00:43<31:18,  3.83s/it]progress:   2%|[34m         [0m| 11/500 [00:43<31:13,  3.83s/it]                                                          Episode 12	 reward: -20.10	 makespan: 1989.70	 Mean_loss: 17.98911858,  training time: 3.75
progress:   2%|[34m         [0m| 11/500 [00:46<31:13,  3.83s/it]progress:   2%|[34m         [0m| 12/500 [00:46<30:58,  3.81s/it]                                                          Episode 13	 reward: -20.55	 makespan: 2034.85	 Mean_loss: 17.08071518,  training time: 3.86
progress:   2%|[34m         [0m| 12/500 [00:50<30:58,  3.81s/it]progress:   3%|[34m         [0m| 13/500 [00:50<31:02,  3.82s/it]                                                          Episode 14	 reward: -19.92	 makespan: 1972.50	 Mean_loss: 14.38840008,  training time: 3.75
progress:   3%|[34m         [0m| 13/500 [00:54<31:02,  3.82s/it]progress:   3%|[34m         [0m| 14/500 [00:54<30:47,  3.80s/it]                                                          Episode 15	 reward: -20.33	 makespan: 2012.60	 Mean_loss: 13.88965702,  training time: 3.81
progress:   3%|[34m         [0m| 14/500 [00:58<30:47,  3.80s/it]progress:   3%|[34m         [0m| 15/500 [00:58<30:44,  3.80s/it]                                                          Episode 16	 reward: -20.38	 makespan: 2017.55	 Mean_loss: 14.04613113,  training time: 3.75
progress:   3%|[34m         [0m| 15/500 [01:02<30:44,  3.80s/it]progress:   3%|[34m         [0m| 16/500 [01:02<30:33,  3.79s/it]                                                          Episode 17	 reward: -20.38	 makespan: 2017.70	 Mean_loss: 14.73794270,  training time: 3.86
progress:   3%|[34m         [0m| 16/500 [01:06<30:33,  3.79s/it]progress:   3%|[34m         [0m| 17/500 [01:06<30:40,  3.81s/it]                                                          Episode 18	 reward: -19.95	 makespan: 1975.10	 Mean_loss: 12.93645954,  training time: 3.82
progress:   3%|[34m         [0m| 17/500 [01:09<30:40,  3.81s/it]progress:   4%|[34m         [0m| 18/500 [01:09<30:37,  3.81s/it]                                                          Episode 19	 reward: -20.07	 makespan: 1987.25	 Mean_loss: 12.98776627,  training time: 4.00
progress:   4%|[34m         [0m| 18/500 [01:13<30:37,  3.81s/it]progress:   4%|[34m         [0m| 19/500 [01:13<31:00,  3.87s/it]                                                          Episode 20	 reward: -19.84	 makespan: 1964.55	 Mean_loss: 12.62973022,  training time: 3.89
progress:   4%|[34m         [0m| 19/500 [01:17<31:00,  3.87s/it]progress:   4%|[34m         [0m| 20/500 [01:17<30:59,  3.87s/it]                                                          Episode 21	 reward: -19.57	 makespan: 1937.55	 Mean_loss: 10.60758686,  training time: 3.91
progress:   4%|[34m         [0m| 20/500 [01:21<30:59,  3.87s/it]progress:   4%|[34m         [0m| 21/500 [01:21<31:00,  3.88s/it]                                                          Episode 22	 reward: -19.21	 makespan: 1901.30	 Mean_loss: 10.43036652,  training time: 3.88
progress:   4%|[34m         [0m| 21/500 [01:25<31:00,  3.88s/it]progress:   4%|[34m         [0m| 22/500 [01:25<30:55,  3.88s/it]                                                          Episode 23	 reward: -19.08	 makespan: 1888.85	 Mean_loss: 10.00355911,  training time: 3.86
progress:   4%|[34m         [0m| 22/500 [01:29<30:55,  3.88s/it]progress:   5%|[34m         [0m| 23/500 [01:29<30:48,  3.87s/it]                                                          Episode 24	 reward: -18.78	 makespan: 1858.95	 Mean_loss: 9.40468693,  training time: 3.86
progress:   5%|[34m         [0m| 23/500 [01:33<30:48,  3.87s/it]progress:   5%|[34m         [0m| 24/500 [01:33<30:43,  3.87s/it]                                                          Episode 25	 reward: -19.20	 makespan: 1901.20	 Mean_loss: 7.76292372,  training time: 3.81
progress:   5%|[34m         [0m| 24/500 [01:37<30:43,  3.87s/it]progress:   5%|[34m         [0m| 25/500 [01:37<30:30,  3.85s/it]                                                          Episode 26	 reward: -18.65	 makespan: 1845.90	 Mean_loss: 7.43652058,  training time: 3.85
progress:   5%|[34m         [0m| 25/500 [01:40<30:30,  3.85s/it]progress:   5%|[34m         [0m| 26/500 [01:40<30:25,  3.85s/it]                                                          Episode 27	 reward: -18.99	 makespan: 1879.70	 Mean_loss: 6.66188955,  training time: 3.82
progress:   5%|[34m         [0m| 26/500 [01:44<30:25,  3.85s/it]progress:   5%|[34m         [0m| 27/500 [01:44<30:17,  3.84s/it]                                                          Episode 28	 reward: -18.31	 makespan: 1812.90	 Mean_loss: 7.71219683,  training time: 4.02
progress:   5%|[34m         [0m| 27/500 [01:48<30:17,  3.84s/it]progress:   6%|[34m         [0m| 28/500 [01:48<30:38,  3.89s/it]                                                          Episode 29	 reward: -17.82	 makespan: 1763.90	 Mean_loss: 6.52364063,  training time: 3.79
progress:   6%|[34m         [0m| 28/500 [01:52<30:38,  3.89s/it]progress:   6%|[34m         [0m| 29/500 [01:52<30:20,  3.86s/it]                                                          Episode 30	 reward: -18.22	 makespan: 1804.25	 Mean_loss: 5.68852711,  training time: 3.76
progress:   6%|[34m         [0m| 29/500 [01:56<30:20,  3.86s/it]progress:   6%|[34m         [0m| 30/500 [01:56<30:02,  3.83s/it]                                                          Episode 31	 reward: -18.46	 makespan: 1827.50	 Mean_loss: 6.05961752,  training time: 3.80
progress:   6%|[34m         [0m| 30/500 [02:00<30:02,  3.83s/it]progress:   6%|[34m         [0m| 31/500 [02:00<29:52,  3.82s/it]                                                          Episode 32	 reward: -18.18	 makespan: 1799.65	 Mean_loss: 5.68772030,  training time: 3.96
progress:   6%|[34m         [0m| 31/500 [02:04<29:52,  3.82s/it]progress:   6%|[34m         [0m| 32/500 [02:04<30:08,  3.86s/it]                                                          Episode 33	 reward: -17.56	 makespan: 1738.40	 Mean_loss: 4.66762829,  training time: 3.77
progress:   6%|[34m         [0m| 32/500 [02:07<30:08,  3.86s/it]progress:   7%|[34m         [0m| 33/500 [02:07<29:52,  3.84s/it]                                                          Episode 34	 reward: -17.52	 makespan: 1734.90	 Mean_loss: 4.43782902,  training time: 3.78
progress:   7%|[34m         [0m| 33/500 [02:11<29:52,  3.84s/it]progress:   7%|[34m         [0m| 34/500 [02:11<29:40,  3.82s/it]                                                          Episode 35	 reward: -17.45	 makespan: 1727.55	 Mean_loss: 4.23502254,  training time: 3.83
progress:   7%|[34m         [0m| 34/500 [02:15<29:40,  3.82s/it]progress:   7%|[34m         [0m| 35/500 [02:15<29:37,  3.82s/it]                                                          Episode 36	 reward: -17.17	 makespan: 1700.15	 Mean_loss: 3.54858923,  training time: 3.79
progress:   7%|[34m         [0m| 35/500 [02:19<29:37,  3.82s/it]progress:   7%|[34m         [0m| 36/500 [02:19<29:29,  3.81s/it]                                                          Episode 37	 reward: -16.93	 makespan: 1676.05	 Mean_loss: 3.57624149,  training time: 3.76
progress:   7%|[34m         [0m| 36/500 [02:22<29:29,  3.81s/it]progress:   7%|[34m         [0m| 37/500 [02:22<29:18,  3.80s/it]                                                          Episode 38	 reward: -16.52	 makespan: 1635.50	 Mean_loss: 3.08301544,  training time: 3.80
progress:   7%|[34m         [0m| 37/500 [02:26<29:18,  3.80s/it]progress:   8%|[34m         [0m| 38/500 [02:26<29:14,  3.80s/it]                                                          Episode 39	 reward: -16.65	 makespan: 1647.95	 Mean_loss: 2.89313984,  training time: 3.79
progress:   8%|[34m         [0m| 38/500 [02:30<29:14,  3.80s/it]progress:   8%|[34m         [0m| 39/500 [02:30<29:09,  3.80s/it]                                                          Episode 40	 reward: -16.63	 makespan: 1646.50	 Mean_loss: 2.83532262,  training time: 3.80
progress:   8%|[34m         [0m| 39/500 [02:34<29:09,  3.80s/it]progress:   8%|[34m         [0m| 40/500 [02:34<29:06,  3.80s/it]                                                          Episode 41	 reward: -16.23	 makespan: 1607.25	 Mean_loss: 2.45438671,  training time: 3.89
progress:   8%|[34m         [0m| 40/500 [02:38<29:06,  3.80s/it]progress:   8%|[34m         [0m| 41/500 [02:38<29:15,  3.82s/it]                                                          Episode 42	 reward: -15.73	 makespan: 1557.35	 Mean_loss: 2.38245082,  training time: 3.79
progress:   8%|[34m         [0m| 41/500 [02:42<29:15,  3.82s/it]progress:   8%|[34m         [0m| 42/500 [02:42<29:07,  3.82s/it]                                                          Episode 43	 reward: -15.82	 makespan: 1566.55	 Mean_loss: 2.04183602,  training time: 3.80
progress:   8%|[34m         [0m| 42/500 [02:45<29:07,  3.82s/it]progress:   9%|[34m         [0m| 43/500 [02:45<29:01,  3.81s/it]                                                          Episode 44	 reward: -15.44	 makespan: 1528.45	 Mean_loss: 1.78653288,  training time: 3.84
progress:   9%|[34m         [0m| 43/500 [02:49<29:01,  3.81s/it]progress:   9%|[34m         [0m| 44/500 [02:49<29:01,  3.82s/it]                                                          Episode 45	 reward: -14.94	 makespan: 1479.10	 Mean_loss: 1.59957480,  training time: 3.83
progress:   9%|[34m         [0m| 44/500 [02:53<29:01,  3.82s/it]progress:   9%|[34m         [0m| 45/500 [02:53<28:59,  3.82s/it]                                                          Episode 46	 reward: -15.24	 makespan: 1509.15	 Mean_loss: 1.50843740,  training time: 3.86
progress:   9%|[34m         [0m| 45/500 [02:57<28:59,  3.82s/it]progress:   9%|[34m         [0m| 46/500 [02:57<29:01,  3.84s/it]                                                          Episode 47	 reward: -15.11	 makespan: 1496.25	 Mean_loss: 1.40774202,  training time: 4.10
progress:   9%|[34m         [0m| 46/500 [03:01<29:01,  3.84s/it]progress:   9%|[34m         [0m| 47/500 [03:01<29:33,  3.92s/it]                                                          Episode 48	 reward: -14.98	 makespan: 1483.35	 Mean_loss: 1.41385412,  training time: 3.99
progress:   9%|[34m         [0m| 47/500 [03:05<29:33,  3.92s/it]progress:  10%|[34m         [0m| 48/500 [03:05<29:40,  3.94s/it]                                                          Episode 49	 reward: -14.68	 makespan: 1453.75	 Mean_loss: 1.23452830,  training time: 3.76
progress:  10%|[34m         [0m| 48/500 [03:09<29:40,  3.94s/it]progress:  10%|[34m         [0m| 49/500 [03:09<29:12,  3.89s/it]                                                          Episode 50	 reward: -14.66	 makespan: 1451.75	 Mean_loss: 1.15756798,  training time: 3.84
progress:  10%|[34m         [0m| 49/500 [03:13<29:12,  3.89s/it]progress:  10%|[34m         [0m| 50/500 [03:13<29:02,  3.87s/it]                                                          Episode 51	 reward: -14.63	 makespan: 1447.95	 Mean_loss: 1.05170989,  training time: 3.78
progress:  10%|[34m         [0m| 50/500 [03:16<29:02,  3.87s/it]progress:  10%|[34m         [0m| 51/500 [03:16<28:46,  3.84s/it]                                                          Episode 52	 reward: -14.23	 makespan: 1408.85	 Mean_loss: 0.85944444,  training time: 3.77
progress:  10%|[34m         [0m| 51/500 [03:20<28:46,  3.84s/it]progress:  10%|[34m         [0m| 52/500 [03:20<28:32,  3.82s/it]                                                          Episode 53	 reward: -14.39	 makespan: 1424.65	 Mean_loss: 0.94120717,  training time: 3.78
progress:  10%|[34m         [0m| 52/500 [03:24<28:32,  3.82s/it]progress:  11%|[34m         [0m| 53/500 [03:24<28:22,  3.81s/it]                                                          Episode 54	 reward: -14.19	 makespan: 1405.30	 Mean_loss: 0.74456245,  training time: 3.76
progress:  11%|[34m         [0m| 53/500 [03:28<28:22,  3.81s/it]progress:  11%|[34m         [0m| 54/500 [03:28<28:12,  3.80s/it]                                                          Episode 55	 reward: -14.00	 makespan: 1385.60	 Mean_loss: 0.77107179,  training time: 3.78
progress:  11%|[34m         [0m| 54/500 [03:31<28:12,  3.80s/it]progress:  11%|[34m         [0m| 55/500 [03:31<28:07,  3.79s/it]                                                          Episode 56	 reward: -14.17	 makespan: 1402.90	 Mean_loss: 0.76449621,  training time: 3.78
progress:  11%|[34m         [0m| 55/500 [03:35<28:07,  3.79s/it]progress:  11%|[34m         [0m| 56/500 [03:35<28:02,  3.79s/it]                                                          Episode 57	 reward: -14.11	 makespan: 1396.40	 Mean_loss: 0.73814732,  training time: 3.80
progress:  11%|[34m         [0m| 56/500 [03:39<28:02,  3.79s/it]progress:  11%|[34m        [0m| 57/500 [03:39<27:59,  3.79s/it]                                                          Episode 58	 reward: -13.96	 makespan: 1382.15	 Mean_loss: 0.65851790,  training time: 3.83
progress:  11%|[34m        [0m| 57/500 [03:43<27:59,  3.79s/it]progress:  12%|[34m        [0m| 58/500 [03:43<28:00,  3.80s/it]                                                          Episode 59	 reward: -13.88	 makespan: 1374.00	 Mean_loss: 0.59995264,  training time: 3.78
progress:  12%|[34m        [0m| 58/500 [03:47<28:00,  3.80s/it]progress:  12%|[34m        [0m| 59/500 [03:47<27:53,  3.80s/it]                                                          Episode 60	 reward: -13.97	 makespan: 1382.95	 Mean_loss: 0.78221744,  training time: 3.82
progress:  12%|[34m        [0m| 59/500 [03:50<27:53,  3.80s/it]progress:  12%|[34m        [0m| 60/500 [03:50<27:53,  3.80s/it]                                                          Episode 61	 reward: -14.12	 makespan: 1397.70	 Mean_loss: 0.65311533,  training time: 3.94
progress:  12%|[34m        [0m| 60/500 [03:54<27:53,  3.80s/it]progress:  12%|[34m        [0m| 61/500 [03:54<28:08,  3.85s/it]                                                          Episode 62	 reward: -14.06	 makespan: 1391.55	 Mean_loss: 0.68459922,  training time: 3.79
progress:  12%|[34m        [0m| 61/500 [03:58<28:08,  3.85s/it]progress:  12%|[34m        [0m| 62/500 [03:58<27:56,  3.83s/it]                                                          Episode 63	 reward: -14.14	 makespan: 1400.30	 Mean_loss: 0.68176848,  training time: 3.80
progress:  12%|[34m        [0m| 62/500 [04:02<27:56,  3.83s/it]progress:  13%|[34m        [0m| 63/500 [04:02<27:49,  3.82s/it]                                                          Episode 64	 reward: -14.02	 makespan: 1388.45	 Mean_loss: 0.54957223,  training time: 3.81
progress:  13%|[34m        [0m| 63/500 [04:06<27:49,  3.82s/it]progress:  13%|[34m        [0m| 64/500 [04:06<27:44,  3.82s/it]                                                          Episode 65	 reward: -13.96	 makespan: 1382.05	 Mean_loss: 0.60218662,  training time: 3.79
progress:  13%|[34m        [0m| 64/500 [04:10<27:44,  3.82s/it]progress:  13%|[34m        [0m| 65/500 [04:10<27:36,  3.81s/it]                                                          Episode 66	 reward: -13.89	 makespan: 1375.55	 Mean_loss: 0.57564461,  training time: 3.78
progress:  13%|[34m        [0m| 65/500 [04:13<27:36,  3.81s/it]progress:  13%|[34m        [0m| 66/500 [04:13<27:29,  3.80s/it]                                                          Episode 67	 reward: -13.92	 makespan: 1377.60	 Mean_loss: 0.53404468,  training time: 3.85
progress:  13%|[34m        [0m| 66/500 [04:17<27:29,  3.80s/it]progress:  13%|[34m        [0m| 67/500 [04:17<27:32,  3.82s/it]                                                          Episode 68	 reward: -13.61	 makespan: 1347.75	 Mean_loss: 0.55634201,  training time: 3.77
progress:  13%|[34m        [0m| 67/500 [04:21<27:32,  3.82s/it]progress:  14%|[34m        [0m| 68/500 [04:21<27:23,  3.80s/it]                                                          Episode 69	 reward: -13.78	 makespan: 1363.85	 Mean_loss: 0.51011044,  training time: 3.83
progress:  14%|[34m        [0m| 68/500 [04:25<27:23,  3.80s/it]progress:  14%|[34m        [0m| 69/500 [04:25<27:22,  3.81s/it]                                                          Episode 70	 reward: -13.84	 makespan: 1369.80	 Mean_loss: 0.57024574,  training time: 3.82
progress:  14%|[34m        [0m| 69/500 [04:29<27:22,  3.81s/it]progress:  14%|[34m        [0m| 70/500 [04:29<27:20,  3.82s/it]                                                          Episode 71	 reward: -13.79	 makespan: 1365.05	 Mean_loss: 0.49967003,  training time: 3.99
progress:  14%|[34m        [0m| 70/500 [04:33<27:20,  3.82s/it]progress:  14%|[34m        [0m| 71/500 [04:33<27:39,  3.87s/it]                                                          Episode 72	 reward: -13.65	 makespan: 1351.45	 Mean_loss: 0.52749765,  training time: 3.82
progress:  14%|[34m        [0m| 71/500 [04:36<27:39,  3.87s/it]progress:  14%|[34m        [0m| 72/500 [04:36<27:29,  3.85s/it]                                                          Episode 73	 reward: -13.90	 makespan: 1375.90	 Mean_loss: 0.44582883,  training time: 4.10
progress:  14%|[34m        [0m| 72/500 [04:41<27:29,  3.85s/it]progress:  15%|[34m        [0m| 73/500 [04:41<27:58,  3.93s/it]                                                          Episode 74	 reward: -13.72	 makespan: 1357.80	 Mean_loss: 0.49543908,  training time: 4.14
progress:  15%|[34m        [0m| 73/500 [04:45<27:58,  3.93s/it]progress:  15%|[34m        [0m| 74/500 [04:45<28:21,  3.99s/it]                                                          Episode 75	 reward: -13.81	 makespan: 1366.75	 Mean_loss: 0.48073649,  training time: 3.75
progress:  15%|[34m        [0m| 74/500 [04:48<28:21,  3.99s/it]progress:  15%|[34m        [0m| 75/500 [04:48<27:46,  3.92s/it]                                                          Episode 76	 reward: -13.72	 makespan: 1358.15	 Mean_loss: 0.48532462,  training time: 3.79
progress:  15%|[34m        [0m| 75/500 [04:52<27:46,  3.92s/it]progress:  15%|[34m        [0m| 76/500 [04:52<27:25,  3.88s/it]                                                          Episode 77	 reward: -13.65	 makespan: 1350.95	 Mean_loss: 0.46739596,  training time: 3.85
progress:  15%|[34m        [0m| 76/500 [04:56<27:25,  3.88s/it]progress:  15%|[34m        [0m| 77/500 [04:56<27:18,  3.87s/it]                                                          Episode 78	 reward: -13.69	 makespan: 1355.35	 Mean_loss: 0.45523313,  training time: 3.79
progress:  15%|[34m        [0m| 77/500 [05:00<27:18,  3.87s/it]progress:  16%|[34m        [0m| 78/500 [05:00<27:04,  3.85s/it]                                                          Episode 79	 reward: -13.70	 makespan: 1356.15	 Mean_loss: 0.38308305,  training time: 3.98
progress:  16%|[34m        [0m| 78/500 [05:04<27:04,  3.85s/it]progress:  16%|[34m        [0m| 79/500 [05:04<27:16,  3.89s/it]                                                          Episode 80	 reward: -13.78	 makespan: 1364.70	 Mean_loss: 0.43109146,  training time: 3.88
progress:  16%|[34m        [0m| 79/500 [05:08<27:16,  3.89s/it]progress:  16%|[34m        [0m| 80/500 [05:08<27:12,  3.89s/it]                                                          Episode 81	 reward: -13.26	 makespan: 1313.10	 Mean_loss: 0.50027698,  training time: 4.00
progress:  16%|[34m        [0m| 80/500 [05:12<27:12,  3.89s/it]progress:  16%|[34m        [0m| 81/500 [05:12<27:22,  3.92s/it]                                                          Episode 82	 reward: -13.21	 makespan: 1308.10	 Mean_loss: 0.44097504,  training time: 3.83
progress:  16%|[34m        [0m| 81/500 [05:16<27:22,  3.92s/it]progress:  16%|[34m        [0m| 82/500 [05:16<27:07,  3.89s/it]                                                          Episode 83	 reward: -13.46	 makespan: 1332.45	 Mean_loss: 0.42619407,  training time: 3.79
progress:  16%|[34m        [0m| 82/500 [05:19<27:07,  3.89s/it]progress:  17%|[34m        [0m| 83/500 [05:19<26:50,  3.86s/it]                                                          Episode 84	 reward: -13.26	 makespan: 1312.90	 Mean_loss: 0.47000897,  training time: 3.88
progress:  17%|[34m        [0m| 83/500 [05:23<26:50,  3.86s/it]progress:  17%|[34m        [0m| 84/500 [05:23<26:48,  3.87s/it]                                                          Episode 85	 reward: -13.22	 makespan: 1309.20	 Mean_loss: 0.37426040,  training time: 3.94
progress:  17%|[34m        [0m| 84/500 [05:27<26:48,  3.87s/it]progress:  17%|[34m        [0m| 85/500 [05:27<26:54,  3.89s/it]                                                          Episode 86	 reward: -13.32	 makespan: 1318.90	 Mean_loss: 0.37879580,  training time: 3.86
progress:  17%|[34m        [0m| 85/500 [05:31<26:54,  3.89s/it]progress:  17%|[34m        [0m| 86/500 [05:31<26:47,  3.88s/it]                                                          Episode 87	 reward: -13.37	 makespan: 1323.25	 Mean_loss: 0.49004146,  training time: 3.85
progress:  17%|[34m        [0m| 86/500 [05:35<26:47,  3.88s/it]progress:  17%|[34m        [0m| 87/500 [05:35<26:38,  3.87s/it]                                                          Episode 88	 reward: -13.21	 makespan: 1307.95	 Mean_loss: 0.33939421,  training time: 3.87
progress:  17%|[34m        [0m| 87/500 [05:39<26:38,  3.87s/it]progress:  18%|[34m        [0m| 88/500 [05:39<26:34,  3.87s/it]                                                          Episode 89	 reward: -13.32	 makespan: 1318.30	 Mean_loss: 0.36987609,  training time: 3.79
progress:  18%|[34m        [0m| 88/500 [05:43<26:34,  3.87s/it]progress:  18%|[34m        [0m| 89/500 [05:43<26:20,  3.85s/it]                                                          Episode 90	 reward: -13.26	 makespan: 1312.95	 Mean_loss: 0.41089872,  training time: 3.94
progress:  18%|[34m        [0m| 89/500 [05:47<26:20,  3.85s/it]progress:  18%|[34m        [0m| 90/500 [05:47<26:28,  3.88s/it]                                                          Episode 91	 reward: -13.23	 makespan: 1310.00	 Mean_loss: 0.40840623,  training time: 3.76
progress:  18%|[34m        [0m| 90/500 [05:50<26:28,  3.88s/it]progress:  18%|[34m        [0m| 91/500 [05:50<26:11,  3.84s/it]                                                          Episode 92	 reward: -13.33	 makespan: 1319.95	 Mean_loss: 0.40562516,  training time: 3.76
progress:  18%|[34m        [0m| 91/500 [05:54<26:11,  3.84s/it]progress:  18%|[34m        [0m| 92/500 [05:54<25:57,  3.82s/it]                                                          Episode 93	 reward: -13.29	 makespan: 1315.45	 Mean_loss: 0.38456923,  training time: 3.76
progress:  18%|[34m        [0m| 92/500 [05:58<25:57,  3.82s/it]progress:  19%|[34m        [0m| 93/500 [05:58<25:47,  3.80s/it]                                                          Episode 94	 reward: -13.20	 makespan: 1306.60	 Mean_loss: 0.39450189,  training time: 3.99
progress:  19%|[34m        [0m| 93/500 [06:02<25:47,  3.80s/it]progress:  19%|[34m        [0m| 94/500 [06:02<26:05,  3.86s/it]                                                          Episode 95	 reward: -13.36	 makespan: 1322.65	 Mean_loss: 0.32278425,  training time: 3.79
progress:  19%|[34m        [0m| 94/500 [06:06<26:05,  3.86s/it]progress:  19%|[34m        [0m| 95/500 [06:06<25:54,  3.84s/it]                                                          Episode 96	 reward: -13.33	 makespan: 1319.20	 Mean_loss: 0.35902116,  training time: 3.79
progress:  19%|[34m        [0m| 95/500 [06:09<25:54,  3.84s/it]progress:  19%|[34m        [0m| 96/500 [06:09<25:44,  3.82s/it]                                                          Episode 97	 reward: -13.02	 makespan: 1288.70	 Mean_loss: 0.28815120,  training time: 3.81
progress:  19%|[34m        [0m| 96/500 [06:13<25:44,  3.82s/it]progress:  19%|[34m        [0m| 97/500 [06:13<25:39,  3.82s/it]                                                          Episode 98	 reward: -13.43	 makespan: 1329.25	 Mean_loss: 0.37972853,  training time: 3.88
progress:  19%|[34m        [0m| 97/500 [06:17<25:39,  3.82s/it]progress:  20%|[34m        [0m| 98/500 [06:17<25:43,  3.84s/it]                                                          Episode 99	 reward: -13.32	 makespan: 1318.40	 Mean_loss: 0.32885835,  training time: 3.92
progress:  20%|[34m        [0m| 98/500 [06:21<25:43,  3.84s/it]progress:  20%|[34m        [0m| 99/500 [06:21<25:49,  3.86s/it]                                                          Episode 100	 reward: -13.48	 makespan: 1334.90	 Mean_loss: 0.34762219,  training time: 3.96
progress:  20%|[34m        [0m| 99/500 [06:25<25:49,  3.86s/it]progress:  20%|[34m        [0m| 100/500 [06:25<25:57,  3.89s/it]                                                           Episode 101	 reward: -13.53	 makespan: 1339.65	 Mean_loss: 0.38693419,  training time: 4.03
progress:  20%|[34m        [0m| 100/500 [06:29<25:57,  3.89s/it]progress:  20%|[34m        [0m| 101/500 [06:29<26:10,  3.94s/it]                                                           Episode 102	 reward: -13.40	 makespan: 1326.75	 Mean_loss: 0.42707583,  training time: 3.93
progress:  20%|[34m        [0m| 101/500 [06:33<26:10,  3.94s/it]progress:  20%|[34m        [0m| 102/500 [06:33<26:06,  3.93s/it]                                                           Episode 103	 reward: -13.38	 makespan: 1325.00	 Mean_loss: 0.42738879,  training time: 3.78
progress:  20%|[34m        [0m| 102/500 [06:37<26:06,  3.93s/it]progress:  21%|[34m        [0m| 103/500 [06:37<25:43,  3.89s/it]                                                           Episode 104	 reward: -13.45	 makespan: 1331.70	 Mean_loss: 0.37201470,  training time: 3.78
progress:  21%|[34m        [0m| 103/500 [06:40<25:43,  3.89s/it]progress:  21%|[34m        [0m| 104/500 [06:40<25:27,  3.86s/it]                                                           Episode 105	 reward: -13.47	 makespan: 1333.60	 Mean_loss: 0.37295705,  training time: 3.81
progress:  21%|[34m        [0m| 104/500 [06:44<25:27,  3.86s/it]progress:  21%|[34m        [0m| 105/500 [06:44<25:18,  3.84s/it]                                                           Episode 106	 reward: -13.30	 makespan: 1316.70	 Mean_loss: 0.27733856,  training time: 3.76
progress:  21%|[34m        [0m| 105/500 [06:48<25:18,  3.84s/it]progress:  21%|[34m        [0m| 106/500 [06:48<25:04,  3.82s/it]                                                           Episode 107	 reward: -13.30	 makespan: 1316.40	 Mean_loss: 0.37203920,  training time: 3.86
progress:  21%|[34m        [0m| 106/500 [06:52<25:04,  3.82s/it]progress:  21%|[34m       [0m| 107/500 [06:52<25:05,  3.83s/it]                                                           Episode 108	 reward: -13.26	 makespan: 1312.35	 Mean_loss: 0.35799873,  training time: 3.86
progress:  21%|[34m       [0m| 107/500 [06:56<25:05,  3.83s/it]progress:  22%|[34m       [0m| 108/500 [06:56<25:05,  3.84s/it]                                                           Episode 109	 reward: -13.30	 makespan: 1316.45	 Mean_loss: 0.35244328,  training time: 3.84
progress:  22%|[34m       [0m| 108/500 [07:00<25:05,  3.84s/it]progress:  22%|[34m       [0m| 109/500 [07:00<25:01,  3.84s/it]                                                           Episode 110	 reward: -13.26	 makespan: 1312.75	 Mean_loss: 0.30510095,  training time: 3.83
progress:  22%|[34m       [0m| 109/500 [07:03<25:01,  3.84s/it]progress:  22%|[34m       [0m| 110/500 [07:03<24:57,  3.84s/it]                                                           Episode 111	 reward: -13.34	 makespan: 1320.60	 Mean_loss: 0.29409257,  training time: 3.83
progress:  22%|[34m       [0m| 110/500 [07:07<24:57,  3.84s/it]progress:  22%|[34m       [0m| 111/500 [07:07<24:52,  3.84s/it]                                                           Episode 112	 reward: -13.18	 makespan: 1304.40	 Mean_loss: 0.33453178,  training time: 3.83
progress:  22%|[34m       [0m| 111/500 [07:11<24:52,  3.84s/it]progress:  22%|[34m       [0m| 112/500 [07:11<24:47,  3.83s/it]                                                           Episode 113	 reward: -13.41	 makespan: 1327.70	 Mean_loss: 0.36171401,  training time: 3.84
progress:  22%|[34m       [0m| 112/500 [07:15<24:47,  3.83s/it]progress:  23%|[34m       [0m| 113/500 [07:15<24:44,  3.84s/it]                                                           Episode 114	 reward: -13.34	 makespan: 1320.85	 Mean_loss: 0.44226331,  training time: 4.09
progress:  23%|[34m       [0m| 113/500 [07:19<24:44,  3.84s/it]progress:  23%|[34m       [0m| 114/500 [07:19<25:09,  3.91s/it]                                                           Episode 115	 reward: -13.27	 makespan: 1313.50	 Mean_loss: 0.28301147,  training time: 3.78
progress:  23%|[34m       [0m| 114/500 [07:23<25:09,  3.91s/it]progress:  23%|[34m       [0m| 115/500 [07:23<24:51,  3.87s/it]                                                           Episode 116	 reward: -13.33	 makespan: 1319.35	 Mean_loss: 0.30848220,  training time: 3.97
progress:  23%|[34m       [0m| 115/500 [07:27<24:51,  3.87s/it]progress:  23%|[34m       [0m| 116/500 [07:27<24:58,  3.90s/it]                                                           Episode 117	 reward: -13.43	 makespan: 1329.30	 Mean_loss: 0.38725901,  training time: 3.90
progress:  23%|[34m       [0m| 116/500 [07:31<24:58,  3.90s/it]progress:  23%|[34m       [0m| 117/500 [07:31<24:54,  3.90s/it]                                                           Episode 118	 reward: -13.23	 makespan: 1310.20	 Mean_loss: 0.33190578,  training time: 3.98
progress:  23%|[34m       [0m| 117/500 [07:35<24:54,  3.90s/it]progress:  24%|[34m       [0m| 118/500 [07:35<24:59,  3.93s/it]                                                           Episode 119	 reward: -13.35	 makespan: 1321.95	 Mean_loss: 0.35909575,  training time: 3.78
progress:  24%|[34m       [0m| 118/500 [07:38<24:59,  3.93s/it]progress:  24%|[34m       [0m| 119/500 [07:38<24:39,  3.88s/it]                                                           Episode 120	 reward: -13.54	 makespan: 1340.15	 Mean_loss: 0.32003248,  training time: 3.82
progress:  24%|[34m       [0m| 119/500 [07:42<24:39,  3.88s/it]progress:  24%|[34m       [0m| 120/500 [07:42<24:28,  3.87s/it]                                                           Episode 121	 reward: -13.56	 makespan: 1342.05	 Mean_loss: 0.31342193,  training time: 3.87
progress:  24%|[34m       [0m| 120/500 [07:46<24:28,  3.87s/it]progress:  24%|[34m       [0m| 121/500 [07:46<24:25,  3.87s/it]                                                           Episode 122	 reward: -13.60	 makespan: 1346.55	 Mean_loss: 0.33658302,  training time: 3.88
progress:  24%|[34m       [0m| 121/500 [07:50<24:25,  3.87s/it]progress:  24%|[34m       [0m| 122/500 [07:50<24:22,  3.87s/it]                                                           Episode 123	 reward: -13.40	 makespan: 1326.55	 Mean_loss: 0.29036126,  training time: 3.85
progress:  24%|[34m       [0m| 122/500 [07:54<24:22,  3.87s/it]progress:  25%|[34m       [0m| 123/500 [07:54<24:16,  3.86s/it]                                                           Episode 124	 reward: -13.37	 makespan: 1324.10	 Mean_loss: 0.27417925,  training time: 3.91
progress:  25%|[34m       [0m| 123/500 [07:58<24:16,  3.86s/it]progress:  25%|[34m       [0m| 124/500 [07:58<24:17,  3.88s/it]                                                           Episode 125	 reward: -13.56	 makespan: 1342.25	 Mean_loss: 0.34618810,  training time: 3.91
progress:  25%|[34m       [0m| 124/500 [08:02<24:17,  3.88s/it]progress:  25%|[34m       [0m| 125/500 [08:02<24:17,  3.89s/it]                                                           Episode 126	 reward: -13.46	 makespan: 1332.30	 Mean_loss: 0.33108875,  training time: 3.97
progress:  25%|[34m       [0m| 125/500 [08:06<24:17,  3.89s/it]progress:  25%|[34m       [0m| 126/500 [08:06<24:23,  3.91s/it]                                                           Episode 127	 reward: -13.54	 makespan: 1340.15	 Mean_loss: 0.27515215,  training time: 4.01
progress:  25%|[34m       [0m| 126/500 [08:10<24:23,  3.91s/it]progress:  25%|[34m       [0m| 127/500 [08:10<24:30,  3.94s/it]                                                           Episode 128	 reward: -13.52	 makespan: 1338.50	 Mean_loss: 0.29982817,  training time: 3.78
progress:  25%|[34m       [0m| 127/500 [08:13<24:30,  3.94s/it]progress:  26%|[34m       [0m| 128/500 [08:13<24:08,  3.89s/it]                                                           Episode 129	 reward: -13.48	 makespan: 1334.70	 Mean_loss: 0.34773791,  training time: 3.78
progress:  26%|[34m       [0m| 128/500 [08:17<24:08,  3.89s/it]progress:  26%|[34m       [0m| 129/500 [08:17<23:51,  3.86s/it]                                                           Episode 130	 reward: -13.41	 makespan: 1327.15	 Mean_loss: 0.26314431,  training time: 3.79
progress:  26%|[34m       [0m| 129/500 [08:21<23:51,  3.86s/it]progress:  26%|[34m       [0m| 130/500 [08:21<23:40,  3.84s/it]                                                           Episode 131	 reward: -13.48	 makespan: 1334.90	 Mean_loss: 0.26457801,  training time: 3.84
progress:  26%|[34m       [0m| 130/500 [08:25<23:40,  3.84s/it]progress:  26%|[34m       [0m| 131/500 [08:25<23:36,  3.84s/it]                                                           Episode 132	 reward: -13.46	 makespan: 1332.90	 Mean_loss: 0.28658599,  training time: 3.80
progress:  26%|[34m       [0m| 131/500 [08:29<23:36,  3.84s/it]progress:  26%|[34m       [0m| 132/500 [08:29<23:28,  3.83s/it]                                                           Episode 133	 reward: -13.52	 makespan: 1338.45	 Mean_loss: 0.28807816,  training time: 3.93
progress:  26%|[34m       [0m| 132/500 [08:33<23:28,  3.83s/it]progress:  27%|[34m       [0m| 133/500 [08:33<23:36,  3.86s/it]                                                           Episode 134	 reward: -13.45	 makespan: 1331.50	 Mean_loss: 0.26665118,  training time: 3.80
progress:  27%|[34m       [0m| 133/500 [08:36<23:36,  3.86s/it]progress:  27%|[34m       [0m| 134/500 [08:36<23:26,  3.84s/it]                                                           Episode 135	 reward: -13.60	 makespan: 1346.00	 Mean_loss: 0.34797767,  training time: 3.78
progress:  27%|[34m       [0m| 134/500 [08:40<23:26,  3.84s/it]progress:  27%|[34m       [0m| 135/500 [08:40<23:16,  3.83s/it]                                                           Episode 136	 reward: -13.37	 makespan: 1323.90	 Mean_loss: 0.26317433,  training time: 3.80
progress:  27%|[34m       [0m| 135/500 [08:44<23:16,  3.83s/it]progress:  27%|[34m       [0m| 136/500 [08:44<23:09,  3.82s/it]                                                           Episode 137	 reward: -13.47	 makespan: 1333.10	 Mean_loss: 0.28038126,  training time: 3.77
progress:  27%|[34m       [0m| 136/500 [08:48<23:09,  3.82s/it]progress:  27%|[34m       [0m| 137/500 [08:48<23:00,  3.80s/it]                                                           Episode 138	 reward: -13.58	 makespan: 1344.15	 Mean_loss: 0.29789963,  training time: 3.75
progress:  27%|[34m       [0m| 137/500 [08:52<23:00,  3.80s/it]progress:  28%|[34m       [0m| 138/500 [08:52<22:51,  3.79s/it]                                                           Episode 139	 reward: -13.52	 makespan: 1338.05	 Mean_loss: 0.26158518,  training time: 3.90
progress:  28%|[34m       [0m| 138/500 [08:55<22:51,  3.79s/it]progress:  28%|[34m       [0m| 139/500 [08:55<22:59,  3.82s/it]                                                           Episode 140	 reward: -13.39	 makespan: 1325.95	 Mean_loss: 0.27389762,  training time: 3.81
progress:  28%|[34m       [0m| 139/500 [08:59<22:59,  3.82s/it]progress:  28%|[34m       [0m| 140/500 [08:59<22:54,  3.82s/it]                                                           Episode 141	 reward: -13.04	 makespan: 1291.45	 Mean_loss: 0.23760472,  training time: 3.93
progress:  28%|[34m       [0m| 140/500 [09:03<22:54,  3.82s/it]progress:  28%|[34m       [0m| 141/500 [09:03<23:02,  3.85s/it]                                                           Episode 142	 reward: -13.03	 makespan: 1290.30	 Mean_loss: 0.24754913,  training time: 3.83
progress:  28%|[34m       [0m| 141/500 [09:07<23:02,  3.85s/it]progress:  28%|[34m       [0m| 142/500 [09:07<22:55,  3.84s/it]                                                           Episode 143	 reward: -12.84	 makespan: 1270.85	 Mean_loss: 0.24613814,  training time: 3.84
progress:  28%|[34m       [0m| 142/500 [09:11<22:55,  3.84s/it]progress:  29%|[34m       [0m| 143/500 [09:11<22:51,  3.84s/it]                                                           Episode 144	 reward: -13.05	 makespan: 1292.10	 Mean_loss: 0.24940914,  training time: 3.76
progress:  29%|[34m       [0m| 143/500 [09:15<22:51,  3.84s/it]progress:  29%|[34m       [0m| 144/500 [09:15<22:38,  3.82s/it]                                                           Episode 145	 reward: -12.98	 makespan: 1285.40	 Mean_loss: 0.25703424,  training time: 3.76
progress:  29%|[34m       [0m| 144/500 [09:18<22:38,  3.82s/it]progress:  29%|[34m       [0m| 145/500 [09:18<22:28,  3.80s/it]                                                           Episode 146	 reward: -12.94	 makespan: 1281.30	 Mean_loss: 0.24060220,  training time: 3.76
progress:  29%|[34m       [0m| 145/500 [09:22<22:28,  3.80s/it]progress:  29%|[34m       [0m| 146/500 [09:22<22:20,  3.79s/it]                                                           Episode 147	 reward: -13.11	 makespan: 1297.85	 Mean_loss: 0.21505360,  training time: 3.76
progress:  29%|[34m       [0m| 146/500 [09:26<22:20,  3.79s/it]progress:  29%|[34m       [0m| 147/500 [09:26<22:14,  3.78s/it]                                                           Episode 148	 reward: -12.98	 makespan: 1284.75	 Mean_loss: 0.21393387,  training time: 3.76
progress:  29%|[34m       [0m| 147/500 [09:30<22:14,  3.78s/it]progress:  30%|[34m       [0m| 148/500 [09:30<22:08,  3.77s/it]                                                           Episode 149	 reward: -13.16	 makespan: 1302.95	 Mean_loss: 0.26019901,  training time: 3.94
progress:  30%|[34m       [0m| 148/500 [09:34<22:08,  3.77s/it]progress:  30%|[34m       [0m| 149/500 [09:34<22:22,  3.82s/it]                                                           Episode 150	 reward: -12.82	 makespan: 1269.30	 Mean_loss: 0.25073603,  training time: 3.92
progress:  30%|[34m       [0m| 149/500 [09:37<22:22,  3.82s/it]progress:  30%|[34m       [0m| 150/500 [09:37<22:28,  3.85s/it]                                                           Episode 151	 reward: -12.88	 makespan: 1274.65	 Mean_loss: 0.22945687,  training time: 3.83
progress:  30%|[34m       [0m| 150/500 [09:41<22:28,  3.85s/it]progress:  30%|[34m       [0m| 151/500 [09:41<22:22,  3.85s/it]                                                           Episode 152	 reward: -12.86	 makespan: 1273.55	 Mean_loss: 0.22746789,  training time: 3.87
progress:  30%|[34m       [0m| 151/500 [09:45<22:22,  3.85s/it]progress:  30%|[34m       [0m| 152/500 [09:45<22:21,  3.85s/it]                                                           Episode 153	 reward: -12.82	 makespan: 1269.05	 Mean_loss: 0.22606160,  training time: 3.91
progress:  30%|[34m       [0m| 152/500 [09:49<22:21,  3.85s/it]progress:  31%|[34m       [0m| 153/500 [09:49<22:23,  3.87s/it]                                                           Episode 154	 reward: -12.87	 makespan: 1274.20	 Mean_loss: 0.27193227,  training time: 3.84
progress:  31%|[34m       [0m| 153/500 [09:53<22:23,  3.87s/it]progress:  31%|[34m       [0m| 154/500 [09:53<22:16,  3.86s/it]                                                           Episode 155	 reward: -12.83	 makespan: 1269.75	 Mean_loss: 0.20724240,  training time: 3.76
progress:  31%|[34m       [0m| 154/500 [09:57<22:16,  3.86s/it]progress:  31%|[34m       [0m| 155/500 [09:57<22:01,  3.83s/it]                                                           Episode 156	 reward: -12.92	 makespan: 1278.75	 Mean_loss: 0.27596626,  training time: 3.80
progress:  31%|[34m       [0m| 155/500 [10:01<22:01,  3.83s/it]progress:  31%|[34m       [0m| 156/500 [10:01<21:54,  3.82s/it]                                                           Episode 157	 reward: -12.80	 makespan: 1266.85	 Mean_loss: 0.23829383,  training time: 3.90
progress:  31%|[34m       [0m| 156/500 [10:04<21:54,  3.82s/it]progress:  31%|[34m      [0m| 157/500 [10:04<21:58,  3.84s/it]                                                           Episode 158	 reward: -12.89	 makespan: 1276.45	 Mean_loss: 0.20697102,  training time: 3.78
progress:  31%|[34m      [0m| 157/500 [10:08<21:58,  3.84s/it]progress:  32%|[34m      [0m| 158/500 [10:08<21:48,  3.83s/it]                                                           Episode 159	 reward: -12.80	 makespan: 1267.10	 Mean_loss: 0.19545639,  training time: 3.84
progress:  32%|[34m      [0m| 158/500 [10:12<21:48,  3.83s/it]progress:  32%|[34m      [0m| 159/500 [10:12<21:45,  3.83s/it]                                                           Episode 160	 reward: -12.86	 makespan: 1272.80	 Mean_loss: 0.20004500,  training time: 3.85
progress:  32%|[34m      [0m| 159/500 [10:16<21:45,  3.83s/it]progress:  32%|[34m      [0m| 160/500 [10:16<21:44,  3.84s/it]                                                           Episode 161	 reward: -12.92	 makespan: 1278.80	 Mean_loss: 0.26259133,  training time: 4.19
progress:  32%|[34m      [0m| 160/500 [10:20<21:44,  3.84s/it]progress:  32%|[34m      [0m| 161/500 [10:20<22:16,  3.94s/it]                                                           Episode 162	 reward: -12.98	 makespan: 1284.90	 Mean_loss: 0.37331694,  training time: 3.78
progress:  32%|[34m      [0m| 161/500 [10:24<22:16,  3.94s/it]progress:  32%|[34m      [0m| 162/500 [10:24<21:56,  3.89s/it]                                                           Episode 163	 reward: -12.93	 makespan: 1280.35	 Mean_loss: 0.30871713,  training time: 3.95
progress:  32%|[34m      [0m| 162/500 [10:28<21:56,  3.89s/it]progress:  33%|[34m      [0m| 163/500 [10:28<21:58,  3.91s/it]                                                           Episode 164	 reward: -12.90	 makespan: 1277.10	 Mean_loss: 0.27800223,  training time: 3.81
progress:  33%|[34m      [0m| 163/500 [10:32<21:58,  3.91s/it]progress:  33%|[34m      [0m| 164/500 [10:32<21:44,  3.88s/it]                                                           Episode 165	 reward: -12.88	 makespan: 1274.90	 Mean_loss: 0.25734428,  training time: 3.82
progress:  33%|[34m      [0m| 164/500 [10:35<21:44,  3.88s/it]progress:  33%|[34m      [0m| 165/500 [10:35<21:34,  3.86s/it]                                                           Episode 166	 reward: -13.00	 makespan: 1287.40	 Mean_loss: 0.32294276,  training time: 3.89
progress:  33%|[34m      [0m| 165/500 [10:39<21:34,  3.86s/it]progress:  33%|[34m      [0m| 166/500 [10:39<21:33,  3.87s/it]                                                           Episode 167	 reward: -13.12	 makespan: 1298.40	 Mean_loss: 0.28224584,  training time: 3.82
progress:  33%|[34m      [0m| 166/500 [10:43<21:33,  3.87s/it]progress:  33%|[34m      [0m| 167/500 [10:43<21:24,  3.86s/it]                                                           Episode 168	 reward: -12.99	 makespan: 1286.45	 Mean_loss: 0.34275848,  training time: 3.84
progress:  33%|[34m      [0m| 167/500 [10:47<21:24,  3.86s/it]progress:  34%|[34m      [0m| 168/500 [10:47<21:18,  3.85s/it]                                                           Episode 169	 reward: -12.97	 makespan: 1284.35	 Mean_loss: 0.27661893,  training time: 3.90
progress:  34%|[34m      [0m| 168/500 [10:51<21:18,  3.85s/it]progress:  34%|[34m      [0m| 169/500 [10:51<21:19,  3.87s/it]                                                           Episode 170	 reward: -13.03	 makespan: 1289.85	 Mean_loss: 0.30811346,  training time: 3.79
progress:  34%|[34m      [0m| 169/500 [10:55<21:19,  3.87s/it]progress:  34%|[34m      [0m| 170/500 [10:55<21:08,  3.84s/it]                                                           Episode 171	 reward: -12.84	 makespan: 1270.75	 Mean_loss: 0.28224853,  training time: 3.80
progress:  34%|[34m      [0m| 170/500 [10:58<21:08,  3.84s/it]progress:  34%|[34m      [0m| 171/500 [10:58<20:59,  3.83s/it]                                                           Episode 172	 reward: -12.93	 makespan: 1280.05	 Mean_loss: 0.30282152,  training time: 4.08
progress:  34%|[34m      [0m| 171/500 [11:03<20:59,  3.83s/it]progress:  34%|[34m      [0m| 172/500 [11:03<21:20,  3.90s/it]                                                           Episode 173	 reward: -13.02	 makespan: 1289.00	 Mean_loss: 0.32861713,  training time: 3.86
progress:  34%|[34m      [0m| 172/500 [11:06<21:20,  3.90s/it]progress:  35%|[34m      [0m| 173/500 [11:06<21:12,  3.89s/it]                                                           Episode 174	 reward: -13.06	 makespan: 1293.20	 Mean_loss: 0.34816074,  training time: 3.80
progress:  35%|[34m      [0m| 173/500 [11:10<21:12,  3.89s/it]progress:  35%|[34m      [0m| 174/500 [11:10<20:59,  3.86s/it]                                                           Episode 175	 reward: -12.83	 makespan: 1270.60	 Mean_loss: 0.26057941,  training time: 3.83
progress:  35%|[34m      [0m| 174/500 [11:14<20:59,  3.86s/it]progress:  35%|[34m      [0m| 175/500 [11:14<20:52,  3.85s/it]                                                           Episode 176	 reward: -12.93	 makespan: 1279.70	 Mean_loss: 0.23975046,  training time: 3.81
progress:  35%|[34m      [0m| 175/500 [11:18<20:52,  3.85s/it]progress:  35%|[34m      [0m| 176/500 [11:18<20:44,  3.84s/it]                                                           Episode 177	 reward: -12.89	 makespan: 1276.35	 Mean_loss: 0.28380233,  training time: 3.82
progress:  35%|[34m      [0m| 176/500 [11:22<20:44,  3.84s/it]progress:  35%|[34m      [0m| 177/500 [11:22<20:38,  3.84s/it]                                                           Episode 178	 reward: -13.03	 makespan: 1290.15	 Mean_loss: 0.25735101,  training time: 4.12
progress:  35%|[34m      [0m| 177/500 [11:26<20:38,  3.84s/it]progress:  36%|[34m      [0m| 178/500 [11:26<21:02,  3.92s/it]                                                           Episode 179	 reward: -13.02	 makespan: 1288.65	 Mean_loss: 0.30233619,  training time: 3.87
progress:  36%|[34m      [0m| 178/500 [11:30<21:02,  3.92s/it]progress:  36%|[34m      [0m| 179/500 [11:30<20:53,  3.90s/it]                                                           Episode 180	 reward: -13.08	 makespan: 1295.30	 Mean_loss: 0.26860657,  training time: 4.09
progress:  36%|[34m      [0m| 179/500 [11:34<20:53,  3.90s/it]progress:  36%|[34m      [0m| 180/500 [11:34<21:07,  3.96s/it]                                                           Episode 181	 reward: -13.29	 makespan: 1315.45	 Mean_loss: 0.23143224,  training time: 3.86
progress:  36%|[34m      [0m| 180/500 [11:38<21:07,  3.96s/it]progress:  36%|[34m      [0m| 181/500 [11:38<20:54,  3.93s/it]                                                           Episode 182	 reward: -13.36	 makespan: 1322.90	 Mean_loss: 0.26878968,  training time: 3.78
progress:  36%|[34m      [0m| 181/500 [11:41<20:54,  3.93s/it]progress:  36%|[34m      [0m| 182/500 [11:41<20:35,  3.89s/it]                                                           Episode 183	 reward: -13.31	 makespan: 1317.70	 Mean_loss: 0.24833298,  training time: 3.77
progress:  36%|[34m      [0m| 182/500 [11:45<20:35,  3.89s/it]progress:  37%|[34m      [0m| 183/500 [11:45<20:20,  3.85s/it]                                                           Episode 184	 reward: -13.21	 makespan: 1307.90	 Mean_loss: 0.26317421,  training time: 3.95
progress:  37%|[34m      [0m| 183/500 [11:49<20:20,  3.85s/it]progress:  37%|[34m      [0m| 184/500 [11:49<20:26,  3.88s/it]                                                           Episode 185	 reward: -13.13	 makespan: 1299.65	 Mean_loss: 0.23088184,  training time: 3.78
progress:  37%|[34m      [0m| 184/500 [11:53<20:26,  3.88s/it]progress:  37%|[34m      [0m| 185/500 [11:53<20:13,  3.85s/it]                                                           Episode 186	 reward: -13.12	 makespan: 1299.20	 Mean_loss: 0.20878147,  training time: 3.93
progress:  37%|[34m      [0m| 185/500 [11:57<20:13,  3.85s/it]progress:  37%|[34m      [0m| 186/500 [11:57<20:16,  3.87s/it]                                                           Episode 187	 reward: -13.17	 makespan: 1303.65	 Mean_loss: 0.26934594,  training time: 3.77
progress:  37%|[34m      [0m| 186/500 [12:01<20:16,  3.87s/it]progress:  37%|[34m      [0m| 187/500 [12:01<20:02,  3.84s/it]                                                           Episode 188	 reward: -13.24	 makespan: 1311.05	 Mean_loss: 0.22527751,  training time: 3.75
progress:  37%|[34m      [0m| 187/500 [12:04<20:02,  3.84s/it]progress:  38%|[34m      [0m| 188/500 [12:04<19:50,  3.81s/it]                                                           Episode 189	 reward: -13.17	 makespan: 1303.70	 Mean_loss: 0.21614172,  training time: 3.77
progress:  38%|[34m      [0m| 188/500 [12:08<19:50,  3.81s/it]progress:  38%|[34m      [0m| 189/500 [12:08<19:42,  3.80s/it]                                                           Episode 190	 reward: -13.17	 makespan: 1303.55	 Mean_loss: 0.19880262,  training time: 3.97
progress:  38%|[34m      [0m| 189/500 [12:12<19:42,  3.80s/it]progress:  38%|[34m      [0m| 190/500 [12:12<19:54,  3.85s/it]                                                           Episode 191	 reward: -13.25	 makespan: 1311.60	 Mean_loss: 0.22467181,  training time: 4.20
progress:  38%|[34m      [0m| 190/500 [12:16<19:54,  3.85s/it]progress:  38%|[34m      [0m| 191/500 [12:16<20:22,  3.96s/it]                                                           Episode 192	 reward: -13.34	 makespan: 1320.55	 Mean_loss: 0.21027875,  training time: 3.75
progress:  38%|[34m      [0m| 191/500 [12:20<20:22,  3.96s/it]progress:  38%|[34m      [0m| 192/500 [12:20<20:00,  3.90s/it]                                                           Episode 193	 reward: -13.20	 makespan: 1306.45	 Mean_loss: 0.19010232,  training time: 3.94
progress:  38%|[34m      [0m| 192/500 [12:24<20:00,  3.90s/it]progress:  39%|[34m      [0m| 193/500 [12:24<20:00,  3.91s/it]                                                           Episode 194	 reward: -13.17	 makespan: 1303.80	 Mean_loss: 0.21257815,  training time: 4.01
progress:  39%|[34m      [0m| 193/500 [12:28<20:00,  3.91s/it]progress:  39%|[34m      [0m| 194/500 [12:28<20:05,  3.94s/it]                                                           Episode 195	 reward: -13.14	 makespan: 1300.80	 Mean_loss: 0.18687165,  training time: 4.00
progress:  39%|[34m      [0m| 194/500 [12:32<20:05,  3.94s/it]progress:  39%|[34m      [0m| 195/500 [12:32<20:07,  3.96s/it]                                                           Episode 196	 reward: -13.14	 makespan: 1300.60	 Mean_loss: 0.16079357,  training time: 3.79
progress:  39%|[34m      [0m| 195/500 [12:36<20:07,  3.96s/it]progress:  39%|[34m      [0m| 196/500 [12:36<19:47,  3.91s/it]                                                           Episode 197	 reward: -13.19	 makespan: 1305.75	 Mean_loss: 0.22787696,  training time: 3.79
progress:  39%|[34m      [0m| 196/500 [12:40<19:47,  3.91s/it]progress:  39%|[34m      [0m| 197/500 [12:40<19:33,  3.87s/it]                                                           Episode 198	 reward: -13.27	 makespan: 1313.55	 Mean_loss: 0.21240729,  training time: 3.78
progress:  39%|[34m      [0m| 197/500 [12:43<19:33,  3.87s/it]progress:  40%|[34m      [0m| 198/500 [12:43<19:21,  3.85s/it]                                                           Episode 199	 reward: -13.11	 makespan: 1297.90	 Mean_loss: 0.23989217,  training time: 3.82
progress:  40%|[34m      [0m| 198/500 [12:47<19:21,  3.85s/it]progress:  40%|[34m      [0m| 199/500 [12:47<19:14,  3.84s/it]                                                           Episode 200	 reward: -13.21	 makespan: 1308.00	 Mean_loss: 0.22497605,  training time: 3.78
progress:  40%|[34m      [0m| 199/500 [12:51<19:14,  3.84s/it]progress:  40%|[34m      [0m| 200/500 [12:51<19:05,  3.82s/it]                                                           Episode 201	 reward: -12.86	 makespan: 1273.30	 Mean_loss: 0.19962686,  training time: 3.88
progress:  40%|[34m      [0m| 200/500 [12:55<19:05,  3.82s/it]progress:  40%|[34m      [0m| 201/500 [12:55<19:07,  3.84s/it]                                                           Episode 202	 reward: -12.71	 makespan: 1258.70	 Mean_loss: 0.18967120,  training time: 3.97
progress:  40%|[34m      [0m| 201/500 [12:59<19:07,  3.84s/it]progress:  40%|[34m      [0m| 202/500 [12:59<19:15,  3.88s/it]                                                           Episode 203	 reward: -12.91	 makespan: 1277.95	 Mean_loss: 0.20062336,  training time: 3.77
progress:  40%|[34m      [0m| 202/500 [13:03<19:15,  3.88s/it]progress:  41%|[34m      [0m| 203/500 [13:03<19:02,  3.85s/it]                                                           Episode 204	 reward: -12.81	 makespan: 1267.90	 Mean_loss: 0.17138502,  training time: 3.89
progress:  41%|[34m      [0m| 203/500 [13:06<19:02,  3.85s/it]progress:  41%|[34m      [0m| 204/500 [13:06<19:02,  3.86s/it]                                                           Episode 205	 reward: -12.80	 makespan: 1267.50	 Mean_loss: 0.19495519,  training time: 3.79
progress:  41%|[34m      [0m| 204/500 [13:10<19:02,  3.86s/it]progress:  41%|[34m      [0m| 205/500 [13:10<18:52,  3.84s/it]                                                           Episode 206	 reward: -12.84	 makespan: 1270.80	 Mean_loss: 0.17037719,  training time: 3.85
progress:  41%|[34m      [0m| 205/500 [13:14<18:52,  3.84s/it]progress:  41%|[34m      [0m| 206/500 [13:14<18:49,  3.84s/it]                                                           Episode 207	 reward: -12.92	 makespan: 1278.90	 Mean_loss: 0.16657518,  training time: 3.84
progress:  41%|[34m      [0m| 206/500 [13:18<18:49,  3.84s/it]progress:  41%|[34m     [0m| 207/500 [13:18<18:45,  3.84s/it]                                                           Episode 208	 reward: -12.93	 makespan: 1280.25	 Mean_loss: 0.19629927,  training time: 3.78
progress:  41%|[34m     [0m| 207/500 [13:22<18:45,  3.84s/it]progress:  42%|[34m     [0m| 208/500 [13:22<18:36,  3.82s/it]                                                           Episode 209	 reward: -12.76	 makespan: 1263.35	 Mean_loss: 0.17261192,  training time: 3.87
progress:  42%|[34m     [0m| 208/500 [13:26<18:36,  3.82s/it]progress:  42%|[34m     [0m| 209/500 [13:26<18:37,  3.84s/it]                                                           Episode 210	 reward: -12.85	 makespan: 1271.95	 Mean_loss: 0.18127808,  training time: 3.92
progress:  42%|[34m     [0m| 209/500 [13:30<18:37,  3.84s/it]progress:  42%|[34m     [0m| 210/500 [13:30<18:40,  3.86s/it]                                                           Episode 211	 reward: -12.86	 makespan: 1272.80	 Mean_loss: 0.21450229,  training time: 3.81
progress:  42%|[34m     [0m| 210/500 [13:33<18:40,  3.86s/it]progress:  42%|[34m     [0m| 211/500 [13:33<18:31,  3.85s/it]                                                           Episode 212	 reward: -12.66	 makespan: 1253.35	 Mean_loss: 0.18136965,  training time: 3.75
progress:  42%|[34m     [0m| 211/500 [13:37<18:31,  3.85s/it]progress:  42%|[34m     [0m| 212/500 [13:37<18:20,  3.82s/it]                                                           Episode 213	 reward: -12.81	 makespan: 1268.55	 Mean_loss: 0.24057965,  training time: 4.02
progress:  42%|[34m     [0m| 212/500 [13:41<18:20,  3.82s/it]progress:  43%|[34m     [0m| 213/500 [13:41<18:33,  3.88s/it]                                                           Episode 214	 reward: -12.82	 makespan: 1269.00	 Mean_loss: 0.13546243,  training time: 3.91
progress:  43%|[34m     [0m| 213/500 [13:45<18:33,  3.88s/it]progress:  43%|[34m     [0m| 214/500 [13:45<18:32,  3.89s/it]                                                           Episode 215	 reward: -12.83	 makespan: 1269.95	 Mean_loss: 0.17981389,  training time: 3.96
progress:  43%|[34m     [0m| 214/500 [13:49<18:32,  3.89s/it]progress:  43%|[34m     [0m| 215/500 [13:49<18:34,  3.91s/it]                                                           Episode 216	 reward: -12.80	 makespan: 1267.65	 Mean_loss: 0.14983177,  training time: 3.90
progress:  43%|[34m     [0m| 215/500 [13:53<18:34,  3.91s/it]progress:  43%|[34m     [0m| 216/500 [13:53<18:29,  3.91s/it]                                                           Episode 217	 reward: -12.85	 makespan: 1271.80	 Mean_loss: 0.18690969,  training time: 4.01
progress:  43%|[34m     [0m| 216/500 [13:57<18:29,  3.91s/it]progress:  43%|[34m     [0m| 217/500 [13:57<18:34,  3.94s/it]                                                           Episode 218	 reward: -12.97	 makespan: 1283.70	 Mean_loss: 0.18484214,  training time: 3.94
progress:  43%|[34m     [0m| 217/500 [14:01<18:34,  3.94s/it]progress:  44%|[34m     [0m| 218/500 [14:01<18:31,  3.94s/it]                                                           Episode 219	 reward: -12.84	 makespan: 1271.55	 Mean_loss: 0.19469310,  training time: 3.84
progress:  44%|[34m     [0m| 218/500 [14:05<18:31,  3.94s/it]progress:  44%|[34m     [0m| 219/500 [14:05<18:18,  3.91s/it]                                                           Episode 220	 reward: -13.01	 makespan: 1288.45	 Mean_loss: 0.20633091,  training time: 4.03
progress:  44%|[34m     [0m| 219/500 [14:09<18:18,  3.91s/it]progress:  44%|[34m     [0m| 220/500 [14:09<18:24,  3.95s/it]                                                           Episode 221	 reward: -12.95	 makespan: 1281.80	 Mean_loss: 0.18612444,  training time: 3.86
progress:  44%|[34m     [0m| 220/500 [14:13<18:24,  3.95s/it]progress:  44%|[34m     [0m| 221/500 [14:13<18:13,  3.92s/it]                                                           Episode 222	 reward: -12.99	 makespan: 1286.30	 Mean_loss: 0.20328586,  training time: 3.79
progress:  44%|[34m     [0m| 221/500 [14:16<18:13,  3.92s/it]progress:  44%|[34m     [0m| 222/500 [14:16<17:58,  3.88s/it]                                                           Episode 223	 reward: -12.86	 makespan: 1273.15	 Mean_loss: 0.16110539,  training time: 3.78
progress:  44%|[34m     [0m| 222/500 [14:20<17:58,  3.88s/it]progress:  45%|[34m     [0m| 223/500 [14:20<17:46,  3.85s/it]                                                           Episode 224	 reward: -12.90	 makespan: 1277.35	 Mean_loss: 0.21838482,  training time: 3.78
progress:  45%|[34m     [0m| 223/500 [14:24<17:46,  3.85s/it]progress:  45%|[34m     [0m| 224/500 [14:24<17:37,  3.83s/it]                                                           Episode 225	 reward: -12.78	 makespan: 1265.10	 Mean_loss: 0.15581460,  training time: 3.76
progress:  45%|[34m     [0m| 224/500 [14:28<17:37,  3.83s/it]progress:  45%|[34m     [0m| 225/500 [14:28<17:27,  3.81s/it]                                                           Episode 226	 reward: -12.70	 makespan: 1257.55	 Mean_loss: 0.18314770,  training time: 3.91
progress:  45%|[34m     [0m| 225/500 [14:32<17:27,  3.81s/it]progress:  45%|[34m     [0m| 226/500 [14:32<17:32,  3.84s/it]                                                           Episode 227	 reward: -12.74	 makespan: 1260.85	 Mean_loss: 0.16000107,  training time: 3.91
progress:  45%|[34m     [0m| 226/500 [14:36<17:32,  3.84s/it]progress:  45%|[34m     [0m| 227/500 [14:36<17:34,  3.86s/it]                                                           Episode 228	 reward: -12.73	 makespan: 1260.45	 Mean_loss: 0.16078557,  training time: 3.91
progress:  45%|[34m     [0m| 227/500 [14:39<17:34,  3.86s/it]progress:  46%|[34m     [0m| 228/500 [14:39<17:34,  3.88s/it]                                                           Episode 229	 reward: -12.82	 makespan: 1269.65	 Mean_loss: 0.15759134,  training time: 3.78
progress:  46%|[34m     [0m| 228/500 [14:43<17:34,  3.88s/it]progress:  46%|[34m     [0m| 229/500 [14:43<17:22,  3.85s/it]                                                           Episode 230	 reward: -12.78	 makespan: 1265.05	 Mean_loss: 0.16384636,  training time: 3.79
progress:  46%|[34m     [0m| 229/500 [14:47<17:22,  3.85s/it]progress:  46%|[34m     [0m| 230/500 [14:47<17:13,  3.83s/it]                                                           Episode 231	 reward: -12.87	 makespan: 1274.20	 Mean_loss: 0.15476982,  training time: 3.87
progress:  46%|[34m     [0m| 230/500 [14:51<17:13,  3.83s/it]progress:  46%|[34m     [0m| 231/500 [14:51<17:13,  3.84s/it]                                                           Episode 232	 reward: -12.67	 makespan: 1254.80	 Mean_loss: 0.14404222,  training time: 3.88
progress:  46%|[34m     [0m| 231/500 [14:55<17:13,  3.84s/it]progress:  46%|[34m     [0m| 232/500 [14:55<17:12,  3.85s/it]                                                           Episode 233	 reward: -12.79	 makespan: 1266.55	 Mean_loss: 0.17656773,  training time: 3.94
progress:  46%|[34m     [0m| 232/500 [14:59<17:12,  3.85s/it]progress:  47%|[34m     [0m| 233/500 [14:59<17:15,  3.88s/it]                                                           Episode 234	 reward: -12.75	 makespan: 1262.65	 Mean_loss: 0.17453045,  training time: 4.07
progress:  47%|[34m     [0m| 233/500 [15:03<17:15,  3.88s/it]progress:  47%|[34m     [0m| 234/500 [15:03<17:27,  3.94s/it]                                                           Episode 235	 reward: -12.79	 makespan: 1266.65	 Mean_loss: 0.20814379,  training time: 3.77
progress:  47%|[34m     [0m| 234/500 [15:07<17:27,  3.94s/it]progress:  47%|[34m     [0m| 235/500 [15:07<17:10,  3.89s/it]                                                           Episode 236	 reward: -12.75	 makespan: 1261.80	 Mean_loss: 0.14880162,  training time: 3.78
progress:  47%|[34m     [0m| 235/500 [15:10<17:10,  3.89s/it]progress:  47%|[34m     [0m| 236/500 [15:10<16:58,  3.86s/it]                                                           Episode 237	 reward: -12.77	 makespan: 1264.10	 Mean_loss: 0.17873371,  training time: 3.76
progress:  47%|[34m     [0m| 236/500 [15:14<16:58,  3.86s/it]progress:  47%|[34m     [0m| 237/500 [15:14<16:46,  3.83s/it]                                                           Episode 238	 reward: -12.81	 makespan: 1268.10	 Mean_loss: 0.16633482,  training time: 3.85
progress:  47%|[34m     [0m| 237/500 [15:18<16:46,  3.83s/it]progress:  48%|[34m     [0m| 238/500 [15:18<16:44,  3.83s/it]                                                           Episode 239	 reward: -12.79	 makespan: 1266.55	 Mean_loss: 0.15759808,  training time: 4.03
progress:  48%|[34m     [0m| 238/500 [15:22<16:44,  3.83s/it]progress:  48%|[34m     [0m| 239/500 [15:22<16:56,  3.89s/it]                                                           Episode 240	 reward: -12.72	 makespan: 1259.25	 Mean_loss: 0.12692004,  training time: 3.95
progress:  48%|[34m     [0m| 239/500 [15:26<16:56,  3.89s/it]progress:  48%|[34m     [0m| 240/500 [15:26<16:56,  3.91s/it]                                                           Episode 241	 reward: -12.60	 makespan: 1246.95	 Mean_loss: 0.15775326,  training time: 3.87
progress:  48%|[34m     [0m| 240/500 [15:30<16:56,  3.91s/it]progress:  48%|[34m     [0m| 241/500 [15:30<16:49,  3.90s/it]                                                           Episode 242	 reward: -12.69	 makespan: 1256.45	 Mean_loss: 0.16131049,  training time: 3.90
progress:  48%|[34m     [0m| 241/500 [15:34<16:49,  3.90s/it]progress:  48%|[34m     [0m| 242/500 [15:34<16:45,  3.90s/it]                                                           Episode 243	 reward: -12.60	 makespan: 1247.50	 Mean_loss: 0.14672644,  training time: 4.08
progress:  48%|[34m     [0m| 242/500 [15:38<16:45,  3.90s/it]progress:  49%|[34m     [0m| 243/500 [15:38<16:55,  3.95s/it]                                                           Episode 244	 reward: -12.53	 makespan: 1240.35	 Mean_loss: 0.16207448,  training time: 4.35
progress:  49%|[34m     [0m| 243/500 [15:42<16:55,  3.95s/it]progress:  49%|[34m     [0m| 244/500 [15:42<17:22,  4.07s/it]                                                           Episode 245	 reward: -12.43	 makespan: 1230.30	 Mean_loss: 0.13558851,  training time: 3.82
progress:  49%|[34m     [0m| 244/500 [15:46<17:22,  4.07s/it]progress:  49%|[34m     [0m| 245/500 [15:46<16:59,  4.00s/it]                                                           Episode 246	 reward: -12.59	 makespan: 1246.70	 Mean_loss: 0.13198200,  training time: 3.79
progress:  49%|[34m     [0m| 245/500 [15:50<16:59,  4.00s/it]progress:  49%|[34m     [0m| 246/500 [15:50<16:40,  3.94s/it]                                                           Episode 247	 reward: -12.58	 makespan: 1245.20	 Mean_loss: 0.16795594,  training time: 3.96
progress:  49%|[34m     [0m| 246/500 [15:54<16:40,  3.94s/it]progress:  49%|[34m     [0m| 247/500 [15:54<16:38,  3.95s/it]                                                           Episode 248	 reward: -12.43	 makespan: 1230.95	 Mean_loss: 0.13754924,  training time: 3.78
progress:  49%|[34m     [0m| 247/500 [15:57<16:38,  3.95s/it]progress:  50%|[34m     [0m| 248/500 [15:57<16:21,  3.90s/it]                                                           Episode 249	 reward: -12.46	 makespan: 1233.70	 Mean_loss: 0.12266532,  training time: 4.97
progress:  50%|[34m     [0m| 248/500 [16:02<16:21,  3.90s/it]progress:  50%|[34m     [0m| 249/500 [16:02<17:39,  4.22s/it]                                                           Episode 250	 reward: -12.59	 makespan: 1246.90	 Mean_loss: 0.11983967,  training time: 3.87
progress:  50%|[34m     [0m| 249/500 [16:06<17:39,  4.22s/it]progress:  50%|[34m     [0m| 250/500 [16:06<17:08,  4.11s/it]                                                           Episode 251	 reward: -12.49	 makespan: 1236.70	 Mean_loss: 0.12755555,  training time: 3.84
progress:  50%|[34m     [0m| 250/500 [16:10<17:08,  4.11s/it]progress:  50%|[34m     [0m| 251/500 [16:10<16:43,  4.03s/it]                                                           Episode 252	 reward: -12.68	 makespan: 1254.85	 Mean_loss: 0.13714206,  training time: 3.85
progress:  50%|[34m     [0m| 251/500 [16:14<16:43,  4.03s/it]progress:  50%|[34m     [0m| 252/500 [16:14<16:26,  3.98s/it]                                                           Episode 253	 reward: -12.59	 makespan: 1246.05	 Mean_loss: 0.12680750,  training time: 3.74
progress:  50%|[34m     [0m| 252/500 [16:18<16:26,  3.98s/it]progress:  51%|[34m     [0m| 253/500 [16:18<16:05,  3.91s/it]                                                           Episode 254	 reward: -12.44	 makespan: 1231.80	 Mean_loss: 0.19295239,  training time: 3.83
progress:  51%|[34m     [0m| 253/500 [16:22<16:05,  3.91s/it]progress:  51%|[34m     [0m| 254/500 [16:22<15:55,  3.89s/it]                                                           Episode 255	 reward: -12.23	 makespan: 1210.50	 Mean_loss: 0.13292821,  training time: 3.73
progress:  51%|[34m     [0m| 254/500 [16:25<15:55,  3.89s/it]progress:  51%|[34m     [0m| 255/500 [16:25<15:40,  3.84s/it]                                                           Episode 256	 reward: -12.53	 makespan: 1240.85	 Mean_loss: 0.17356358,  training time: 4.15
progress:  51%|[34m     [0m| 255/500 [16:29<15:40,  3.84s/it]progress:  51%|[34m     [0m| 256/500 [16:29<15:59,  3.93s/it]                                                           Episode 257	 reward: -12.51	 makespan: 1238.25	 Mean_loss: 0.13168471,  training time: 3.83
progress:  51%|[34m     [0m| 256/500 [16:33<15:59,  3.93s/it]progress:  51%|[34m    [0m| 257/500 [16:33<15:48,  3.90s/it]                                                           Episode 258	 reward: -12.48	 makespan: 1235.25	 Mean_loss: 0.13637693,  training time: 3.84
progress:  51%|[34m    [0m| 257/500 [16:37<15:48,  3.90s/it]progress:  52%|[34m    [0m| 258/500 [16:37<15:39,  3.88s/it]                                                           Episode 259	 reward: -12.41	 makespan: 1229.00	 Mean_loss: 0.11700483,  training time: 4.14
progress:  52%|[34m    [0m| 258/500 [16:41<15:39,  3.88s/it]progress:  52%|[34m    [0m| 259/500 [16:41<15:54,  3.96s/it]                                                           Episode 260	 reward: -12.55	 makespan: 1242.35	 Mean_loss: 0.12184738,  training time: 3.97
progress:  52%|[34m    [0m| 259/500 [16:45<15:54,  3.96s/it]progress:  52%|[34m    [0m| 260/500 [16:45<15:51,  3.96s/it]                                                           Episode 261	 reward: -12.82	 makespan: 1269.00	 Mean_loss: 0.27195859,  training time: 3.84
progress:  52%|[34m    [0m| 260/500 [16:49<15:51,  3.96s/it]progress:  52%|[34m    [0m| 261/500 [16:49<15:38,  3.93s/it]                                                           Episode 262	 reward: -12.79	 makespan: 1266.65	 Mean_loss: 0.23945245,  training time: 4.12
progress:  52%|[34m    [0m| 261/500 [16:53<15:38,  3.93s/it]progress:  52%|[34m    [0m| 262/500 [16:53<15:48,  3.99s/it]                                                           Episode 263	 reward: -12.69	 makespan: 1256.30	 Mean_loss: 0.19281459,  training time: 3.91
progress:  52%|[34m    [0m| 262/500 [16:57<15:48,  3.99s/it]progress:  53%|[34m    [0m| 263/500 [16:57<15:39,  3.96s/it]                                                           Episode 264	 reward: -12.71	 makespan: 1258.05	 Mean_loss: 0.18542811,  training time: 3.73
progress:  53%|[34m    [0m| 263/500 [17:01<15:39,  3.96s/it]progress:  53%|[34m    [0m| 264/500 [17:01<15:18,  3.89s/it]                                                           Episode 265	 reward: -12.93	 makespan: 1280.40	 Mean_loss: 0.26434103,  training time: 3.73
progress:  53%|[34m    [0m| 264/500 [17:05<15:18,  3.89s/it]progress:  53%|[34m    [0m| 265/500 [17:05<15:03,  3.85s/it]                                                           Episode 266	 reward: -12.99	 makespan: 1285.90	 Mean_loss: 0.28857100,  training time: 3.71
progress:  53%|[34m    [0m| 265/500 [17:08<15:03,  3.85s/it]progress:  53%|[34m    [0m| 266/500 [17:08<14:50,  3.81s/it]                                                           Episode 267	 reward: -12.72	 makespan: 1259.40	 Mean_loss: 0.21096633,  training time: 4.86
progress:  53%|[34m    [0m| 266/500 [17:13<14:50,  3.81s/it]progress:  53%|[34m    [0m| 267/500 [17:13<16:00,  4.12s/it]                                                           Episode 268	 reward: -12.73	 makespan: 1260.55	 Mean_loss: 0.25910231,  training time: 3.72
progress:  53%|[34m    [0m| 267/500 [17:17<16:00,  4.12s/it]progress:  54%|[34m    [0m| 268/500 [17:17<15:28,  4.00s/it]                                                           Episode 269	 reward: -12.69	 makespan: 1256.05	 Mean_loss: 0.20229682,  training time: 3.78
progress:  54%|[34m    [0m| 268/500 [17:21<15:28,  4.00s/it]progress:  54%|[34m    [0m| 269/500 [17:21<15:09,  3.94s/it]                                                           Episode 270	 reward: -12.85	 makespan: 1272.40	 Mean_loss: 0.21619757,  training time: 3.83
progress:  54%|[34m    [0m| 269/500 [17:24<15:09,  3.94s/it]progress:  54%|[34m    [0m| 270/500 [17:24<14:58,  3.91s/it]                                                           Episode 271	 reward: -12.77	 makespan: 1264.65	 Mean_loss: 0.19049077,  training time: 4.17
progress:  54%|[34m    [0m| 270/500 [17:29<14:58,  3.91s/it]progress:  54%|[34m    [0m| 271/500 [17:29<15:12,  3.99s/it]                                                           Episode 272	 reward: -12.76	 makespan: 1263.50	 Mean_loss: 0.20871046,  training time: 3.94
progress:  54%|[34m    [0m| 271/500 [17:33<15:12,  3.99s/it]progress:  54%|[34m    [0m| 272/500 [17:33<15:05,  3.97s/it]                                                           Episode 273	 reward: -12.88	 makespan: 1275.45	 Mean_loss: 0.22618248,  training time: 3.83
progress:  54%|[34m    [0m| 272/500 [17:36<15:05,  3.97s/it]progress:  55%|[34m    [0m| 273/500 [17:36<14:52,  3.93s/it]                                                           Episode 274	 reward: -12.67	 makespan: 1254.70	 Mean_loss: 0.18449277,  training time: 3.84
progress:  55%|[34m    [0m| 273/500 [17:40<14:52,  3.93s/it]progress:  55%|[34m    [0m| 274/500 [17:40<14:41,  3.90s/it]                                                           Episode 275	 reward: -12.79	 makespan: 1265.95	 Mean_loss: 0.22861756,  training time: 3.83
progress:  55%|[34m    [0m| 274/500 [17:44<14:41,  3.90s/it]progress:  55%|[34m    [0m| 275/500 [17:44<14:33,  3.88s/it]                                                           Episode 276	 reward: -12.77	 makespan: 1264.05	 Mean_loss: 0.23389620,  training time: 4.28
progress:  55%|[34m    [0m| 275/500 [17:48<14:33,  3.88s/it]progress:  55%|[34m    [0m| 276/500 [17:48<14:56,  4.00s/it]                                                           Episode 277	 reward: -12.87	 makespan: 1274.60	 Mean_loss: 0.20551945,  training time: 3.88
progress:  55%|[34m    [0m| 276/500 [17:52<14:56,  4.00s/it]progress:  55%|[34m    [0m| 277/500 [17:52<14:44,  3.96s/it]                                                           Episode 278	 reward: -12.91	 makespan: 1277.80	 Mean_loss: 0.18182464,  training time: 3.79
progress:  55%|[34m    [0m| 277/500 [17:56<14:44,  3.96s/it]progress:  56%|[34m    [0m| 278/500 [17:56<14:28,  3.91s/it]                                                           Episode 279	 reward: -12.77	 makespan: 1264.20	 Mean_loss: 0.21636531,  training time: 3.80
progress:  56%|[34m    [0m| 278/500 [18:00<14:28,  3.91s/it]progress:  56%|[34m    [0m| 279/500 [18:00<14:17,  3.88s/it]                                                           Episode 280	 reward: -12.92	 makespan: 1279.20	 Mean_loss: 0.19961108,  training time: 4.71
progress:  56%|[34m    [0m| 279/500 [18:05<14:17,  3.88s/it]progress:  56%|[34m    [0m| 280/500 [18:05<15:08,  4.13s/it]                                                           Episode 281	 reward: -12.69	 makespan: 1255.90	 Mean_loss: 0.20984966,  training time: 3.91
progress:  56%|[34m    [0m| 280/500 [18:08<15:08,  4.13s/it]progress:  56%|[34m    [0m| 281/500 [18:08<14:50,  4.06s/it]                                                           Episode 282	 reward: -12.64	 makespan: 1251.85	 Mean_loss: 0.17968270,  training time: 5.23
progress:  56%|[34m    [0m| 281/500 [18:14<14:50,  4.06s/it]progress:  56%|[34m    [0m| 282/500 [18:14<16:02,  4.41s/it]                                                           Episode 283	 reward: -12.60	 makespan: 1247.15	 Mean_loss: 0.17826620,  training time: 3.99
progress:  56%|[34m    [0m| 282/500 [18:18<16:02,  4.41s/it]progress:  57%|[34m    [0m| 283/500 [18:18<15:30,  4.29s/it]                                                           Episode 284	 reward: -12.58	 makespan: 1245.75	 Mean_loss: 0.18741512,  training time: 3.90
progress:  57%|[34m    [0m| 283/500 [18:22<15:30,  4.29s/it]progress:  57%|[34m    [0m| 284/500 [18:22<15:00,  4.17s/it]                                                           Episode 285	 reward: -12.56	 makespan: 1243.75	 Mean_loss: 0.19983876,  training time: 4.09
progress:  57%|[34m    [0m| 284/500 [18:26<15:00,  4.17s/it]progress:  57%|[34m    [0m| 285/500 [18:26<14:51,  4.15s/it]                                                           Episode 286	 reward: -12.65	 makespan: 1252.35	 Mean_loss: 0.17877530,  training time: 4.58
progress:  57%|[34m    [0m| 285/500 [18:30<14:51,  4.15s/it]progress:  57%|[34m    [0m| 286/500 [18:30<15:15,  4.28s/it]                                                           Episode 287	 reward: -12.59	 makespan: 1246.75	 Mean_loss: 0.17672798,  training time: 3.71
progress:  57%|[34m    [0m| 286/500 [18:34<15:15,  4.28s/it]progress:  57%|[34m    [0m| 287/500 [18:34<14:34,  4.11s/it]                                                           Episode 288	 reward: -12.58	 makespan: 1245.85	 Mean_loss: 0.16283348,  training time: 3.71
progress:  57%|[34m    [0m| 287/500 [18:38<14:34,  4.11s/it]progress:  58%|[34m    [0m| 288/500 [18:38<14:05,  3.99s/it]                                                           Episode 289	 reward: -12.51	 makespan: 1238.55	 Mean_loss: 0.18048203,  training time: 4.27
progress:  58%|[34m    [0m| 288/500 [18:42<14:05,  3.99s/it]progress:  58%|[34m    [0m| 289/500 [18:42<14:19,  4.07s/it]                                                           Episode 290	 reward: -12.52	 makespan: 1239.70	 Mean_loss: 0.16817267,  training time: 3.79
progress:  58%|[34m    [0m| 289/500 [18:46<14:19,  4.07s/it]progress:  58%|[34m    [0m| 290/500 [18:46<13:57,  3.99s/it]                                                           Episode 291	 reward: -12.53	 makespan: 1240.10	 Mean_loss: 0.16823560,  training time: 3.79
progress:  58%|[34m    [0m| 290/500 [18:50<13:57,  3.99s/it]progress:  58%|[34m    [0m| 291/500 [18:50<13:41,  3.93s/it]                                                           Episode 292	 reward: -12.58	 makespan: 1245.55	 Mean_loss: 0.14159800,  training time: 3.84
progress:  58%|[34m    [0m| 291/500 [18:53<13:41,  3.93s/it]progress:  58%|[34m    [0m| 292/500 [18:53<13:31,  3.90s/it]                                                           Episode 293	 reward: -12.54	 makespan: 1241.80	 Mean_loss: 0.16192120,  training time: 4.45
progress:  58%|[34m    [0m| 292/500 [18:58<13:31,  3.90s/it]progress:  59%|[34m    [0m| 293/500 [18:58<14:01,  4.07s/it]                                                           Episode 294	 reward: -12.72	 makespan: 1259.45	 Mean_loss: 0.18839742,  training time: 3.72
progress:  59%|[34m    [0m| 293/500 [19:02<14:01,  4.07s/it]progress:  59%|[34m    [0m| 294/500 [19:02<13:36,  3.96s/it]                                                           Episode 295	 reward: -12.53	 makespan: 1240.50	 Mean_loss: 0.14841811,  training time: 3.71
progress:  59%|[34m    [0m| 294/500 [19:05<13:36,  3.96s/it]progress:  59%|[34m    [0m| 295/500 [19:05<13:16,  3.89s/it]                                                           Episode 296	 reward: -12.43	 makespan: 1231.05	 Mean_loss: 0.16459425,  training time: 4.72
progress:  59%|[34m    [0m| 295/500 [19:10<13:16,  3.89s/it]progress:  59%|[34m    [0m| 296/500 [19:10<14:03,  4.14s/it]                                                           Episode 297	 reward: -12.58	 makespan: 1245.90	 Mean_loss: 0.18865158,  training time: 3.73
progress:  59%|[34m    [0m| 296/500 [19:14<14:03,  4.14s/it]progress:  59%|[34m    [0m| 297/500 [19:14<13:35,  4.01s/it]                                                           Episode 298	 reward: -12.45	 makespan: 1232.85	 Mean_loss: 0.17642514,  training time: 3.69
progress:  59%|[34m    [0m| 297/500 [19:17<13:35,  4.01s/it]progress:  60%|[34m    [0m| 298/500 [19:17<13:11,  3.92s/it]                                                           Episode 299	 reward: -12.53	 makespan: 1240.05	 Mean_loss: 0.15867890,  training time: 3.83
progress:  60%|[34m    [0m| 298/500 [19:21<13:11,  3.92s/it]progress:  60%|[34m    [0m| 299/500 [19:21<13:02,  3.89s/it]                                                           Episode 300	 reward: -12.54	 makespan: 1241.10	 Mean_loss: 0.19978401,  training time: 4.63
progress:  60%|[34m    [0m| 299/500 [19:26<13:02,  3.89s/it]progress:  60%|[34m    [0m| 300/500 [19:26<13:44,  4.12s/it]                                                           Episode 301	 reward: -12.55	 makespan: 1242.40	 Mean_loss: 0.13565625,  training time: 3.95
progress:  60%|[34m    [0m| 300/500 [19:30<13:44,  4.12s/it]progress:  60%|[34m    [0m| 301/500 [19:30<13:43,  4.14s/it]                                                           Episode 302	 reward: -12.70	 makespan: 1256.90	 Mean_loss: 0.15014181,  training time: 3.76
progress:  60%|[34m    [0m| 301/500 [19:34<13:43,  4.14s/it]progress:  60%|[34m    [0m| 302/500 [19:34<13:16,  4.02s/it]                                                           Episode 303	 reward: -12.57	 makespan: 1244.35	 Mean_loss: 0.14870252,  training time: 4.15
progress:  60%|[34m    [0m| 302/500 [19:38<13:16,  4.02s/it]progress:  61%|[34m    [0m| 303/500 [19:38<13:23,  4.08s/it]                                                           Episode 304	 reward: -12.56	 makespan: 1243.25	 Mean_loss: 0.14033845,  training time: 3.86
progress:  61%|[34m    [0m| 303/500 [19:42<13:23,  4.08s/it]progress:  61%|[34m    [0m| 304/500 [19:42<13:06,  4.02s/it]                                                           Episode 305	 reward: -12.51	 makespan: 1238.75	 Mean_loss: 0.15001056,  training time: 3.79
progress:  61%|[34m    [0m| 304/500 [19:46<13:06,  4.02s/it]progress:  61%|[34m    [0m| 305/500 [19:46<12:49,  3.95s/it]                                                           Episode 306	 reward: -12.65	 makespan: 1252.65	 Mean_loss: 0.13717331,  training time: 3.80
progress:  61%|[34m    [0m| 305/500 [19:50<12:49,  3.95s/it]progress:  61%|[34m    [0m| 306/500 [19:50<12:37,  3.91s/it]                                                           Episode 307	 reward: -12.62	 makespan: 1249.05	 Mean_loss: 0.14184143,  training time: 3.81
progress:  61%|[34m    [0m| 306/500 [19:53<12:37,  3.91s/it]progress:  61%|[34m   [0m| 307/500 [19:53<12:28,  3.88s/it]                                                           Episode 308	 reward: -12.55	 makespan: 1242.75	 Mean_loss: 0.15520227,  training time: 4.26
progress:  61%|[34m   [0m| 307/500 [19:58<12:28,  3.88s/it]progress:  62%|[34m   [0m| 308/500 [19:58<12:46,  3.99s/it]                                                           Episode 309	 reward: -12.61	 makespan: 1248.35	 Mean_loss: 0.14552136,  training time: 4.11
progress:  62%|[34m   [0m| 308/500 [20:02<12:46,  3.99s/it]progress:  62%|[34m   [0m| 309/500 [20:02<12:49,  4.03s/it]                                                           Episode 310	 reward: -12.51	 makespan: 1238.00	 Mean_loss: 0.14325210,  training time: 3.78
progress:  62%|[34m   [0m| 309/500 [20:05<12:49,  4.03s/it]progress:  62%|[34m   [0m| 310/500 [20:05<12:31,  3.95s/it]                                                           Episode 311	 reward: -12.61	 makespan: 1248.05	 Mean_loss: 0.14401270,  training time: 3.80
progress:  62%|[34m   [0m| 310/500 [20:09<12:31,  3.95s/it]progress:  62%|[34m   [0m| 311/500 [20:09<12:18,  3.91s/it]                                                           Episode 312	 reward: -12.42	 makespan: 1229.10	 Mean_loss: 0.13881648,  training time: 3.91
progress:  62%|[34m   [0m| 311/500 [20:13<12:18,  3.91s/it]progress:  62%|[34m   [0m| 312/500 [20:13<12:14,  3.91s/it]                                                           Episode 313	 reward: -12.58	 makespan: 1245.70	 Mean_loss: 0.12601712,  training time: 3.93
progress:  62%|[34m   [0m| 312/500 [20:17<12:14,  3.91s/it]progress:  63%|[34m   [0m| 313/500 [20:17<12:11,  3.91s/it]                                                           Episode 314	 reward: -12.43	 makespan: 1230.65	 Mean_loss: 0.13266698,  training time: 3.80
progress:  63%|[34m   [0m| 313/500 [20:21<12:11,  3.91s/it]progress:  63%|[34m   [0m| 314/500 [20:21<12:01,  3.88s/it]                                                           Episode 315	 reward: -12.57	 makespan: 1244.20	 Mean_loss: 0.18964727,  training time: 3.99
progress:  63%|[34m   [0m| 314/500 [20:25<12:01,  3.88s/it]progress:  63%|[34m   [0m| 315/500 [20:25<12:03,  3.91s/it]                                                           Episode 316	 reward: -12.62	 makespan: 1249.00	 Mean_loss: 0.13746588,  training time: 4.08
progress:  63%|[34m   [0m| 315/500 [20:29<12:03,  3.91s/it]progress:  63%|[34m   [0m| 316/500 [20:29<12:08,  3.96s/it]                                                           Episode 317	 reward: -12.52	 makespan: 1239.60	 Mean_loss: 0.13676892,  training time: 4.08
progress:  63%|[34m   [0m| 316/500 [20:33<12:08,  3.96s/it]progress:  63%|[34m   [0m| 317/500 [20:33<12:11,  4.00s/it]                                                           Episode 318	 reward: -12.62	 makespan: 1249.40	 Mean_loss: 0.14095923,  training time: 3.74
progress:  63%|[34m   [0m| 317/500 [20:37<12:11,  4.00s/it]progress:  64%|[34m   [0m| 318/500 [20:37<11:56,  3.94s/it]                                                           Episode 319	 reward: -12.64	 makespan: 1251.65	 Mean_loss: 0.13463891,  training time: 3.74
progress:  64%|[34m   [0m| 318/500 [20:41<11:56,  3.94s/it]progress:  64%|[34m   [0m| 319/500 [20:41<11:42,  3.88s/it]                                                           Episode 320	 reward: -12.74	 makespan: 1261.00	 Mean_loss: 0.11236519,  training time: 3.76
progress:  64%|[34m   [0m| 319/500 [20:44<11:42,  3.88s/it]progress:  64%|[34m   [0m| 320/500 [20:44<11:32,  3.84s/it]                                                           Episode 321	 reward: -12.67	 makespan: 1254.35	 Mean_loss: 0.19421801,  training time: 4.07
progress:  64%|[34m   [0m| 320/500 [20:48<11:32,  3.84s/it]progress:  64%|[34m   [0m| 321/500 [20:48<11:40,  3.91s/it]                                                           Episode 322	 reward: -12.79	 makespan: 1266.45	 Mean_loss: 0.21661483,  training time: 3.83
progress:  64%|[34m   [0m| 321/500 [20:52<11:40,  3.91s/it]progress:  64%|[34m   [0m| 322/500 [20:52<11:31,  3.89s/it]                                                           Episode 323	 reward: -12.67	 makespan: 1254.55	 Mean_loss: 0.14490217,  training time: 3.79
progress:  64%|[34m   [0m| 322/500 [20:56<11:31,  3.89s/it]progress:  65%|[34m   [0m| 323/500 [20:56<11:22,  3.86s/it]                                                           Episode 324	 reward: -12.77	 makespan: 1264.45	 Mean_loss: 0.17918094,  training time: 3.78
progress:  65%|[34m   [0m| 323/500 [21:00<11:22,  3.86s/it]progress:  65%|[34m   [0m| 324/500 [21:00<11:14,  3.83s/it]                                                           Episode 325	 reward: -12.75	 makespan: 1262.60	 Mean_loss: 0.18980563,  training time: 3.76
progress:  65%|[34m   [0m| 324/500 [21:04<11:14,  3.83s/it]progress:  65%|[34m   [0m| 325/500 [21:04<11:07,  3.81s/it]                                                           Episode 326	 reward: -12.70	 makespan: 1257.30	 Mean_loss: 0.18994275,  training time: 4.15
progress:  65%|[34m   [0m| 325/500 [21:08<11:07,  3.81s/it]progress:  65%|[34m   [0m| 326/500 [21:08<11:21,  3.91s/it]                                                           Episode 327	 reward: -12.74	 makespan: 1261.45	 Mean_loss: 0.18782751,  training time: 4.38
progress:  65%|[34m   [0m| 326/500 [21:12<11:21,  3.91s/it]progress:  65%|[34m   [0m| 327/500 [21:12<11:41,  4.05s/it]                                                           Episode 328	 reward: -13.00	 makespan: 1286.95	 Mean_loss: 0.19229376,  training time: 3.83
progress:  65%|[34m   [0m| 327/500 [21:16<11:41,  4.05s/it]progress:  66%|[34m   [0m| 328/500 [21:16<11:25,  3.99s/it]                                                           Episode 329	 reward: -12.90	 makespan: 1276.70	 Mean_loss: 0.17531422,  training time: 3.82
progress:  66%|[34m   [0m| 328/500 [21:20<11:25,  3.99s/it]progress:  66%|[34m   [0m| 329/500 [21:20<11:13,  3.94s/it]                                                           Episode 330	 reward: -12.78	 makespan: 1265.00	 Mean_loss: 0.13340378,  training time: 5.12
progress:  66%|[34m   [0m| 329/500 [21:25<11:13,  3.94s/it]progress:  66%|[34m   [0m| 330/500 [21:25<12:09,  4.29s/it]                                                           Episode 331	 reward: -12.76	 makespan: 1263.65	 Mean_loss: 0.14726581,  training time: 4.01
progress:  66%|[34m   [0m| 330/500 [21:29<12:09,  4.29s/it]progress:  66%|[34m   [0m| 331/500 [21:29<11:51,  4.21s/it]                                                           Episode 332	 reward: -12.68	 makespan: 1255.60	 Mean_loss: 0.11815939,  training time: 3.82
progress:  66%|[34m   [0m| 331/500 [21:33<11:51,  4.21s/it]progress:  66%|[34m   [0m| 332/500 [21:33<11:27,  4.09s/it]                                                           Episode 333	 reward: -12.77	 makespan: 1264.05	 Mean_loss: 0.14739183,  training time: 3.71
progress:  66%|[34m   [0m| 332/500 [21:36<11:27,  4.09s/it]progress:  67%|[34m   [0m| 333/500 [21:36<11:04,  3.98s/it]                                                           Episode 334	 reward: -12.79	 makespan: 1266.60	 Mean_loss: 0.13343176,  training time: 4.14
progress:  67%|[34m   [0m| 333/500 [21:41<11:04,  3.98s/it]progress:  67%|[34m   [0m| 334/500 [21:41<11:08,  4.03s/it]                                                           Episode 335	 reward: -12.84	 makespan: 1271.60	 Mean_loss: 0.17421108,  training time: 3.73
progress:  67%|[34m   [0m| 334/500 [21:44<11:08,  4.03s/it]progress:  67%|[34m   [0m| 335/500 [21:44<10:50,  3.94s/it]                                                           Episode 336	 reward: -12.78	 makespan: 1265.00	 Mean_loss: 0.15847003,  training time: 4.23
progress:  67%|[34m   [0m| 335/500 [21:49<10:50,  3.94s/it]progress:  67%|[34m   [0m| 336/500 [21:49<11:00,  4.03s/it]                                                           Episode 337	 reward: -12.79	 makespan: 1266.05	 Mean_loss: 0.14848530,  training time: 4.04
progress:  67%|[34m   [0m| 336/500 [21:53<11:00,  4.03s/it]progress:  67%|[34m   [0m| 337/500 [21:53<10:57,  4.03s/it]                                                           Episode 338	 reward: -12.66	 makespan: 1253.40	 Mean_loss: 0.13758047,  training time: 3.99
progress:  67%|[34m   [0m| 337/500 [21:57<10:57,  4.03s/it]progress:  68%|[34m   [0m| 338/500 [21:57<10:51,  4.02s/it]                                                           Episode 339	 reward: -12.87	 makespan: 1274.45	 Mean_loss: 0.18984699,  training time: 3.78
progress:  68%|[34m   [0m| 338/500 [22:00<10:51,  4.02s/it]progress:  68%|[34m   [0m| 339/500 [22:00<10:35,  3.95s/it]                                                           Episode 340	 reward: -12.86	 makespan: 1273.25	 Mean_loss: 0.13632140,  training time: 3.73
progress:  68%|[34m   [0m| 339/500 [22:04<10:35,  3.95s/it]progress:  68%|[34m   [0m| 340/500 [22:04<10:21,  3.88s/it]                                                           Episode 341	 reward: -12.43	 makespan: 1230.95	 Mean_loss: 0.14215454,  training time: 3.86
progress:  68%|[34m   [0m| 340/500 [22:08<10:21,  3.88s/it]progress:  68%|[34m   [0m| 341/500 [22:08<10:16,  3.88s/it]                                                           Episode 342	 reward: -12.64	 makespan: 1251.70	 Mean_loss: 0.13211764,  training time: 4.60
progress:  68%|[34m   [0m| 341/500 [22:13<10:16,  3.88s/it]progress:  68%|[34m   [0m| 342/500 [22:13<10:46,  4.09s/it]                                                           Episode 343	 reward: -12.42	 makespan: 1229.85	 Mean_loss: 0.16042903,  training time: 3.92
progress:  68%|[34m   [0m| 342/500 [22:16<10:46,  4.09s/it]progress:  69%|[34m   [0m| 343/500 [22:16<10:34,  4.04s/it]                                                           Episode 344	 reward: -12.43	 makespan: 1230.55	 Mean_loss: 0.14960849,  training time: 3.83
progress:  69%|[34m   [0m| 343/500 [22:20<10:34,  4.04s/it]progress:  69%|[34m   [0m| 344/500 [22:20<10:20,  3.98s/it]                                                           Episode 345	 reward: -12.34	 makespan: 1221.45	 Mean_loss: 0.10346057,  training time: 3.82
progress:  69%|[34m   [0m| 344/500 [22:24<10:20,  3.98s/it]progress:  69%|[34m   [0m| 345/500 [22:24<10:09,  3.93s/it]                                                           Episode 346	 reward: -12.38	 makespan: 1225.45	 Mean_loss: 0.13447079,  training time: 4.45
progress:  69%|[34m   [0m| 345/500 [22:29<10:09,  3.93s/it]progress:  69%|[34m   [0m| 346/500 [22:29<10:29,  4.09s/it]                                                           Episode 347	 reward: -12.47	 makespan: 1234.15	 Mean_loss: 0.17951748,  training time: 3.72
progress:  69%|[34m   [0m| 346/500 [22:32<10:29,  4.09s/it]progress:  69%|[34m   [0m| 347/500 [22:32<10:08,  3.98s/it]                                                           Episode 348	 reward: -12.31	 makespan: 1218.95	 Mean_loss: 0.12968521,  training time: 3.74
progress:  69%|[34m   [0m| 347/500 [22:36<10:08,  3.98s/it]progress:  70%|[34m   [0m| 348/500 [22:36<09:54,  3.91s/it]                                                           Episode 349	 reward: -12.40	 makespan: 1227.85	 Mean_loss: 0.12698285,  training time: 3.92
progress:  70%|[34m   [0m| 348/500 [22:40<09:54,  3.91s/it]progress:  70%|[34m   [0m| 349/500 [22:40<09:50,  3.91s/it]                                                           Episode 350	 reward: -12.37	 makespan: 1225.10	 Mean_loss: 0.16141769,  training time: 3.72
progress:  70%|[34m   [0m| 349/500 [22:44<09:50,  3.91s/it]progress:  70%|[34m   [0m| 350/500 [22:44<09:38,  3.86s/it]                                                           Episode 351	 reward: -12.37	 makespan: 1224.60	 Mean_loss: 0.15709631,  training time: 3.98
progress:  70%|[34m   [0m| 350/500 [22:48<09:38,  3.86s/it]progress:  70%|[34m   [0m| 351/500 [22:48<09:40,  3.89s/it]                                                           Episode 352	 reward: -12.41	 makespan: 1228.40	 Mean_loss: 0.17136513,  training time: 4.41
progress:  70%|[34m   [0m| 351/500 [22:52<09:40,  3.89s/it]progress:  70%|[34m   [0m| 352/500 [22:52<09:59,  4.05s/it]                                                           Episode 353	 reward: -12.40	 makespan: 1227.40	 Mean_loss: 0.15402479,  training time: 3.81
progress:  70%|[34m   [0m| 352/500 [22:56<09:59,  4.05s/it]progress:  71%|[34m   [0m| 353/500 [22:56<09:44,  3.98s/it]                                                           Episode 354	 reward: -12.32	 makespan: 1219.30	 Mean_loss: 0.14016099,  training time: 3.79
progress:  71%|[34m   [0m| 353/500 [23:00<09:44,  3.98s/it]progress:  71%|[34m   [0m| 354/500 [23:00<09:32,  3.92s/it]                                                           Episode 355	 reward: -12.47	 makespan: 1234.55	 Mean_loss: 0.17114118,  training time: 4.59
progress:  71%|[34m   [0m| 354/500 [23:04<09:32,  3.92s/it]progress:  71%|[34m   [0m| 355/500 [23:04<09:57,  4.12s/it]                                                           Episode 356	 reward: -12.30	 makespan: 1218.05	 Mean_loss: 0.14191210,  training time: 4.05
progress:  71%|[34m   [0m| 355/500 [23:08<09:57,  4.12s/it]progress:  71%|[34m   [0m| 356/500 [23:08<09:50,  4.10s/it]                                                           Episode 357	 reward: -12.27	 makespan: 1214.50	 Mean_loss: 0.13151799,  training time: 3.88
progress:  71%|[34m   [0m| 356/500 [23:12<09:50,  4.10s/it]progress:  71%|[34m  [0m| 357/500 [23:12<09:37,  4.04s/it]                                                           Episode 358	 reward: -12.34	 makespan: 1221.90	 Mean_loss: 0.14084798,  training time: 3.92
progress:  71%|[34m  [0m| 357/500 [23:16<09:37,  4.04s/it]progress:  72%|[34m  [0m| 358/500 [23:16<09:28,  4.00s/it]                                                           Episode 359	 reward: -12.34	 makespan: 1221.30	 Mean_loss: 0.15698329,  training time: 3.95
progress:  72%|[34m  [0m| 358/500 [23:20<09:28,  4.00s/it]progress:  72%|[34m  [0m| 359/500 [23:20<09:22,  3.99s/it]                                                           Episode 360	 reward: -12.35	 makespan: 1222.90	 Mean_loss: 0.13572985,  training time: 3.74
progress:  72%|[34m  [0m| 359/500 [23:24<09:22,  3.99s/it]progress:  72%|[34m  [0m| 360/500 [23:24<09:08,  3.92s/it]                                                           Episode 361	 reward: -12.57	 makespan: 1244.20	 Mean_loss: 0.16255842,  training time: 3.86
progress:  72%|[34m  [0m| 360/500 [23:28<09:08,  3.92s/it]progress:  72%|[34m  [0m| 361/500 [23:28<09:02,  3.90s/it]                                                           Episode 362	 reward: -12.43	 makespan: 1230.10	 Mean_loss: 0.16476268,  training time: 4.74
progress:  72%|[34m  [0m| 361/500 [23:32<09:02,  3.90s/it]progress:  72%|[34m  [0m| 362/500 [23:32<09:32,  4.15s/it]                                                           Episode 363	 reward: -12.43	 makespan: 1230.90	 Mean_loss: 0.17198488,  training time: 4.24
progress:  72%|[34m  [0m| 362/500 [23:37<09:32,  4.15s/it]progress:  73%|[34m  [0m| 363/500 [23:37<09:32,  4.18s/it]                                                           Episode 364	 reward: -12.59	 makespan: 1246.60	 Mean_loss: 0.20418055,  training time: 3.71
progress:  73%|[34m  [0m| 363/500 [23:40<09:32,  4.18s/it]progress:  73%|[34m  [0m| 364/500 [23:40<09:09,  4.04s/it]                                                           Episode 365	 reward: -12.51	 makespan: 1238.40	 Mean_loss: 0.17541292,  training time: 3.69
progress:  73%|[34m  [0m| 364/500 [23:44<09:09,  4.04s/it]progress:  73%|[34m  [0m| 365/500 [23:44<08:51,  3.93s/it]                                                           Episode 366	 reward: -12.59	 makespan: 1246.25	 Mean_loss: 0.14883059,  training time: 3.69
progress:  73%|[34m  [0m| 365/500 [23:48<08:51,  3.93s/it]progress:  73%|[34m  [0m| 366/500 [23:48<08:37,  3.86s/it]                                                           Episode 367	 reward: -12.56	 makespan: 1243.10	 Mean_loss: 0.23822130,  training time: 4.64
progress:  73%|[34m  [0m| 366/500 [23:52<08:37,  3.86s/it]progress:  73%|[34m  [0m| 367/500 [23:52<09:04,  4.10s/it]                                                           Episode 368	 reward: -12.60	 makespan: 1246.95	 Mean_loss: 0.14318982,  training time: 3.88
progress:  73%|[34m  [0m| 367/500 [23:56<09:04,  4.10s/it]progress:  74%|[34m  [0m| 368/500 [23:56<08:52,  4.03s/it]                                                           Episode 369	 reward: -12.57	 makespan: 1244.60	 Mean_loss: 0.15193349,  training time: 3.73
progress:  74%|[34m  [0m| 368/500 [24:00<08:52,  4.03s/it]progress:  74%|[34m  [0m| 369/500 [24:00<08:36,  3.94s/it]                                                           Episode 370	 reward: -12.44	 makespan: 1231.15	 Mean_loss: 0.15154348,  training time: 3.74
progress:  74%|[34m  [0m| 369/500 [24:04<08:36,  3.94s/it]progress:  74%|[34m  [0m| 370/500 [24:04<08:24,  3.88s/it]                                                           Episode 371	 reward: -12.58	 makespan: 1245.55	 Mean_loss: 0.16410333,  training time: 4.45
progress:  74%|[34m  [0m| 370/500 [24:08<08:24,  3.88s/it]progress:  74%|[34m  [0m| 371/500 [24:08<08:42,  4.05s/it]                                                           Episode 372	 reward: -12.62	 makespan: 1249.25	 Mean_loss: 0.17796762,  training time: 3.71
progress:  74%|[34m  [0m| 371/500 [24:12<08:42,  4.05s/it]progress:  74%|[34m  [0m| 372/500 [24:12<08:25,  3.95s/it]                                                           Episode 373	 reward: -12.55	 makespan: 1242.00	 Mean_loss: 0.16080306,  training time: 3.72
progress:  74%|[34m  [0m| 372/500 [24:16<08:25,  3.95s/it]progress:  75%|[34m  [0m| 373/500 [24:16<08:12,  3.88s/it]                                                           Episode 374	 reward: -12.57	 makespan: 1244.00	 Mean_loss: 0.14418389,  training time: 4.85
progress:  75%|[34m  [0m| 373/500 [24:21<08:12,  3.88s/it]progress:  75%|[34m  [0m| 374/500 [24:21<08:45,  4.17s/it]                                                           Episode 375	 reward: -12.60	 makespan: 1247.05	 Mean_loss: 0.20009379,  training time: 3.76
progress:  75%|[34m  [0m| 374/500 [24:24<08:45,  4.17s/it]progress:  75%|[34m  [0m| 375/500 [24:24<08:25,  4.05s/it]                                                           Episode 376	 reward: -12.53	 makespan: 1240.00	 Mean_loss: 0.17557652,  training time: 3.71
progress:  75%|[34m  [0m| 375/500 [24:28<08:25,  4.05s/it]progress:  75%|[34m  [0m| 376/500 [24:28<08:09,  3.95s/it]                                                           Episode 377	 reward: -12.57	 makespan: 1244.25	 Mean_loss: 0.15938447,  training time: 7.07
progress:  75%|[34m  [0m| 376/500 [24:35<08:09,  3.95s/it]progress:  75%|[34m  [0m| 377/500 [24:35<10:00,  4.88s/it]                                                           Episode 378	 reward: -12.59	 makespan: 1246.20	 Mean_loss: 0.17370470,  training time: 3.87
progress:  75%|[34m  [0m| 377/500 [24:39<10:00,  4.88s/it]progress:  76%|[34m  [0m| 378/500 [24:39<09:18,  4.58s/it]                                                           Episode 379	 reward: -12.47	 makespan: 1234.25	 Mean_loss: 0.15086094,  training time: 3.98
progress:  76%|[34m  [0m| 378/500 [24:43<09:18,  4.58s/it]progress:  76%|[34m  [0m| 379/500 [24:43<08:52,  4.40s/it]                                                           Episode 380	 reward: -12.54	 makespan: 1241.30	 Mean_loss: 0.14497909,  training time: 5.03
progress:  76%|[34m  [0m| 379/500 [24:48<08:52,  4.40s/it]progress:  76%|[34m  [0m| 380/500 [24:48<09:10,  4.59s/it]                                                           Episode 381	 reward: -12.77	 makespan: 1264.05	 Mean_loss: 0.19496651,  training time: 3.82
progress:  76%|[34m  [0m| 380/500 [24:52<09:10,  4.59s/it]progress:  76%|[34m  [0m| 381/500 [24:52<08:38,  4.36s/it]                                                           Episode 382	 reward: -12.72	 makespan: 1259.10	 Mean_loss: 0.16928035,  training time: 3.76
progress:  76%|[34m  [0m| 381/500 [24:56<08:38,  4.36s/it]progress:  76%|[34m  [0m| 382/500 [24:56<08:13,  4.18s/it]                                                           Episode 383	 reward: -12.81	 makespan: 1268.50	 Mean_loss: 0.20214286,  training time: 3.77
progress:  76%|[34m  [0m| 382/500 [24:59<08:13,  4.18s/it]progress:  77%|[34m  [0m| 383/500 [24:59<07:54,  4.06s/it]                                                           Episode 384	 reward: -12.64	 makespan: 1251.85	 Mean_loss: 0.16367975,  training time: 4.60
progress:  77%|[34m  [0m| 383/500 [25:04<07:54,  4.06s/it]progress:  77%|[34m  [0m| 384/500 [25:04<08:15,  4.27s/it]                                                           Episode 385	 reward: -12.72	 makespan: 1259.25	 Mean_loss: 0.16819964,  training time: 3.84
progress:  77%|[34m  [0m| 384/500 [25:08<08:15,  4.27s/it]progress:  77%|[34m  [0m| 385/500 [25:08<07:56,  4.15s/it]                                                           Episode 386	 reward: -12.71	 makespan: 1257.85	 Mean_loss: 0.17529388,  training time: 3.85
progress:  77%|[34m  [0m| 385/500 [25:12<07:56,  4.15s/it]progress:  77%|[34m  [0m| 386/500 [25:12<07:42,  4.06s/it]                                                           Episode 387	 reward: -12.72	 makespan: 1259.55	 Mean_loss: 0.16143157,  training time: 3.85
progress:  77%|[34m  [0m| 386/500 [25:16<07:42,  4.06s/it]progress:  77%|[34m  [0m| 387/500 [25:16<07:31,  3.99s/it]                                                           Episode 388	 reward: -12.74	 makespan: 1260.95	 Mean_loss: 0.16424108,  training time: 4.96
progress:  77%|[34m  [0m| 387/500 [25:21<07:31,  3.99s/it]progress:  78%|[34m  [0m| 388/500 [25:21<07:59,  4.28s/it]                                                           Episode 389	 reward: -12.74	 makespan: 1260.95	 Mean_loss: 0.15043595,  training time: 3.91
progress:  78%|[34m  [0m| 388/500 [25:25<07:59,  4.28s/it]progress:  78%|[34m  [0m| 389/500 [25:25<07:43,  4.17s/it]                                                           Episode 390	 reward: -12.90	 makespan: 1276.70	 Mean_loss: 0.21088219,  training time: 3.78
progress:  78%|[34m  [0m| 389/500 [25:28<07:43,  4.17s/it]progress:  78%|[34m  [0m| 390/500 [25:28<07:26,  4.05s/it]                                                           Episode 391	 reward: -12.77	 makespan: 1264.35	 Mean_loss: 0.14775376,  training time: 3.80
progress:  78%|[34m  [0m| 390/500 [25:32<07:26,  4.05s/it]progress:  78%|[34m  [0m| 391/500 [25:32<07:13,  3.98s/it]                                                           Episode 392	 reward: -12.75	 makespan: 1262.60	 Mean_loss: 0.18962927,  training time: 3.88
progress:  78%|[34m  [0m| 391/500 [25:36<07:13,  3.98s/it]progress:  78%|[34m  [0m| 392/500 [25:36<07:06,  3.95s/it]                                                           Episode 393	 reward: -12.79	 makespan: 1265.85	 Mean_loss: 0.20610166,  training time: 3.84
progress:  78%|[34m  [0m| 392/500 [25:40<07:06,  3.95s/it]progress:  79%|[34m  [0m| 393/500 [25:40<06:58,  3.92s/it]                                                           Episode 394	 reward: -12.68	 makespan: 1255.55	 Mean_loss: 0.16802873,  training time: 3.72
progress:  79%|[34m  [0m| 393/500 [25:44<06:58,  3.92s/it]progress:  79%|[34m  [0m| 394/500 [25:44<06:48,  3.86s/it]                                                           Episode 395	 reward: -12.66	 makespan: 1253.55	 Mean_loss: 0.17470862,  training time: 5.00
progress:  79%|[34m  [0m| 394/500 [25:49<06:48,  3.86s/it]progress:  79%|[34m  [0m| 395/500 [25:49<07:21,  4.20s/it]                                                           Episode 396	 reward: -12.57	 makespan: 1244.70	 Mean_loss: 0.13297296,  training time: 3.82
progress:  79%|[34m  [0m| 395/500 [25:52<07:21,  4.20s/it]progress:  79%|[34m  [0m| 396/500 [25:52<07:04,  4.09s/it]                                                           Episode 397	 reward: -12.70	 makespan: 1257.30	 Mean_loss: 0.14753091,  training time: 3.91
progress:  79%|[34m  [0m| 396/500 [25:56<07:04,  4.09s/it]progress:  79%|[34m  [0m| 397/500 [25:56<06:55,  4.04s/it]                                                           Episode 398	 reward: -12.78	 makespan: 1265.25	 Mean_loss: 0.18661523,  training time: 3.78
progress:  79%|[34m  [0m| 397/500 [26:00<06:55,  4.04s/it]progress:  80%|[34m  [0m| 398/500 [26:00<06:44,  3.97s/it]                                                           Episode 399	 reward: -12.66	 makespan: 1252.85	 Mean_loss: 0.14203422,  training time: 4.43
progress:  80%|[34m  [0m| 398/500 [26:05<06:44,  3.97s/it]progress:  80%|[34m  [0m| 399/500 [26:05<06:54,  4.11s/it]                                                           Episode 400	 reward: -12.84	 makespan: 1271.05	 Mean_loss: 0.16268672,  training time: 3.74
progress:  80%|[34m  [0m| 399/500 [26:08<06:54,  4.11s/it]progress:  80%|[34m  [0m| 400/500 [26:08<06:39,  4.00s/it]                                                           Episode 401	 reward: -12.41	 makespan: 1229.05	 Mean_loss: 0.17571637,  training time: 4.04
progress:  80%|[34m  [0m| 400/500 [26:12<06:39,  4.00s/it]progress:  80%|[34m  [0m| 401/500 [26:12<06:37,  4.01s/it]                                                           Episode 402	 reward: -12.41	 makespan: 1228.10	 Mean_loss: 0.19210447,  training time: 3.84
progress:  80%|[34m  [0m| 401/500 [26:16<06:37,  4.01s/it]progress:  80%|[34m  [0m| 402/500 [26:16<06:28,  3.96s/it]                                                           Episode 403	 reward: -12.42	 makespan: 1229.10	 Mean_loss: 0.18160383,  training time: 3.83
progress:  80%|[34m  [0m| 402/500 [26:20<06:28,  3.96s/it]progress:  81%|[34m  [0m| 403/500 [26:20<06:20,  3.92s/it]                                                           Episode 404	 reward: -12.36	 makespan: 1223.80	 Mean_loss: 0.17906989,  training time: 3.83
progress:  81%|[34m  [0m| 403/500 [26:24<06:20,  3.92s/it]progress:  81%|[34m  [0m| 404/500 [26:24<06:13,  3.90s/it]                                                           Episode 405	 reward: -12.42	 makespan: 1229.30	 Mean_loss: 0.16148990,  training time: 4.38
progress:  81%|[34m  [0m| 404/500 [26:28<06:13,  3.90s/it]progress:  81%|[34m  [0m| 405/500 [26:28<06:23,  4.04s/it]                                                           Episode 406	 reward: -12.32	 makespan: 1219.30	 Mean_loss: 0.18487799,  training time: 3.93
progress:  81%|[34m  [0m| 405/500 [26:32<06:23,  4.04s/it]progress:  81%|[34m  [0m| 406/500 [26:32<06:16,  4.01s/it]                                                           Episode 407	 reward: -12.46	 makespan: 1233.60	 Mean_loss: 0.15695047,  training time: 3.86
progress:  81%|[34m  [0m| 406/500 [26:36<06:16,  4.01s/it]progress:  81%|[34m [0m| 407/500 [26:36<06:08,  3.96s/it]                                                           Episode 408	 reward: -12.46	 makespan: 1233.70	 Mean_loss: 0.20158154,  training time: 3.75
progress:  81%|[34m [0m| 407/500 [26:40<06:08,  3.96s/it]progress:  82%|[34m [0m| 408/500 [26:40<05:58,  3.90s/it]                                                           Episode 409	 reward: -12.36	 makespan: 1223.25	 Mean_loss: 0.13583991,  training time: 3.90
progress:  82%|[34m [0m| 408/500 [26:44<05:58,  3.90s/it]progress:  82%|[34m [0m| 409/500 [26:44<05:54,  3.90s/it]                                                           Episode 410	 reward: -12.27	 makespan: 1214.65	 Mean_loss: 0.16814372,  training time: 3.73
progress:  82%|[34m [0m| 409/500 [26:47<05:54,  3.90s/it]progress:  82%|[34m [0m| 410/500 [26:47<05:46,  3.85s/it]                                                           Episode 411	 reward: -12.43	 makespan: 1230.25	 Mean_loss: 0.18442500,  training time: 4.01
progress:  82%|[34m [0m| 410/500 [26:51<05:46,  3.85s/it]progress:  82%|[34m [0m| 411/500 [26:51<05:46,  3.90s/it]                                                           Episode 412	 reward: -12.46	 makespan: 1233.75	 Mean_loss: 0.14329952,  training time: 3.90
progress:  82%|[34m [0m| 411/500 [26:55<05:46,  3.90s/it]progress:  82%|[34m [0m| 412/500 [26:55<05:42,  3.90s/it]                                                           Episode 413	 reward: -12.28	 makespan: 1215.50	 Mean_loss: 0.14092955,  training time: 3.78
progress:  82%|[34m [0m| 412/500 [26:59<05:42,  3.90s/it]progress:  83%|[34m [0m| 413/500 [26:59<05:36,  3.86s/it]                                                           Episode 414	 reward: -12.44	 makespan: 1231.95	 Mean_loss: 0.18171559,  training time: 4.79
progress:  83%|[34m [0m| 413/500 [27:04<05:36,  3.86s/it]progress:  83%|[34m [0m| 414/500 [27:04<05:56,  4.14s/it]                                                           Episode 415	 reward: -12.42	 makespan: 1230.00	 Mean_loss: 0.15626478,  training time: 4.31
progress:  83%|[34m [0m| 414/500 [27:08<05:56,  4.14s/it]progress:  83%|[34m [0m| 415/500 [27:08<05:56,  4.19s/it]                                                           Episode 416	 reward: -12.39	 makespan: 1226.95	 Mean_loss: 0.13668147,  training time: 4.03
progress:  83%|[34m [0m| 415/500 [27:12<05:56,  4.19s/it]progress:  83%|[34m [0m| 416/500 [27:12<05:47,  4.14s/it]                                                           Episode 417	 reward: -12.52	 makespan: 1239.85	 Mean_loss: 0.16259544,  training time: 3.74
progress:  83%|[34m [0m| 416/500 [27:16<05:47,  4.14s/it]progress:  83%|[34m [0m| 417/500 [27:16<05:33,  4.02s/it]                                                           Episode 418	 reward: -12.42	 makespan: 1229.65	 Mean_loss: 0.13307381,  training time: 4.49
progress:  83%|[34m [0m| 417/500 [27:20<05:33,  4.02s/it]progress:  84%|[34m [0m| 418/500 [27:20<05:41,  4.16s/it]                                                           Episode 419	 reward: -12.33	 makespan: 1220.25	 Mean_loss: 0.15759976,  training time: 3.95
progress:  84%|[34m [0m| 418/500 [27:24<05:41,  4.16s/it]progress:  84%|[34m [0m| 419/500 [27:24<05:32,  4.10s/it]                                                           Episode 420	 reward: -12.34	 makespan: 1221.55	 Mean_loss: 0.15370181,  training time: 3.87
progress:  84%|[34m [0m| 419/500 [27:28<05:32,  4.10s/it]progress:  84%|[34m [0m| 420/500 [27:28<05:22,  4.03s/it]                                                           Episode 421	 reward: -12.43	 makespan: 1230.20	 Mean_loss: 0.14939651,  training time: 3.89
progress:  84%|[34m [0m| 420/500 [27:32<05:22,  4.03s/it]progress:  84%|[34m [0m| 421/500 [27:32<05:15,  3.99s/it]                                                           Episode 422	 reward: -12.54	 makespan: 1241.85	 Mean_loss: 0.14167425,  training time: 3.82
progress:  84%|[34m [0m| 421/500 [27:36<05:15,  3.99s/it]progress:  84%|[34m [0m| 422/500 [27:36<05:07,  3.94s/it]                                                           Episode 423	 reward: -12.42	 makespan: 1230.00	 Mean_loss: 0.12049174,  training time: 4.38
progress:  84%|[34m [0m| 422/500 [27:40<05:07,  3.94s/it]progress:  85%|[34m [0m| 423/500 [27:40<05:13,  4.07s/it]                                                           Episode 424	 reward: -12.47	 makespan: 1234.80	 Mean_loss: 0.15074061,  training time: 4.12
progress:  85%|[34m [0m| 423/500 [27:44<05:13,  4.07s/it]progress:  85%|[34m [0m| 424/500 [27:44<05:10,  4.09s/it]                                                           Episode 425	 reward: -12.62	 makespan: 1249.50	 Mean_loss: 0.16086069,  training time: 3.82
progress:  85%|[34m [0m| 424/500 [27:48<05:10,  4.09s/it]progress:  85%|[34m [0m| 425/500 [27:48<05:00,  4.01s/it]                                                           Episode 426	 reward: -12.56	 makespan: 1243.75	 Mean_loss: 0.15116543,  training time: 3.79
progress:  85%|[34m [0m| 425/500 [27:52<05:00,  4.01s/it]progress:  85%|[34m [0m| 426/500 [27:52<04:51,  3.94s/it]                                                           Episode 427	 reward: -12.42	 makespan: 1230.00	 Mean_loss: 0.13805921,  training time: 3.74
progress:  85%|[34m [0m| 426/500 [27:56<04:51,  3.94s/it]progress:  85%|[34m [0m| 427/500 [27:56<04:43,  3.88s/it]                                                           Episode 428	 reward: -12.45	 makespan: 1232.55	 Mean_loss: 0.11621168,  training time: 3.85
progress:  85%|[34m [0m| 427/500 [28:00<04:43,  3.88s/it]progress:  86%|[34m [0m| 428/500 [28:00<04:38,  3.87s/it]                                                           Episode 429	 reward: -12.48	 makespan: 1235.35	 Mean_loss: 0.19139236,  training time: 3.80
progress:  86%|[34m [0m| 428/500 [28:03<04:38,  3.87s/it]progress:  86%|[34m [0m| 429/500 [28:03<04:33,  3.85s/it]                                                           Episode 430	 reward: -12.38	 makespan: 1225.75	 Mean_loss: 0.13681333,  training time: 3.72
progress:  86%|[34m [0m| 429/500 [28:07<04:33,  3.85s/it]progress:  86%|[34m [0m| 430/500 [28:07<04:26,  3.81s/it]                                                           Episode 431	 reward: -12.39	 makespan: 1226.70	 Mean_loss: 0.13712564,  training time: 3.74
progress:  86%|[34m [0m| 430/500 [28:11<04:26,  3.81s/it]progress:  86%|[34m [0m| 431/500 [28:11<04:21,  3.79s/it]                                                           Episode 432	 reward: -12.47	 makespan: 1234.25	 Mean_loss: 0.11758353,  training time: 3.93
progress:  86%|[34m [0m| 431/500 [28:15<04:21,  3.79s/it]progress:  86%|[34m [0m| 432/500 [28:15<04:20,  3.83s/it]                                                           Episode 433	 reward: -12.26	 makespan: 1213.75	 Mean_loss: 0.12253611,  training time: 3.77
progress:  86%|[34m [0m| 432/500 [28:19<04:20,  3.83s/it]progress:  87%|[34m [0m| 433/500 [28:19<04:15,  3.81s/it]                                                           Episode 434	 reward: -12.37	 makespan: 1224.50	 Mean_loss: 0.12933843,  training time: 3.73
progress:  87%|[34m [0m| 433/500 [28:22<04:15,  3.81s/it]progress:  87%|[34m [0m| 434/500 [28:22<04:09,  3.79s/it]                                                           Episode 435	 reward: -12.44	 makespan: 1231.45	 Mean_loss: 0.13919771,  training time: 3.75
progress:  87%|[34m [0m| 434/500 [28:26<04:09,  3.79s/it]progress:  87%|[34m [0m| 435/500 [28:26<04:05,  3.78s/it]                                                           Episode 436	 reward: -12.46	 makespan: 1233.85	 Mean_loss: 0.11899686,  training time: 3.73
progress:  87%|[34m [0m| 435/500 [28:30<04:05,  3.78s/it]progress:  87%|[34m [0m| 436/500 [28:30<04:00,  3.76s/it]                                                           Episode 437	 reward: -12.42	 makespan: 1229.35	 Mean_loss: 0.11308361,  training time: 4.16
progress:  87%|[34m [0m| 436/500 [28:34<04:00,  3.76s/it]progress:  87%|[34m [0m| 437/500 [28:34<04:04,  3.88s/it]                                                           Episode 438	 reward: -12.33	 makespan: 1220.65	 Mean_loss: 0.14357437,  training time: 4.07
progress:  87%|[34m [0m| 437/500 [28:38<04:04,  3.88s/it]progress:  88%|[34m [0m| 438/500 [28:38<04:04,  3.94s/it]                                                           Episode 439	 reward: -12.34	 makespan: 1221.50	 Mean_loss: 0.12200978,  training time: 3.79
progress:  88%|[34m [0m| 438/500 [28:42<04:04,  3.94s/it]progress:  88%|[34m [0m| 439/500 [28:42<03:57,  3.90s/it]                                                           Episode 440	 reward: -12.44	 makespan: 1231.65	 Mean_loss: 0.13004144,  training time: 4.01
progress:  88%|[34m [0m| 439/500 [28:46<03:57,  3.90s/it]progress:  88%|[34m [0m| 440/500 [28:46<03:55,  3.93s/it]                                                           Episode 441	 reward: -12.65	 makespan: 1252.10	 Mean_loss: 0.21076702,  training time: 4.24
progress:  88%|[34m [0m| 440/500 [28:50<03:55,  3.93s/it]progress:  88%|[34m [0m| 441/500 [28:50<03:57,  4.02s/it]                                                           Episode 442	 reward: -12.71	 makespan: 1258.25	 Mean_loss: 0.17077389,  training time: 3.73
progress:  88%|[34m [0m| 441/500 [28:54<03:57,  4.02s/it]progress:  88%|[34m [0m| 442/500 [28:54<03:49,  3.95s/it]                                                           Episode 443	 reward: -12.52	 makespan: 1239.90	 Mean_loss: 0.13871993,  training time: 3.71
progress:  88%|[34m [0m| 442/500 [28:58<03:49,  3.95s/it]progress:  89%|[34m [0m| 443/500 [28:58<03:40,  3.88s/it]                                                           Episode 444	 reward: -12.63	 makespan: 1250.60	 Mean_loss: 0.15631829,  training time: 3.81
progress:  89%|[34m [0m| 443/500 [29:01<03:40,  3.88s/it]progress:  89%|[34m [0m| 444/500 [29:01<03:35,  3.86s/it]                                                           Episode 445	 reward: -12.55	 makespan: 1242.60	 Mean_loss: 0.12502231,  training time: 3.95
progress:  89%|[34m [0m| 444/500 [29:05<03:35,  3.86s/it]progress:  89%|[34m [0m| 445/500 [29:05<03:33,  3.88s/it]                                                           Episode 446	 reward: -12.68	 makespan: 1255.25	 Mean_loss: 0.14093855,  training time: 3.88
progress:  89%|[34m [0m| 445/500 [29:09<03:33,  3.88s/it]progress:  89%|[34m [0m| 446/500 [29:09<03:29,  3.88s/it]                                                           Episode 447	 reward: -12.62	 makespan: 1249.00	 Mean_loss: 0.15386860,  training time: 3.78
progress:  89%|[34m [0m| 446/500 [29:13<03:29,  3.88s/it]progress:  89%|[34m [0m| 447/500 [29:13<03:24,  3.85s/it]                                                           Episode 448	 reward: -12.66	 makespan: 1253.35	 Mean_loss: 0.14003780,  training time: 3.79
progress:  89%|[34m [0m| 447/500 [29:17<03:24,  3.85s/it]progress:  90%|[34m [0m| 448/500 [29:17<03:19,  3.83s/it]                                                           Episode 449	 reward: -12.67	 makespan: 1254.30	 Mean_loss: 0.13482377,  training time: 3.84
progress:  90%|[34m [0m| 448/500 [29:21<03:19,  3.83s/it]progress:  90%|[34m [0m| 449/500 [29:21<03:15,  3.84s/it]                                                           Episode 450	 reward: -12.66	 makespan: 1253.45	 Mean_loss: 0.13240960,  training time: 3.76
progress:  90%|[34m [0m| 449/500 [29:24<03:15,  3.84s/it]progress:  90%|[34m [0m| 450/500 [29:24<03:10,  3.81s/it]                                                           Episode 451	 reward: -12.63	 makespan: 1250.75	 Mean_loss: 0.13859616,  training time: 4.69
progress:  90%|[34m [0m| 450/500 [29:29<03:10,  3.81s/it]progress:  90%|[34m [0m| 451/500 [29:29<03:19,  4.08s/it]                                                           Episode 452	 reward: -12.59	 makespan: 1246.80	 Mean_loss: 0.17091738,  training time: 3.74
progress:  90%|[34m [0m| 451/500 [29:33<03:19,  4.08s/it]progress:  90%|[34m [0m| 452/500 [29:33<03:10,  3.97s/it]                                                           Episode 453	 reward: -12.60	 makespan: 1247.25	 Mean_loss: 0.15348141,  training time: 3.74
progress:  90%|[34m [0m| 452/500 [29:37<03:10,  3.97s/it]progress:  91%|[34m [0m| 453/500 [29:37<03:03,  3.90s/it]                                                           Episode 454	 reward: -12.64	 makespan: 1251.75	 Mean_loss: 0.13481435,  training time: 3.73
progress:  91%|[34m [0m| 453/500 [29:40<03:03,  3.90s/it]progress:  91%|[34m [0m| 454/500 [29:40<02:57,  3.85s/it]                                                           Episode 455	 reward: -12.59	 makespan: 1246.30	 Mean_loss: 0.13052809,  training time: 4.43
progress:  91%|[34m [0m| 454/500 [29:45<02:57,  3.85s/it]progress:  91%|[34m [0m| 455/500 [29:45<03:01,  4.03s/it]                                                           Episode 456	 reward: -12.68	 makespan: 1255.80	 Mean_loss: 0.13182893,  training time: 3.77
progress:  91%|[34m [0m| 455/500 [29:48<03:01,  4.03s/it]progress:  91%|[34m [0m| 456/500 [29:49<02:53,  3.95s/it]                                                           Episode 457	 reward: -12.58	 makespan: 1245.35	 Mean_loss: 0.12273382,  training time: 4.58
progress:  91%|[34m [0m| 456/500 [29:53<02:53,  3.95s/it]progress:  91%|[34m[0m| 457/500 [29:53<02:59,  4.16s/it]                                                           Episode 458	 reward: -12.53	 makespan: 1240.65	 Mean_loss: 0.11913320,  training time: 3.79
progress:  91%|[34m[0m| 457/500 [29:57<02:59,  4.16s/it]progress:  92%|[34m[0m| 458/500 [29:57<02:50,  4.06s/it]                                                           Episode 459	 reward: -12.47	 makespan: 1234.95	 Mean_loss: 0.12141746,  training time: 3.74
progress:  92%|[34m[0m| 458/500 [30:01<02:50,  4.06s/it]progress:  92%|[34m[0m| 459/500 [30:01<02:42,  3.97s/it]                                                           Episode 460	 reward: -12.77	 makespan: 1264.35	 Mean_loss: 0.15943797,  training time: 4.09
progress:  92%|[34m[0m| 459/500 [30:05<02:42,  3.97s/it]progress:  92%|[34m[0m| 460/500 [30:05<02:40,  4.00s/it]                                                           Episode 461	 reward: -12.42	 makespan: 1229.40	 Mean_loss: 0.12988652,  training time: 4.03
progress:  92%|[34m[0m| 460/500 [30:09<02:40,  4.00s/it]progress:  92%|[34m[0m| 461/500 [30:09<02:36,  4.01s/it]                                                           Episode 462	 reward: -12.46	 makespan: 1233.30	 Mean_loss: 0.14492419,  training time: 3.75
progress:  92%|[34m[0m| 461/500 [30:13<02:36,  4.01s/it]progress:  92%|[34m[0m| 462/500 [30:13<02:29,  3.93s/it]                                                           Episode 463	 reward: -12.39	 makespan: 1226.75	 Mean_loss: 0.11989437,  training time: 5.22
progress:  92%|[34m[0m| 462/500 [30:18<02:29,  3.93s/it]progress:  93%|[34m[0m| 463/500 [30:18<02:39,  4.32s/it]                                                           Episode 464	 reward: -12.39	 makespan: 1226.40	 Mean_loss: 0.13463131,  training time: 3.78
progress:  93%|[34m[0m| 463/500 [30:22<02:39,  4.32s/it]progress:  93%|[34m[0m| 464/500 [30:22<02:29,  4.16s/it]                                                           Episode 465	 reward: -12.35	 makespan: 1222.65	 Mean_loss: 0.12257080,  training time: 4.65
progress:  93%|[34m[0m| 464/500 [30:26<02:29,  4.16s/it]progress:  93%|[34m[0m| 465/500 [30:26<02:30,  4.31s/it]                                                           Episode 466	 reward: -12.33	 makespan: 1220.65	 Mean_loss: 0.11532836,  training time: 3.91
progress:  93%|[34m[0m| 465/500 [30:30<02:30,  4.31s/it]progress:  93%|[34m[0m| 466/500 [30:30<02:22,  4.19s/it]                                                           Episode 467	 reward: -12.33	 makespan: 1220.35	 Mean_loss: 0.14920847,  training time: 3.84
progress:  93%|[34m[0m| 466/500 [30:34<02:22,  4.19s/it]progress:  93%|[34m[0m| 467/500 [30:34<02:14,  4.08s/it]                                                           Episode 468	 reward: -12.35	 makespan: 1223.10	 Mean_loss: 0.13182530,  training time: 3.84
progress:  93%|[34m[0m| 467/500 [30:38<02:14,  4.08s/it]progress:  94%|[34m[0m| 468/500 [30:38<02:08,  4.01s/it]                                                           Episode 469	 reward: -12.38	 makespan: 1225.60	 Mean_loss: 0.14879927,  training time: 3.80
progress:  94%|[34m[0m| 468/500 [30:42<02:08,  4.01s/it]progress:  94%|[34m[0m| 469/500 [30:42<02:02,  3.95s/it]                                                           Episode 470	 reward: -12.38	 makespan: 1225.25	 Mean_loss: 0.10718139,  training time: 4.10
progress:  94%|[34m[0m| 469/500 [30:46<02:02,  3.95s/it]progress:  94%|[34m[0m| 470/500 [30:46<01:59,  3.99s/it]                                                           Episode 471	 reward: -12.31	 makespan: 1219.00	 Mean_loss: 0.15831974,  training time: 3.87
progress:  94%|[34m[0m| 470/500 [30:50<01:59,  3.99s/it]progress:  94%|[34m[0m| 471/500 [30:50<01:54,  3.96s/it]                                                           Episode 472	 reward: -12.49	 makespan: 1236.80	 Mean_loss: 0.13833828,  training time: 3.80
progress:  94%|[34m[0m| 471/500 [30:53<01:54,  3.96s/it]progress:  94%|[34m[0m| 472/500 [30:53<01:49,  3.91s/it]                                                           Episode 473	 reward: -12.50	 makespan: 1237.60	 Mean_loss: 0.13219923,  training time: 3.78
progress:  94%|[34m[0m| 472/500 [30:57<01:49,  3.91s/it]progress:  95%|[34m[0m| 473/500 [30:57<01:44,  3.87s/it]                                                           Episode 474	 reward: -12.41	 makespan: 1228.50	 Mean_loss: 0.14184457,  training time: 3.76
progress:  95%|[34m[0m| 473/500 [31:01<01:44,  3.87s/it]progress:  95%|[34m[0m| 474/500 [31:01<01:39,  3.84s/it]                                                           Episode 475	 reward: -12.41	 makespan: 1228.15	 Mean_loss: 0.16024604,  training time: 3.86
progress:  95%|[34m[0m| 474/500 [31:05<01:39,  3.84s/it]progress:  95%|[34m[0m| 475/500 [31:05<01:36,  3.85s/it]                                                           Episode 476	 reward: -12.30	 makespan: 1217.30	 Mean_loss: 0.11862567,  training time: 3.86
progress:  95%|[34m[0m| 475/500 [31:09<01:36,  3.85s/it]progress:  95%|[34m[0m| 476/500 [31:09<01:32,  3.85s/it]                                                           Episode 477	 reward: -12.23	 makespan: 1210.90	 Mean_loss: 0.10535771,  training time: 3.83
progress:  95%|[34m[0m| 476/500 [31:13<01:32,  3.85s/it]progress:  95%|[34m[0m| 477/500 [31:13<01:28,  3.85s/it]                                                           Episode 478	 reward: -12.37	 makespan: 1224.15	 Mean_loss: 0.13321483,  training time: 3.78
progress:  95%|[34m[0m| 477/500 [31:16<01:28,  3.85s/it]progress:  96%|[34m[0m| 478/500 [31:16<01:24,  3.83s/it]                                                           Episode 479	 reward: -12.48	 makespan: 1235.20	 Mean_loss: 0.12243710,  training time: 3.82
progress:  96%|[34m[0m| 478/500 [31:20<01:24,  3.83s/it]progress:  96%|[34m[0m| 479/500 [31:20<01:20,  3.83s/it]                                                           Episode 480	 reward: -12.43	 makespan: 1230.45	 Mean_loss: 0.12343144,  training time: 3.93
progress:  96%|[34m[0m| 479/500 [31:24<01:20,  3.83s/it]progress:  96%|[34m[0m| 480/500 [31:24<01:17,  3.86s/it]                                                           Episode 481	 reward: -12.21	 makespan: 1208.45	 Mean_loss: 0.13469452,  training time: 3.97
progress:  96%|[34m[0m| 480/500 [31:28<01:17,  3.86s/it]progress:  96%|[34m[0m| 481/500 [31:28<01:13,  3.89s/it]                                                           Episode 482	 reward: -12.28	 makespan: 1215.70	 Mean_loss: 0.10441407,  training time: 3.73
progress:  96%|[34m[0m| 481/500 [31:32<01:13,  3.89s/it]progress:  96%|[34m[0m| 482/500 [31:32<01:09,  3.84s/it]                                                           Episode 483	 reward: -12.19	 makespan: 1207.30	 Mean_loss: 0.11664779,  training time: 3.94
progress:  96%|[34m[0m| 482/500 [31:36<01:09,  3.84s/it]progress:  97%|[34m[0m| 483/500 [31:36<01:05,  3.87s/it]                                                           Episode 484	 reward: -12.37	 makespan: 1224.40	 Mean_loss: 0.14974122,  training time: 3.78
progress:  97%|[34m[0m| 483/500 [31:39<01:05,  3.87s/it]progress:  97%|[34m[0m| 484/500 [31:39<01:01,  3.85s/it]                                                           Episode 485	 reward: -12.18	 makespan: 1205.65	 Mean_loss: 0.13838950,  training time: 3.79
progress:  97%|[34m[0m| 484/500 [31:43<01:01,  3.85s/it]progress:  97%|[34m[0m| 485/500 [31:43<00:57,  3.83s/it]                                                           Episode 486	 reward: -12.29	 makespan: 1216.80	 Mean_loss: 0.13138770,  training time: 4.04
progress:  97%|[34m[0m| 485/500 [31:47<00:57,  3.83s/it]progress:  97%|[34m[0m| 486/500 [31:47<00:54,  3.89s/it]                                                           Episode 487	 reward: -12.23	 makespan: 1211.25	 Mean_loss: 0.10994973,  training time: 3.72
progress:  97%|[34m[0m| 486/500 [31:51<00:54,  3.89s/it]progress:  97%|[34m[0m| 487/500 [31:51<00:49,  3.84s/it]                                                           Episode 488	 reward: -12.27	 makespan: 1215.15	 Mean_loss: 0.09563598,  training time: 4.14
progress:  97%|[34m[0m| 487/500 [31:55<00:49,  3.84s/it]progress:  98%|[34m[0m| 488/500 [31:55<00:47,  3.93s/it]                                                           Episode 489	 reward: -12.18	 makespan: 1205.45	 Mean_loss: 0.08546784,  training time: 4.41
progress:  98%|[34m[0m| 488/500 [32:00<00:47,  3.93s/it]progress:  98%|[34m[0m| 489/500 [32:00<00:44,  4.08s/it]                                                           Episode 490	 reward: -12.28	 makespan: 1216.10	 Mean_loss: 0.16204809,  training time: 3.74
progress:  98%|[34m[0m| 489/500 [32:03<00:44,  4.08s/it]progress:  98%|[34m[0m| 490/500 [32:03<00:39,  3.98s/it]                                                           Episode 491	 reward: -12.29	 makespan: 1216.25	 Mean_loss: 0.08976875,  training time: 4.04
progress:  98%|[34m[0m| 490/500 [32:07<00:39,  3.98s/it]progress:  98%|[34m[0m| 491/500 [32:07<00:35,  4.00s/it]                                                           Episode 492	 reward: -12.23	 makespan: 1210.40	 Mean_loss: 0.08003820,  training time: 4.95
progress:  98%|[34m[0m| 491/500 [32:12<00:35,  4.00s/it]progress:  98%|[34m[0m| 492/500 [32:12<00:34,  4.28s/it]                                                           Episode 493	 reward: -12.17	 makespan: 1205.20	 Mean_loss: 0.10572788,  training time: 3.92
progress:  98%|[34m[0m| 492/500 [32:16<00:34,  4.28s/it]progress:  99%|[34m[0m| 493/500 [32:16<00:29,  4.18s/it]                                                           Episode 494	 reward: -12.19	 makespan: 1206.35	 Mean_loss: 0.12371708,  training time: 3.80
progress:  99%|[34m[0m| 493/500 [32:20<00:29,  4.18s/it]progress:  99%|[34m[0m| 494/500 [32:20<00:24,  4.06s/it]                                                           Episode 495	 reward: -12.13	 makespan: 1201.15	 Mean_loss: 0.11464413,  training time: 4.00
progress:  99%|[34m[0m| 494/500 [32:24<00:24,  4.06s/it]progress:  99%|[34m[0m| 495/500 [32:24<00:20,  4.04s/it]                                                           Episode 496	 reward: -12.12	 makespan: 1199.95	 Mean_loss: 0.09462507,  training time: 4.18
progress:  99%|[34m[0m| 495/500 [32:28<00:20,  4.04s/it]progress:  99%|[34m[0m| 496/500 [32:28<00:16,  4.09s/it]                                                           Episode 497	 reward: -12.33	 makespan: 1220.25	 Mean_loss: 0.14795384,  training time: 4.31
progress:  99%|[34m[0m| 496/500 [32:33<00:16,  4.09s/it]progress:  99%|[34m[0m| 497/500 [32:33<00:12,  4.15s/it]                                                           Episode 498	 reward: -12.21	 makespan: 1208.60	 Mean_loss: 0.14208083,  training time: 4.02
progress:  99%|[34m[0m| 497/500 [32:37<00:12,  4.15s/it]progress: 100%|[34m[0m| 498/500 [32:37<00:08,  4.11s/it]                                                           Episode 499	 reward: -12.22	 makespan: 1210.15	 Mean_loss: 0.13840877,  training time: 3.81
progress: 100%|[34m[0m| 498/500 [32:40<00:08,  4.11s/it]progress: 100%|[34m[0m| 499/500 [32:40<00:04,  4.02s/it]                                                           Episode 500	 reward: -12.22	 makespan: 1209.90	 Mean_loss: 0.12102673,  training time: 4.37
progress: 100%|[34m[0m| 499/500 [32:45<00:04,  4.02s/it]progress: 100%|[34m[0m| 500/500 [32:45<00:00,  4.13s/it]progress: 100%|[34m[0m| 500/500 [32:45<00:00,  3.93s/it]
+ test_m_op='13,10 10,4 10,12 5,10'
+ n_j=15
+ for model in 15x13+mix+SD2 15x5+mix+SD2
+ echo 13,10 10,4 10,12 5,10
+ tr ' ' '\n'
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2/15x13x10 --model_suffix free --finetuning_model 15x13+mix+SD2 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x13+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2/15x10x4 --model_suffix free --finetuning_model 15x13+mix+SD2 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2/15x10x12 --model_suffix free --finetuning_model 15x13+mix+SD2 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2/15x5x10 --model_suffix free --finetuning_model 15x13+mix+SD2 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x13+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ for model in 15x13+mix+SD2 15x5+mix+SD2
+ echo 13,10 10,4 10,12 5,10
+ tr ' ' '\n'
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2/15x13x10 --model_suffix free --finetuning_model 15x5+mix+SD2 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x5+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2/15x10x4 --model_suffix free --finetuning_model 15x5+mix+SD2 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2/15x10x12 --model_suffix free --finetuning_model 15x5+mix+SD2 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2/15x5x10 --model_suffix free --finetuning_model 15x5+mix+SD2 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 131, in <module>
    main()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 127, in main
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/DAN_finetuning.py", line 39, in train
    state = self.env.set_initial_data(dataset_job_length, dataset_op_pt)
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ IFS=,
+ read n_m op_per_job
+ model_suffix=exp17_1_500_512_3_1
+ logdir_maml=./runs/exp17_1/maml
+ python train/multi_task_maml_exp17.py --logdir ./runs/exp17_1/maml/train_model --model_suffix exp17_1_500_512_3_1 --maml_model True --meta_iterations 500 --num_tasks 4 --max_updates 500 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --n_j_options 15 15 15 15 --n_m_options 13 10 7 5 --op_per_job_options 4 7 10 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/10x5+mix
save model name:  maml+exp17_1_500_512_3_1
self.n_js:  [15, 15, 15, 15]
self.n_m_options:  [13, 10, 7, 5]
self.op_per_job_options:  [4, 7, 10, 12]
Traceback (most recent call last):
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/multi_task_maml_exp17.py", line 98, in <module>
    trainer.train()
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/train/multi_task_maml_exp17.py", line 41, in train
    env.set_initial_data(*self.sample_training_instances(
  File "/work/home/lxx_hzau/project/FJSP-DRL-main/fjsp_env_same_op_nums.py", line 138, in set_initial_data
    self.op_pt = np.array(op_pt_list)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.
+ n_j=15
+ for model in 'maml+$model_suffix'
+ echo 13,10 10,4 10,12 5,10
+ tr ' ' '\n'
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_500_512_3_1/15x13 --model_suffix free --finetuning_model maml+exp17_1_500_512_3_1 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10 ' ' --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
usage: DAN_finetuning.py [-h] [--device DEVICE] [--device_id DEVICE_ID]
                         [--model_suffix MODEL_SUFFIX]
                         [--data_suffix DATA_SUFFIX] [--cover_flag COVER_FLAG]
                         [--cover_data_flag COVER_DATA_FLAG]
                         [--cover_heu_flag COVER_HEU_FLAG]
                         [--cover_train_flag COVER_TRAIN_FLAG]
                         [--model_source MODEL_SOURCE]
                         [--data_source DATA_SOURCE] [--op_per_job OP_PER_JOB]
                         [--op_per_mch_min OP_PER_MCH_MIN]
                         [--op_per_mch_max OP_PER_MCH_MAX]
                         [--data_size DATA_SIZE] [--data_type DATA_TYPE]
                         [--sort_flag SORT_FLAG]
                         [--max_solve_time MAX_SOLVE_TIME]
                         [--seed_datagen SEED_DATAGEN]
                         [--seed_train_vali_datagen SEED_TRAIN_VALI_DATAGEN]
                         [--seed_train SEED_TRAIN] [--seed_test SEED_TEST]
                         [--n_j N_J] [--n_m N_M] [--n_op N_OP] [--low LOW]
                         [--high HIGH]
                         [--n_j_options N_J_OPTIONS [N_J_OPTIONS ...]]
                         [--n_m_options N_M_OPTIONS [N_M_OPTIONS ...]]
                         [--op_per_job_options OP_PER_JOB_OPTIONS [OP_PER_JOB_OPTIONS ...]]
                         [--fea_j_input_dim FEA_J_INPUT_DIM]
                         [--fea_m_input_dim FEA_M_INPUT_DIM]
                         [--dropout_prob DROPOUT_PROB]
                         [--num_heads_OAB NUM_HEADS_OAB [NUM_HEADS_OAB ...]]
                         [--num_heads_MAB NUM_HEADS_MAB [NUM_HEADS_MAB ...]]
                         [--layer_fea_output_dim LAYER_FEA_OUTPUT_DIM [LAYER_FEA_OUTPUT_DIM ...]]
                         [--num_mlp_layers_actor NUM_MLP_LAYERS_ACTOR]
                         [--hidden_dim_actor HIDDEN_DIM_ACTOR]
                         [--num_mlp_layers_critic NUM_MLP_LAYERS_CRITIC]
                         [--hidden_dim_critic HIDDEN_DIM_CRITIC]
                         [--num_envs NUM_ENVS] [--max_updates MAX_UPDATES]
                         [--lr LR] [--gamma GAMMA] [--k_epochs K_EPOCHS]
                         [--eps_clip EPS_CLIP] [--vloss_coef VLOSS_COEF]
                         [--ploss_coef PLOSS_COEF]
                         [--entloss_coef ENTLOSS_COEF] [--tau TAU]
                         [--gae_lambda GAE_LAMBDA] [--train_size TRAIN_SIZE]
                         [--validate_timestep VALIDATE_TIMESTEP]
                         [--reset_env_timestep RESET_ENV_TIMESTEP]
                         [--minibatch_size MINIBATCH_SIZE]
                         [--meta_iterations META_ITERATIONS]
                         [--meta_lr META_LR] [--task_lr TASK_LR]
                         [--adapt_lr ADAPT_LR] [--adapt_steps ADAPT_STEPS]
                         [--adapt_nums ADAPT_NUMS] [--num_tasks NUM_TASKS]
                         [--maml_model MAML_MODEL]
                         [--finetuning_model FINETUNING_MODEL]
                         [--test_data TEST_DATA [TEST_DATA ...]]
                         [--test_mode TEST_MODE] [--sample_times SAMPLE_TIMES]
                         [--test_model TEST_MODEL [TEST_MODEL ...]]
                         [--test_method TEST_METHOD [TEST_METHOD ...]]
                         [--logdir LOGDIR]
DAN_finetuning.py: error: unrecognized arguments:  
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_500_512_3_1/15x10 --model_suffix free --finetuning_model maml+exp17_1_500_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4 ' ' --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
usage: DAN_finetuning.py [-h] [--device DEVICE] [--device_id DEVICE_ID]
                         [--model_suffix MODEL_SUFFIX]
                         [--data_suffix DATA_SUFFIX] [--cover_flag COVER_FLAG]
                         [--cover_data_flag COVER_DATA_FLAG]
                         [--cover_heu_flag COVER_HEU_FLAG]
                         [--cover_train_flag COVER_TRAIN_FLAG]
                         [--model_source MODEL_SOURCE]
                         [--data_source DATA_SOURCE] [--op_per_job OP_PER_JOB]
                         [--op_per_mch_min OP_PER_MCH_MIN]
                         [--op_per_mch_max OP_PER_MCH_MAX]
                         [--data_size DATA_SIZE] [--data_type DATA_TYPE]
                         [--sort_flag SORT_FLAG]
                         [--max_solve_time MAX_SOLVE_TIME]
                         [--seed_datagen SEED_DATAGEN]
                         [--seed_train_vali_datagen SEED_TRAIN_VALI_DATAGEN]
                         [--seed_train SEED_TRAIN] [--seed_test SEED_TEST]
                         [--n_j N_J] [--n_m N_M] [--n_op N_OP] [--low LOW]
                         [--high HIGH]
                         [--n_j_options N_J_OPTIONS [N_J_OPTIONS ...]]
                         [--n_m_options N_M_OPTIONS [N_M_OPTIONS ...]]
                         [--op_per_job_options OP_PER_JOB_OPTIONS [OP_PER_JOB_OPTIONS ...]]
                         [--fea_j_input_dim FEA_J_INPUT_DIM]
                         [--fea_m_input_dim FEA_M_INPUT_DIM]
                         [--dropout_prob DROPOUT_PROB]
                         [--num_heads_OAB NUM_HEADS_OAB [NUM_HEADS_OAB ...]]
                         [--num_heads_MAB NUM_HEADS_MAB [NUM_HEADS_MAB ...]]
                         [--layer_fea_output_dim LAYER_FEA_OUTPUT_DIM [LAYER_FEA_OUTPUT_DIM ...]]
                         [--num_mlp_layers_actor NUM_MLP_LAYERS_ACTOR]
                         [--hidden_dim_actor HIDDEN_DIM_ACTOR]
                         [--num_mlp_layers_critic NUM_MLP_LAYERS_CRITIC]
                         [--hidden_dim_critic HIDDEN_DIM_CRITIC]
                         [--num_envs NUM_ENVS] [--max_updates MAX_UPDATES]
                         [--lr LR] [--gamma GAMMA] [--k_epochs K_EPOCHS]
                         [--eps_clip EPS_CLIP] [--vloss_coef VLOSS_COEF]
                         [--ploss_coef PLOSS_COEF]
                         [--entloss_coef ENTLOSS_COEF] [--tau TAU]
                         [--gae_lambda GAE_LAMBDA] [--train_size TRAIN_SIZE]
                         [--validate_timestep VALIDATE_TIMESTEP]
                         [--reset_env_timestep RESET_ENV_TIMESTEP]
                         [--minibatch_size MINIBATCH_SIZE]
                         [--meta_iterations META_ITERATIONS]
                         [--meta_lr META_LR] [--task_lr TASK_LR]
                         [--adapt_lr ADAPT_LR] [--adapt_steps ADAPT_STEPS]
                         [--adapt_nums ADAPT_NUMS] [--num_tasks NUM_TASKS]
                         [--maml_model MAML_MODEL]
                         [--finetuning_model FINETUNING_MODEL]
                         [--test_data TEST_DATA [TEST_DATA ...]]
                         [--test_mode TEST_MODE] [--sample_times SAMPLE_TIMES]
                         [--test_model TEST_MODEL [TEST_MODEL ...]]
                         [--test_method TEST_METHOD [TEST_METHOD ...]]
                         [--logdir LOGDIR]
DAN_finetuning.py: error: unrecognized arguments:  
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_500_512_3_1/15x10 --model_suffix free --finetuning_model maml+exp17_1_500_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12 ' ' --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
usage: DAN_finetuning.py [-h] [--device DEVICE] [--device_id DEVICE_ID]
                         [--model_suffix MODEL_SUFFIX]
                         [--data_suffix DATA_SUFFIX] [--cover_flag COVER_FLAG]
                         [--cover_data_flag COVER_DATA_FLAG]
                         [--cover_heu_flag COVER_HEU_FLAG]
                         [--cover_train_flag COVER_TRAIN_FLAG]
                         [--model_source MODEL_SOURCE]
                         [--data_source DATA_SOURCE] [--op_per_job OP_PER_JOB]
                         [--op_per_mch_min OP_PER_MCH_MIN]
                         [--op_per_mch_max OP_PER_MCH_MAX]
                         [--data_size DATA_SIZE] [--data_type DATA_TYPE]
                         [--sort_flag SORT_FLAG]
                         [--max_solve_time MAX_SOLVE_TIME]
                         [--seed_datagen SEED_DATAGEN]
                         [--seed_train_vali_datagen SEED_TRAIN_VALI_DATAGEN]
                         [--seed_train SEED_TRAIN] [--seed_test SEED_TEST]
                         [--n_j N_J] [--n_m N_M] [--n_op N_OP] [--low LOW]
                         [--high HIGH]
                         [--n_j_options N_J_OPTIONS [N_J_OPTIONS ...]]
                         [--n_m_options N_M_OPTIONS [N_M_OPTIONS ...]]
                         [--op_per_job_options OP_PER_JOB_OPTIONS [OP_PER_JOB_OPTIONS ...]]
                         [--fea_j_input_dim FEA_J_INPUT_DIM]
                         [--fea_m_input_dim FEA_M_INPUT_DIM]
                         [--dropout_prob DROPOUT_PROB]
                         [--num_heads_OAB NUM_HEADS_OAB [NUM_HEADS_OAB ...]]
                         [--num_heads_MAB NUM_HEADS_MAB [NUM_HEADS_MAB ...]]
                         [--layer_fea_output_dim LAYER_FEA_OUTPUT_DIM [LAYER_FEA_OUTPUT_DIM ...]]
                         [--num_mlp_layers_actor NUM_MLP_LAYERS_ACTOR]
                         [--hidden_dim_actor HIDDEN_DIM_ACTOR]
                         [--num_mlp_layers_critic NUM_MLP_LAYERS_CRITIC]
                         [--hidden_dim_critic HIDDEN_DIM_CRITIC]
                         [--num_envs NUM_ENVS] [--max_updates MAX_UPDATES]
                         [--lr LR] [--gamma GAMMA] [--k_epochs K_EPOCHS]
                         [--eps_clip EPS_CLIP] [--vloss_coef VLOSS_COEF]
                         [--ploss_coef PLOSS_COEF]
                         [--entloss_coef ENTLOSS_COEF] [--tau TAU]
                         [--gae_lambda GAE_LAMBDA] [--train_size TRAIN_SIZE]
                         [--validate_timestep VALIDATE_TIMESTEP]
                         [--reset_env_timestep RESET_ENV_TIMESTEP]
                         [--minibatch_size MINIBATCH_SIZE]
                         [--meta_iterations META_ITERATIONS]
                         [--meta_lr META_LR] [--task_lr TASK_LR]
                         [--adapt_lr ADAPT_LR] [--adapt_steps ADAPT_STEPS]
                         [--adapt_nums ADAPT_NUMS] [--num_tasks NUM_TASKS]
                         [--maml_model MAML_MODEL]
                         [--finetuning_model FINETUNING_MODEL]
                         [--test_data TEST_DATA [TEST_DATA ...]]
                         [--test_mode TEST_MODE] [--sample_times SAMPLE_TIMES]
                         [--test_model TEST_MODEL [TEST_MODEL ...]]
                         [--test_method TEST_METHOD [TEST_METHOD ...]]
                         [--logdir LOGDIR]
DAN_finetuning.py: error: unrecognized arguments:  
+ IFS=,
+ read n_m op_per_job
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_500_512_3_1/15x5 --model_suffix free --finetuning_model maml+exp17_1_500_512_3_1 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10 ' ' --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
usage: DAN_finetuning.py [-h] [--device DEVICE] [--device_id DEVICE_ID]
                         [--model_suffix MODEL_SUFFIX]
                         [--data_suffix DATA_SUFFIX] [--cover_flag COVER_FLAG]
                         [--cover_data_flag COVER_DATA_FLAG]
                         [--cover_heu_flag COVER_HEU_FLAG]
                         [--cover_train_flag COVER_TRAIN_FLAG]
                         [--model_source MODEL_SOURCE]
                         [--data_source DATA_SOURCE] [--op_per_job OP_PER_JOB]
                         [--op_per_mch_min OP_PER_MCH_MIN]
                         [--op_per_mch_max OP_PER_MCH_MAX]
                         [--data_size DATA_SIZE] [--data_type DATA_TYPE]
                         [--sort_flag SORT_FLAG]
                         [--max_solve_time MAX_SOLVE_TIME]
                         [--seed_datagen SEED_DATAGEN]
                         [--seed_train_vali_datagen SEED_TRAIN_VALI_DATAGEN]
                         [--seed_train SEED_TRAIN] [--seed_test SEED_TEST]
                         [--n_j N_J] [--n_m N_M] [--n_op N_OP] [--low LOW]
                         [--high HIGH]
                         [--n_j_options N_J_OPTIONS [N_J_OPTIONS ...]]
                         [--n_m_options N_M_OPTIONS [N_M_OPTIONS ...]]
                         [--op_per_job_options OP_PER_JOB_OPTIONS [OP_PER_JOB_OPTIONS ...]]
                         [--fea_j_input_dim FEA_J_INPUT_DIM]
                         [--fea_m_input_dim FEA_M_INPUT_DIM]
                         [--dropout_prob DROPOUT_PROB]
                         [--num_heads_OAB NUM_HEADS_OAB [NUM_HEADS_OAB ...]]
                         [--num_heads_MAB NUM_HEADS_MAB [NUM_HEADS_MAB ...]]
                         [--layer_fea_output_dim LAYER_FEA_OUTPUT_DIM [LAYER_FEA_OUTPUT_DIM ...]]
                         [--num_mlp_layers_actor NUM_MLP_LAYERS_ACTOR]
                         [--hidden_dim_actor HIDDEN_DIM_ACTOR]
                         [--num_mlp_layers_critic NUM_MLP_LAYERS_CRITIC]
                         [--hidden_dim_critic HIDDEN_DIM_CRITIC]
                         [--num_envs NUM_ENVS] [--max_updates MAX_UPDATES]
                         [--lr LR] [--gamma GAMMA] [--k_epochs K_EPOCHS]
                         [--eps_clip EPS_CLIP] [--vloss_coef VLOSS_COEF]
                         [--ploss_coef PLOSS_COEF]
                         [--entloss_coef ENTLOSS_COEF] [--tau TAU]
                         [--gae_lambda GAE_LAMBDA] [--train_size TRAIN_SIZE]
                         [--validate_timestep VALIDATE_TIMESTEP]
                         [--reset_env_timestep RESET_ENV_TIMESTEP]
                         [--minibatch_size MINIBATCH_SIZE]
                         [--meta_iterations META_ITERATIONS]
                         [--meta_lr META_LR] [--task_lr TASK_LR]
                         [--adapt_lr ADAPT_LR] [--adapt_steps ADAPT_STEPS]
                         [--adapt_nums ADAPT_NUMS] [--num_tasks NUM_TASKS]
                         [--maml_model MAML_MODEL]
                         [--finetuning_model FINETUNING_MODEL]
                         [--test_data TEST_DATA [TEST_DATA ...]]
                         [--test_mode TEST_MODE] [--sample_times SAMPLE_TIMES]
                         [--test_model TEST_MODEL [TEST_MODEL ...]]
                         [--test_method TEST_METHOD [TEST_METHOD ...]]
                         [--logdir LOGDIR]
DAN_finetuning.py: error: unrecognized arguments:  
+ IFS=,
+ read n_m op_per_job

+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/check.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/check.sh
++++ export CHECK_HOME=/opt/hpc/setfreq/
++++ CHECK_HOME=/opt/hpc/setfreq/
++++ export PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 6813 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ exp=exp17_1
+ echo exp17_1
exp17_1
+ cat

->  op_per_job ->
+ n_j_options='15 15 15 15'
+ n_m_options='13 10 7 5'
+ op_per_job_options='4 7 10 12'
+ logdir=./runs/exp17_1
+ hidden_dim_actor=512
+ hidden_dim_critic=512
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ meta_iterations=200
+ max_updates_maml=500
+ num_tasks=4
+ max_updates_finetune=50
+ lr=0.003
+ data='13,4 10,7 7,10 5,12'
+ logdir_dan=./runs/exp17_1/DAN
+ model_suffix=exp17_1_200_512_3_1
+ logdir_maml=./runs/exp17_1/maml
+ n_j=15
+ for model in 'maml+$model_suffix'
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x13_4 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 4 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -2.72	 makespan: 269.00	 Mean_loss: 5.50766706,  training time: 3.65
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:58,  3.65s/it]                                                        Episode 2	 reward: -2.88	 makespan: 285.00	 Mean_loss: 1.41831684,  training time: 1.04
progress:   2%|[34m         [0m| 1/50 [00:04<02:58,  3.65s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:41,  2.12s/it]                                                        Episode 3	 reward: -3.06	 makespan: 302.50	 Mean_loss: 0.62327778,  training time: 1.04
progress:   4%|[34m         [0m| 2/50 [00:05<01:41,  2.12s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:16,  1.62s/it]                                                        Episode 4	 reward: -3.25	 makespan: 321.75	 Mean_loss: 0.38764778,  training time: 1.10
progress:   6%|[34m         [0m| 3/50 [00:06<01:16,  1.62s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:05,  1.42s/it]                                                        Episode 5	 reward: -3.04	 makespan: 301.00	 Mean_loss: 0.39227861,  training time: 1.03
progress:   8%|[34m         [0m| 4/50 [00:07<01:05,  1.42s/it]progress:  10%|[34m         [0m| 5/50 [00:07<00:57,  1.28s/it]                                                        Episode 6	 reward: -3.07	 makespan: 304.25	 Mean_loss: 0.17442331,  training time: 1.06
progress:  10%|[34m         [0m| 5/50 [00:08<00:57,  1.28s/it]progress:  12%|[34m        [0m| 6/50 [00:08<00:52,  1.20s/it]                                                        Episode 7	 reward: -3.41	 makespan: 337.75	 Mean_loss: 0.19064951,  training time: 1.06
progress:  12%|[34m        [0m| 6/50 [00:09<00:52,  1.20s/it]progress:  14%|[34m        [0m| 7/50 [00:09<00:49,  1.16s/it]                                                        Episode 8	 reward: -3.32	 makespan: 328.25	 Mean_loss: 0.12384138,  training time: 1.07
progress:  14%|[34m        [0m| 7/50 [00:11<00:49,  1.16s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:47,  1.13s/it]                                                        Episode 9	 reward: -2.85	 makespan: 282.50	 Mean_loss: 0.07393692,  training time: 1.08
progress:  16%|[34m        [0m| 8/50 [00:12<00:47,  1.13s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:45,  1.11s/it]                                                        Episode 10	 reward: -3.15	 makespan: 311.50	 Mean_loss: 0.06382910,  training time: 1.07
progress:  18%|[34m        [0m| 9/50 [00:13<00:45,  1.11s/it]progress:  20%|[34m        [0m| 10/50 [00:13<00:43,  1.10s/it]                                                         Episode 11	 reward: -3.26	 makespan: 322.75	 Mean_loss: 0.07692036,  training time: 1.07
progress:  20%|[34m        [0m| 10/50 [00:14<00:43,  1.10s/it]progress:  22%|[34m       [0m| 11/50 [00:14<00:42,  1.09s/it]                                                         Episode 12	 reward: -3.33	 makespan: 329.25	 Mean_loss: 0.07228819,  training time: 1.15
progress:  22%|[34m       [0m| 11/50 [00:15<00:42,  1.09s/it]progress:  24%|[34m       [0m| 12/50 [00:15<00:42,  1.11s/it]                                                         Episode 13	 reward: -3.68	 makespan: 364.75	 Mean_loss: 0.19352883,  training time: 1.05
progress:  24%|[34m       [0m| 12/50 [00:16<00:42,  1.11s/it]progress:  26%|[34m       [0m| 13/50 [00:16<00:40,  1.09s/it]                                                         Episode 14	 reward: -3.05	 makespan: 301.75	 Mean_loss: 0.08801901,  training time: 1.07
progress:  26%|[34m       [0m| 13/50 [00:17<00:40,  1.09s/it]progress:  28%|[34m       [0m| 14/50 [00:17<00:39,  1.08s/it]                                                         Episode 15	 reward: -3.76	 makespan: 372.25	 Mean_loss: 0.12809065,  training time: 1.04
progress:  28%|[34m       [0m| 14/50 [00:18<00:39,  1.08s/it]progress:  30%|[34m       [0m| 15/50 [00:18<00:37,  1.07s/it]                                                         Episode 16	 reward: -3.29	 makespan: 325.25	 Mean_loss: 0.07105212,  training time: 1.06
progress:  30%|[34m       [0m| 15/50 [00:19<00:37,  1.07s/it]progress:  32%|[34m      [0m| 16/50 [00:19<00:36,  1.07s/it]                                                         Episode 17	 reward: -3.16	 makespan: 312.50	 Mean_loss: 0.04509457,  training time: 1.05
progress:  32%|[34m      [0m| 16/50 [00:20<00:36,  1.07s/it]progress:  34%|[34m      [0m| 17/50 [00:20<00:35,  1.06s/it]                                                         Episode 18	 reward: -3.31	 makespan: 327.75	 Mean_loss: 0.12256581,  training time: 1.05
progress:  34%|[34m      [0m| 17/50 [00:21<00:35,  1.06s/it]progress:  36%|[34m      [0m| 18/50 [00:21<00:33,  1.06s/it]                                                         Episode 19	 reward: -3.97	 makespan: 393.25	 Mean_loss: 0.09876961,  training time: 1.05
progress:  36%|[34m      [0m| 18/50 [00:22<00:33,  1.06s/it]progress:  38%|[34m      [0m| 19/50 [00:22<00:32,  1.06s/it]                                                         Episode 20	 reward: -3.19	 makespan: 316.25	 Mean_loss: 0.09973922,  training time: 1.06
progress:  38%|[34m      [0m| 19/50 [00:23<00:32,  1.06s/it]progress:  40%|[34m      [0m| 20/50 [00:23<00:31,  1.06s/it]                                                         Episode 21	 reward: -2.83	 makespan: 279.75	 Mean_loss: 0.02782067,  training time: 1.05
progress:  40%|[34m      [0m| 20/50 [00:24<00:31,  1.06s/it]progress:  42%|[34m     [0m| 21/50 [00:24<00:30,  1.06s/it]                                                         Episode 22	 reward: -3.07	 makespan: 304.25	 Mean_loss: 0.06303222,  training time: 1.06
progress:  42%|[34m     [0m| 21/50 [00:25<00:30,  1.06s/it]progress:  44%|[34m     [0m| 22/50 [00:25<00:29,  1.06s/it]                                                         Episode 23	 reward: -3.15	 makespan: 311.75	 Mean_loss: 0.07134648,  training time: 1.05
progress:  44%|[34m     [0m| 22/50 [00:27<00:29,  1.06s/it]progress:  46%|[34m     [0m| 23/50 [00:27<00:28,  1.06s/it]                                                         Episode 24	 reward: -3.02	 makespan: 298.75	 Mean_loss: 0.03287727,  training time: 1.06
progress:  46%|[34m     [0m| 23/50 [00:28<00:28,  1.06s/it]progress:  48%|[34m     [0m| 24/50 [00:28<00:27,  1.06s/it]                                                         Episode 25	 reward: -2.74	 makespan: 271.75	 Mean_loss: 0.03983104,  training time: 1.06
progress:  48%|[34m     [0m| 24/50 [00:29<00:27,  1.06s/it]progress:  50%|[34m     [0m| 25/50 [00:29<00:26,  1.06s/it]                                                         Episode 26	 reward: -3.20	 makespan: 317.25	 Mean_loss: 0.10439864,  training time: 1.05
progress:  50%|[34m     [0m| 25/50 [00:30<00:26,  1.06s/it]progress:  52%|[34m    [0m| 26/50 [00:30<00:25,  1.06s/it]                                                         Episode 27	 reward: -2.91	 makespan: 288.00	 Mean_loss: 0.05314877,  training time: 1.07
progress:  52%|[34m    [0m| 26/50 [00:31<00:25,  1.06s/it]progress:  54%|[34m    [0m| 27/50 [00:31<00:24,  1.06s/it]                                                         Episode 28	 reward: -2.87	 makespan: 284.50	 Mean_loss: 0.03857820,  training time: 1.06
progress:  54%|[34m    [0m| 27/50 [00:32<00:24,  1.06s/it]progress:  56%|[34m    [0m| 28/50 [00:32<00:23,  1.06s/it]                                                         Episode 29	 reward: -3.07	 makespan: 303.75	 Mean_loss: 0.02418035,  training time: 1.14
progress:  56%|[34m    [0m| 28/50 [00:33<00:23,  1.06s/it]progress:  58%|[34m    [0m| 29/50 [00:33<00:22,  1.09s/it]                                                         Episode 30	 reward: -2.93	 makespan: 290.00	 Mean_loss: 0.01402769,  training time: 1.07
progress:  58%|[34m    [0m| 29/50 [00:34<00:22,  1.09s/it]progress:  60%|[34m    [0m| 30/50 [00:34<00:21,  1.08s/it]                                                         Episode 31	 reward: -2.92	 makespan: 289.00	 Mean_loss: 0.03965759,  training time: 1.06
progress:  60%|[34m    [0m| 30/50 [00:35<00:21,  1.08s/it]progress:  62%|[34m   [0m| 31/50 [00:35<00:20,  1.08s/it]                                                         Episode 32	 reward: -2.97	 makespan: 294.25	 Mean_loss: 0.01424013,  training time: 1.06
progress:  62%|[34m   [0m| 31/50 [00:36<00:20,  1.08s/it]progress:  64%|[34m   [0m| 32/50 [00:36<00:19,  1.07s/it]                                                         Episode 33	 reward: -3.34	 makespan: 330.50	 Mean_loss: 0.04976732,  training time: 1.06
progress:  64%|[34m   [0m| 32/50 [00:37<00:19,  1.07s/it]progress:  66%|[34m   [0m| 33/50 [00:37<00:18,  1.07s/it]                                                         Episode 34	 reward: -2.88	 makespan: 284.75	 Mean_loss: 0.02821079,  training time: 1.06
progress:  66%|[34m   [0m| 33/50 [00:38<00:18,  1.07s/it]progress:  68%|[34m   [0m| 34/50 [00:38<00:17,  1.07s/it]                                                         Episode 35	 reward: -2.85	 makespan: 282.25	 Mean_loss: 0.02635819,  training time: 1.07
progress:  68%|[34m   [0m| 34/50 [00:39<00:17,  1.07s/it]progress:  70%|[34m   [0m| 35/50 [00:39<00:16,  1.07s/it]                                                         Episode 36	 reward: -3.10	 makespan: 306.50	 Mean_loss: 0.07950698,  training time: 1.06
progress:  70%|[34m   [0m| 35/50 [00:40<00:16,  1.07s/it]progress:  72%|[34m  [0m| 36/50 [00:40<00:14,  1.07s/it]                                                         Episode 37	 reward: -2.86	 makespan: 282.75	 Mean_loss: 0.03130255,  training time: 1.07
progress:  72%|[34m  [0m| 36/50 [00:42<00:14,  1.07s/it]progress:  74%|[34m  [0m| 37/50 [00:42<00:13,  1.07s/it]                                                         Episode 38	 reward: -3.28	 makespan: 324.50	 Mean_loss: 0.07200441,  training time: 1.07
progress:  74%|[34m  [0m| 37/50 [00:43<00:13,  1.07s/it]progress:  76%|[34m  [0m| 38/50 [00:43<00:12,  1.07s/it]                                                         Episode 39	 reward: -2.73	 makespan: 270.50	 Mean_loss: 0.03742811,  training time: 1.07
progress:  76%|[34m  [0m| 38/50 [00:44<00:12,  1.07s/it]progress:  78%|[34m  [0m| 39/50 [00:44<00:11,  1.07s/it]                                                         Episode 40	 reward: -3.24	 makespan: 321.25	 Mean_loss: 0.05642119,  training time: 1.05
progress:  78%|[34m  [0m| 39/50 [00:45<00:11,  1.07s/it]progress:  80%|[34m  [0m| 40/50 [00:45<00:10,  1.06s/it]                                                         Episode 41	 reward: -2.72	 makespan: 269.00	 Mean_loss: 0.06239424,  training time: 1.06
progress:  80%|[34m  [0m| 40/50 [00:46<00:10,  1.06s/it]progress:  82%|[34m [0m| 41/50 [00:46<00:09,  1.06s/it]                                                         Episode 42	 reward: -2.85	 makespan: 282.50	 Mean_loss: 0.04962096,  training time: 1.06
progress:  82%|[34m [0m| 41/50 [00:47<00:09,  1.06s/it]progress:  84%|[34m [0m| 42/50 [00:47<00:08,  1.06s/it]                                                         Episode 43	 reward: -3.01	 makespan: 297.75	 Mean_loss: 0.03574868,  training time: 1.12
progress:  84%|[34m [0m| 42/50 [00:48<00:08,  1.06s/it]progress:  86%|[34m [0m| 43/50 [00:48<00:07,  1.08s/it]                                                         Episode 44	 reward: -3.00	 makespan: 296.75	 Mean_loss: 0.01866170,  training time: 1.06
progress:  86%|[34m [0m| 43/50 [00:49<00:07,  1.08s/it]progress:  88%|[34m [0m| 44/50 [00:49<00:06,  1.07s/it]                                                         Episode 45	 reward: -2.71	 makespan: 268.75	 Mean_loss: 0.04159693,  training time: 1.06
progress:  88%|[34m [0m| 44/50 [00:50<00:06,  1.07s/it]progress:  90%|[34m [0m| 45/50 [00:50<00:05,  1.07s/it]                                                         Episode 46	 reward: -2.74	 makespan: 271.50	 Mean_loss: 0.02197379,  training time: 1.06
progress:  90%|[34m [0m| 45/50 [00:51<00:05,  1.07s/it]progress:  92%|[34m[0m| 46/50 [00:51<00:04,  1.07s/it]                                                         Episode 47	 reward: -2.62	 makespan: 259.50	 Mean_loss: 0.04013567,  training time: 1.06
progress:  92%|[34m[0m| 46/50 [00:52<00:04,  1.07s/it]progress:  94%|[34m[0m| 47/50 [00:52<00:03,  1.06s/it]                                                         Episode 48	 reward: -2.60	 makespan: 257.00	 Mean_loss: 0.01420275,  training time: 1.07
progress:  94%|[34m[0m| 47/50 [00:53<00:03,  1.06s/it]progress:  96%|[34m[0m| 48/50 [00:53<00:02,  1.07s/it]                                                         Episode 49	 reward: -2.81	 makespan: 278.25	 Mean_loss: 0.01909327,  training time: 1.07
progress:  96%|[34m[0m| 48/50 [00:54<00:02,  1.07s/it]progress:  98%|[34m[0m| 49/50 [00:54<00:01,  1.07s/it]                                                         Episode 50	 reward: -2.92	 makespan: 289.50	 Mean_loss: 0.06307315,  training time: 1.07
progress:  98%|[34m[0m| 49/50 [00:55<00:01,  1.07s/it]progress: 100%|[34m[0m| 50/50 [00:55<00:00,  1.07s/it]progress: 100%|[34m[0m| 50/50 [00:55<00:00,  1.12s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x13_7 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 7 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.60	 makespan: 455.75	 Mean_loss: 4.81687880,  training time: 2.81
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:17,  2.82s/it]                                                        Episode 2	 reward: -4.58	 makespan: 453.25	 Mean_loss: 0.98898792,  training time: 1.73
progress:   2%|[34m         [0m| 1/50 [00:04<02:17,  2.82s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:44,  2.18s/it]                                                        Episode 3	 reward: -4.37	 makespan: 432.50	 Mean_loss: 0.60236561,  training time: 1.76
progress:   4%|[34m         [0m| 2/50 [00:06<01:44,  2.18s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:33,  1.99s/it]                                                        Episode 4	 reward: -4.45	 makespan: 440.25	 Mean_loss: 0.30651647,  training time: 1.74
progress:   6%|[34m         [0m| 3/50 [00:08<01:33,  1.99s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:26,  1.89s/it]                                                        Episode 5	 reward: -4.47	 makespan: 443.00	 Mean_loss: 0.26648793,  training time: 1.74
progress:   8%|[34m         [0m| 4/50 [00:09<01:26,  1.89s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:22,  1.83s/it]                                                        Episode 6	 reward: -4.54	 makespan: 449.00	 Mean_loss: 0.13176073,  training time: 1.72
progress:  10%|[34m         [0m| 5/50 [00:11<01:22,  1.83s/it]progress:  12%|[34m        [0m| 6/50 [00:11<01:19,  1.80s/it]                                                        Episode 7	 reward: -4.58	 makespan: 453.00	 Mean_loss: 0.13674821,  training time: 1.77
progress:  12%|[34m        [0m| 6/50 [00:13<01:19,  1.80s/it]progress:  14%|[34m        [0m| 7/50 [00:13<01:16,  1.79s/it]                                                        Episode 8	 reward: -4.34	 makespan: 429.25	 Mean_loss: 0.07877146,  training time: 1.75
progress:  14%|[34m        [0m| 7/50 [00:15<01:16,  1.79s/it]progress:  16%|[34m        [0m| 8/50 [00:15<01:14,  1.78s/it]                                                        Episode 9	 reward: -4.19	 makespan: 415.25	 Mean_loss: 0.08052595,  training time: 1.76
progress:  16%|[34m        [0m| 8/50 [00:16<01:14,  1.78s/it]progress:  18%|[34m        [0m| 9/50 [00:16<01:12,  1.77s/it]                                                        Episode 10	 reward: -4.43	 makespan: 438.50	 Mean_loss: 0.06786614,  training time: 1.72
progress:  18%|[34m        [0m| 9/50 [00:18<01:12,  1.77s/it]progress:  20%|[34m        [0m| 10/50 [00:18<01:10,  1.76s/it]                                                         Episode 11	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.06312523,  training time: 1.72
progress:  20%|[34m        [0m| 10/50 [00:20<01:10,  1.76s/it]progress:  22%|[34m       [0m| 11/50 [00:20<01:08,  1.74s/it]                                                         Episode 12	 reward: -4.54	 makespan: 449.25	 Mean_loss: 0.04633560,  training time: 1.72
progress:  22%|[34m       [0m| 11/50 [00:21<01:08,  1.74s/it]progress:  24%|[34m       [0m| 12/50 [00:21<01:06,  1.74s/it]                                                         Episode 13	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.05174073,  training time: 1.82
progress:  24%|[34m       [0m| 12/50 [00:23<01:06,  1.74s/it]progress:  26%|[34m       [0m| 13/50 [00:23<01:05,  1.76s/it]                                                         Episode 14	 reward: -4.47	 makespan: 443.00	 Mean_loss: 0.06813431,  training time: 1.72
progress:  26%|[34m       [0m| 13/50 [00:25<01:05,  1.76s/it]progress:  28%|[34m       [0m| 14/50 [00:25<01:02,  1.75s/it]                                                         Episode 15	 reward: -4.29	 makespan: 424.75	 Mean_loss: 0.04372245,  training time: 1.72
progress:  28%|[34m       [0m| 14/50 [00:27<01:02,  1.75s/it]progress:  30%|[34m       [0m| 15/50 [00:27<01:00,  1.74s/it]                                                         Episode 16	 reward: -4.39	 makespan: 434.25	 Mean_loss: 0.04028177,  training time: 1.73
progress:  30%|[34m       [0m| 15/50 [00:28<01:00,  1.74s/it]progress:  32%|[34m      [0m| 16/50 [00:28<00:59,  1.74s/it]                                                         Episode 17	 reward: -4.35	 makespan: 430.50	 Mean_loss: 0.01881420,  training time: 1.73
progress:  32%|[34m      [0m| 16/50 [00:30<00:59,  1.74s/it]progress:  34%|[34m      [0m| 17/50 [00:30<00:57,  1.73s/it]                                                         Episode 18	 reward: -4.27	 makespan: 422.50	 Mean_loss: 0.06495576,  training time: 1.73
progress:  34%|[34m      [0m| 17/50 [00:32<00:57,  1.73s/it]progress:  36%|[34m      [0m| 18/50 [00:32<00:55,  1.73s/it]                                                         Episode 19	 reward: -4.45	 makespan: 440.75	 Mean_loss: 0.04658923,  training time: 1.72
progress:  36%|[34m      [0m| 18/50 [00:34<00:55,  1.73s/it]progress:  38%|[34m      [0m| 19/50 [00:34<00:53,  1.73s/it]                                                         Episode 20	 reward: -4.35	 makespan: 430.50	 Mean_loss: 0.04685410,  training time: 1.78
progress:  38%|[34m      [0m| 19/50 [00:35<00:53,  1.73s/it]progress:  40%|[34m      [0m| 20/50 [00:35<00:52,  1.75s/it]                                                         Episode 21	 reward: -4.06	 makespan: 402.25	 Mean_loss: 0.02073146,  training time: 1.76
progress:  40%|[34m      [0m| 20/50 [00:37<00:52,  1.75s/it]progress:  42%|[34m     [0m| 21/50 [00:37<00:50,  1.75s/it]                                                         Episode 22	 reward: -4.27	 makespan: 423.00	 Mean_loss: 0.02986521,  training time: 1.74
progress:  42%|[34m     [0m| 21/50 [00:39<00:50,  1.75s/it]progress:  44%|[34m     [0m| 22/50 [00:39<00:48,  1.75s/it]                                                         Episode 23	 reward: -4.19	 makespan: 414.50	 Mean_loss: 0.03032570,  training time: 1.73
progress:  44%|[34m     [0m| 22/50 [00:41<00:48,  1.75s/it]progress:  46%|[34m     [0m| 23/50 [00:41<00:46,  1.74s/it]                                                         Episode 24	 reward: -4.59	 makespan: 454.50	 Mean_loss: 0.04072379,  training time: 1.73
progress:  46%|[34m     [0m| 23/50 [00:42<00:46,  1.74s/it]progress:  48%|[34m     [0m| 24/50 [00:42<00:45,  1.74s/it]                                                         Episode 25	 reward: -4.53	 makespan: 448.25	 Mean_loss: 0.05078473,  training time: 1.73
progress:  48%|[34m     [0m| 24/50 [00:44<00:45,  1.74s/it]progress:  50%|[34m     [0m| 25/50 [00:44<00:43,  1.74s/it]                                                         Episode 26	 reward: -4.26	 makespan: 421.25	 Mean_loss: 0.04474508,  training time: 1.73
progress:  50%|[34m     [0m| 25/50 [00:46<00:43,  1.74s/it]progress:  52%|[34m    [0m| 26/50 [00:46<00:41,  1.73s/it]                                                         Episode 27	 reward: -4.25	 makespan: 420.75	 Mean_loss: 0.04623732,  training time: 1.74
progress:  52%|[34m    [0m| 26/50 [00:48<00:41,  1.73s/it]progress:  54%|[34m    [0m| 27/50 [00:48<00:39,  1.74s/it]                                                         Episode 28	 reward: -4.48	 makespan: 443.50	 Mean_loss: 0.04518968,  training time: 1.74
progress:  54%|[34m    [0m| 27/50 [00:49<00:39,  1.74s/it]progress:  56%|[34m    [0m| 28/50 [00:49<00:38,  1.74s/it]                                                         Episode 29	 reward: -4.23	 makespan: 418.75	 Mean_loss: 0.04319225,  training time: 1.73
progress:  56%|[34m    [0m| 28/50 [00:51<00:38,  1.74s/it]progress:  58%|[34m    [0m| 29/50 [00:51<00:36,  1.73s/it]                                                         Episode 30	 reward: -4.31	 makespan: 427.00	 Mean_loss: 0.02471562,  training time: 1.73
progress:  58%|[34m    [0m| 29/50 [00:53<00:36,  1.73s/it]progress:  60%|[34m    [0m| 30/50 [00:53<00:34,  1.73s/it]                                                         Episode 31	 reward: -4.32	 makespan: 427.75	 Mean_loss: 0.02378662,  training time: 1.73
progress:  60%|[34m    [0m| 30/50 [00:54<00:34,  1.73s/it]progress:  62%|[34m   [0m| 31/50 [00:54<00:32,  1.73s/it]                                                         Episode 32	 reward: -4.49	 makespan: 445.00	 Mean_loss: 0.01585594,  training time: 1.73
progress:  62%|[34m   [0m| 31/50 [00:56<00:32,  1.73s/it]progress:  64%|[34m   [0m| 32/50 [00:56<00:31,  1.73s/it]                                                         Episode 33	 reward: -4.34	 makespan: 430.00	 Mean_loss: 0.01757950,  training time: 1.80
progress:  64%|[34m   [0m| 32/50 [00:58<00:31,  1.73s/it]progress:  66%|[34m   [0m| 33/50 [00:58<00:29,  1.75s/it]                                                         Episode 34	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.04885231,  training time: 1.72
progress:  66%|[34m   [0m| 33/50 [01:00<00:29,  1.75s/it]progress:  68%|[34m   [0m| 34/50 [01:00<00:27,  1.74s/it]                                                         Episode 35	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.01972776,  training time: 1.72
progress:  68%|[34m   [0m| 34/50 [01:01<00:27,  1.74s/it]progress:  70%|[34m   [0m| 35/50 [01:01<00:26,  1.74s/it]                                                         Episode 36	 reward: -5.06	 makespan: 500.50	 Mean_loss: 0.03552131,  training time: 1.73
progress:  70%|[34m   [0m| 35/50 [01:03<00:26,  1.74s/it]progress:  72%|[34m  [0m| 36/50 [01:03<00:24,  1.73s/it]                                                         Episode 37	 reward: -4.62	 makespan: 457.00	 Mean_loss: 0.05079176,  training time: 1.72
progress:  72%|[34m  [0m| 36/50 [01:05<00:24,  1.73s/it]progress:  74%|[34m  [0m| 37/50 [01:05<00:22,  1.73s/it]                                                         Episode 38	 reward: -4.78	 makespan: 473.25	 Mean_loss: 0.02554628,  training time: 1.71
progress:  74%|[34m  [0m| 37/50 [01:07<00:22,  1.73s/it]progress:  76%|[34m  [0m| 38/50 [01:07<00:20,  1.72s/it]                                                         Episode 39	 reward: -4.19	 makespan: 414.75	 Mean_loss: 0.05453019,  training time: 1.72
progress:  76%|[34m  [0m| 38/50 [01:08<00:20,  1.72s/it]progress:  78%|[34m  [0m| 39/50 [01:08<00:18,  1.72s/it]                                                         Episode 40	 reward: -5.10	 makespan: 504.75	 Mean_loss: 0.04396408,  training time: 1.72
progress:  78%|[34m  [0m| 39/50 [01:10<00:18,  1.72s/it]progress:  80%|[34m  [0m| 40/50 [01:10<00:17,  1.72s/it]                                                         Episode 41	 reward: -4.84	 makespan: 479.50	 Mean_loss: 0.03056322,  training time: 1.72
progress:  80%|[34m  [0m| 40/50 [01:12<00:17,  1.72s/it]progress:  82%|[34m [0m| 41/50 [01:12<00:15,  1.72s/it]                                                         Episode 42	 reward: -4.95	 makespan: 490.50	 Mean_loss: 0.03359475,  training time: 1.71
progress:  82%|[34m [0m| 41/50 [01:14<00:15,  1.72s/it]progress:  84%|[34m [0m| 42/50 [01:14<00:13,  1.72s/it]                                                         Episode 43	 reward: -4.90	 makespan: 485.00	 Mean_loss: 0.07480285,  training time: 1.72
progress:  84%|[34m [0m| 42/50 [01:15<00:13,  1.72s/it]progress:  86%|[34m [0m| 43/50 [01:15<00:12,  1.72s/it]                                                         Episode 44	 reward: -4.44	 makespan: 440.00	 Mean_loss: 0.03287840,  training time: 1.72
progress:  86%|[34m [0m| 43/50 [01:17<00:12,  1.72s/it]progress:  88%|[34m [0m| 44/50 [01:17<00:10,  1.72s/it]                                                         Episode 45	 reward: -4.85	 makespan: 479.75	 Mean_loss: 0.02505883,  training time: 1.74
progress:  88%|[34m [0m| 44/50 [01:19<00:10,  1.72s/it]progress:  90%|[34m [0m| 45/50 [01:19<00:08,  1.73s/it]                                                         Episode 46	 reward: -5.00	 makespan: 495.25	 Mean_loss: 0.04156807,  training time: 1.73
progress:  90%|[34m [0m| 45/50 [01:20<00:08,  1.73s/it]progress:  92%|[34m[0m| 46/50 [01:20<00:06,  1.73s/it]                                                         Episode 47	 reward: -5.06	 makespan: 500.50	 Mean_loss: 0.05559210,  training time: 1.73
progress:  92%|[34m[0m| 46/50 [01:22<00:06,  1.73s/it]progress:  94%|[34m[0m| 47/50 [01:22<00:05,  1.73s/it]                                                         Episode 48	 reward: -5.30	 makespan: 524.25	 Mean_loss: 0.09132743,  training time: 1.73
progress:  94%|[34m[0m| 47/50 [01:24<00:05,  1.73s/it]progress:  96%|[34m[0m| 48/50 [01:24<00:03,  1.73s/it]                                                         Episode 49	 reward: -4.77	 makespan: 471.75	 Mean_loss: 0.03548466,  training time: 1.72
progress:  96%|[34m[0m| 48/50 [01:26<00:03,  1.73s/it]progress:  98%|[34m[0m| 49/50 [01:26<00:01,  1.73s/it]                                                         Episode 50	 reward: -4.66	 makespan: 461.50	 Mean_loss: 0.04927637,  training time: 1.72
progress:  98%|[34m[0m| 49/50 [01:27<00:01,  1.73s/it]progress: 100%|[34m[0m| 50/50 [01:27<00:00,  1.73s/it]progress: 100%|[34m[0m| 50/50 [01:27<00:00,  1.76s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x13_10 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.06	 makespan: 600.00	 Mean_loss: 4.61228848,  training time: 3.46
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:49,  3.46s/it]                                                        Episode 2	 reward: -6.43	 makespan: 636.50	 Mean_loss: 1.32528639,  training time: 2.54
progress:   2%|[34m         [0m| 1/50 [00:05<02:49,  3.46s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:20,  2.92s/it]                                                        Episode 3	 reward: -5.99	 makespan: 593.25	 Mean_loss: 0.82366991,  training time: 2.45
progress:   4%|[34m         [0m| 2/50 [00:08<02:20,  2.92s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:07,  2.70s/it]                                                        Episode 4	 reward: -5.98	 makespan: 592.00	 Mean_loss: 0.42829591,  training time: 2.45
progress:   6%|[34m         [0m| 3/50 [00:10<02:07,  2.70s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:59,  2.61s/it]                                                        Episode 5	 reward: -6.52	 makespan: 645.75	 Mean_loss: 0.35684770,  training time: 2.45
progress:   8%|[34m         [0m| 4/50 [00:13<01:59,  2.61s/it]progress:  10%|[34m         [0m| 5/50 [00:13<01:54,  2.55s/it]                                                        Episode 6	 reward: -6.01	 makespan: 595.00	 Mean_loss: 0.24548516,  training time: 2.67
progress:  10%|[34m         [0m| 5/50 [00:16<01:54,  2.55s/it]progress:  12%|[34m        [0m| 6/50 [00:16<01:54,  2.59s/it]                                                        Episode 7	 reward: -6.19	 makespan: 613.00	 Mean_loss: 0.10506902,  training time: 2.46
progress:  12%|[34m        [0m| 6/50 [00:18<01:54,  2.59s/it]progress:  14%|[34m        [0m| 7/50 [00:18<01:49,  2.55s/it]                                                        Episode 8	 reward: -6.09	 makespan: 603.25	 Mean_loss: 0.09183811,  training time: 2.47
progress:  14%|[34m        [0m| 7/50 [00:20<01:49,  2.55s/it]progress:  16%|[34m        [0m| 8/50 [00:20<01:45,  2.52s/it]                                                        Episode 9	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.05081920,  training time: 2.45
progress:  16%|[34m        [0m| 8/50 [00:23<01:45,  2.52s/it]progress:  18%|[34m        [0m| 9/50 [00:23<01:42,  2.50s/it]                                                        Episode 10	 reward: -6.03	 makespan: 596.75	 Mean_loss: 0.07531708,  training time: 2.43
progress:  18%|[34m        [0m| 9/50 [00:25<01:42,  2.50s/it]progress:  20%|[34m        [0m| 10/50 [00:25<01:39,  2.48s/it]                                                         Episode 11	 reward: -6.32	 makespan: 625.50	 Mean_loss: 0.07241732,  training time: 2.43
progress:  20%|[34m        [0m| 10/50 [00:28<01:39,  2.48s/it]progress:  22%|[34m       [0m| 11/50 [00:28<01:36,  2.46s/it]                                                         Episode 12	 reward: -6.23	 makespan: 616.75	 Mean_loss: 0.05336445,  training time: 2.43
progress:  22%|[34m       [0m| 11/50 [00:30<01:36,  2.46s/it]progress:  24%|[34m       [0m| 12/50 [00:30<01:33,  2.45s/it]                                                         Episode 13	 reward: -6.24	 makespan: 618.00	 Mean_loss: 0.04989121,  training time: 2.43
progress:  24%|[34m       [0m| 12/50 [00:33<01:33,  2.45s/it]progress:  26%|[34m       [0m| 13/50 [00:33<01:30,  2.45s/it]                                                         Episode 14	 reward: -6.12	 makespan: 606.25	 Mean_loss: 0.05502054,  training time: 2.43
progress:  26%|[34m       [0m| 13/50 [00:35<01:30,  2.45s/it]progress:  28%|[34m       [0m| 14/50 [00:35<01:27,  2.44s/it]                                                         Episode 15	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.05050197,  training time: 2.43
progress:  28%|[34m       [0m| 14/50 [00:37<01:27,  2.44s/it]progress:  30%|[34m       [0m| 15/50 [00:37<01:25,  2.44s/it]                                                         Episode 16	 reward: -6.00	 makespan: 594.25	 Mean_loss: 0.04880738,  training time: 2.44
progress:  30%|[34m       [0m| 15/50 [00:40<01:25,  2.44s/it]progress:  32%|[34m      [0m| 16/50 [00:40<01:22,  2.44s/it]                                                         Episode 17	 reward: -6.09	 makespan: 603.00	 Mean_loss: 0.04064763,  training time: 2.44
progress:  32%|[34m      [0m| 16/50 [00:42<01:22,  2.44s/it]progress:  34%|[34m      [0m| 17/50 [00:42<01:20,  2.44s/it]                                                         Episode 18	 reward: -6.23	 makespan: 616.50	 Mean_loss: 0.05316456,  training time: 2.45
progress:  34%|[34m      [0m| 17/50 [00:45<01:20,  2.44s/it]progress:  36%|[34m      [0m| 18/50 [00:45<01:18,  2.44s/it]                                                         Episode 19	 reward: -6.30	 makespan: 623.75	 Mean_loss: 0.05455377,  training time: 2.42
progress:  36%|[34m      [0m| 18/50 [00:47<01:18,  2.44s/it]progress:  38%|[34m      [0m| 19/50 [00:47<01:15,  2.44s/it]                                                         Episode 20	 reward: -6.14	 makespan: 608.25	 Mean_loss: 0.04581834,  training time: 2.42
progress:  38%|[34m      [0m| 19/50 [00:50<01:15,  2.44s/it]progress:  40%|[34m      [0m| 20/50 [00:50<01:12,  2.43s/it]                                                         Episode 21	 reward: -6.21	 makespan: 614.50	 Mean_loss: 0.04896265,  training time: 2.42
progress:  40%|[34m      [0m| 20/50 [00:52<01:12,  2.43s/it]progress:  42%|[34m     [0m| 21/50 [00:52<01:10,  2.43s/it]                                                         Episode 22	 reward: -6.00	 makespan: 593.75	 Mean_loss: 0.05332167,  training time: 2.42
progress:  42%|[34m     [0m| 21/50 [00:54<01:10,  2.43s/it]progress:  44%|[34m     [0m| 22/50 [00:54<01:07,  2.43s/it]                                                         Episode 23	 reward: -5.83	 makespan: 577.50	 Mean_loss: 0.04851142,  training time: 2.43
progress:  44%|[34m     [0m| 22/50 [00:57<01:07,  2.43s/it]progress:  46%|[34m     [0m| 23/50 [00:57<01:05,  2.43s/it]                                                         Episode 24	 reward: -6.07	 makespan: 601.00	 Mean_loss: 0.04383279,  training time: 2.42
progress:  46%|[34m     [0m| 23/50 [00:59<01:05,  2.43s/it]progress:  48%|[34m     [0m| 24/50 [00:59<01:03,  2.43s/it]                                                         Episode 25	 reward: -5.97	 makespan: 591.50	 Mean_loss: 0.06927980,  training time: 2.41
progress:  48%|[34m     [0m| 24/50 [01:02<01:03,  2.43s/it]progress:  50%|[34m     [0m| 25/50 [01:02<01:00,  2.42s/it]                                                         Episode 26	 reward: -5.82	 makespan: 576.25	 Mean_loss: 0.03526594,  training time: 2.42
progress:  50%|[34m     [0m| 25/50 [01:04<01:00,  2.42s/it]progress:  52%|[34m    [0m| 26/50 [01:04<00:58,  2.42s/it]                                                         Episode 27	 reward: -6.01	 makespan: 595.00	 Mean_loss: 0.04349407,  training time: 2.41
progress:  52%|[34m    [0m| 26/50 [01:07<00:58,  2.42s/it]progress:  54%|[34m    [0m| 27/50 [01:07<00:55,  2.42s/it]                                                         Episode 28	 reward: -5.98	 makespan: 591.75	 Mean_loss: 0.03614295,  training time: 2.42
progress:  54%|[34m    [0m| 27/50 [01:09<00:55,  2.42s/it]progress:  56%|[34m    [0m| 28/50 [01:09<00:53,  2.42s/it]                                                         Episode 29	 reward: -6.27	 makespan: 621.00	 Mean_loss: 0.02954531,  training time: 2.42
progress:  56%|[34m    [0m| 28/50 [01:11<00:53,  2.42s/it]progress:  58%|[34m    [0m| 29/50 [01:11<00:50,  2.42s/it]                                                         Episode 30	 reward: -6.37	 makespan: 630.50	 Mean_loss: 0.04760903,  training time: 2.42
progress:  58%|[34m    [0m| 29/50 [01:14<00:50,  2.42s/it]progress:  60%|[34m    [0m| 30/50 [01:14<00:48,  2.42s/it]                                                         Episode 31	 reward: -6.04	 makespan: 597.50	 Mean_loss: 0.05527397,  training time: 2.42
progress:  60%|[34m    [0m| 30/50 [01:16<00:48,  2.42s/it]progress:  62%|[34m   [0m| 31/50 [01:16<00:45,  2.42s/it]                                                         Episode 32	 reward: -5.95	 makespan: 589.25	 Mean_loss: 0.04756895,  training time: 2.43
progress:  62%|[34m   [0m| 31/50 [01:19<00:45,  2.42s/it]progress:  64%|[34m   [0m| 32/50 [01:19<00:43,  2.42s/it]                                                         Episode 33	 reward: -6.08	 makespan: 602.00	 Mean_loss: 0.06268144,  training time: 2.43
progress:  64%|[34m   [0m| 32/50 [01:21<00:43,  2.42s/it]progress:  66%|[34m   [0m| 33/50 [01:21<00:41,  2.42s/it]                                                         Episode 34	 reward: -6.04	 makespan: 597.75	 Mean_loss: 0.04796181,  training time: 2.41
progress:  66%|[34m   [0m| 33/50 [01:24<00:41,  2.42s/it]progress:  68%|[34m   [0m| 34/50 [01:24<00:38,  2.42s/it]                                                         Episode 35	 reward: -5.78	 makespan: 572.25	 Mean_loss: 0.03976282,  training time: 2.42
progress:  68%|[34m   [0m| 34/50 [01:26<00:38,  2.42s/it]progress:  70%|[34m   [0m| 35/50 [01:26<00:36,  2.42s/it]                                                         Episode 36	 reward: -5.73	 makespan: 567.25	 Mean_loss: 0.03049510,  training time: 2.41
progress:  70%|[34m   [0m| 35/50 [01:28<00:36,  2.42s/it]progress:  72%|[34m  [0m| 36/50 [01:28<00:33,  2.42s/it]                                                         Episode 37	 reward: -6.11	 makespan: 604.75	 Mean_loss: 0.04289044,  training time: 2.41
progress:  72%|[34m  [0m| 36/50 [01:31<00:33,  2.42s/it]progress:  74%|[34m  [0m| 37/50 [01:31<00:31,  2.42s/it]                                                         Episode 38	 reward: -6.06	 makespan: 600.25	 Mean_loss: 0.03261198,  training time: 2.41
progress:  74%|[34m  [0m| 37/50 [01:33<00:31,  2.42s/it]progress:  76%|[34m  [0m| 38/50 [01:33<00:28,  2.42s/it]                                                         Episode 39	 reward: -5.95	 makespan: 589.00	 Mean_loss: 0.02982040,  training time: 2.41
progress:  76%|[34m  [0m| 38/50 [01:36<00:28,  2.42s/it]progress:  78%|[34m  [0m| 39/50 [01:36<00:26,  2.41s/it]                                                         Episode 40	 reward: -5.97	 makespan: 591.25	 Mean_loss: 0.03300405,  training time: 2.42
progress:  78%|[34m  [0m| 39/50 [01:38<00:26,  2.41s/it]progress:  80%|[34m  [0m| 40/50 [01:38<00:24,  2.42s/it]                                                         Episode 41	 reward: -5.94	 makespan: 588.50	 Mean_loss: 0.03237806,  training time: 2.42
progress:  80%|[34m  [0m| 40/50 [01:40<00:24,  2.42s/it]progress:  82%|[34m [0m| 41/50 [01:40<00:21,  2.42s/it]                                                         Episode 42	 reward: -6.52	 makespan: 645.75	 Mean_loss: 0.07100669,  training time: 2.41
progress:  82%|[34m [0m| 41/50 [01:43<00:21,  2.42s/it]progress:  84%|[34m [0m| 42/50 [01:43<00:19,  2.42s/it]                                                         Episode 43	 reward: -5.99	 makespan: 593.25	 Mean_loss: 0.05376056,  training time: 2.42
progress:  84%|[34m [0m| 42/50 [01:45<00:19,  2.42s/it]progress:  86%|[34m [0m| 43/50 [01:45<00:16,  2.42s/it]                                                         Episode 44	 reward: -6.10	 makespan: 603.50	 Mean_loss: 0.03655258,  training time: 2.41
progress:  86%|[34m [0m| 43/50 [01:48<00:16,  2.42s/it]progress:  88%|[34m [0m| 44/50 [01:48<00:14,  2.42s/it]                                                         Episode 45	 reward: -6.04	 makespan: 598.00	 Mean_loss: 0.04120344,  training time: 2.40
progress:  88%|[34m [0m| 44/50 [01:50<00:14,  2.42s/it]progress:  90%|[34m [0m| 45/50 [01:50<00:12,  2.41s/it]                                                         Episode 46	 reward: -6.11	 makespan: 604.50	 Mean_loss: 0.03172969,  training time: 2.41
progress:  90%|[34m [0m| 45/50 [01:53<00:12,  2.41s/it]progress:  92%|[34m[0m| 46/50 [01:53<00:09,  2.41s/it]                                                         Episode 47	 reward: -6.00	 makespan: 593.75	 Mean_loss: 0.03903175,  training time: 2.40
progress:  92%|[34m[0m| 46/50 [01:55<00:09,  2.41s/it]progress:  94%|[34m[0m| 47/50 [01:55<00:07,  2.41s/it]                                                         Episode 48	 reward: -5.89	 makespan: 583.25	 Mean_loss: 0.03442598,  training time: 2.40
progress:  94%|[34m[0m| 47/50 [01:57<00:07,  2.41s/it]progress:  96%|[34m[0m| 48/50 [01:57<00:04,  2.41s/it]                                                         Episode 49	 reward: -6.08	 makespan: 601.75	 Mean_loss: 0.04355040,  training time: 2.42
progress:  96%|[34m[0m| 48/50 [02:00<00:04,  2.41s/it]progress:  98%|[34m[0m| 49/50 [02:00<00:02,  2.41s/it]                                                         Episode 50	 reward: -6.24	 makespan: 617.75	 Mean_loss: 0.06406974,  training time: 2.41
progress:  98%|[34m[0m| 49/50 [02:02<00:02,  2.41s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.41s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.45s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x13_12 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 12 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.35	 makespan: 727.25	 Mean_loss: 6.47462463,  training time: 4.04
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:18,  4.05s/it]                                                        Episode 2	 reward: -7.38	 makespan: 730.25	 Mean_loss: 0.42888585,  training time: 2.89
progress:   2%|[34m         [0m| 1/50 [00:06<03:18,  4.05s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:41,  3.37s/it]                                                        Episode 3	 reward: -7.22	 makespan: 715.25	 Mean_loss: 0.53751719,  training time: 2.94
progress:   4%|[34m         [0m| 2/50 [00:09<02:41,  3.37s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:29,  3.18s/it]                                                        Episode 4	 reward: -7.69	 makespan: 761.00	 Mean_loss: 0.58217877,  training time: 2.92
progress:   6%|[34m         [0m| 3/50 [00:12<02:29,  3.18s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:21,  3.08s/it]                                                        Episode 5	 reward: -7.55	 makespan: 747.25	 Mean_loss: 0.48176247,  training time: 3.01
progress:   8%|[34m         [0m| 4/50 [00:15<02:21,  3.08s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:17,  3.05s/it]                                                        Episode 6	 reward: -6.96	 makespan: 689.25	 Mean_loss: 0.53464746,  training time: 2.89
progress:  10%|[34m         [0m| 5/50 [00:18<02:17,  3.05s/it]progress:  12%|[34m        [0m| 6/50 [00:18<02:12,  3.00s/it]                                                        Episode 7	 reward: -7.30	 makespan: 722.75	 Mean_loss: 0.33364072,  training time: 2.89
progress:  12%|[34m        [0m| 6/50 [00:21<02:12,  3.00s/it]progress:  14%|[34m        [0m| 7/50 [00:21<02:07,  2.96s/it]                                                        Episode 8	 reward: -7.32	 makespan: 724.50	 Mean_loss: 0.31126902,  training time: 2.85
progress:  14%|[34m        [0m| 7/50 [00:24<02:07,  2.96s/it]progress:  16%|[34m        [0m| 8/50 [00:24<02:03,  2.93s/it]                                                        Episode 9	 reward: -7.27	 makespan: 719.25	 Mean_loss: 0.19334239,  training time: 2.86
progress:  16%|[34m        [0m| 8/50 [00:27<02:03,  2.93s/it]progress:  18%|[34m        [0m| 9/50 [00:27<01:59,  2.91s/it]                                                        Episode 10	 reward: -7.14	 makespan: 706.75	 Mean_loss: 0.15029335,  training time: 2.89
progress:  18%|[34m        [0m| 9/50 [00:30<01:59,  2.91s/it]progress:  20%|[34m        [0m| 10/50 [00:30<01:56,  2.90s/it]                                                         Episode 11	 reward: -7.25	 makespan: 717.75	 Mean_loss: 0.10089004,  training time: 2.87
progress:  20%|[34m        [0m| 10/50 [00:33<01:56,  2.90s/it]progress:  22%|[34m       [0m| 11/50 [00:33<01:52,  2.89s/it]                                                         Episode 12	 reward: -7.24	 makespan: 716.50	 Mean_loss: 0.12970272,  training time: 2.85
progress:  22%|[34m       [0m| 11/50 [00:35<01:52,  2.89s/it]progress:  24%|[34m       [0m| 12/50 [00:35<01:49,  2.88s/it]                                                         Episode 13	 reward: -7.99	 makespan: 790.75	 Mean_loss: 0.12508538,  training time: 2.87
progress:  24%|[34m       [0m| 12/50 [00:38<01:49,  2.88s/it]progress:  26%|[34m       [0m| 13/50 [00:38<01:46,  2.88s/it]                                                         Episode 14	 reward: -7.75	 makespan: 767.50	 Mean_loss: 0.14138885,  training time: 2.86
progress:  26%|[34m       [0m| 13/50 [00:41<01:46,  2.88s/it]progress:  28%|[34m       [0m| 14/50 [00:41<01:43,  2.87s/it]                                                         Episode 15	 reward: -7.69	 makespan: 761.00	 Mean_loss: 0.11691872,  training time: 2.86
progress:  28%|[34m       [0m| 14/50 [00:44<01:43,  2.87s/it]progress:  30%|[34m       [0m| 15/50 [00:44<01:40,  2.87s/it]                                                         Episode 16	 reward: -7.61	 makespan: 753.75	 Mean_loss: 0.09787842,  training time: 2.87
progress:  30%|[34m       [0m| 15/50 [00:47<01:40,  2.87s/it]progress:  32%|[34m      [0m| 16/50 [00:47<01:37,  2.87s/it]                                                         Episode 17	 reward: -7.28	 makespan: 720.75	 Mean_loss: 0.08555593,  training time: 2.85
progress:  32%|[34m      [0m| 16/50 [00:50<01:37,  2.87s/it]progress:  34%|[34m      [0m| 17/50 [00:50<01:34,  2.87s/it]                                                         Episode 18	 reward: -7.56	 makespan: 748.50	 Mean_loss: 0.10407502,  training time: 2.85
progress:  34%|[34m      [0m| 17/50 [00:53<01:34,  2.87s/it]progress:  36%|[34m      [0m| 18/50 [00:53<01:31,  2.86s/it]                                                         Episode 19	 reward: -7.45	 makespan: 738.00	 Mean_loss: 0.05364282,  training time: 2.85
progress:  36%|[34m      [0m| 18/50 [00:55<01:31,  2.86s/it]progress:  38%|[34m      [0m| 19/50 [00:55<01:28,  2.86s/it]                                                         Episode 20	 reward: -7.07	 makespan: 700.00	 Mean_loss: 0.07231580,  training time: 2.86
progress:  38%|[34m      [0m| 19/50 [00:58<01:28,  2.86s/it]progress:  40%|[34m      [0m| 20/50 [00:58<01:25,  2.86s/it]                                                         Episode 21	 reward: -7.37	 makespan: 729.50	 Mean_loss: 0.07201994,  training time: 2.85
progress:  40%|[34m      [0m| 20/50 [01:01<01:25,  2.86s/it]progress:  42%|[34m     [0m| 21/50 [01:01<01:22,  2.86s/it]                                                         Episode 22	 reward: -7.68	 makespan: 760.25	 Mean_loss: 0.06715172,  training time: 2.84
progress:  42%|[34m     [0m| 21/50 [01:04<01:22,  2.86s/it]progress:  44%|[34m     [0m| 22/50 [01:04<01:19,  2.85s/it]                                                         Episode 23	 reward: -7.38	 makespan: 731.00	 Mean_loss: 0.06709280,  training time: 2.85
progress:  44%|[34m     [0m| 22/50 [01:07<01:19,  2.85s/it]progress:  46%|[34m     [0m| 23/50 [01:07<01:17,  2.85s/it]                                                         Episode 24	 reward: -7.69	 makespan: 761.75	 Mean_loss: 0.06096073,  training time: 2.85
progress:  46%|[34m     [0m| 23/50 [01:10<01:17,  2.85s/it]progress:  48%|[34m     [0m| 24/50 [01:10<01:14,  2.85s/it]                                                         Episode 25	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.07943104,  training time: 2.84
progress:  48%|[34m     [0m| 24/50 [01:13<01:14,  2.85s/it]progress:  50%|[34m     [0m| 25/50 [01:13<01:11,  2.85s/it]                                                         Episode 26	 reward: -7.37	 makespan: 729.75	 Mean_loss: 0.06040965,  training time: 2.84
progress:  50%|[34m     [0m| 25/50 [01:15<01:11,  2.85s/it]progress:  52%|[34m    [0m| 26/50 [01:15<01:08,  2.85s/it]                                                         Episode 27	 reward: -7.37	 makespan: 729.25	 Mean_loss: 0.04677283,  training time: 2.85
progress:  52%|[34m    [0m| 26/50 [01:18<01:08,  2.85s/it]progress:  54%|[34m    [0m| 27/50 [01:18<01:05,  2.85s/it]                                                         Episode 28	 reward: -7.07	 makespan: 700.00	 Mean_loss: 0.04658008,  training time: 2.86
progress:  54%|[34m    [0m| 27/50 [01:21<01:05,  2.85s/it]progress:  56%|[34m    [0m| 28/50 [01:21<01:02,  2.85s/it]                                                         Episode 29	 reward: -7.19	 makespan: 711.75	 Mean_loss: 0.05180781,  training time: 2.85
progress:  56%|[34m    [0m| 28/50 [01:24<01:02,  2.85s/it]progress:  58%|[34m    [0m| 29/50 [01:24<00:59,  2.85s/it]                                                         Episode 30	 reward: -7.66	 makespan: 758.00	 Mean_loss: 0.06483394,  training time: 2.85
progress:  58%|[34m    [0m| 29/50 [01:27<00:59,  2.85s/it]progress:  60%|[34m    [0m| 30/50 [01:27<00:57,  2.85s/it]                                                         Episode 31	 reward: -7.33	 makespan: 726.00	 Mean_loss: 0.05444607,  training time: 2.85
progress:  60%|[34m    [0m| 30/50 [01:30<00:57,  2.85s/it]progress:  62%|[34m   [0m| 31/50 [01:30<00:54,  2.85s/it]                                                         Episode 32	 reward: -7.41	 makespan: 733.25	 Mean_loss: 0.05603264,  training time: 2.84
progress:  62%|[34m   [0m| 31/50 [01:33<00:54,  2.85s/it]progress:  64%|[34m   [0m| 32/50 [01:33<00:51,  2.85s/it]                                                         Episode 33	 reward: -7.31	 makespan: 723.25	 Mean_loss: 0.05807857,  training time: 2.84
progress:  64%|[34m   [0m| 32/50 [01:35<00:51,  2.85s/it]progress:  66%|[34m   [0m| 33/50 [01:35<00:48,  2.85s/it]                                                         Episode 34	 reward: -7.33	 makespan: 725.25	 Mean_loss: 0.05191673,  training time: 2.85
progress:  66%|[34m   [0m| 33/50 [01:38<00:48,  2.85s/it]progress:  68%|[34m   [0m| 34/50 [01:38<00:45,  2.85s/it]                                                         Episode 35	 reward: -7.34	 makespan: 727.00	 Mean_loss: 0.06421017,  training time: 2.85
progress:  68%|[34m   [0m| 34/50 [01:41<00:45,  2.85s/it]progress:  70%|[34m   [0m| 35/50 [01:41<00:42,  2.85s/it]                                                         Episode 36	 reward: -7.28	 makespan: 720.75	 Mean_loss: 0.05187101,  training time: 2.86
progress:  70%|[34m   [0m| 35/50 [01:44<00:42,  2.85s/it]progress:  72%|[34m  [0m| 36/50 [01:44<00:39,  2.85s/it]                                                         Episode 37	 reward: -6.98	 makespan: 691.00	 Mean_loss: 0.04541316,  training time: 2.84
progress:  72%|[34m  [0m| 36/50 [01:47<00:39,  2.85s/it]progress:  74%|[34m  [0m| 37/50 [01:47<00:37,  2.85s/it]                                                         Episode 38	 reward: -7.26	 makespan: 718.50	 Mean_loss: 0.06995685,  training time: 2.85
progress:  74%|[34m  [0m| 37/50 [01:50<00:37,  2.85s/it]progress:  76%|[34m  [0m| 38/50 [01:50<00:34,  2.85s/it]                                                         Episode 39	 reward: -7.61	 makespan: 753.25	 Mean_loss: 0.07218651,  training time: 2.85
progress:  76%|[34m  [0m| 38/50 [01:52<00:34,  2.85s/it]progress:  78%|[34m  [0m| 39/50 [01:52<00:31,  2.85s/it]                                                         Episode 40	 reward: -7.01	 makespan: 694.25	 Mean_loss: 0.05573435,  training time: 2.83
progress:  78%|[34m  [0m| 39/50 [01:55<00:31,  2.85s/it]progress:  80%|[34m  [0m| 40/50 [01:55<00:28,  2.84s/it]                                                         Episode 41	 reward: -7.04	 makespan: 697.25	 Mean_loss: 0.04664542,  training time: 2.85
progress:  80%|[34m  [0m| 40/50 [01:58<00:28,  2.84s/it]progress:  82%|[34m [0m| 41/50 [01:58<00:25,  2.85s/it]                                                         Episode 42	 reward: -7.03	 makespan: 696.25	 Mean_loss: 0.04954682,  training time: 2.82
progress:  82%|[34m [0m| 41/50 [02:01<00:25,  2.85s/it]progress:  84%|[34m [0m| 42/50 [02:01<00:22,  2.84s/it]                                                         Episode 43	 reward: -7.41	 makespan: 733.50	 Mean_loss: 0.05270414,  training time: 2.84
progress:  84%|[34m [0m| 42/50 [02:04<00:22,  2.84s/it]progress:  86%|[34m [0m| 43/50 [02:04<00:19,  2.84s/it]                                                         Episode 44	 reward: -7.44	 makespan: 737.00	 Mean_loss: 0.04610210,  training time: 2.86
progress:  86%|[34m [0m| 43/50 [02:07<00:19,  2.84s/it]progress:  88%|[34m [0m| 44/50 [02:07<00:17,  2.85s/it]                                                         Episode 45	 reward: -7.33	 makespan: 725.25	 Mean_loss: 0.05249979,  training time: 2.83
progress:  88%|[34m [0m| 44/50 [02:10<00:17,  2.85s/it]progress:  90%|[34m [0m| 45/50 [02:10<00:14,  2.84s/it]                                                         Episode 46	 reward: -7.21	 makespan: 714.25	 Mean_loss: 0.04500268,  training time: 2.85
progress:  90%|[34m [0m| 45/50 [02:12<00:14,  2.84s/it]progress:  92%|[34m[0m| 46/50 [02:12<00:11,  2.85s/it]                                                         Episode 47	 reward: -7.29	 makespan: 721.50	 Mean_loss: 0.05371162,  training time: 2.84
progress:  92%|[34m[0m| 46/50 [02:15<00:11,  2.85s/it]progress:  94%|[34m[0m| 47/50 [02:15<00:08,  2.84s/it]                                                         Episode 48	 reward: -7.20	 makespan: 712.50	 Mean_loss: 0.03302422,  training time: 2.84
progress:  94%|[34m[0m| 47/50 [02:18<00:08,  2.84s/it]progress:  96%|[34m[0m| 48/50 [02:18<00:05,  2.84s/it]                                                         Episode 49	 reward: -7.45	 makespan: 738.00	 Mean_loss: 0.03874706,  training time: 2.85
progress:  96%|[34m[0m| 48/50 [02:21<00:05,  2.84s/it]progress:  98%|[34m[0m| 49/50 [02:21<00:02,  2.85s/it]                                                         Episode 50	 reward: -7.37	 makespan: 729.75	 Mean_loss: 0.05286046,  training time: 2.85
progress:  98%|[34m[0m| 49/50 [02:24<00:02,  2.85s/it]progress: 100%|[34m[0m| 50/50 [02:24<00:00,  2.85s/it]progress: 100%|[34m[0m| 50/50 [02:24<00:00,  2.89s/it]
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x10_4 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -3.21	 makespan: 318.25	 Mean_loss: 5.49899244,  training time: 2.09
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:42,  2.09s/it]                                                        Episode 2	 reward: -3.16	 makespan: 313.00	 Mean_loss: 1.42568040,  training time: 1.02
progress:   2%|[34m         [0m| 1/50 [00:03<01:42,  2.09s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:10,  1.46s/it]                                                        Episode 3	 reward: -3.11	 makespan: 308.00	 Mean_loss: 0.67991364,  training time: 1.04
progress:   4%|[34m         [0m| 2/50 [00:04<01:10,  1.46s/it]progress:   6%|[34m         [0m| 3/50 [00:04<00:59,  1.27s/it]                                                        Episode 4	 reward: -2.92	 makespan: 289.25	 Mean_loss: 0.50998843,  training time: 1.05
progress:   6%|[34m         [0m| 3/50 [00:05<00:59,  1.27s/it]progress:   8%|[34m         [0m| 4/50 [00:05<00:54,  1.18s/it]                                                        Episode 5	 reward: -2.98	 makespan: 295.25	 Mean_loss: 0.38861763,  training time: 1.05
progress:   8%|[34m         [0m| 4/50 [00:06<00:54,  1.18s/it]progress:  10%|[34m         [0m| 5/50 [00:06<00:51,  1.14s/it]                                                        Episode 6	 reward: -3.28	 makespan: 324.25	 Mean_loss: 0.20177151,  training time: 1.04
progress:  10%|[34m         [0m| 5/50 [00:07<00:51,  1.14s/it]progress:  12%|[34m        [0m| 6/50 [00:07<00:48,  1.10s/it]                                                        Episode 7	 reward: -3.37	 makespan: 333.50	 Mean_loss: 0.23031490,  training time: 1.04
progress:  12%|[34m        [0m| 6/50 [00:08<00:48,  1.10s/it]progress:  14%|[34m        [0m| 7/50 [00:08<00:46,  1.08s/it]                                                        Episode 8	 reward: -2.78	 makespan: 275.25	 Mean_loss: 0.13949391,  training time: 1.04
progress:  14%|[34m        [0m| 7/50 [00:09<00:46,  1.08s/it]progress:  16%|[34m        [0m| 8/50 [00:09<00:44,  1.07s/it]                                                        Episode 9	 reward: -2.87	 makespan: 284.00	 Mean_loss: 0.06333502,  training time: 1.04
progress:  16%|[34m        [0m| 8/50 [00:10<00:44,  1.07s/it]progress:  18%|[34m        [0m| 9/50 [00:10<00:43,  1.06s/it]                                                        Episode 10	 reward: -2.77	 makespan: 273.75	 Mean_loss: 0.05486588,  training time: 1.04
progress:  18%|[34m        [0m| 9/50 [00:11<00:43,  1.06s/it]progress:  20%|[34m        [0m| 10/50 [00:11<00:42,  1.05s/it]                                                         Episode 11	 reward: -3.02	 makespan: 299.00	 Mean_loss: 0.04827074,  training time: 1.04
progress:  20%|[34m        [0m| 10/50 [00:12<00:42,  1.05s/it]progress:  22%|[34m       [0m| 11/50 [00:12<00:40,  1.05s/it]                                                         Episode 12	 reward: -3.18	 makespan: 314.50	 Mean_loss: 0.04006577,  training time: 1.16
progress:  22%|[34m       [0m| 11/50 [00:13<00:40,  1.05s/it]progress:  24%|[34m       [0m| 12/50 [00:13<00:41,  1.08s/it]                                                         Episode 13	 reward: -3.10	 makespan: 307.25	 Mean_loss: 0.06547741,  training time: 1.01
progress:  24%|[34m       [0m| 12/50 [00:14<00:41,  1.08s/it]progress:  26%|[34m       [0m| 13/50 [00:14<00:39,  1.06s/it]                                                         Episode 14	 reward: -2.94	 makespan: 291.00	 Mean_loss: 0.03180526,  training time: 1.04
progress:  26%|[34m       [0m| 13/50 [00:15<00:39,  1.06s/it]progress:  28%|[34m       [0m| 14/50 [00:15<00:38,  1.06s/it]                                                         Episode 15	 reward: -3.14	 makespan: 310.50	 Mean_loss: 0.05693264,  training time: 1.03
progress:  28%|[34m       [0m| 14/50 [00:16<00:38,  1.06s/it]progress:  30%|[34m       [0m| 15/50 [00:16<00:36,  1.05s/it]                                                         Episode 16	 reward: -3.38	 makespan: 335.00	 Mean_loss: 0.10036767,  training time: 1.03
progress:  30%|[34m       [0m| 15/50 [00:17<00:36,  1.05s/it]progress:  32%|[34m      [0m| 16/50 [00:17<00:35,  1.04s/it]                                                         Episode 17	 reward: -2.98	 makespan: 295.25	 Mean_loss: 0.03720424,  training time: 1.05
progress:  32%|[34m      [0m| 16/50 [00:18<00:35,  1.04s/it]progress:  34%|[34m      [0m| 17/50 [00:18<00:34,  1.04s/it]                                                         Episode 18	 reward: -2.96	 makespan: 293.00	 Mean_loss: 0.03489861,  training time: 1.06
progress:  34%|[34m      [0m| 17/50 [00:19<00:34,  1.04s/it]progress:  36%|[34m      [0m| 18/50 [00:19<00:33,  1.05s/it]                                                         Episode 19	 reward: -2.95	 makespan: 292.50	 Mean_loss: 0.02805145,  training time: 1.05
progress:  36%|[34m      [0m| 18/50 [00:20<00:33,  1.05s/it]progress:  38%|[34m      [0m| 19/50 [00:20<00:32,  1.05s/it]                                                         Episode 20	 reward: -2.89	 makespan: 286.00	 Mean_loss: 0.02825484,  training time: 1.05
progress:  38%|[34m      [0m| 19/50 [00:21<00:32,  1.05s/it]progress:  40%|[34m      [0m| 20/50 [00:21<00:31,  1.05s/it]                                                         Episode 21	 reward: -2.90	 makespan: 287.50	 Mean_loss: 0.04830256,  training time: 1.04
progress:  40%|[34m      [0m| 20/50 [00:23<00:31,  1.05s/it]progress:  42%|[34m     [0m| 21/50 [00:23<00:30,  1.05s/it]                                                         Episode 22	 reward: -2.90	 makespan: 287.25	 Mean_loss: 0.02355456,  training time: 1.06
progress:  42%|[34m     [0m| 21/50 [00:24<00:30,  1.05s/it]progress:  44%|[34m     [0m| 22/50 [00:24<00:29,  1.05s/it]                                                         Episode 23	 reward: -3.26	 makespan: 322.50	 Mean_loss: 0.05726051,  training time: 1.04
progress:  44%|[34m     [0m| 22/50 [00:25<00:29,  1.05s/it]progress:  46%|[34m     [0m| 23/50 [00:25<00:28,  1.05s/it]                                                         Episode 24	 reward: -3.12	 makespan: 309.00	 Mean_loss: 0.02145856,  training time: 1.06
progress:  46%|[34m     [0m| 23/50 [00:26<00:28,  1.05s/it]progress:  48%|[34m     [0m| 24/50 [00:26<00:27,  1.05s/it]                                                         Episode 25	 reward: -2.82	 makespan: 279.25	 Mean_loss: 0.03280611,  training time: 1.05
progress:  48%|[34m     [0m| 24/50 [00:27<00:27,  1.05s/it]progress:  50%|[34m     [0m| 25/50 [00:27<00:26,  1.05s/it]                                                         Episode 26	 reward: -3.00	 makespan: 297.25	 Mean_loss: 0.03641555,  training time: 1.05
progress:  50%|[34m     [0m| 25/50 [00:28<00:26,  1.05s/it]progress:  52%|[34m    [0m| 26/50 [00:28<00:25,  1.05s/it]                                                         Episode 27	 reward: -3.02	 makespan: 298.75	 Mean_loss: 0.02929453,  training time: 1.05
progress:  52%|[34m    [0m| 26/50 [00:29<00:25,  1.05s/it]progress:  54%|[34m    [0m| 27/50 [00:29<00:24,  1.05s/it]                                                         Episode 28	 reward: -2.76	 makespan: 273.00	 Mean_loss: 0.01309021,  training time: 1.04
progress:  54%|[34m    [0m| 27/50 [00:30<00:24,  1.05s/it]progress:  56%|[34m    [0m| 28/50 [00:30<00:23,  1.05s/it]                                                         Episode 29	 reward: -3.02	 makespan: 298.75	 Mean_loss: 0.04414127,  training time: 1.05
progress:  56%|[34m    [0m| 28/50 [00:31<00:23,  1.05s/it]progress:  58%|[34m    [0m| 29/50 [00:31<00:22,  1.05s/it]                                                         Episode 30	 reward: -2.90	 makespan: 287.50	 Mean_loss: 0.02559029,  training time: 1.05
progress:  58%|[34m    [0m| 29/50 [00:32<00:22,  1.05s/it]progress:  60%|[34m    [0m| 30/50 [00:32<00:21,  1.05s/it]                                                         Episode 31	 reward: -2.91	 makespan: 288.25	 Mean_loss: 0.01277982,  training time: 1.05
progress:  60%|[34m    [0m| 30/50 [00:33<00:21,  1.05s/it]progress:  62%|[34m   [0m| 31/50 [00:33<00:19,  1.05s/it]                                                         Episode 32	 reward: -2.87	 makespan: 283.75	 Mean_loss: 0.01506629,  training time: 1.05
progress:  62%|[34m   [0m| 31/50 [00:34<00:19,  1.05s/it]progress:  64%|[34m   [0m| 32/50 [00:34<00:18,  1.05s/it]                                                         Episode 33	 reward: -2.93	 makespan: 290.25	 Mean_loss: 0.02615289,  training time: 1.05
progress:  64%|[34m   [0m| 32/50 [00:35<00:18,  1.05s/it]progress:  66%|[34m   [0m| 33/50 [00:35<00:17,  1.05s/it]                                                         Episode 34	 reward: -3.31	 makespan: 327.50	 Mean_loss: 0.07253930,  training time: 1.06
progress:  66%|[34m   [0m| 33/50 [00:36<00:17,  1.05s/it]progress:  68%|[34m   [0m| 34/50 [00:36<00:16,  1.05s/it]                                                         Episode 35	 reward: -2.97	 makespan: 294.25	 Mean_loss: 0.03369401,  training time: 1.06
progress:  68%|[34m   [0m| 34/50 [00:37<00:16,  1.05s/it]progress:  70%|[34m   [0m| 35/50 [00:37<00:15,  1.05s/it]                                                         Episode 36	 reward: -3.07	 makespan: 304.00	 Mean_loss: 0.02992952,  training time: 1.08
progress:  70%|[34m   [0m| 35/50 [00:38<00:15,  1.05s/it]progress:  72%|[34m  [0m| 36/50 [00:38<00:14,  1.06s/it]                                                         Episode 37	 reward: -2.85	 makespan: 281.75	 Mean_loss: 0.03411505,  training time: 1.06
progress:  72%|[34m  [0m| 36/50 [00:39<00:14,  1.06s/it]progress:  74%|[34m  [0m| 37/50 [00:39<00:13,  1.06s/it]                                                         Episode 38	 reward: -3.30	 makespan: 326.25	 Mean_loss: 0.11657348,  training time: 1.06
progress:  74%|[34m  [0m| 37/50 [00:40<00:13,  1.06s/it]progress:  76%|[34m  [0m| 38/50 [00:40<00:12,  1.06s/it]                                                         Episode 39	 reward: -3.03	 makespan: 299.50	 Mean_loss: 0.04003610,  training time: 1.05
progress:  76%|[34m  [0m| 38/50 [00:42<00:12,  1.06s/it]progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.06s/it]                                                         Episode 40	 reward: -2.80	 makespan: 277.00	 Mean_loss: 0.03599456,  training time: 1.05
progress:  78%|[34m  [0m| 39/50 [00:43<00:11,  1.06s/it]progress:  80%|[34m  [0m| 40/50 [00:43<00:10,  1.06s/it]                                                         Episode 41	 reward: -2.98	 makespan: 294.75	 Mean_loss: 0.02036500,  training time: 1.05
progress:  80%|[34m  [0m| 40/50 [00:44<00:10,  1.06s/it]progress:  82%|[34m [0m| 41/50 [00:44<00:09,  1.06s/it]                                                         Episode 42	 reward: -2.96	 makespan: 293.00	 Mean_loss: 0.03590210,  training time: 1.04
progress:  82%|[34m [0m| 41/50 [00:45<00:09,  1.06s/it]progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.05s/it]                                                         Episode 43	 reward: -2.84	 makespan: 281.00	 Mean_loss: 0.02977238,  training time: 1.05
progress:  84%|[34m [0m| 42/50 [00:46<00:08,  1.05s/it]progress:  86%|[34m [0m| 43/50 [00:46<00:07,  1.05s/it]                                                         Episode 44	 reward: -2.95	 makespan: 292.50	 Mean_loss: 0.00956286,  training time: 1.04
progress:  86%|[34m [0m| 43/50 [00:47<00:07,  1.05s/it]progress:  88%|[34m [0m| 44/50 [00:47<00:06,  1.05s/it]                                                         Episode 45	 reward: -3.08	 makespan: 304.75	 Mean_loss: 0.01791370,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:48<00:06,  1.05s/it]progress:  90%|[34m [0m| 45/50 [00:48<00:05,  1.05s/it]                                                         Episode 46	 reward: -2.86	 makespan: 283.25	 Mean_loss: 0.03677376,  training time: 1.05
progress:  90%|[34m [0m| 45/50 [00:49<00:05,  1.05s/it]progress:  92%|[34m[0m| 46/50 [00:49<00:04,  1.05s/it]                                                         Episode 47	 reward: -2.96	 makespan: 293.50	 Mean_loss: 0.02226395,  training time: 1.05
progress:  92%|[34m[0m| 46/50 [00:50<00:04,  1.05s/it]progress:  94%|[34m[0m| 47/50 [00:50<00:03,  1.05s/it]                                                         Episode 48	 reward: -3.13	 makespan: 310.00	 Mean_loss: 0.05124054,  training time: 1.06
progress:  94%|[34m[0m| 47/50 [00:51<00:03,  1.05s/it]progress:  96%|[34m[0m| 48/50 [00:51<00:02,  1.05s/it]                                                         Episode 49	 reward: -3.04	 makespan: 301.00	 Mean_loss: 0.03123982,  training time: 1.07
progress:  96%|[34m[0m| 48/50 [00:52<00:02,  1.05s/it]progress:  98%|[34m[0m| 49/50 [00:52<00:01,  1.06s/it]                                                         Episode 50	 reward: -2.90	 makespan: 287.00	 Mean_loss: 0.02333232,  training time: 1.05
progress:  98%|[34m[0m| 49/50 [00:53<00:01,  1.06s/it]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.05s/it]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.07s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x10_7 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 7 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.35	 makespan: 529.50	 Mean_loss: 5.17546415,  training time: 2.83
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:18,  2.83s/it]                                                        Episode 2	 reward: -5.85	 makespan: 579.00	 Mean_loss: 1.32580769,  training time: 1.71
progress:   2%|[34m         [0m| 1/50 [00:04<02:18,  2.83s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:44,  2.17s/it]                                                        Episode 3	 reward: -6.02	 makespan: 596.25	 Mean_loss: 1.00862443,  training time: 1.71
progress:   4%|[34m         [0m| 2/50 [00:06<01:44,  2.17s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:32,  1.96s/it]                                                        Episode 4	 reward: -5.90	 makespan: 584.25	 Mean_loss: 0.60324210,  training time: 1.72
progress:   6%|[34m         [0m| 3/50 [00:07<01:32,  1.96s/it]progress:   8%|[34m         [0m| 4/50 [00:07<01:26,  1.87s/it]                                                        Episode 5	 reward: -6.44	 makespan: 637.50	 Mean_loss: 0.42529500,  training time: 1.73
progress:   8%|[34m         [0m| 4/50 [00:09<01:26,  1.87s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:21,  1.82s/it]                                                        Episode 6	 reward: -6.36	 makespan: 629.75	 Mean_loss: 0.25973409,  training time: 1.71
progress:  10%|[34m         [0m| 5/50 [00:11<01:21,  1.82s/it]progress:  12%|[34m        [0m| 6/50 [00:11<01:18,  1.78s/it]                                                        Episode 7	 reward: -5.89	 makespan: 583.25	 Mean_loss: 0.18164068,  training time: 1.72
progress:  12%|[34m        [0m| 6/50 [00:13<01:18,  1.78s/it]progress:  14%|[34m        [0m| 7/50 [00:13<01:15,  1.76s/it]                                                        Episode 8	 reward: -6.14	 makespan: 607.75	 Mean_loss: 0.19243443,  training time: 1.73
progress:  14%|[34m        [0m| 7/50 [00:14<01:15,  1.76s/it]progress:  16%|[34m        [0m| 8/50 [00:14<01:13,  1.75s/it]                                                        Episode 9	 reward: -5.77	 makespan: 571.00	 Mean_loss: 0.19204453,  training time: 1.72
progress:  16%|[34m        [0m| 8/50 [00:16<01:13,  1.75s/it]progress:  18%|[34m        [0m| 9/50 [00:16<01:11,  1.74s/it]                                                        Episode 10	 reward: -5.51	 makespan: 545.25	 Mean_loss: 0.14513645,  training time: 1.73
progress:  18%|[34m        [0m| 9/50 [00:18<01:11,  1.74s/it]progress:  20%|[34m        [0m| 10/50 [00:18<01:09,  1.74s/it]                                                         Episode 11	 reward: -6.20	 makespan: 613.75	 Mean_loss: 0.17356789,  training time: 1.71
progress:  20%|[34m        [0m| 10/50 [00:20<01:09,  1.74s/it]progress:  22%|[34m       [0m| 11/50 [00:20<01:07,  1.73s/it]                                                         Episode 12	 reward: -5.92	 makespan: 586.50	 Mean_loss: 0.09845515,  training time: 1.72
progress:  22%|[34m       [0m| 11/50 [00:21<01:07,  1.73s/it]progress:  24%|[34m       [0m| 12/50 [00:21<01:05,  1.73s/it]                                                         Episode 13	 reward: -5.83	 makespan: 576.75	 Mean_loss: 0.12327216,  training time: 1.85
progress:  24%|[34m       [0m| 12/50 [00:23<01:05,  1.73s/it]progress:  26%|[34m       [0m| 13/50 [00:23<01:05,  1.76s/it]                                                         Episode 14	 reward: -5.71	 makespan: 565.00	 Mean_loss: 0.09347688,  training time: 1.73
progress:  26%|[34m       [0m| 13/50 [00:25<01:05,  1.76s/it]progress:  28%|[34m       [0m| 14/50 [00:25<01:03,  1.75s/it]                                                         Episode 15	 reward: -5.77	 makespan: 571.25	 Mean_loss: 0.11092465,  training time: 1.84
progress:  28%|[34m       [0m| 14/50 [00:27<01:03,  1.75s/it]progress:  30%|[34m       [0m| 15/50 [00:27<01:02,  1.78s/it]                                                         Episode 16	 reward: -6.00	 makespan: 593.75	 Mean_loss: 0.09735718,  training time: 1.70
progress:  30%|[34m       [0m| 15/50 [00:28<01:02,  1.78s/it]progress:  32%|[34m      [0m| 16/50 [00:28<00:59,  1.76s/it]                                                         Episode 17	 reward: -6.43	 makespan: 637.00	 Mean_loss: 0.11656008,  training time: 1.72
progress:  32%|[34m      [0m| 16/50 [00:30<00:59,  1.76s/it]progress:  34%|[34m      [0m| 17/50 [00:30<00:57,  1.75s/it]                                                         Episode 18	 reward: -6.15	 makespan: 609.25	 Mean_loss: 0.08526249,  training time: 1.70
progress:  34%|[34m      [0m| 17/50 [00:32<00:57,  1.75s/it]progress:  36%|[34m      [0m| 18/50 [00:32<00:55,  1.73s/it]                                                         Episode 19	 reward: -5.54	 makespan: 548.50	 Mean_loss: 0.11801057,  training time: 1.84
progress:  36%|[34m      [0m| 18/50 [00:34<00:55,  1.73s/it]progress:  38%|[34m      [0m| 19/50 [00:34<00:54,  1.76s/it]                                                         Episode 20	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.08589171,  training time: 1.77
progress:  38%|[34m      [0m| 19/50 [00:35<00:54,  1.76s/it]progress:  40%|[34m      [0m| 20/50 [00:35<00:52,  1.77s/it]                                                         Episode 21	 reward: -6.03	 makespan: 597.25	 Mean_loss: 0.10530119,  training time: 1.73
progress:  40%|[34m      [0m| 20/50 [00:37<00:52,  1.77s/it]progress:  42%|[34m     [0m| 21/50 [00:37<00:50,  1.75s/it]                                                         Episode 22	 reward: -5.29	 makespan: 524.00	 Mean_loss: 0.09266711,  training time: 1.71
progress:  42%|[34m     [0m| 21/50 [00:39<00:50,  1.75s/it]progress:  44%|[34m     [0m| 22/50 [00:39<00:48,  1.74s/it]                                                         Episode 23	 reward: -5.06	 makespan: 500.50	 Mean_loss: 0.05826206,  training time: 1.79
progress:  44%|[34m     [0m| 22/50 [00:41<00:48,  1.74s/it]progress:  46%|[34m     [0m| 23/50 [00:41<00:47,  1.76s/it]                                                         Episode 24	 reward: -4.81	 makespan: 476.50	 Mean_loss: 0.08426748,  training time: 1.71
progress:  46%|[34m     [0m| 23/50 [00:42<00:47,  1.76s/it]progress:  48%|[34m     [0m| 24/50 [00:42<00:45,  1.74s/it]                                                         Episode 25	 reward: -5.47	 makespan: 541.75	 Mean_loss: 0.10134479,  training time: 1.71
progress:  48%|[34m     [0m| 24/50 [00:44<00:45,  1.74s/it]progress:  50%|[34m     [0m| 25/50 [00:44<00:43,  1.73s/it]                                                         Episode 26	 reward: -5.40	 makespan: 534.75	 Mean_loss: 0.05583316,  training time: 1.78
progress:  50%|[34m     [0m| 25/50 [00:46<00:43,  1.73s/it]progress:  52%|[34m    [0m| 26/50 [00:46<00:41,  1.75s/it]                                                         Episode 27	 reward: -5.28	 makespan: 522.75	 Mean_loss: 0.05061331,  training time: 1.70
progress:  52%|[34m    [0m| 26/50 [00:48<00:41,  1.75s/it]progress:  54%|[34m    [0m| 27/50 [00:48<00:39,  1.73s/it]                                                         Episode 28	 reward: -5.24	 makespan: 519.25	 Mean_loss: 0.03565999,  training time: 1.71
progress:  54%|[34m    [0m| 27/50 [00:49<00:39,  1.73s/it]progress:  56%|[34m    [0m| 28/50 [00:49<00:37,  1.73s/it]                                                         Episode 29	 reward: -5.08	 makespan: 502.75	 Mean_loss: 0.05234266,  training time: 1.69
progress:  56%|[34m    [0m| 28/50 [00:51<00:37,  1.73s/it]progress:  58%|[34m    [0m| 29/50 [00:51<00:36,  1.72s/it]                                                         Episode 30	 reward: -5.41	 makespan: 535.50	 Mean_loss: 0.05379241,  training time: 1.70
progress:  58%|[34m    [0m| 29/50 [00:53<00:36,  1.72s/it]progress:  60%|[34m    [0m| 30/50 [00:53<00:34,  1.71s/it]                                                         Episode 31	 reward: -5.38	 makespan: 532.25	 Mean_loss: 0.03466230,  training time: 1.70
progress:  60%|[34m    [0m| 30/50 [00:54<00:34,  1.71s/it]progress:  62%|[34m   [0m| 31/50 [00:54<00:32,  1.71s/it]                                                         Episode 32	 reward: -5.06	 makespan: 501.00	 Mean_loss: 0.04921799,  training time: 1.76
progress:  62%|[34m   [0m| 31/50 [00:56<00:32,  1.71s/it]progress:  64%|[34m   [0m| 32/50 [00:56<00:31,  1.73s/it]                                                         Episode 33	 reward: -5.01	 makespan: 496.25	 Mean_loss: 0.02849453,  training time: 1.73
progress:  64%|[34m   [0m| 32/50 [00:58<00:31,  1.73s/it]progress:  66%|[34m   [0m| 33/50 [00:58<00:29,  1.73s/it]                                                         Episode 34	 reward: -5.00	 makespan: 495.25	 Mean_loss: 0.02726689,  training time: 1.70
progress:  66%|[34m   [0m| 33/50 [01:00<00:29,  1.73s/it]progress:  68%|[34m   [0m| 34/50 [01:00<00:27,  1.72s/it]                                                         Episode 35	 reward: -4.89	 makespan: 484.50	 Mean_loss: 0.03799611,  training time: 1.72
progress:  68%|[34m   [0m| 34/50 [01:01<00:27,  1.72s/it]progress:  70%|[34m   [0m| 35/50 [01:01<00:25,  1.72s/it]                                                         Episode 36	 reward: -5.05	 makespan: 500.00	 Mean_loss: 0.02590894,  training time: 1.78
progress:  70%|[34m   [0m| 35/50 [01:03<00:25,  1.72s/it]progress:  72%|[34m  [0m| 36/50 [01:03<00:24,  1.74s/it]                                                         Episode 37	 reward: -4.87	 makespan: 482.25	 Mean_loss: 0.02320657,  training time: 1.69
progress:  72%|[34m  [0m| 36/50 [01:05<00:24,  1.74s/it]progress:  74%|[34m  [0m| 37/50 [01:05<00:22,  1.73s/it]                                                         Episode 38	 reward: -5.01	 makespan: 496.00	 Mean_loss: 0.02096779,  training time: 1.69
progress:  74%|[34m  [0m| 37/50 [01:06<00:22,  1.73s/it]progress:  76%|[34m  [0m| 38/50 [01:06<00:20,  1.72s/it]                                                         Episode 39	 reward: -5.00	 makespan: 495.25	 Mean_loss: 0.01495189,  training time: 1.69
progress:  76%|[34m  [0m| 38/50 [01:08<00:20,  1.72s/it]progress:  78%|[34m  [0m| 39/50 [01:08<00:18,  1.71s/it]                                                         Episode 40	 reward: -4.80	 makespan: 474.75	 Mean_loss: 0.01495929,  training time: 1.69
progress:  78%|[34m  [0m| 39/50 [01:10<00:18,  1.71s/it]progress:  80%|[34m  [0m| 40/50 [01:10<00:17,  1.70s/it]                                                         Episode 41	 reward: -4.82	 makespan: 477.25	 Mean_loss: 0.01487885,  training time: 1.69
progress:  80%|[34m  [0m| 40/50 [01:12<00:17,  1.70s/it]progress:  82%|[34m [0m| 41/50 [01:12<00:15,  1.70s/it]                                                         Episode 42	 reward: -4.80	 makespan: 475.00	 Mean_loss: 0.01841658,  training time: 1.70
progress:  82%|[34m [0m| 41/50 [01:13<00:15,  1.70s/it]progress:  84%|[34m [0m| 42/50 [01:13<00:13,  1.70s/it]                                                         Episode 43	 reward: -5.04	 makespan: 498.75	 Mean_loss: 0.01652920,  training time: 1.69
progress:  84%|[34m [0m| 42/50 [01:15<00:13,  1.70s/it]progress:  86%|[34m [0m| 43/50 [01:15<00:11,  1.70s/it]                                                         Episode 44	 reward: -5.10	 makespan: 504.75	 Mean_loss: 0.02444116,  training time: 1.70
progress:  86%|[34m [0m| 43/50 [01:17<00:11,  1.70s/it]progress:  88%|[34m [0m| 44/50 [01:17<00:10,  1.70s/it]                                                         Episode 45	 reward: -4.63	 makespan: 458.25	 Mean_loss: 0.02681971,  training time: 1.67
progress:  88%|[34m [0m| 44/50 [01:18<00:10,  1.70s/it]progress:  90%|[34m [0m| 45/50 [01:18<00:08,  1.69s/it]                                                         Episode 46	 reward: -4.58	 makespan: 453.50	 Mean_loss: 0.02989002,  training time: 1.80
progress:  90%|[34m [0m| 45/50 [01:20<00:08,  1.69s/it]progress:  92%|[34m[0m| 46/50 [01:20<00:06,  1.72s/it]                                                         Episode 47	 reward: -4.70	 makespan: 465.50	 Mean_loss: 0.01995757,  training time: 1.70
progress:  92%|[34m[0m| 46/50 [01:22<00:06,  1.72s/it]progress:  94%|[34m[0m| 47/50 [01:22<00:05,  1.72s/it]                                                         Episode 48	 reward: -4.85	 makespan: 479.75	 Mean_loss: 0.02367781,  training time: 1.70
progress:  94%|[34m[0m| 47/50 [01:23<00:05,  1.72s/it]progress:  96%|[34m[0m| 48/50 [01:23<00:03,  1.71s/it]                                                         Episode 49	 reward: -4.81	 makespan: 476.00	 Mean_loss: 0.01969264,  training time: 1.70
progress:  96%|[34m[0m| 48/50 [01:25<00:03,  1.71s/it]progress:  98%|[34m[0m| 49/50 [01:25<00:01,  1.71s/it]                                                         Episode 50	 reward: -4.74	 makespan: 469.25	 Mean_loss: 0.00983315,  training time: 1.69
progress:  98%|[34m[0m| 49/50 [01:27<00:01,  1.71s/it]progress: 100%|[34m[0m| 50/50 [01:27<00:00,  1.70s/it]progress: 100%|[34m[0m| 50/50 [01:27<00:00,  1.75s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x10_10 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 10 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.11	 makespan: 703.50	 Mean_loss: 2.86167407,  training time: 3.45
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:48,  3.45s/it]                                                        Episode 2	 reward: -6.92	 makespan: 685.25	 Mean_loss: 1.26759231,  training time: 2.37
progress:   2%|[34m         [0m| 1/50 [00:05<02:48,  3.45s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:15,  2.82s/it]                                                        Episode 3	 reward: -6.74	 makespan: 667.00	 Mean_loss: 0.38187957,  training time: 2.36
progress:   4%|[34m         [0m| 2/50 [00:08<02:15,  2.82s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:02,  2.61s/it]                                                        Episode 4	 reward: -6.60	 makespan: 653.75	 Mean_loss: 0.41058502,  training time: 2.37
progress:   6%|[34m         [0m| 3/50 [00:10<02:02,  2.61s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:55,  2.51s/it]                                                        Episode 5	 reward: -7.01	 makespan: 694.00	 Mean_loss: 0.20108911,  training time: 2.34
progress:   8%|[34m         [0m| 4/50 [00:12<01:55,  2.51s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:50,  2.45s/it]                                                        Episode 6	 reward: -6.84	 makespan: 677.00	 Mean_loss: 0.19407898,  training time: 2.45
progress:  10%|[34m         [0m| 5/50 [00:15<01:50,  2.45s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:47,  2.45s/it]                                                        Episode 7	 reward: -7.49	 makespan: 741.25	 Mean_loss: 0.19567114,  training time: 2.36
progress:  12%|[34m        [0m| 6/50 [00:17<01:47,  2.45s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:44,  2.42s/it]                                                        Episode 8	 reward: -6.87	 makespan: 680.25	 Mean_loss: 0.15794922,  training time: 2.35
progress:  14%|[34m        [0m| 7/50 [00:20<01:44,  2.42s/it]progress:  16%|[34m        [0m| 8/50 [00:20<01:40,  2.40s/it]                                                        Episode 9	 reward: -7.13	 makespan: 706.25	 Mean_loss: 0.14243189,  training time: 2.37
progress:  16%|[34m        [0m| 8/50 [00:22<01:40,  2.40s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:37,  2.39s/it]                                                        Episode 10	 reward: -7.43	 makespan: 735.75	 Mean_loss: 0.13298751,  training time: 2.39
progress:  18%|[34m        [0m| 9/50 [00:24<01:37,  2.39s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:35,  2.39s/it]                                                         Episode 11	 reward: -7.26	 makespan: 718.25	 Mean_loss: 0.14848222,  training time: 2.37
progress:  20%|[34m        [0m| 10/50 [00:27<01:35,  2.39s/it]progress:  22%|[34m       [0m| 11/50 [00:27<01:33,  2.39s/it]                                                         Episode 12	 reward: -6.86	 makespan: 679.50	 Mean_loss: 0.11582945,  training time: 2.36
progress:  22%|[34m       [0m| 11/50 [00:29<01:33,  2.39s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:30,  2.38s/it]                                                         Episode 13	 reward: -6.83	 makespan: 676.50	 Mean_loss: 0.13066179,  training time: 2.40
progress:  24%|[34m       [0m| 12/50 [00:31<01:30,  2.38s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:28,  2.38s/it]                                                         Episode 14	 reward: -6.98	 makespan: 691.00	 Mean_loss: 0.15357754,  training time: 2.36
progress:  26%|[34m       [0m| 13/50 [00:34<01:28,  2.38s/it]progress:  28%|[34m       [0m| 14/50 [00:34<01:25,  2.38s/it]                                                         Episode 15	 reward: -6.58	 makespan: 651.75	 Mean_loss: 0.06640489,  training time: 2.35
progress:  28%|[34m       [0m| 14/50 [00:36<01:25,  2.38s/it]progress:  30%|[34m       [0m| 15/50 [00:36<01:22,  2.37s/it]                                                         Episode 16	 reward: -6.62	 makespan: 655.00	 Mean_loss: 0.05284118,  training time: 2.36
progress:  30%|[34m       [0m| 15/50 [00:39<01:22,  2.37s/it]progress:  32%|[34m      [0m| 16/50 [00:39<01:20,  2.37s/it]                                                         Episode 17	 reward: -7.23	 makespan: 716.25	 Mean_loss: 0.08991150,  training time: 2.36
progress:  32%|[34m      [0m| 16/50 [00:41<01:20,  2.37s/it]progress:  34%|[34m      [0m| 17/50 [00:41<01:18,  2.37s/it]                                                         Episode 18	 reward: -7.02	 makespan: 694.50	 Mean_loss: 0.08073054,  training time: 2.37
progress:  34%|[34m      [0m| 17/50 [00:43<01:18,  2.37s/it]progress:  36%|[34m      [0m| 18/50 [00:43<01:15,  2.37s/it]                                                         Episode 19	 reward: -6.92	 makespan: 684.75	 Mean_loss: 0.08535720,  training time: 2.37
progress:  36%|[34m      [0m| 18/50 [00:46<01:15,  2.37s/it]progress:  38%|[34m      [0m| 19/50 [00:46<01:13,  2.37s/it]                                                         Episode 20	 reward: -6.94	 makespan: 687.00	 Mean_loss: 0.09273288,  training time: 2.37
progress:  38%|[34m      [0m| 19/50 [00:48<01:13,  2.37s/it]progress:  40%|[34m      [0m| 20/50 [00:48<01:11,  2.37s/it]                                                         Episode 21	 reward: -7.08	 makespan: 700.50	 Mean_loss: 0.10024080,  training time: 2.36
progress:  40%|[34m      [0m| 20/50 [00:50<01:11,  2.37s/it]progress:  42%|[34m     [0m| 21/50 [00:50<01:08,  2.37s/it]                                                         Episode 22	 reward: -6.60	 makespan: 653.50	 Mean_loss: 0.06923790,  training time: 2.37
progress:  42%|[34m     [0m| 21/50 [00:53<01:08,  2.37s/it]progress:  44%|[34m     [0m| 22/50 [00:53<01:06,  2.37s/it]                                                         Episode 23	 reward: -6.92	 makespan: 685.00	 Mean_loss: 0.05052285,  training time: 2.38
progress:  44%|[34m     [0m| 22/50 [00:55<01:06,  2.37s/it]progress:  46%|[34m     [0m| 23/50 [00:55<01:04,  2.37s/it]                                                         Episode 24	 reward: -6.70	 makespan: 663.25	 Mean_loss: 0.07821797,  training time: 2.37
progress:  46%|[34m     [0m| 23/50 [00:57<01:04,  2.37s/it]progress:  48%|[34m     [0m| 24/50 [00:57<01:01,  2.37s/it]                                                         Episode 25	 reward: -7.04	 makespan: 697.25	 Mean_loss: 0.10030425,  training time: 2.36
progress:  48%|[34m     [0m| 24/50 [01:00<01:01,  2.37s/it]progress:  50%|[34m     [0m| 25/50 [01:00<00:59,  2.37s/it]                                                         Episode 26	 reward: -6.95	 makespan: 688.00	 Mean_loss: 0.08676386,  training time: 2.36
progress:  50%|[34m     [0m| 25/50 [01:02<00:59,  2.37s/it]progress:  52%|[34m    [0m| 26/50 [01:02<00:56,  2.37s/it]                                                         Episode 27	 reward: -6.74	 makespan: 667.00	 Mean_loss: 0.05931943,  training time: 2.36
progress:  52%|[34m    [0m| 26/50 [01:05<00:56,  2.37s/it]progress:  54%|[34m    [0m| 27/50 [01:05<00:54,  2.37s/it]                                                         Episode 28	 reward: -6.71	 makespan: 664.00	 Mean_loss: 0.04467694,  training time: 2.35
progress:  54%|[34m    [0m| 27/50 [01:07<00:54,  2.37s/it]progress:  56%|[34m    [0m| 28/50 [01:07<00:51,  2.36s/it]                                                         Episode 29	 reward: -7.10	 makespan: 702.75	 Mean_loss: 0.05109072,  training time: 2.36
progress:  56%|[34m    [0m| 28/50 [01:09<00:51,  2.36s/it]progress:  58%|[34m    [0m| 29/50 [01:09<00:49,  2.36s/it]                                                         Episode 30	 reward: -6.87	 makespan: 680.25	 Mean_loss: 0.08998075,  training time: 2.36
progress:  58%|[34m    [0m| 29/50 [01:12<00:49,  2.36s/it]progress:  60%|[34m    [0m| 30/50 [01:12<00:47,  2.36s/it]                                                         Episode 31	 reward: -6.74	 makespan: 667.25	 Mean_loss: 0.07766616,  training time: 2.36
progress:  60%|[34m    [0m| 30/50 [01:14<00:47,  2.36s/it]progress:  62%|[34m   [0m| 31/50 [01:14<00:44,  2.36s/it]                                                         Episode 32	 reward: -6.59	 makespan: 652.25	 Mean_loss: 0.05890110,  training time: 2.46
progress:  62%|[34m   [0m| 31/50 [01:16<00:44,  2.36s/it]progress:  64%|[34m   [0m| 32/50 [01:16<00:43,  2.39s/it]                                                         Episode 33	 reward: -6.55	 makespan: 648.25	 Mean_loss: 0.04758863,  training time: 2.38
progress:  64%|[34m   [0m| 32/50 [01:19<00:43,  2.39s/it]progress:  66%|[34m   [0m| 33/50 [01:19<00:40,  2.39s/it]                                                         Episode 34	 reward: -6.75	 makespan: 668.00	 Mean_loss: 0.04020881,  training time: 2.39
progress:  66%|[34m   [0m| 33/50 [01:21<00:40,  2.39s/it]progress:  68%|[34m   [0m| 34/50 [01:21<00:38,  2.39s/it]                                                         Episode 35	 reward: -6.74	 makespan: 667.75	 Mean_loss: 0.05878011,  training time: 2.38
progress:  68%|[34m   [0m| 34/50 [01:24<00:38,  2.39s/it]progress:  70%|[34m   [0m| 35/50 [01:24<00:35,  2.39s/it]                                                         Episode 36	 reward: -7.08	 makespan: 700.75	 Mean_loss: 0.04549126,  training time: 2.38
progress:  70%|[34m   [0m| 35/50 [01:26<00:35,  2.39s/it]progress:  72%|[34m  [0m| 36/50 [01:26<00:33,  2.38s/it]                                                         Episode 37	 reward: -6.88	 makespan: 680.75	 Mean_loss: 0.06346467,  training time: 2.40
progress:  72%|[34m  [0m| 36/50 [01:28<00:33,  2.38s/it]progress:  74%|[34m  [0m| 37/50 [01:28<00:31,  2.39s/it]                                                         Episode 38	 reward: -6.67	 makespan: 660.25	 Mean_loss: 0.04685186,  training time: 2.40
progress:  74%|[34m  [0m| 37/50 [01:31<00:31,  2.39s/it]progress:  76%|[34m  [0m| 38/50 [01:31<00:28,  2.39s/it]                                                         Episode 39	 reward: -6.73	 makespan: 666.50	 Mean_loss: 0.07036839,  training time: 2.38
progress:  76%|[34m  [0m| 38/50 [01:33<00:28,  2.39s/it]progress:  78%|[34m  [0m| 39/50 [01:33<00:26,  2.39s/it]                                                         Episode 40	 reward: -7.57	 makespan: 749.50	 Mean_loss: 0.11862148,  training time: 2.40
progress:  78%|[34m  [0m| 39/50 [01:36<00:26,  2.39s/it]progress:  80%|[34m  [0m| 40/50 [01:36<00:23,  2.39s/it]                                                         Episode 41	 reward: -6.78	 makespan: 671.00	 Mean_loss: 0.06322791,  training time: 2.50
progress:  80%|[34m  [0m| 40/50 [01:38<00:23,  2.39s/it]progress:  82%|[34m [0m| 41/50 [01:38<00:21,  2.42s/it]                                                         Episode 42	 reward: -6.72	 makespan: 665.25	 Mean_loss: 0.05257677,  training time: 2.39
progress:  82%|[34m [0m| 41/50 [01:40<00:21,  2.42s/it]progress:  84%|[34m [0m| 42/50 [01:40<00:19,  2.42s/it]                                                         Episode 43	 reward: -6.93	 makespan: 686.25	 Mean_loss: 0.06771150,  training time: 2.38
progress:  84%|[34m [0m| 42/50 [01:43<00:19,  2.42s/it]progress:  86%|[34m [0m| 43/50 [01:43<00:16,  2.41s/it]                                                         Episode 44	 reward: -6.72	 makespan: 665.00	 Mean_loss: 0.04231777,  training time: 2.38
progress:  86%|[34m [0m| 43/50 [01:45<00:16,  2.41s/it]progress:  88%|[34m [0m| 44/50 [01:45<00:14,  2.40s/it]                                                         Episode 45	 reward: -7.20	 makespan: 712.75	 Mean_loss: 0.04232736,  training time: 2.38
progress:  88%|[34m [0m| 44/50 [01:48<00:14,  2.40s/it]progress:  90%|[34m [0m| 45/50 [01:48<00:11,  2.39s/it]                                                         Episode 46	 reward: -6.69	 makespan: 662.00	 Mean_loss: 0.06087850,  training time: 2.39
progress:  90%|[34m [0m| 45/50 [01:50<00:11,  2.39s/it]progress:  92%|[34m[0m| 46/50 [01:50<00:09,  2.39s/it]                                                         Episode 47	 reward: -6.90	 makespan: 683.25	 Mean_loss: 0.04620183,  training time: 2.44
progress:  92%|[34m[0m| 46/50 [01:52<00:09,  2.39s/it]progress:  94%|[34m[0m| 47/50 [01:52<00:07,  2.41s/it]                                                         Episode 48	 reward: -7.15	 makespan: 707.50	 Mean_loss: 0.04661496,  training time: 2.39
progress:  94%|[34m[0m| 47/50 [01:55<00:07,  2.41s/it]progress:  96%|[34m[0m| 48/50 [01:55<00:04,  2.40s/it]                                                         Episode 49	 reward: -7.01	 makespan: 694.00	 Mean_loss: 0.07199748,  training time: 2.34
progress:  96%|[34m[0m| 48/50 [01:57<00:04,  2.40s/it]progress:  98%|[34m[0m| 49/50 [01:57<00:02,  2.38s/it]                                                         Episode 50	 reward: -7.21	 makespan: 714.00	 Mean_loss: 0.06507211,  training time: 2.39
progress:  98%|[34m[0m| 49/50 [02:00<00:02,  2.38s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.39s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.40s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x10_12 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.39	 makespan: 830.50	 Mean_loss: 7.28158331,  training time: 3.98
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:15,  3.98s/it]                                                        Episode 2	 reward: -7.97	 makespan: 789.25	 Mean_loss: 0.51356459,  training time: 2.85
progress:   2%|[34m         [0m| 1/50 [00:06<03:15,  3.98s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:39,  3.32s/it]                                                        Episode 3	 reward: -8.31	 makespan: 823.00	 Mean_loss: 0.55788314,  training time: 2.85
progress:   4%|[34m         [0m| 2/50 [00:09<02:39,  3.32s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:26,  3.11s/it]                                                        Episode 4	 reward: -8.36	 makespan: 827.50	 Mean_loss: 0.47755060,  training time: 2.84
progress:   6%|[34m         [0m| 3/50 [00:12<02:26,  3.11s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:18,  3.00s/it]                                                        Episode 5	 reward: -8.49	 makespan: 840.75	 Mean_loss: 0.43935183,  training time: 2.96
progress:   8%|[34m         [0m| 4/50 [00:15<02:18,  3.00s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:14,  2.99s/it]                                                        Episode 6	 reward: -8.41	 makespan: 832.75	 Mean_loss: 0.40545851,  training time: 2.86
progress:  10%|[34m         [0m| 5/50 [00:18<02:14,  2.99s/it]progress:  12%|[34m        [0m| 6/50 [00:18<02:09,  2.95s/it]                                                        Episode 7	 reward: -8.35	 makespan: 827.00	 Mean_loss: 0.52192712,  training time: 2.84
progress:  12%|[34m        [0m| 6/50 [00:21<02:09,  2.95s/it]progress:  14%|[34m        [0m| 7/50 [00:21<02:05,  2.91s/it]                                                        Episode 8	 reward: -8.80	 makespan: 871.50	 Mean_loss: 0.34370226,  training time: 2.82
progress:  14%|[34m        [0m| 7/50 [00:24<02:05,  2.91s/it]progress:  16%|[34m        [0m| 8/50 [00:24<02:01,  2.88s/it]                                                        Episode 9	 reward: -8.64	 makespan: 855.75	 Mean_loss: 0.28306940,  training time: 2.82
progress:  16%|[34m        [0m| 8/50 [00:26<02:01,  2.88s/it]progress:  18%|[34m        [0m| 9/50 [00:26<01:57,  2.86s/it]                                                        Episode 10	 reward: -8.60	 makespan: 851.50	 Mean_loss: 0.24084640,  training time: 2.82
progress:  18%|[34m        [0m| 9/50 [00:29<01:57,  2.86s/it]progress:  20%|[34m        [0m| 10/50 [00:29<01:53,  2.85s/it]                                                         Episode 11	 reward: -8.51	 makespan: 842.25	 Mean_loss: 0.20808089,  training time: 2.82
progress:  20%|[34m        [0m| 10/50 [00:32<01:53,  2.85s/it]progress:  22%|[34m       [0m| 11/50 [00:32<01:50,  2.84s/it]                                                         Episode 12	 reward: -8.99	 makespan: 889.75	 Mean_loss: 0.22013639,  training time: 2.81
progress:  22%|[34m       [0m| 11/50 [00:35<01:50,  2.84s/it]progress:  24%|[34m       [0m| 12/50 [00:35<01:47,  2.83s/it]                                                         Episode 13	 reward: -8.70	 makespan: 861.25	 Mean_loss: 0.18389550,  training time: 2.82
progress:  24%|[34m       [0m| 12/50 [00:38<01:47,  2.83s/it]progress:  26%|[34m       [0m| 13/50 [00:38<01:44,  2.83s/it]                                                         Episode 14	 reward: -8.47	 makespan: 839.00	 Mean_loss: 0.16651139,  training time: 2.82
progress:  26%|[34m       [0m| 13/50 [00:40<01:44,  2.83s/it]progress:  28%|[34m       [0m| 14/50 [00:40<01:41,  2.83s/it]                                                         Episode 15	 reward: -8.32	 makespan: 824.00	 Mean_loss: 0.15755999,  training time: 2.85
progress:  28%|[34m       [0m| 14/50 [00:43<01:41,  2.83s/it]progress:  30%|[34m       [0m| 15/50 [00:43<01:39,  2.83s/it]                                                         Episode 16	 reward: -8.29	 makespan: 821.00	 Mean_loss: 0.15805618,  training time: 2.83
progress:  30%|[34m       [0m| 15/50 [00:46<01:39,  2.83s/it]progress:  32%|[34m      [0m| 16/50 [00:46<01:36,  2.83s/it]                                                         Episode 17	 reward: -8.64	 makespan: 855.00	 Mean_loss: 0.16776575,  training time: 2.81
progress:  32%|[34m      [0m| 16/50 [00:49<01:36,  2.83s/it]progress:  34%|[34m      [0m| 17/50 [00:49<01:33,  2.83s/it]                                                         Episode 18	 reward: -8.59	 makespan: 850.25	 Mean_loss: 0.15305918,  training time: 2.80
progress:  34%|[34m      [0m| 17/50 [00:52<01:33,  2.83s/it]progress:  36%|[34m      [0m| 18/50 [00:52<01:30,  2.82s/it]                                                         Episode 19	 reward: -8.48	 makespan: 839.75	 Mean_loss: 0.14670190,  training time: 2.77
progress:  36%|[34m      [0m| 18/50 [00:54<01:30,  2.82s/it]progress:  38%|[34m      [0m| 19/50 [00:54<01:26,  2.80s/it]                                                         Episode 20	 reward: -8.31	 makespan: 822.75	 Mean_loss: 0.17527951,  training time: 2.81
progress:  38%|[34m      [0m| 19/50 [00:57<01:26,  2.80s/it]progress:  40%|[34m      [0m| 20/50 [00:57<01:24,  2.81s/it]                                                         Episode 21	 reward: -8.19	 makespan: 810.50	 Mean_loss: 0.15210596,  training time: 2.79
progress:  40%|[34m      [0m| 20/50 [01:00<01:24,  2.81s/it]progress:  42%|[34m     [0m| 21/50 [01:00<01:21,  2.80s/it]                                                         Episode 22	 reward: -8.94	 makespan: 884.75	 Mean_loss: 0.08487208,  training time: 2.81
progress:  42%|[34m     [0m| 21/50 [01:03<01:21,  2.80s/it]progress:  44%|[34m     [0m| 22/50 [01:03<01:18,  2.80s/it]                                                         Episode 23	 reward: -8.46	 makespan: 837.50	 Mean_loss: 0.12364008,  training time: 2.80
progress:  44%|[34m     [0m| 22/50 [01:06<01:18,  2.80s/it]progress:  46%|[34m     [0m| 23/50 [01:06<01:15,  2.80s/it]                                                         Episode 24	 reward: -8.78	 makespan: 869.50	 Mean_loss: 0.11641464,  training time: 2.80
progress:  46%|[34m     [0m| 23/50 [01:09<01:15,  2.80s/it]progress:  48%|[34m     [0m| 24/50 [01:09<01:12,  2.80s/it]                                                         Episode 25	 reward: -8.86	 makespan: 877.50	 Mean_loss: 0.07515982,  training time: 2.80
progress:  48%|[34m     [0m| 24/50 [01:11<01:12,  2.80s/it]progress:  50%|[34m     [0m| 25/50 [01:11<01:10,  2.80s/it]                                                         Episode 26	 reward: -8.81	 makespan: 872.50	 Mean_loss: 0.08331143,  training time: 2.81
progress:  50%|[34m     [0m| 25/50 [01:14<01:10,  2.80s/it]progress:  52%|[34m    [0m| 26/50 [01:14<01:07,  2.80s/it]                                                         Episode 27	 reward: -8.85	 makespan: 876.50	 Mean_loss: 0.08814956,  training time: 2.81
progress:  52%|[34m    [0m| 26/50 [01:17<01:07,  2.80s/it]progress:  54%|[34m    [0m| 27/50 [01:17<01:04,  2.81s/it]                                                         Episode 28	 reward: -9.13	 makespan: 903.50	 Mean_loss: 0.10657939,  training time: 2.80
progress:  54%|[34m    [0m| 27/50 [01:20<01:04,  2.81s/it]progress:  56%|[34m    [0m| 28/50 [01:20<01:01,  2.80s/it]                                                         Episode 29	 reward: -8.59	 makespan: 850.25	 Mean_loss: 0.07038321,  training time: 2.80
progress:  56%|[34m    [0m| 28/50 [01:23<01:01,  2.80s/it]progress:  58%|[34m    [0m| 29/50 [01:23<00:58,  2.80s/it]                                                         Episode 30	 reward: -9.06	 makespan: 897.00	 Mean_loss: 0.05381773,  training time: 2.80
progress:  58%|[34m    [0m| 29/50 [01:25<00:58,  2.80s/it]progress:  60%|[34m    [0m| 30/50 [01:25<00:56,  2.80s/it]                                                         Episode 31	 reward: -8.67	 makespan: 858.75	 Mean_loss: 0.07673973,  training time: 2.81
progress:  60%|[34m    [0m| 30/50 [01:28<00:56,  2.80s/it]progress:  62%|[34m   [0m| 31/50 [01:28<00:53,  2.81s/it]                                                         Episode 32	 reward: -8.73	 makespan: 864.50	 Mean_loss: 0.09502172,  training time: 2.79
progress:  62%|[34m   [0m| 31/50 [01:31<00:53,  2.81s/it]progress:  64%|[34m   [0m| 32/50 [01:31<00:50,  2.80s/it]                                                         Episode 33	 reward: -9.02	 makespan: 893.00	 Mean_loss: 0.08933561,  training time: 2.80
progress:  64%|[34m   [0m| 32/50 [01:34<00:50,  2.80s/it]progress:  66%|[34m   [0m| 33/50 [01:34<00:47,  2.80s/it]                                                         Episode 34	 reward: -8.42	 makespan: 834.00	 Mean_loss: 0.09308891,  training time: 2.79
progress:  66%|[34m   [0m| 33/50 [01:37<00:47,  2.80s/it]progress:  68%|[34m   [0m| 34/50 [01:37<00:44,  2.80s/it]                                                         Episode 35	 reward: -8.99	 makespan: 890.25	 Mean_loss: 0.07723257,  training time: 2.80
progress:  68%|[34m   [0m| 34/50 [01:39<00:44,  2.80s/it]progress:  70%|[34m   [0m| 35/50 [01:39<00:41,  2.80s/it]                                                         Episode 36	 reward: -8.20	 makespan: 812.25	 Mean_loss: 0.10225806,  training time: 2.80
progress:  70%|[34m   [0m| 35/50 [01:42<00:41,  2.80s/it]progress:  72%|[34m  [0m| 36/50 [01:42<00:39,  2.80s/it]                                                         Episode 37	 reward: -8.58	 makespan: 849.00	 Mean_loss: 0.07711522,  training time: 2.80
progress:  72%|[34m  [0m| 36/50 [01:45<00:39,  2.80s/it]progress:  74%|[34m  [0m| 37/50 [01:45<00:36,  2.80s/it]                                                         Episode 38	 reward: -8.51	 makespan: 842.50	 Mean_loss: 0.10772607,  training time: 2.82
progress:  74%|[34m  [0m| 37/50 [01:48<00:36,  2.80s/it]progress:  76%|[34m  [0m| 38/50 [01:48<00:33,  2.81s/it]                                                         Episode 39	 reward: -8.79	 makespan: 870.00	 Mean_loss: 0.09335230,  training time: 2.78
progress:  76%|[34m  [0m| 38/50 [01:51<00:33,  2.81s/it]progress:  78%|[34m  [0m| 39/50 [01:51<00:30,  2.80s/it]                                                         Episode 40	 reward: -8.85	 makespan: 876.50	 Mean_loss: 0.08143631,  training time: 2.80
progress:  78%|[34m  [0m| 39/50 [01:53<00:30,  2.80s/it]progress:  80%|[34m  [0m| 40/50 [01:53<00:27,  2.80s/it]                                                         Episode 41	 reward: -8.48	 makespan: 839.75	 Mean_loss: 0.07179653,  training time: 2.90
progress:  80%|[34m  [0m| 40/50 [01:56<00:27,  2.80s/it]progress:  82%|[34m [0m| 41/50 [01:56<00:25,  2.83s/it]                                                         Episode 42	 reward: -8.59	 makespan: 850.50	 Mean_loss: 0.05819667,  training time: 2.87
progress:  82%|[34m [0m| 41/50 [01:59<00:25,  2.83s/it]progress:  84%|[34m [0m| 42/50 [01:59<00:22,  2.84s/it]                                                         Episode 43	 reward: -8.23	 makespan: 814.75	 Mean_loss: 0.06622214,  training time: 2.87
progress:  84%|[34m [0m| 42/50 [02:02<00:22,  2.84s/it]progress:  86%|[34m [0m| 43/50 [02:02<00:19,  2.85s/it]                                                         Episode 44	 reward: -8.52	 makespan: 843.75	 Mean_loss: 0.05511970,  training time: 2.82
progress:  86%|[34m [0m| 43/50 [02:05<00:19,  2.85s/it]progress:  88%|[34m [0m| 44/50 [02:05<00:17,  2.84s/it]                                                         Episode 45	 reward: -8.30	 makespan: 821.25	 Mean_loss: 0.06843781,  training time: 2.83
progress:  88%|[34m [0m| 44/50 [02:08<00:17,  2.84s/it]progress:  90%|[34m [0m| 45/50 [02:08<00:14,  2.84s/it]                                                         Episode 46	 reward: -8.39	 makespan: 830.25	 Mean_loss: 0.04374891,  training time: 2.84
progress:  90%|[34m [0m| 45/50 [02:10<00:14,  2.84s/it]progress:  92%|[34m[0m| 46/50 [02:10<00:11,  2.84s/it]                                                         Episode 47	 reward: -8.30	 makespan: 821.25	 Mean_loss: 0.05041305,  training time: 2.84
progress:  92%|[34m[0m| 46/50 [02:13<00:11,  2.84s/it]progress:  94%|[34m[0m| 47/50 [02:13<00:08,  2.84s/it]                                                         Episode 48	 reward: -8.55	 makespan: 846.50	 Mean_loss: 0.04967263,  training time: 2.80
progress:  94%|[34m[0m| 47/50 [02:16<00:08,  2.84s/it]progress:  96%|[34m[0m| 48/50 [02:16<00:05,  2.83s/it]                                                         Episode 49	 reward: -8.40	 makespan: 831.75	 Mean_loss: 0.03888384,  training time: 2.82
progress:  96%|[34m[0m| 48/50 [02:19<00:05,  2.83s/it]progress:  98%|[34m[0m| 49/50 [02:19<00:02,  2.83s/it]                                                         Episode 50	 reward: -8.73	 makespan: 864.25	 Mean_loss: 0.04761955,  training time: 2.82
progress:  98%|[34m[0m| 49/50 [02:22<00:02,  2.83s/it]progress: 100%|[34m[0m| 50/50 [02:22<00:00,  2.83s/it]progress: 100%|[34m[0m| 50/50 [02:22<00:00,  2.84s/it]
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x7_4 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 4 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -3.44	 makespan: 340.25	 Mean_loss: 4.21013546,  training time: 2.18
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:46,  2.18s/it]                                                        Episode 2	 reward: -3.72	 makespan: 368.50	 Mean_loss: 1.22979021,  training time: 1.06
progress:   2%|[34m         [0m| 1/50 [00:03<01:46,  2.18s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:12,  1.52s/it]                                                        Episode 3	 reward: -3.93	 makespan: 388.75	 Mean_loss: 0.71657419,  training time: 1.03
progress:   4%|[34m         [0m| 2/50 [00:04<01:12,  1.52s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:00,  1.30s/it]                                                        Episode 4	 reward: -4.23	 makespan: 418.75	 Mean_loss: 0.35209465,  training time: 1.06
progress:   6%|[34m         [0m| 3/50 [00:05<01:00,  1.30s/it]progress:   8%|[34m         [0m| 4/50 [00:05<00:55,  1.20s/it]                                                        Episode 5	 reward: -4.21	 makespan: 417.00	 Mean_loss: 0.28498819,  training time: 1.05
progress:   8%|[34m         [0m| 4/50 [00:06<00:55,  1.20s/it]progress:  10%|[34m         [0m| 5/50 [00:06<00:51,  1.15s/it]                                                        Episode 6	 reward: -4.31	 makespan: 426.75	 Mean_loss: 0.21119249,  training time: 1.04
progress:  10%|[34m         [0m| 5/50 [00:07<00:51,  1.15s/it]progress:  12%|[34m        [0m| 6/50 [00:07<00:48,  1.11s/it]                                                        Episode 7	 reward: -4.22	 makespan: 417.50	 Mean_loss: 0.17620757,  training time: 1.02
progress:  12%|[34m        [0m| 6/50 [00:08<00:48,  1.11s/it]progress:  14%|[34m        [0m| 7/50 [00:08<00:46,  1.08s/it]                                                        Episode 8	 reward: -3.83	 makespan: 379.25	 Mean_loss: 0.11740287,  training time: 1.04
progress:  14%|[34m        [0m| 7/50 [00:09<00:46,  1.08s/it]progress:  16%|[34m        [0m| 8/50 [00:09<00:44,  1.07s/it]                                                        Episode 9	 reward: -3.92	 makespan: 388.25	 Mean_loss: 0.09288737,  training time: 1.06
progress:  16%|[34m        [0m| 8/50 [00:10<00:44,  1.07s/it]progress:  18%|[34m        [0m| 9/50 [00:10<00:43,  1.07s/it]                                                        Episode 10	 reward: -3.87	 makespan: 383.50	 Mean_loss: 0.11889323,  training time: 1.05
progress:  18%|[34m        [0m| 9/50 [00:11<00:43,  1.07s/it]progress:  20%|[34m        [0m| 10/50 [00:11<00:42,  1.06s/it]                                                         Episode 11	 reward: -3.83	 makespan: 379.50	 Mean_loss: 0.07367451,  training time: 1.05
progress:  20%|[34m        [0m| 10/50 [00:12<00:42,  1.06s/it]progress:  22%|[34m       [0m| 11/50 [00:12<00:41,  1.06s/it]                                                         Episode 12	 reward: -3.93	 makespan: 389.00	 Mean_loss: 0.09199773,  training time: 1.15
progress:  22%|[34m       [0m| 11/50 [00:13<00:41,  1.06s/it]progress:  24%|[34m       [0m| 12/50 [00:13<00:41,  1.09s/it]                                                         Episode 13	 reward: -3.94	 makespan: 390.00	 Mean_loss: 0.07181995,  training time: 1.05
progress:  24%|[34m       [0m| 12/50 [00:14<00:41,  1.09s/it]progress:  26%|[34m       [0m| 13/50 [00:14<00:39,  1.08s/it]                                                         Episode 14	 reward: -4.34	 makespan: 429.25	 Mean_loss: 0.11523445,  training time: 1.11
progress:  26%|[34m       [0m| 13/50 [00:15<00:39,  1.08s/it]progress:  28%|[34m       [0m| 14/50 [00:15<00:39,  1.09s/it]                                                         Episode 15	 reward: -4.02	 makespan: 398.25	 Mean_loss: 0.11726093,  training time: 1.07
progress:  28%|[34m       [0m| 14/50 [00:17<00:39,  1.09s/it]progress:  30%|[34m       [0m| 15/50 [00:17<00:37,  1.08s/it]                                                         Episode 16	 reward: -4.19	 makespan: 415.25	 Mean_loss: 0.09070844,  training time: 1.07
progress:  30%|[34m       [0m| 15/50 [00:18<00:37,  1.08s/it]progress:  32%|[34m      [0m| 16/50 [00:18<00:36,  1.08s/it]                                                         Episode 17	 reward: -3.93	 makespan: 389.00	 Mean_loss: 0.08068779,  training time: 1.07
progress:  32%|[34m      [0m| 16/50 [00:19<00:36,  1.08s/it]progress:  34%|[34m      [0m| 17/50 [00:19<00:35,  1.08s/it]                                                         Episode 18	 reward: -3.81	 makespan: 376.75	 Mean_loss: 0.10496360,  training time: 1.05
progress:  34%|[34m      [0m| 17/50 [00:20<00:35,  1.08s/it]progress:  36%|[34m      [0m| 18/50 [00:20<00:34,  1.07s/it]                                                         Episode 19	 reward: -3.82	 makespan: 378.00	 Mean_loss: 0.05276322,  training time: 1.06
progress:  36%|[34m      [0m| 18/50 [00:21<00:34,  1.07s/it]progress:  38%|[34m      [0m| 19/50 [00:21<00:33,  1.07s/it]                                                         Episode 20	 reward: -3.99	 makespan: 395.50	 Mean_loss: 0.06263635,  training time: 1.07
progress:  38%|[34m      [0m| 19/50 [00:22<00:33,  1.07s/it]progress:  40%|[34m      [0m| 20/50 [00:22<00:32,  1.07s/it]                                                         Episode 21	 reward: -3.81	 makespan: 376.75	 Mean_loss: 0.05816341,  training time: 1.04
progress:  40%|[34m      [0m| 20/50 [00:23<00:32,  1.07s/it]progress:  42%|[34m     [0m| 21/50 [00:23<00:30,  1.06s/it]                                                         Episode 22	 reward: -4.13	 makespan: 408.50	 Mean_loss: 0.08630349,  training time: 1.12
progress:  42%|[34m     [0m| 21/50 [00:24<00:30,  1.06s/it]progress:  44%|[34m     [0m| 22/50 [00:24<00:30,  1.08s/it]                                                         Episode 23	 reward: -3.98	 makespan: 394.50	 Mean_loss: 0.05591437,  training time: 1.05
progress:  44%|[34m     [0m| 22/50 [00:25<00:30,  1.08s/it]progress:  46%|[34m     [0m| 23/50 [00:25<00:28,  1.07s/it]                                                         Episode 24	 reward: -4.09	 makespan: 404.50	 Mean_loss: 0.08421502,  training time: 1.02
progress:  46%|[34m     [0m| 23/50 [00:26<00:28,  1.07s/it]progress:  48%|[34m     [0m| 24/50 [00:26<00:27,  1.06s/it]                                                         Episode 25	 reward: -4.33	 makespan: 428.25	 Mean_loss: 0.07494327,  training time: 0.99
progress:  48%|[34m     [0m| 24/50 [00:27<00:27,  1.06s/it]progress:  50%|[34m     [0m| 25/50 [00:27<00:25,  1.04s/it]                                                         Episode 26	 reward: -4.11	 makespan: 406.50	 Mean_loss: 0.07606126,  training time: 1.02
progress:  50%|[34m     [0m| 25/50 [00:28<00:25,  1.04s/it]progress:  52%|[34m    [0m| 26/50 [00:28<00:24,  1.03s/it]                                                         Episode 27	 reward: -4.15	 makespan: 410.50	 Mean_loss: 0.07187102,  training time: 1.03
progress:  52%|[34m    [0m| 26/50 [00:29<00:24,  1.03s/it]progress:  54%|[34m    [0m| 27/50 [00:29<00:23,  1.03s/it]                                                         Episode 28	 reward: -3.96	 makespan: 392.00	 Mean_loss: 0.10564543,  training time: 1.03
progress:  54%|[34m    [0m| 27/50 [00:30<00:23,  1.03s/it]progress:  56%|[34m    [0m| 28/50 [00:30<00:22,  1.03s/it]                                                         Episode 29	 reward: -4.05	 makespan: 401.00	 Mean_loss: 0.07789522,  training time: 1.04
progress:  56%|[34m    [0m| 28/50 [00:31<00:22,  1.03s/it]progress:  58%|[34m    [0m| 29/50 [00:31<00:21,  1.04s/it]                                                         Episode 30	 reward: -3.84	 makespan: 379.75	 Mean_loss: 0.05274809,  training time: 1.04
progress:  58%|[34m    [0m| 29/50 [00:32<00:21,  1.04s/it]progress:  60%|[34m    [0m| 30/50 [00:32<00:20,  1.04s/it]                                                         Episode 31	 reward: -3.83	 makespan: 379.00	 Mean_loss: 0.04307185,  training time: 1.04
progress:  60%|[34m    [0m| 30/50 [00:33<00:20,  1.04s/it]progress:  62%|[34m   [0m| 31/50 [00:33<00:19,  1.04s/it]                                                         Episode 32	 reward: -4.05	 makespan: 400.50	 Mean_loss: 0.05408630,  training time: 1.03
progress:  62%|[34m   [0m| 31/50 [00:34<00:19,  1.04s/it]progress:  64%|[34m   [0m| 32/50 [00:34<00:18,  1.04s/it]                                                         Episode 33	 reward: -3.98	 makespan: 394.00	 Mean_loss: 0.04546313,  training time: 1.04
progress:  64%|[34m   [0m| 32/50 [00:35<00:18,  1.04s/it]progress:  66%|[34m   [0m| 33/50 [00:35<00:17,  1.04s/it]                                                         Episode 34	 reward: -3.60	 makespan: 356.00	 Mean_loss: 0.09708782,  training time: 1.01
progress:  66%|[34m   [0m| 33/50 [00:36<00:17,  1.04s/it]progress:  68%|[34m   [0m| 34/50 [00:36<00:16,  1.03s/it]                                                         Episode 35	 reward: -3.79	 makespan: 375.25	 Mean_loss: 0.06426884,  training time: 1.01
progress:  68%|[34m   [0m| 34/50 [00:37<00:16,  1.03s/it]progress:  70%|[34m   [0m| 35/50 [00:37<00:15,  1.02s/it]                                                         Episode 36	 reward: -3.84	 makespan: 379.75	 Mean_loss: 0.05145513,  training time: 1.00
progress:  70%|[34m   [0m| 35/50 [00:38<00:15,  1.02s/it]progress:  72%|[34m  [0m| 36/50 [00:38<00:14,  1.02s/it]                                                         Episode 37	 reward: -3.84	 makespan: 380.00	 Mean_loss: 0.04437274,  training time: 1.04
progress:  72%|[34m  [0m| 36/50 [00:39<00:14,  1.02s/it]progress:  74%|[34m  [0m| 37/50 [00:39<00:13,  1.02s/it]                                                         Episode 38	 reward: -3.98	 makespan: 394.50	 Mean_loss: 0.10183153,  training time: 1.05
progress:  74%|[34m  [0m| 37/50 [00:40<00:13,  1.02s/it]progress:  76%|[34m  [0m| 38/50 [00:40<00:12,  1.03s/it]                                                         Episode 39	 reward: -3.97	 makespan: 393.25	 Mean_loss: 0.03472764,  training time: 1.00
progress:  76%|[34m  [0m| 38/50 [00:42<00:12,  1.03s/it]progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.02s/it]                                                         Episode 40	 reward: -3.89	 makespan: 385.00	 Mean_loss: 0.03527200,  training time: 0.99
progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.02s/it]progress:  80%|[34m  [0m| 40/50 [00:42<00:10,  1.01s/it]                                                         Episode 41	 reward: -3.88	 makespan: 384.50	 Mean_loss: 0.05814318,  training time: 1.02
progress:  80%|[34m  [0m| 40/50 [00:44<00:10,  1.01s/it]progress:  82%|[34m [0m| 41/50 [00:44<00:09,  1.02s/it]                                                         Episode 42	 reward: -3.87	 makespan: 383.00	 Mean_loss: 0.05399672,  training time: 0.99
progress:  82%|[34m [0m| 41/50 [00:45<00:09,  1.02s/it]progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.01s/it]                                                         Episode 43	 reward: -4.13	 makespan: 409.00	 Mean_loss: 0.03835513,  training time: 0.99
progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.01s/it]progress:  86%|[34m [0m| 43/50 [00:45<00:07,  1.00s/it]                                                         Episode 44	 reward: -3.58	 makespan: 354.75	 Mean_loss: 0.05564511,  training time: 0.99
progress:  86%|[34m [0m| 43/50 [00:46<00:07,  1.00s/it]progress:  88%|[34m [0m| 44/50 [00:46<00:05,  1.00it/s]                                                         Episode 45	 reward: -4.07	 makespan: 403.25	 Mean_loss: 0.03614483,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:48<00:05,  1.00it/s]progress:  90%|[34m [0m| 45/50 [00:48<00:05,  1.01s/it]                                                         Episode 46	 reward: -4.18	 makespan: 414.00	 Mean_loss: 0.05527068,  training time: 1.03
progress:  90%|[34m [0m| 45/50 [00:49<00:05,  1.01s/it]progress:  92%|[34m[0m| 46/50 [00:49<00:04,  1.02s/it]                                                         Episode 47	 reward: -4.10	 makespan: 406.00	 Mean_loss: 0.04526470,  training time: 0.99
progress:  92%|[34m[0m| 46/50 [00:50<00:04,  1.02s/it]progress:  94%|[34m[0m| 47/50 [00:50<00:03,  1.01s/it]                                                         Episode 48	 reward: -4.44	 makespan: 439.75	 Mean_loss: 0.04523569,  training time: 1.00
progress:  94%|[34m[0m| 47/50 [00:51<00:03,  1.01s/it]progress:  96%|[34m[0m| 48/50 [00:51<00:02,  1.01s/it]                                                         Episode 49	 reward: -3.94	 makespan: 390.50	 Mean_loss: 0.10130610,  training time: 1.00
progress:  96%|[34m[0m| 48/50 [00:52<00:02,  1.01s/it]progress:  98%|[34m[0m| 49/50 [00:52<00:01,  1.01s/it]                                                         Episode 50	 reward: -3.92	 makespan: 388.50	 Mean_loss: 0.07318000,  training time: 0.96
progress:  98%|[34m[0m| 49/50 [00:53<00:01,  1.01s/it]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.01it/s]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.06s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x7_7 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 7 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.70	 makespan: 663.25	 Mean_loss: 2.83379388,  training time: 2.81
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:17,  2.81s/it]                                                        Episode 2	 reward: -6.05	 makespan: 599.25	 Mean_loss: 1.36173749,  training time: 1.71
progress:   2%|[34m         [0m| 1/50 [00:04<02:17,  2.81s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:43,  2.16s/it]                                                        Episode 3	 reward: -5.96	 makespan: 590.25	 Mean_loss: 0.33945164,  training time: 1.72
progress:   4%|[34m         [0m| 2/50 [00:06<01:43,  2.16s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:32,  1.96s/it]                                                        Episode 4	 reward: -5.91	 makespan: 584.75	 Mean_loss: 0.25716594,  training time: 1.70
progress:   6%|[34m         [0m| 3/50 [00:07<01:32,  1.96s/it]progress:   8%|[34m         [0m| 4/50 [00:07<01:25,  1.86s/it]                                                        Episode 5	 reward: -5.71	 makespan: 565.00	 Mean_loss: 0.20490368,  training time: 1.72
progress:   8%|[34m         [0m| 4/50 [00:09<01:25,  1.86s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:21,  1.81s/it]                                                        Episode 6	 reward: -5.71	 makespan: 565.25	 Mean_loss: 0.16755182,  training time: 1.70
progress:  10%|[34m         [0m| 5/50 [00:11<01:21,  1.81s/it]progress:  12%|[34m        [0m| 6/50 [00:11<01:17,  1.77s/it]                                                        Episode 7	 reward: -6.09	 makespan: 603.25	 Mean_loss: 0.09299190,  training time: 1.69
progress:  12%|[34m        [0m| 6/50 [00:13<01:17,  1.77s/it]progress:  14%|[34m        [0m| 7/50 [00:13<01:15,  1.75s/it]                                                        Episode 8	 reward: -6.34	 makespan: 627.50	 Mean_loss: 0.15878572,  training time: 1.70
progress:  14%|[34m        [0m| 7/50 [00:14<01:15,  1.75s/it]progress:  16%|[34m        [0m| 8/50 [00:14<01:12,  1.73s/it]                                                        Episode 9	 reward: -6.06	 makespan: 600.00	 Mean_loss: 0.11483796,  training time: 1.70
progress:  16%|[34m        [0m| 8/50 [00:16<01:12,  1.73s/it]progress:  18%|[34m        [0m| 9/50 [00:16<01:10,  1.72s/it]                                                        Episode 10	 reward: -5.81	 makespan: 575.50	 Mean_loss: 0.17722344,  training time: 1.71
progress:  18%|[34m        [0m| 9/50 [00:18<01:10,  1.72s/it]progress:  20%|[34m        [0m| 10/50 [00:18<01:08,  1.72s/it]                                                         Episode 11	 reward: -5.93	 makespan: 586.75	 Mean_loss: 0.10292907,  training time: 1.69
progress:  20%|[34m        [0m| 10/50 [00:19<01:08,  1.72s/it]progress:  22%|[34m       [0m| 11/50 [00:19<01:06,  1.71s/it]                                                         Episode 12	 reward: -6.17	 makespan: 611.25	 Mean_loss: 0.13475566,  training time: 1.70
progress:  22%|[34m       [0m| 11/50 [00:21<01:06,  1.71s/it]progress:  24%|[34m       [0m| 12/50 [00:21<01:04,  1.71s/it]                                                         Episode 13	 reward: -5.86	 makespan: 579.75	 Mean_loss: 0.06513954,  training time: 1.82
progress:  24%|[34m       [0m| 12/50 [00:23<01:04,  1.71s/it]progress:  26%|[34m       [0m| 13/50 [00:23<01:04,  1.74s/it]                                                         Episode 14	 reward: -6.15	 makespan: 608.50	 Mean_loss: 0.08037996,  training time: 1.70
progress:  26%|[34m       [0m| 13/50 [00:25<01:04,  1.74s/it]progress:  28%|[34m       [0m| 14/50 [00:25<01:02,  1.73s/it]                                                         Episode 15	 reward: -6.73	 makespan: 666.50	 Mean_loss: 0.13466230,  training time: 1.70
progress:  28%|[34m       [0m| 14/50 [00:26<01:02,  1.73s/it]progress:  30%|[34m       [0m| 15/50 [00:26<01:00,  1.72s/it]                                                         Episode 16	 reward: -6.28	 makespan: 622.00	 Mean_loss: 0.16805735,  training time: 1.70
progress:  30%|[34m       [0m| 15/50 [00:28<01:00,  1.72s/it]progress:  32%|[34m      [0m| 16/50 [00:28<00:58,  1.71s/it]                                                         Episode 17	 reward: -6.08	 makespan: 601.75	 Mean_loss: 0.11692259,  training time: 1.73
progress:  32%|[34m      [0m| 16/50 [00:30<00:58,  1.71s/it]progress:  34%|[34m      [0m| 17/50 [00:30<00:56,  1.72s/it]                                                         Episode 18	 reward: -6.12	 makespan: 605.50	 Mean_loss: 0.07923236,  training time: 1.71
progress:  34%|[34m      [0m| 17/50 [00:31<00:56,  1.72s/it]progress:  36%|[34m      [0m| 18/50 [00:31<00:54,  1.72s/it]                                                         Episode 19	 reward: -6.26	 makespan: 619.75	 Mean_loss: 0.08637147,  training time: 1.69
progress:  36%|[34m      [0m| 18/50 [00:33<00:54,  1.72s/it]progress:  38%|[34m      [0m| 19/50 [00:33<00:53,  1.71s/it]                                                         Episode 20	 reward: -6.06	 makespan: 599.75	 Mean_loss: 0.04511222,  training time: 1.74
progress:  38%|[34m      [0m| 19/50 [00:35<00:53,  1.71s/it]progress:  40%|[34m      [0m| 20/50 [00:35<00:51,  1.72s/it]                                                         Episode 21	 reward: -6.44	 makespan: 638.00	 Mean_loss: 0.09773920,  training time: 1.81
progress:  40%|[34m      [0m| 20/50 [00:37<00:51,  1.72s/it]progress:  42%|[34m     [0m| 21/50 [00:37<00:50,  1.75s/it]                                                         Episode 22	 reward: -5.80	 makespan: 574.00	 Mean_loss: 0.07417919,  training time: 1.70
progress:  42%|[34m     [0m| 21/50 [00:38<00:50,  1.75s/it]progress:  44%|[34m     [0m| 22/50 [00:38<00:48,  1.73s/it]                                                         Episode 23	 reward: -5.81	 makespan: 575.50	 Mean_loss: 0.07872732,  training time: 1.68
progress:  44%|[34m     [0m| 22/50 [00:40<00:48,  1.73s/it]progress:  46%|[34m     [0m| 23/50 [00:40<00:46,  1.72s/it]                                                         Episode 24	 reward: -6.17	 makespan: 611.00	 Mean_loss: 0.05829996,  training time: 1.69
progress:  46%|[34m     [0m| 23/50 [00:42<00:46,  1.72s/it]progress:  48%|[34m     [0m| 24/50 [00:42<00:44,  1.71s/it]                                                         Episode 25	 reward: -5.81	 makespan: 575.00	 Mean_loss: 0.06076958,  training time: 1.68
progress:  48%|[34m     [0m| 24/50 [00:43<00:44,  1.71s/it]progress:  50%|[34m     [0m| 25/50 [00:43<00:42,  1.70s/it]                                                         Episode 26	 reward: -6.21	 makespan: 614.50	 Mean_loss: 0.06852479,  training time: 1.69
progress:  50%|[34m     [0m| 25/50 [00:45<00:42,  1.70s/it]progress:  52%|[34m    [0m| 26/50 [00:45<00:40,  1.70s/it]                                                         Episode 27	 reward: -6.15	 makespan: 608.50	 Mean_loss: 0.07185686,  training time: 1.70
progress:  52%|[34m    [0m| 26/50 [00:47<00:40,  1.70s/it]progress:  54%|[34m    [0m| 27/50 [00:47<00:39,  1.70s/it]                                                         Episode 28	 reward: -5.61	 makespan: 555.25	 Mean_loss: 0.04465875,  training time: 1.68
progress:  54%|[34m    [0m| 27/50 [00:49<00:39,  1.70s/it]progress:  56%|[34m    [0m| 28/50 [00:49<00:37,  1.69s/it]                                                         Episode 29	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.05539774,  training time: 1.67
progress:  56%|[34m    [0m| 28/50 [00:50<00:37,  1.69s/it]progress:  58%|[34m    [0m| 29/50 [00:50<00:35,  1.69s/it]                                                         Episode 30	 reward: -5.90	 makespan: 584.25	 Mean_loss: 0.04601525,  training time: 1.72
progress:  58%|[34m    [0m| 29/50 [00:52<00:35,  1.69s/it]progress:  60%|[34m    [0m| 30/50 [00:52<00:33,  1.70s/it]                                                         Episode 31	 reward: -5.97	 makespan: 590.75	 Mean_loss: 0.06867856,  training time: 1.67
progress:  60%|[34m    [0m| 30/50 [00:54<00:33,  1.70s/it]progress:  62%|[34m   [0m| 31/50 [00:54<00:32,  1.69s/it]                                                         Episode 32	 reward: -5.47	 makespan: 541.25	 Mean_loss: 0.04205518,  training time: 1.68
progress:  62%|[34m   [0m| 31/50 [00:55<00:32,  1.69s/it]progress:  64%|[34m   [0m| 32/50 [00:55<00:30,  1.69s/it]                                                         Episode 33	 reward: -6.08	 makespan: 602.25	 Mean_loss: 0.06331089,  training time: 1.68
progress:  64%|[34m   [0m| 32/50 [00:57<00:30,  1.69s/it]progress:  66%|[34m   [0m| 33/50 [00:57<00:28,  1.68s/it]                                                         Episode 34	 reward: -5.69	 makespan: 563.75	 Mean_loss: 0.05216919,  training time: 1.67
progress:  66%|[34m   [0m| 33/50 [00:59<00:28,  1.68s/it]progress:  68%|[34m   [0m| 34/50 [00:59<00:26,  1.68s/it]                                                         Episode 35	 reward: -6.22	 makespan: 615.50	 Mean_loss: 0.07365746,  training time: 1.66
progress:  68%|[34m   [0m| 34/50 [01:00<00:26,  1.68s/it]progress:  70%|[34m   [0m| 35/50 [01:00<00:25,  1.67s/it]                                                         Episode 36	 reward: -5.94	 makespan: 587.75	 Mean_loss: 0.05174774,  training time: 1.67
progress:  70%|[34m   [0m| 35/50 [01:02<00:25,  1.67s/it]progress:  72%|[34m  [0m| 36/50 [01:02<00:23,  1.67s/it]                                                         Episode 37	 reward: -6.01	 makespan: 594.50	 Mean_loss: 0.06157834,  training time: 1.66
progress:  72%|[34m  [0m| 36/50 [01:04<00:23,  1.67s/it]progress:  74%|[34m  [0m| 37/50 [01:04<00:21,  1.67s/it]                                                         Episode 38	 reward: -5.75	 makespan: 569.00	 Mean_loss: 0.04060590,  training time: 1.67
progress:  74%|[34m  [0m| 37/50 [01:05<00:21,  1.67s/it]progress:  76%|[34m  [0m| 38/50 [01:05<00:20,  1.67s/it]                                                         Episode 39	 reward: -6.25	 makespan: 618.75	 Mean_loss: 0.05130449,  training time: 1.67
progress:  76%|[34m  [0m| 38/50 [01:07<00:20,  1.67s/it]progress:  78%|[34m  [0m| 39/50 [01:07<00:18,  1.67s/it]                                                         Episode 40	 reward: -6.01	 makespan: 595.25	 Mean_loss: 0.03658223,  training time: 1.67
progress:  78%|[34m  [0m| 39/50 [01:09<00:18,  1.67s/it]progress:  80%|[34m  [0m| 40/50 [01:09<00:16,  1.67s/it]                                                         Episode 41	 reward: -5.76	 makespan: 569.75	 Mean_loss: 0.06074542,  training time: 1.66
progress:  80%|[34m  [0m| 40/50 [01:10<00:16,  1.67s/it]progress:  82%|[34m [0m| 41/50 [01:10<00:15,  1.67s/it]                                                         Episode 42	 reward: -5.83	 makespan: 577.50	 Mean_loss: 0.04120198,  training time: 1.64
progress:  82%|[34m [0m| 41/50 [01:12<00:15,  1.67s/it]progress:  84%|[34m [0m| 42/50 [01:12<00:13,  1.66s/it]                                                         Episode 43	 reward: -5.79	 makespan: 573.00	 Mean_loss: 0.04903648,  training time: 1.69
progress:  84%|[34m [0m| 42/50 [01:14<00:13,  1.66s/it]progress:  86%|[34m [0m| 43/50 [01:14<00:11,  1.67s/it]                                                         Episode 44	 reward: -5.85	 makespan: 579.00	 Mean_loss: 0.02876645,  training time: 1.68
progress:  86%|[34m [0m| 43/50 [01:15<00:11,  1.67s/it]progress:  88%|[34m [0m| 44/50 [01:15<00:10,  1.67s/it]                                                         Episode 45	 reward: -5.90	 makespan: 583.75	 Mean_loss: 0.03666648,  training time: 1.68
progress:  88%|[34m [0m| 44/50 [01:17<00:10,  1.67s/it]progress:  90%|[34m [0m| 45/50 [01:17<00:08,  1.67s/it]                                                         Episode 46	 reward: -5.78	 makespan: 571.75	 Mean_loss: 0.04692530,  training time: 1.67
progress:  90%|[34m [0m| 45/50 [01:19<00:08,  1.67s/it]progress:  92%|[34m[0m| 46/50 [01:19<00:06,  1.67s/it]                                                         Episode 47	 reward: -5.68	 makespan: 562.50	 Mean_loss: 0.03678348,  training time: 1.68
progress:  92%|[34m[0m| 46/50 [01:20<00:06,  1.67s/it]progress:  94%|[34m[0m| 47/50 [01:20<00:05,  1.68s/it]                                                         Episode 48	 reward: -5.95	 makespan: 589.00	 Mean_loss: 0.04100750,  training time: 1.78
progress:  94%|[34m[0m| 47/50 [01:22<00:05,  1.68s/it]progress:  96%|[34m[0m| 48/50 [01:22<00:03,  1.71s/it]                                                         Episode 49	 reward: -5.83	 makespan: 577.25	 Mean_loss: 0.03767821,  training time: 1.69
progress:  96%|[34m[0m| 48/50 [01:24<00:03,  1.71s/it]progress:  98%|[34m[0m| 49/50 [01:24<00:01,  1.70s/it]                                                         Episode 50	 reward: -5.81	 makespan: 574.75	 Mean_loss: 0.04494480,  training time: 1.68
progress:  98%|[34m[0m| 49/50 [01:25<00:01,  1.70s/it]progress: 100%|[34m[0m| 50/50 [01:25<00:00,  1.70s/it]progress: 100%|[34m[0m| 50/50 [01:25<00:00,  1.72s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x7_10 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 10 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -9.09	 makespan: 900.25	 Mean_loss: 7.60551596,  training time: 3.44
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:48,  3.44s/it]                                                        Episode 2	 reward: -8.66	 makespan: 857.75	 Mean_loss: 0.77468127,  training time: 2.36
progress:   2%|[34m         [0m| 1/50 [00:05<02:48,  3.44s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:14,  2.81s/it]                                                        Episode 3	 reward: -8.93	 makespan: 884.50	 Mean_loss: 0.85748696,  training time: 2.38
progress:   4%|[34m         [0m| 2/50 [00:08<02:14,  2.81s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:02,  2.61s/it]                                                        Episode 4	 reward: -8.80	 makespan: 871.50	 Mean_loss: 0.61964440,  training time: 2.37
progress:   6%|[34m         [0m| 3/50 [00:10<02:02,  2.61s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:55,  2.52s/it]                                                        Episode 5	 reward: -8.63	 makespan: 854.50	 Mean_loss: 0.58631140,  training time: 2.34
progress:   8%|[34m         [0m| 4/50 [00:12<01:55,  2.52s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:50,  2.46s/it]                                                        Episode 6	 reward: -8.87	 makespan: 878.25	 Mean_loss: 0.57458436,  training time: 2.44
progress:  10%|[34m         [0m| 5/50 [00:15<01:50,  2.46s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:47,  2.45s/it]                                                        Episode 7	 reward: -9.29	 makespan: 919.50	 Mean_loss: 0.31021485,  training time: 2.36
progress:  12%|[34m        [0m| 6/50 [00:17<01:47,  2.45s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:44,  2.42s/it]                                                        Episode 8	 reward: -8.93	 makespan: 884.50	 Mean_loss: 0.30420953,  training time: 2.35
progress:  14%|[34m        [0m| 7/50 [00:20<01:44,  2.42s/it]progress:  16%|[34m        [0m| 8/50 [00:20<01:40,  2.40s/it]                                                        Episode 9	 reward: -8.93	 makespan: 883.75	 Mean_loss: 0.36377120,  training time: 2.35
progress:  16%|[34m        [0m| 8/50 [00:22<01:40,  2.40s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:37,  2.38s/it]                                                        Episode 10	 reward: -9.06	 makespan: 896.50	 Mean_loss: 0.34636396,  training time: 2.36
progress:  18%|[34m        [0m| 9/50 [00:24<01:37,  2.38s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:35,  2.38s/it]                                                         Episode 11	 reward: -8.83	 makespan: 874.50	 Mean_loss: 0.23308049,  training time: 2.35
progress:  20%|[34m        [0m| 10/50 [00:27<01:35,  2.38s/it]progress:  22%|[34m       [0m| 11/50 [00:27<01:32,  2.37s/it]                                                         Episode 12	 reward: -9.18	 makespan: 909.25	 Mean_loss: 0.21619572,  training time: 2.34
progress:  22%|[34m       [0m| 11/50 [00:29<01:32,  2.37s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:29,  2.36s/it]                                                         Episode 13	 reward: -8.88	 makespan: 879.25	 Mean_loss: 0.22990425,  training time: 2.34
progress:  24%|[34m       [0m| 12/50 [00:31<01:29,  2.36s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:27,  2.36s/it]                                                         Episode 14	 reward: -9.62	 makespan: 952.25	 Mean_loss: 0.23756710,  training time: 2.35
progress:  26%|[34m       [0m| 13/50 [00:34<01:27,  2.36s/it]progress:  28%|[34m       [0m| 14/50 [00:34<01:24,  2.35s/it]                                                         Episode 15	 reward: -9.16	 makespan: 907.25	 Mean_loss: 0.21194321,  training time: 2.36
progress:  28%|[34m       [0m| 14/50 [00:36<01:24,  2.35s/it]progress:  30%|[34m       [0m| 15/50 [00:36<01:22,  2.36s/it]                                                         Episode 16	 reward: -9.44	 makespan: 934.25	 Mean_loss: 0.22481444,  training time: 2.35
progress:  30%|[34m       [0m| 15/50 [00:38<01:22,  2.36s/it]progress:  32%|[34m      [0m| 16/50 [00:38<01:20,  2.35s/it]                                                         Episode 17	 reward: -9.04	 makespan: 894.75	 Mean_loss: 0.15711166,  training time: 2.34
progress:  32%|[34m      [0m| 16/50 [00:41<01:20,  2.35s/it]progress:  34%|[34m      [0m| 17/50 [00:41<01:17,  2.35s/it]                                                         Episode 18	 reward: -9.70	 makespan: 960.25	 Mean_loss: 0.16818002,  training time: 2.33
progress:  34%|[34m      [0m| 17/50 [00:43<01:17,  2.35s/it]progress:  36%|[34m      [0m| 18/50 [00:43<01:15,  2.34s/it]                                                         Episode 19	 reward: -9.29	 makespan: 919.75	 Mean_loss: 0.16485032,  training time: 2.34
progress:  36%|[34m      [0m| 18/50 [00:45<01:15,  2.34s/it]progress:  38%|[34m      [0m| 19/50 [00:45<01:12,  2.34s/it]                                                         Episode 20	 reward: -9.13	 makespan: 903.50	 Mean_loss: 0.16474512,  training time: 2.36
progress:  38%|[34m      [0m| 19/50 [00:48<01:12,  2.34s/it]progress:  40%|[34m      [0m| 20/50 [00:48<01:10,  2.35s/it]                                                         Episode 21	 reward: -9.02	 makespan: 893.25	 Mean_loss: 0.17136382,  training time: 2.34
progress:  40%|[34m      [0m| 20/50 [00:50<01:10,  2.35s/it]progress:  42%|[34m     [0m| 21/50 [00:50<01:08,  2.35s/it]                                                         Episode 22	 reward: -9.13	 makespan: 903.50	 Mean_loss: 0.15155242,  training time: 2.36
progress:  42%|[34m     [0m| 21/50 [00:52<01:08,  2.35s/it]progress:  44%|[34m     [0m| 22/50 [00:52<01:05,  2.35s/it]                                                         Episode 23	 reward: -9.31	 makespan: 921.25	 Mean_loss: 0.16191547,  training time: 2.35
progress:  44%|[34m     [0m| 22/50 [00:55<01:05,  2.35s/it]progress:  46%|[34m     [0m| 23/50 [00:55<01:03,  2.35s/it]                                                         Episode 24	 reward: -9.26	 makespan: 916.75	 Mean_loss: 0.16209123,  training time: 2.35
progress:  46%|[34m     [0m| 23/50 [00:57<01:03,  2.35s/it]progress:  48%|[34m     [0m| 24/50 [00:57<01:01,  2.35s/it]                                                         Episode 25	 reward: -9.23	 makespan: 914.25	 Mean_loss: 0.16491792,  training time: 2.34
progress:  48%|[34m     [0m| 24/50 [00:59<01:01,  2.35s/it]progress:  50%|[34m     [0m| 25/50 [00:59<00:58,  2.35s/it]                                                         Episode 26	 reward: -9.10	 makespan: 900.75	 Mean_loss: 0.12317155,  training time: 2.34
progress:  50%|[34m     [0m| 25/50 [01:02<00:58,  2.35s/it]progress:  52%|[34m    [0m| 26/50 [01:02<00:56,  2.35s/it]                                                         Episode 27	 reward: -8.55	 makespan: 846.00	 Mean_loss: 0.14977609,  training time: 2.34
progress:  52%|[34m    [0m| 26/50 [01:04<00:56,  2.35s/it]progress:  54%|[34m    [0m| 27/50 [01:04<00:53,  2.35s/it]                                                         Episode 28	 reward: -8.67	 makespan: 858.50	 Mean_loss: 0.15825814,  training time: 2.35
progress:  54%|[34m    [0m| 27/50 [01:07<00:53,  2.35s/it]progress:  56%|[34m    [0m| 28/50 [01:07<00:51,  2.35s/it]                                                         Episode 29	 reward: -8.57	 makespan: 848.25	 Mean_loss: 0.10560610,  training time: 2.35
progress:  56%|[34m    [0m| 28/50 [01:09<00:51,  2.35s/it]progress:  58%|[34m    [0m| 29/50 [01:09<00:49,  2.35s/it]                                                         Episode 30	 reward: -8.57	 makespan: 848.00	 Mean_loss: 0.12806326,  training time: 2.34
progress:  58%|[34m    [0m| 29/50 [01:11<00:49,  2.35s/it]progress:  60%|[34m    [0m| 30/50 [01:11<00:46,  2.35s/it]                                                         Episode 31	 reward: -8.76	 makespan: 867.50	 Mean_loss: 0.09726823,  training time: 2.35
progress:  60%|[34m    [0m| 30/50 [01:14<00:46,  2.35s/it]progress:  62%|[34m   [0m| 31/50 [01:14<00:44,  2.35s/it]                                                         Episode 32	 reward: -9.02	 makespan: 893.25	 Mean_loss: 0.12920637,  training time: 2.34
progress:  62%|[34m   [0m| 31/50 [01:16<00:44,  2.35s/it]progress:  64%|[34m   [0m| 32/50 [01:16<00:42,  2.35s/it]                                                         Episode 33	 reward: -8.67	 makespan: 858.00	 Mean_loss: 0.08314870,  training time: 2.34
progress:  64%|[34m   [0m| 32/50 [01:18<00:42,  2.35s/it]progress:  66%|[34m   [0m| 33/50 [01:18<00:39,  2.34s/it]                                                         Episode 34	 reward: -8.77	 makespan: 868.50	 Mean_loss: 0.08302947,  training time: 2.34
progress:  66%|[34m   [0m| 33/50 [01:21<00:39,  2.34s/it]progress:  68%|[34m   [0m| 34/50 [01:21<00:37,  2.34s/it]                                                         Episode 35	 reward: -9.13	 makespan: 903.75	 Mean_loss: 0.09832274,  training time: 2.34
progress:  68%|[34m   [0m| 34/50 [01:23<00:37,  2.34s/it]progress:  70%|[34m   [0m| 35/50 [01:23<00:35,  2.34s/it]                                                         Episode 36	 reward: -8.92	 makespan: 883.00	 Mean_loss: 0.11224142,  training time: 2.35
progress:  70%|[34m   [0m| 35/50 [01:25<00:35,  2.34s/it]progress:  72%|[34m  [0m| 36/50 [01:25<00:32,  2.35s/it]                                                         Episode 37	 reward: -9.06	 makespan: 896.50	 Mean_loss: 0.09324487,  training time: 2.34
progress:  72%|[34m  [0m| 36/50 [01:28<00:32,  2.35s/it]progress:  74%|[34m  [0m| 37/50 [01:28<00:30,  2.35s/it]                                                         Episode 38	 reward: -8.85	 makespan: 876.00	 Mean_loss: 0.08274759,  training time: 2.36
progress:  74%|[34m  [0m| 37/50 [01:30<00:30,  2.35s/it]progress:  76%|[34m  [0m| 38/50 [01:30<00:28,  2.35s/it]                                                         Episode 39	 reward: -8.39	 makespan: 830.75	 Mean_loss: 0.10908943,  training time: 2.35
progress:  76%|[34m  [0m| 38/50 [01:32<00:28,  2.35s/it]progress:  78%|[34m  [0m| 39/50 [01:32<00:25,  2.35s/it]                                                         Episode 40	 reward: -8.37	 makespan: 829.00	 Mean_loss: 0.08522732,  training time: 2.34
progress:  78%|[34m  [0m| 39/50 [01:35<00:25,  2.35s/it]progress:  80%|[34m  [0m| 40/50 [01:35<00:23,  2.35s/it]                                                         Episode 41	 reward: -8.83	 makespan: 874.50	 Mean_loss: 0.08067736,  training time: 2.34
progress:  80%|[34m  [0m| 40/50 [01:37<00:23,  2.35s/it]progress:  82%|[34m [0m| 41/50 [01:37<00:21,  2.35s/it]                                                         Episode 42	 reward: -8.72	 makespan: 863.75	 Mean_loss: 0.06633931,  training time: 2.34
progress:  82%|[34m [0m| 41/50 [01:39<00:21,  2.35s/it]progress:  84%|[34m [0m| 42/50 [01:39<00:18,  2.34s/it]                                                         Episode 43	 reward: -8.62	 makespan: 853.00	 Mean_loss: 0.05650207,  training time: 2.34
progress:  84%|[34m [0m| 42/50 [01:42<00:18,  2.34s/it]progress:  86%|[34m [0m| 43/50 [01:42<00:16,  2.34s/it]                                                         Episode 44	 reward: -8.38	 makespan: 829.50	 Mean_loss: 0.08050094,  training time: 2.35
progress:  86%|[34m [0m| 43/50 [01:44<00:16,  2.34s/it]progress:  88%|[34m [0m| 44/50 [01:44<00:14,  2.34s/it]                                                         Episode 45	 reward: -8.53	 makespan: 844.25	 Mean_loss: 0.08915360,  training time: 2.33
progress:  88%|[34m [0m| 44/50 [01:46<00:14,  2.34s/it]progress:  90%|[34m [0m| 45/50 [01:46<00:11,  2.34s/it]                                                         Episode 46	 reward: -8.74	 makespan: 865.25	 Mean_loss: 0.06397872,  training time: 2.33
progress:  90%|[34m [0m| 45/50 [01:49<00:11,  2.34s/it]progress:  92%|[34m[0m| 46/50 [01:49<00:09,  2.34s/it]                                                         Episode 47	 reward: -8.64	 makespan: 855.25	 Mean_loss: 0.07768227,  training time: 2.34
progress:  92%|[34m[0m| 46/50 [01:51<00:09,  2.34s/it]progress:  94%|[34m[0m| 47/50 [01:51<00:07,  2.34s/it]                                                         Episode 48	 reward: -8.89	 makespan: 880.25	 Mean_loss: 0.07108104,  training time: 2.36
progress:  94%|[34m[0m| 47/50 [01:53<00:07,  2.34s/it]progress:  96%|[34m[0m| 48/50 [01:53<00:04,  2.35s/it]                                                         Episode 49	 reward: -8.71	 makespan: 862.25	 Mean_loss: 0.08809647,  training time: 2.36
progress:  96%|[34m[0m| 48/50 [01:56<00:04,  2.35s/it]progress:  98%|[34m[0m| 49/50 [01:56<00:02,  2.35s/it]                                                         Episode 50	 reward: -8.69	 makespan: 860.50	 Mean_loss: 0.07346299,  training time: 2.34
progress:  98%|[34m[0m| 49/50 [01:58<00:02,  2.35s/it]progress: 100%|[34m[0m| 50/50 [01:58<00:00,  2.35s/it]progress: 100%|[34m[0m| 50/50 [01:58<00:00,  2.37s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x7_12 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 12 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -11.48	 makespan: 1136.50	 Mean_loss: 7.52627182,  training time: 3.86
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:09,  3.86s/it]                                                        Episode 2	 reward: -11.41	 makespan: 1129.75	 Mean_loss: 0.99692798,  training time: 2.77
progress:   2%|[34m         [0m| 1/50 [00:06<03:09,  3.86s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:34,  3.22s/it]                                                        Episode 3	 reward: -10.69	 makespan: 1058.25	 Mean_loss: 1.08519828,  training time: 2.79
progress:   4%|[34m         [0m| 2/50 [00:09<02:34,  3.22s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:22,  3.02s/it]                                                        Episode 4	 reward: -11.35	 makespan: 1124.00	 Mean_loss: 0.78509790,  training time: 2.77
progress:   6%|[34m         [0m| 3/50 [00:12<02:22,  3.02s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:14,  2.92s/it]                                                        Episode 5	 reward: -10.32	 makespan: 1021.25	 Mean_loss: 0.91131246,  training time: 2.86
progress:   8%|[34m         [0m| 4/50 [00:15<02:14,  2.92s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:10,  2.90s/it]                                                        Episode 6	 reward: -11.06	 makespan: 1095.25	 Mean_loss: 0.75427324,  training time: 2.77
progress:  10%|[34m         [0m| 5/50 [00:17<02:10,  2.90s/it]progress:  12%|[34m        [0m| 6/50 [00:17<02:05,  2.85s/it]                                                        Episode 7	 reward: -10.42	 makespan: 1031.25	 Mean_loss: 0.73774141,  training time: 2.76
progress:  12%|[34m        [0m| 6/50 [00:20<02:05,  2.85s/it]progress:  14%|[34m        [0m| 7/50 [00:20<02:01,  2.82s/it]                                                        Episode 8	 reward: -11.21	 makespan: 1109.50	 Mean_loss: 0.51105344,  training time: 2.74
progress:  14%|[34m        [0m| 7/50 [00:23<02:01,  2.82s/it]progress:  16%|[34m        [0m| 8/50 [00:23<01:57,  2.80s/it]                                                        Episode 9	 reward: -10.61	 makespan: 1050.50	 Mean_loss: 0.65847921,  training time: 2.75
progress:  16%|[34m        [0m| 8/50 [00:26<01:57,  2.80s/it]progress:  18%|[34m        [0m| 9/50 [00:26<01:54,  2.79s/it]                                                        Episode 10	 reward: -11.24	 makespan: 1112.75	 Mean_loss: 0.50499356,  training time: 2.76
progress:  18%|[34m        [0m| 9/50 [00:28<01:54,  2.79s/it]progress:  20%|[34m        [0m| 10/50 [00:28<01:51,  2.78s/it]                                                         Episode 11	 reward: -10.64	 makespan: 1053.50	 Mean_loss: 0.38345003,  training time: 2.77
progress:  20%|[34m        [0m| 10/50 [00:31<01:51,  2.78s/it]progress:  22%|[34m       [0m| 11/50 [00:31<01:48,  2.78s/it]                                                         Episode 12	 reward: -11.12	 makespan: 1101.25	 Mean_loss: 0.41446123,  training time: 2.78
progress:  22%|[34m       [0m| 11/50 [00:34<01:48,  2.78s/it]progress:  24%|[34m       [0m| 12/50 [00:34<01:45,  2.78s/it]                                                         Episode 13	 reward: -10.89	 makespan: 1078.00	 Mean_loss: 0.35544825,  training time: 2.76
progress:  24%|[34m       [0m| 12/50 [00:37<01:45,  2.78s/it]progress:  26%|[34m       [0m| 13/50 [00:37<01:42,  2.77s/it]                                                         Episode 14	 reward: -10.80	 makespan: 1069.25	 Mean_loss: 0.28199995,  training time: 2.75
progress:  26%|[34m       [0m| 13/50 [00:39<01:42,  2.77s/it]progress:  28%|[34m       [0m| 14/50 [00:39<01:39,  2.77s/it]                                                         Episode 15	 reward: -11.03	 makespan: 1091.75	 Mean_loss: 0.26891500,  training time: 2.76
progress:  28%|[34m       [0m| 14/50 [00:42<01:39,  2.77s/it]progress:  30%|[34m       [0m| 15/50 [00:42<01:36,  2.76s/it]                                                         Episode 16	 reward: -10.19	 makespan: 1009.00	 Mean_loss: 0.23414835,  training time: 2.76
progress:  30%|[34m       [0m| 15/50 [00:45<01:36,  2.76s/it]progress:  32%|[34m      [0m| 16/50 [00:45<01:34,  2.76s/it]                                                         Episode 17	 reward: -10.77	 makespan: 1065.75	 Mean_loss: 0.18854070,  training time: 2.77
progress:  32%|[34m      [0m| 16/50 [00:48<01:34,  2.76s/it]progress:  34%|[34m      [0m| 17/50 [00:48<01:31,  2.77s/it]                                                         Episode 18	 reward: -10.43	 makespan: 1032.50	 Mean_loss: 0.20220681,  training time: 2.75
progress:  34%|[34m      [0m| 17/50 [00:50<01:31,  2.77s/it]progress:  36%|[34m      [0m| 18/50 [00:50<01:28,  2.76s/it]                                                         Episode 19	 reward: -10.26	 makespan: 1015.25	 Mean_loss: 0.14931394,  training time: 2.79
progress:  36%|[34m      [0m| 18/50 [00:53<01:28,  2.76s/it]progress:  38%|[34m      [0m| 19/50 [00:53<01:25,  2.77s/it]                                                         Episode 20	 reward: -10.29	 makespan: 1018.25	 Mean_loss: 0.13566665,  training time: 2.76
progress:  38%|[34m      [0m| 19/50 [00:56<01:25,  2.77s/it]progress:  40%|[34m      [0m| 20/50 [00:56<01:22,  2.77s/it]                                                         Episode 21	 reward: -10.71	 makespan: 1060.50	 Mean_loss: 0.20769091,  training time: 2.75
progress:  40%|[34m      [0m| 20/50 [00:59<01:22,  2.77s/it]progress:  42%|[34m     [0m| 21/50 [00:59<01:20,  2.76s/it]                                                         Episode 22	 reward: -10.51	 makespan: 1040.50	 Mean_loss: 0.12428175,  training time: 2.76
progress:  42%|[34m     [0m| 21/50 [01:02<01:20,  2.76s/it]progress:  44%|[34m     [0m| 22/50 [01:02<01:17,  2.76s/it]                                                         Episode 23	 reward: -10.15	 makespan: 1004.50	 Mean_loss: 0.13189626,  training time: 2.76
progress:  44%|[34m     [0m| 22/50 [01:04<01:17,  2.76s/it]progress:  46%|[34m     [0m| 23/50 [01:04<01:14,  2.76s/it]                                                         Episode 24	 reward: -10.02	 makespan: 992.00	 Mean_loss: 0.14232753,  training time: 2.77
progress:  46%|[34m     [0m| 23/50 [01:07<01:14,  2.76s/it]progress:  48%|[34m     [0m| 24/50 [01:07<01:11,  2.76s/it]                                                         Episode 25	 reward: -9.91	 makespan: 981.25	 Mean_loss: 0.14480966,  training time: 2.76
progress:  48%|[34m     [0m| 24/50 [01:10<01:11,  2.76s/it]progress:  50%|[34m     [0m| 25/50 [01:10<01:09,  2.76s/it]                                                         Episode 26	 reward: -10.55	 makespan: 1044.00	 Mean_loss: 0.13095808,  training time: 2.76
progress:  50%|[34m     [0m| 25/50 [01:13<01:09,  2.76s/it]progress:  52%|[34m    [0m| 26/50 [01:13<01:06,  2.76s/it]                                                         Episode 27	 reward: -10.46	 makespan: 1035.50	 Mean_loss: 0.12493044,  training time: 2.77
progress:  52%|[34m    [0m| 26/50 [01:15<01:06,  2.76s/it]progress:  54%|[34m    [0m| 27/50 [01:15<01:03,  2.76s/it]                                                         Episode 28	 reward: -10.32	 makespan: 1021.75	 Mean_loss: 0.15746273,  training time: 2.76
progress:  54%|[34m    [0m| 27/50 [01:18<01:03,  2.76s/it]progress:  56%|[34m    [0m| 28/50 [01:18<01:00,  2.76s/it]                                                         Episode 29	 reward: -9.82	 makespan: 971.75	 Mean_loss: 0.13129967,  training time: 2.76
progress:  56%|[34m    [0m| 28/50 [01:21<01:00,  2.76s/it]progress:  58%|[34m    [0m| 29/50 [01:21<00:58,  2.76s/it]                                                         Episode 30	 reward: -10.46	 makespan: 1036.00	 Mean_loss: 0.14757380,  training time: 2.76
progress:  58%|[34m    [0m| 29/50 [01:24<00:58,  2.76s/it]progress:  60%|[34m    [0m| 30/50 [01:24<00:55,  2.76s/it]                                                         Episode 31	 reward: -10.74	 makespan: 1063.75	 Mean_loss: 0.17126805,  training time: 2.76
progress:  60%|[34m    [0m| 30/50 [01:26<00:55,  2.76s/it]progress:  62%|[34m   [0m| 31/50 [01:26<00:52,  2.76s/it]                                                         Episode 32	 reward: -10.56	 makespan: 1045.00	 Mean_loss: 0.13262635,  training time: 2.77
progress:  62%|[34m   [0m| 31/50 [01:29<00:52,  2.76s/it]progress:  64%|[34m   [0m| 32/50 [01:29<00:49,  2.76s/it]                                                         Episode 33	 reward: -10.15	 makespan: 1004.50	 Mean_loss: 0.09630266,  training time: 2.77
progress:  64%|[34m   [0m| 32/50 [01:32<00:49,  2.76s/it]progress:  66%|[34m   [0m| 33/50 [01:32<00:47,  2.77s/it]                                                         Episode 34	 reward: -11.08	 makespan: 1096.50	 Mean_loss: 0.13149463,  training time: 2.77
progress:  66%|[34m   [0m| 33/50 [01:35<00:47,  2.77s/it]progress:  68%|[34m   [0m| 34/50 [01:35<00:44,  2.77s/it]                                                         Episode 35	 reward: -10.75	 makespan: 1064.00	 Mean_loss: 0.13347872,  training time: 2.78
progress:  68%|[34m   [0m| 34/50 [01:37<00:44,  2.77s/it]progress:  70%|[34m   [0m| 35/50 [01:37<00:41,  2.77s/it]                                                         Episode 36	 reward: -10.38	 makespan: 1027.75	 Mean_loss: 0.12025350,  training time: 2.75
progress:  70%|[34m   [0m| 35/50 [01:40<00:41,  2.77s/it]progress:  72%|[34m  [0m| 36/50 [01:40<00:38,  2.77s/it]                                                         Episode 37	 reward: -10.13	 makespan: 1003.00	 Mean_loss: 0.15014471,  training time: 2.77
progress:  72%|[34m  [0m| 36/50 [01:43<00:38,  2.77s/it]progress:  74%|[34m  [0m| 37/50 [01:43<00:35,  2.77s/it]                                                         Episode 38	 reward: -10.44	 makespan: 1033.50	 Mean_loss: 0.13590792,  training time: 2.76
progress:  74%|[34m  [0m| 37/50 [01:46<00:35,  2.77s/it]progress:  76%|[34m  [0m| 38/50 [01:46<00:33,  2.77s/it]                                                         Episode 39	 reward: -10.47	 makespan: 1036.75	 Mean_loss: 0.10555677,  training time: 2.76
progress:  76%|[34m  [0m| 38/50 [01:49<00:33,  2.77s/it]progress:  78%|[34m  [0m| 39/50 [01:49<00:30,  2.77s/it]                                                         Episode 40	 reward: -10.82	 makespan: 1071.25	 Mean_loss: 0.13458294,  training time: 2.76
progress:  78%|[34m  [0m| 39/50 [01:51<00:30,  2.77s/it]progress:  80%|[34m  [0m| 40/50 [01:51<00:27,  2.76s/it]                                                         Episode 41	 reward: -10.52	 makespan: 1041.50	 Mean_loss: 0.12126372,  training time: 2.76
progress:  80%|[34m  [0m| 40/50 [01:54<00:27,  2.76s/it]progress:  82%|[34m [0m| 41/50 [01:54<00:24,  2.76s/it]                                                         Episode 42	 reward: -10.56	 makespan: 1045.00	 Mean_loss: 0.15929289,  training time: 2.77
progress:  82%|[34m [0m| 41/50 [01:57<00:24,  2.76s/it]progress:  84%|[34m [0m| 42/50 [01:57<00:22,  2.77s/it]                                                         Episode 43	 reward: -11.21	 makespan: 1109.75	 Mean_loss: 0.15052223,  training time: 2.77
progress:  84%|[34m [0m| 42/50 [02:00<00:22,  2.77s/it]progress:  86%|[34m [0m| 43/50 [02:00<00:19,  2.77s/it]                                                         Episode 44	 reward: -10.68	 makespan: 1057.00	 Mean_loss: 0.14408118,  training time: 2.77
progress:  86%|[34m [0m| 43/50 [02:02<00:19,  2.77s/it]progress:  88%|[34m [0m| 44/50 [02:02<00:16,  2.77s/it]                                                         Episode 45	 reward: -11.14	 makespan: 1102.50	 Mean_loss: 0.15459096,  training time: 2.76
progress:  88%|[34m [0m| 44/50 [02:05<00:16,  2.77s/it]progress:  90%|[34m [0m| 45/50 [02:05<00:13,  2.76s/it]                                                         Episode 46	 reward: -11.20	 makespan: 1108.75	 Mean_loss: 0.21972620,  training time: 2.76
progress:  90%|[34m [0m| 45/50 [02:08<00:13,  2.76s/it]progress:  92%|[34m[0m| 46/50 [02:08<00:11,  2.76s/it]                                                         Episode 47	 reward: -10.57	 makespan: 1046.50	 Mean_loss: 0.12037984,  training time: 2.82
progress:  92%|[34m[0m| 46/50 [02:11<00:11,  2.76s/it]progress:  94%|[34m[0m| 47/50 [02:11<00:08,  2.78s/it]                                                         Episode 48	 reward: -11.04	 makespan: 1093.00	 Mean_loss: 0.17954542,  training time: 2.88
progress:  94%|[34m[0m| 47/50 [02:14<00:08,  2.78s/it]progress:  96%|[34m[0m| 48/50 [02:14<00:05,  2.81s/it]                                                         Episode 49	 reward: -10.81	 makespan: 1069.75	 Mean_loss: 0.09801561,  training time: 2.78
progress:  96%|[34m[0m| 48/50 [02:16<00:05,  2.81s/it]progress:  98%|[34m[0m| 49/50 [02:16<00:02,  2.80s/it]                                                         Episode 50	 reward: -11.03	 makespan: 1092.25	 Mean_loss: 0.13509780,  training time: 2.78
progress:  98%|[34m[0m| 49/50 [02:19<00:02,  2.80s/it]progress: 100%|[34m[0m| 50/50 [02:19<00:00,  2.80s/it]progress: 100%|[34m[0m| 50/50 [02:19<00:00,  2.79s/it]
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x5_4 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 4 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.63	 makespan: 557.50	 Mean_loss: 3.12972713,  training time: 2.11
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:43,  2.11s/it]                                                        Episode 2	 reward: -5.24	 makespan: 518.50	 Mean_loss: 0.81092429,  training time: 1.04
progress:   2%|[34m         [0m| 1/50 [00:03<01:43,  2.11s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:11,  1.48s/it]                                                        Episode 3	 reward: -5.66	 makespan: 560.25	 Mean_loss: 0.67861855,  training time: 1.04
progress:   4%|[34m         [0m| 2/50 [00:04<01:11,  1.48s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:00,  1.28s/it]                                                        Episode 4	 reward: -5.64	 makespan: 558.50	 Mean_loss: 0.43395567,  training time: 1.04
progress:   6%|[34m         [0m| 3/50 [00:05<01:00,  1.28s/it]progress:   8%|[34m         [0m| 4/50 [00:05<00:54,  1.19s/it]                                                        Episode 5	 reward: -5.49	 makespan: 543.25	 Mean_loss: 0.30820665,  training time: 1.00
progress:   8%|[34m         [0m| 4/50 [00:06<00:54,  1.19s/it]progress:  10%|[34m         [0m| 5/50 [00:06<00:50,  1.12s/it]                                                        Episode 6	 reward: -5.58	 makespan: 552.25	 Mean_loss: 0.26505962,  training time: 1.03
progress:  10%|[34m         [0m| 5/50 [00:07<00:50,  1.12s/it]progress:  12%|[34m        [0m| 6/50 [00:07<00:47,  1.09s/it]                                                        Episode 7	 reward: -5.40	 makespan: 535.00	 Mean_loss: 0.22633350,  training time: 1.00
progress:  12%|[34m        [0m| 6/50 [00:08<00:47,  1.09s/it]progress:  14%|[34m        [0m| 7/50 [00:08<00:45,  1.06s/it]                                                        Episode 8	 reward: -5.79	 makespan: 573.00	 Mean_loss: 0.25193381,  training time: 1.04
progress:  14%|[34m        [0m| 7/50 [00:09<00:45,  1.06s/it]progress:  16%|[34m        [0m| 8/50 [00:09<00:44,  1.05s/it]                                                        Episode 9	 reward: -5.65	 makespan: 559.00	 Mean_loss: 0.24455598,  training time: 1.01
progress:  16%|[34m        [0m| 8/50 [00:10<00:44,  1.05s/it]progress:  18%|[34m        [0m| 9/50 [00:10<00:42,  1.04s/it]                                                        Episode 10	 reward: -5.62	 makespan: 556.50	 Mean_loss: 0.28727955,  training time: 1.02
progress:  18%|[34m        [0m| 9/50 [00:11<00:42,  1.04s/it]progress:  20%|[34m        [0m| 10/50 [00:11<00:41,  1.03s/it]                                                         Episode 11	 reward: -6.06	 makespan: 600.00	 Mean_loss: 0.28794855,  training time: 1.00
progress:  20%|[34m        [0m| 10/50 [00:12<00:41,  1.03s/it]progress:  22%|[34m       [0m| 11/50 [00:12<00:40,  1.03s/it]                                                         Episode 12	 reward: -5.63	 makespan: 557.50	 Mean_loss: 0.20793942,  training time: 1.12
progress:  22%|[34m       [0m| 11/50 [00:13<00:40,  1.03s/it]progress:  24%|[34m       [0m| 12/50 [00:13<00:40,  1.06s/it]                                                         Episode 13	 reward: -5.94	 makespan: 587.75	 Mean_loss: 0.17917955,  training time: 1.05
progress:  24%|[34m       [0m| 12/50 [00:14<00:40,  1.06s/it]progress:  26%|[34m       [0m| 13/50 [00:14<00:39,  1.06s/it]                                                         Episode 14	 reward: -5.87	 makespan: 581.25	 Mean_loss: 0.19333762,  training time: 1.04
progress:  26%|[34m       [0m| 13/50 [00:15<00:39,  1.06s/it]progress:  28%|[34m       [0m| 14/50 [00:15<00:37,  1.05s/it]                                                         Episode 15	 reward: -5.53	 makespan: 547.25	 Mean_loss: 0.10134452,  training time: 1.04
progress:  28%|[34m       [0m| 14/50 [00:16<00:37,  1.05s/it]progress:  30%|[34m       [0m| 15/50 [00:16<00:36,  1.05s/it]                                                         Episode 16	 reward: -5.71	 makespan: 565.00	 Mean_loss: 0.15176156,  training time: 1.05
progress:  30%|[34m       [0m| 15/50 [00:17<00:36,  1.05s/it]progress:  32%|[34m      [0m| 16/50 [00:17<00:35,  1.05s/it]                                                         Episode 17	 reward: -5.56	 makespan: 550.25	 Mean_loss: 0.10015504,  training time: 1.04
progress:  32%|[34m      [0m| 16/50 [00:18<00:35,  1.05s/it]progress:  34%|[34m      [0m| 17/50 [00:18<00:34,  1.05s/it]                                                         Episode 18	 reward: -5.49	 makespan: 544.00	 Mean_loss: 0.09816273,  training time: 1.05
progress:  34%|[34m      [0m| 17/50 [00:19<00:34,  1.05s/it]progress:  36%|[34m      [0m| 18/50 [00:19<00:33,  1.05s/it]                                                         Episode 19	 reward: -5.21	 makespan: 516.00	 Mean_loss: 0.10379462,  training time: 1.02
progress:  36%|[34m      [0m| 18/50 [00:20<00:33,  1.05s/it]progress:  38%|[34m      [0m| 19/50 [00:20<00:32,  1.04s/it]                                                         Episode 20	 reward: -5.41	 makespan: 535.50	 Mean_loss: 0.07225227,  training time: 1.00
progress:  38%|[34m      [0m| 19/50 [00:21<00:32,  1.04s/it]progress:  40%|[34m      [0m| 20/50 [00:21<00:30,  1.03s/it]                                                         Episode 21	 reward: -5.81	 makespan: 575.00	 Mean_loss: 0.18350670,  training time: 1.04
progress:  40%|[34m      [0m| 20/50 [00:22<00:30,  1.03s/it]progress:  42%|[34m     [0m| 21/50 [00:22<00:29,  1.03s/it]                                                         Episode 22	 reward: -5.64	 makespan: 558.75	 Mean_loss: 0.07982390,  training time: 1.04
progress:  42%|[34m     [0m| 21/50 [00:23<00:29,  1.03s/it]progress:  44%|[34m     [0m| 22/50 [00:23<00:28,  1.03s/it]                                                         Episode 23	 reward: -5.49	 makespan: 543.50	 Mean_loss: 0.09679767,  training time: 1.06
progress:  44%|[34m     [0m| 22/50 [00:24<00:28,  1.03s/it]progress:  46%|[34m     [0m| 23/50 [00:24<00:28,  1.04s/it]                                                         Episode 24	 reward: -5.49	 makespan: 543.50	 Mean_loss: 0.07297995,  training time: 1.04
progress:  46%|[34m     [0m| 23/50 [00:25<00:28,  1.04s/it]progress:  48%|[34m     [0m| 24/50 [00:25<00:27,  1.04s/it]                                                         Episode 25	 reward: -5.66	 makespan: 560.75	 Mean_loss: 0.08484403,  training time: 1.03
progress:  48%|[34m     [0m| 24/50 [00:26<00:27,  1.04s/it]progress:  50%|[34m     [0m| 25/50 [00:26<00:25,  1.04s/it]                                                         Episode 26	 reward: -5.18	 makespan: 512.75	 Mean_loss: 0.09770957,  training time: 1.04
progress:  50%|[34m     [0m| 25/50 [00:28<00:25,  1.04s/it]progress:  52%|[34m    [0m| 26/50 [00:28<00:24,  1.04s/it]                                                         Episode 27	 reward: -5.69	 makespan: 563.25	 Mean_loss: 0.11904274,  training time: 1.03
progress:  52%|[34m    [0m| 26/50 [00:29<00:24,  1.04s/it]progress:  54%|[34m    [0m| 27/50 [00:29<00:23,  1.04s/it]                                                         Episode 28	 reward: -5.52	 makespan: 546.25	 Mean_loss: 0.09898497,  training time: 1.05
progress:  54%|[34m    [0m| 27/50 [00:30<00:23,  1.04s/it]progress:  56%|[34m    [0m| 28/50 [00:30<00:22,  1.04s/it]                                                         Episode 29	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.09150750,  training time: 1.03
progress:  56%|[34m    [0m| 28/50 [00:31<00:22,  1.04s/it]progress:  58%|[34m    [0m| 29/50 [00:31<00:21,  1.04s/it]                                                         Episode 30	 reward: -5.43	 makespan: 537.25	 Mean_loss: 0.07982416,  training time: 1.04
progress:  58%|[34m    [0m| 29/50 [00:32<00:21,  1.04s/it]progress:  60%|[34m    [0m| 30/50 [00:32<00:20,  1.04s/it]                                                         Episode 31	 reward: -5.38	 makespan: 532.75	 Mean_loss: 0.09296385,  training time: 1.04
progress:  60%|[34m    [0m| 30/50 [00:33<00:20,  1.04s/it]progress:  62%|[34m   [0m| 31/50 [00:33<00:19,  1.04s/it]                                                         Episode 32	 reward: -5.68	 makespan: 562.75	 Mean_loss: 0.08687678,  training time: 1.09
progress:  62%|[34m   [0m| 31/50 [00:34<00:19,  1.04s/it]progress:  64%|[34m   [0m| 32/50 [00:34<00:19,  1.06s/it]                                                         Episode 33	 reward: -5.96	 makespan: 589.75	 Mean_loss: 0.12416187,  training time: 1.10
progress:  64%|[34m   [0m| 32/50 [00:35<00:19,  1.06s/it]progress:  66%|[34m   [0m| 33/50 [00:35<00:18,  1.07s/it]                                                         Episode 34	 reward: -6.06	 makespan: 600.00	 Mean_loss: 0.14101481,  training time: 1.04
progress:  66%|[34m   [0m| 33/50 [00:36<00:18,  1.07s/it]progress:  68%|[34m   [0m| 34/50 [00:36<00:16,  1.06s/it]                                                         Episode 35	 reward: -6.04	 makespan: 598.25	 Mean_loss: 0.06858421,  training time: 1.04
progress:  68%|[34m   [0m| 34/50 [00:37<00:16,  1.06s/it]progress:  70%|[34m   [0m| 35/50 [00:37<00:15,  1.06s/it]                                                         Episode 36	 reward: -5.95	 makespan: 589.00	 Mean_loss: 0.08557436,  training time: 1.03
progress:  70%|[34m   [0m| 35/50 [00:38<00:15,  1.06s/it]progress:  72%|[34m  [0m| 36/50 [00:38<00:14,  1.05s/it]                                                         Episode 37	 reward: -6.15	 makespan: 609.00	 Mean_loss: 0.06867854,  training time: 1.04
progress:  72%|[34m  [0m| 36/50 [00:39<00:14,  1.05s/it]progress:  74%|[34m  [0m| 37/50 [00:39<00:13,  1.05s/it]                                                         Episode 38	 reward: -6.14	 makespan: 608.00	 Mean_loss: 0.08360440,  training time: 1.04
progress:  74%|[34m  [0m| 37/50 [00:40<00:13,  1.05s/it]progress:  76%|[34m  [0m| 38/50 [00:40<00:12,  1.05s/it]                                                         Episode 39	 reward: -6.42	 makespan: 636.00	 Mean_loss: 0.15288351,  training time: 1.03
progress:  76%|[34m  [0m| 38/50 [00:41<00:12,  1.05s/it]progress:  78%|[34m  [0m| 39/50 [00:41<00:11,  1.04s/it]                                                         Episode 40	 reward: -6.07	 makespan: 600.50	 Mean_loss: 0.10740127,  training time: 1.05
progress:  78%|[34m  [0m| 39/50 [00:42<00:11,  1.04s/it]progress:  80%|[34m  [0m| 40/50 [00:42<00:10,  1.05s/it]                                                         Episode 41	 reward: -6.11	 makespan: 604.75	 Mean_loss: 0.10532855,  training time: 1.06
progress:  80%|[34m  [0m| 40/50 [00:43<00:10,  1.05s/it]progress:  82%|[34m [0m| 41/50 [00:43<00:09,  1.05s/it]                                                         Episode 42	 reward: -5.53	 makespan: 547.50	 Mean_loss: 0.07200844,  training time: 1.04
progress:  82%|[34m [0m| 41/50 [00:44<00:09,  1.05s/it]progress:  84%|[34m [0m| 42/50 [00:44<00:08,  1.05s/it]                                                         Episode 43	 reward: -5.79	 makespan: 573.25	 Mean_loss: 0.06593212,  training time: 1.05
progress:  84%|[34m [0m| 42/50 [00:45<00:08,  1.05s/it]progress:  86%|[34m [0m| 43/50 [00:45<00:07,  1.05s/it]                                                         Episode 44	 reward: -5.66	 makespan: 560.75	 Mean_loss: 0.08779830,  training time: 1.03
progress:  86%|[34m [0m| 43/50 [00:46<00:07,  1.05s/it]progress:  88%|[34m [0m| 44/50 [00:46<00:06,  1.04s/it]                                                         Episode 45	 reward: -5.22	 makespan: 516.50	 Mean_loss: 0.05091659,  training time: 1.04
progress:  88%|[34m [0m| 44/50 [00:47<00:06,  1.04s/it]progress:  90%|[34m [0m| 45/50 [00:47<00:05,  1.04s/it]                                                         Episode 46	 reward: -5.31	 makespan: 526.00	 Mean_loss: 0.05966917,  training time: 1.05
progress:  90%|[34m [0m| 45/50 [00:48<00:05,  1.04s/it]progress:  92%|[34m[0m| 46/50 [00:48<00:04,  1.04s/it]                                                         Episode 47	 reward: -5.30	 makespan: 524.25	 Mean_loss: 0.05865951,  training time: 1.04
progress:  92%|[34m[0m| 46/50 [00:50<00:04,  1.04s/it]progress:  94%|[34m[0m| 47/50 [00:50<00:03,  1.04s/it]                                                         Episode 48	 reward: -5.43	 makespan: 537.25	 Mean_loss: 0.02814962,  training time: 1.04
progress:  94%|[34m[0m| 47/50 [00:51<00:03,  1.04s/it]progress:  96%|[34m[0m| 48/50 [00:51<00:02,  1.04s/it]                                                         Episode 49	 reward: -5.51	 makespan: 545.75	 Mean_loss: 0.05449912,  training time: 1.03
progress:  96%|[34m[0m| 48/50 [00:52<00:02,  1.04s/it]progress:  98%|[34m[0m| 49/50 [00:52<00:01,  1.04s/it]                                                         Episode 50	 reward: -5.22	 makespan: 517.00	 Mean_loss: 0.06259822,  training time: 1.02
progress:  98%|[34m[0m| 49/50 [00:53<00:01,  1.04s/it]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.04s/it]progress: 100%|[34m[0m| 50/50 [00:53<00:00,  1.06s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x5_7 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 7 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.86	 makespan: 777.75	 Mean_loss: 5.25647926,  training time: 2.72
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:13,  2.72s/it]                                                        Episode 2	 reward: -7.62	 makespan: 754.00	 Mean_loss: 0.63363147,  training time: 1.68
progress:   2%|[34m         [0m| 1/50 [00:04<02:13,  2.72s/it]progress:   4%|[34m         [0m| 2/50 [00:04<01:41,  2.11s/it]                                                        Episode 3	 reward: -7.90	 makespan: 782.00	 Mean_loss: 1.13229954,  training time: 1.69
progress:   4%|[34m         [0m| 2/50 [00:06<01:41,  2.11s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:30,  1.92s/it]                                                        Episode 4	 reward: -8.16	 makespan: 807.50	 Mean_loss: 0.86533034,  training time: 1.79
progress:   6%|[34m         [0m| 3/50 [00:07<01:30,  1.92s/it]progress:   8%|[34m         [0m| 4/50 [00:07<01:25,  1.87s/it]                                                        Episode 5	 reward: -8.27	 makespan: 819.00	 Mean_loss: 0.57160592,  training time: 1.71
progress:   8%|[34m         [0m| 4/50 [00:09<01:25,  1.87s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:21,  1.81s/it]                                                        Episode 6	 reward: -8.01	 makespan: 793.25	 Mean_loss: 0.38800701,  training time: 1.70
progress:  10%|[34m         [0m| 5/50 [00:11<01:21,  1.81s/it]progress:  12%|[34m        [0m| 6/50 [00:11<01:17,  1.77s/it]                                                        Episode 7	 reward: -7.75	 makespan: 767.25	 Mean_loss: 0.49778831,  training time: 1.70
progress:  12%|[34m        [0m| 6/50 [00:12<01:17,  1.77s/it]progress:  14%|[34m        [0m| 7/50 [00:12<01:15,  1.75s/it]                                                        Episode 8	 reward: -7.45	 makespan: 737.50	 Mean_loss: 0.24569455,  training time: 1.70
progress:  14%|[34m        [0m| 7/50 [00:14<01:15,  1.75s/it]progress:  16%|[34m        [0m| 8/50 [00:14<01:12,  1.73s/it]                                                        Episode 9	 reward: -7.58	 makespan: 750.75	 Mean_loss: 0.19498082,  training time: 1.70
progress:  16%|[34m        [0m| 8/50 [00:16<01:12,  1.73s/it]progress:  18%|[34m        [0m| 9/50 [00:16<01:10,  1.72s/it]                                                        Episode 10	 reward: -7.97	 makespan: 788.75	 Mean_loss: 0.25343561,  training time: 1.70
progress:  18%|[34m        [0m| 9/50 [00:18<01:10,  1.72s/it]progress:  20%|[34m        [0m| 10/50 [00:18<01:08,  1.71s/it]                                                         Episode 11	 reward: -7.90	 makespan: 781.75	 Mean_loss: 0.24719501,  training time: 1.69
progress:  20%|[34m        [0m| 10/50 [00:19<01:08,  1.71s/it]progress:  22%|[34m       [0m| 11/50 [00:19<01:06,  1.71s/it]                                                         Episode 12	 reward: -7.62	 makespan: 754.25	 Mean_loss: 0.18786615,  training time: 1.71
progress:  22%|[34m       [0m| 11/50 [00:21<01:06,  1.71s/it]progress:  24%|[34m       [0m| 12/50 [00:21<01:04,  1.71s/it]                                                         Episode 13	 reward: -7.53	 makespan: 745.25	 Mean_loss: 0.15627828,  training time: 1.79
progress:  24%|[34m       [0m| 12/50 [00:23<01:04,  1.71s/it]progress:  26%|[34m       [0m| 13/50 [00:23<01:04,  1.73s/it]                                                         Episode 14	 reward: -8.14	 makespan: 805.50	 Mean_loss: 0.15743321,  training time: 1.69
progress:  26%|[34m       [0m| 13/50 [00:24<01:04,  1.73s/it]progress:  28%|[34m       [0m| 14/50 [00:24<01:01,  1.72s/it]                                                         Episode 15	 reward: -7.85	 makespan: 777.25	 Mean_loss: 0.14741001,  training time: 1.70
progress:  28%|[34m       [0m| 14/50 [00:26<01:01,  1.72s/it]progress:  30%|[34m       [0m| 15/50 [00:26<01:00,  1.71s/it]                                                         Episode 16	 reward: -7.66	 makespan: 758.75	 Mean_loss: 0.19505790,  training time: 1.69
progress:  30%|[34m       [0m| 15/50 [00:28<01:00,  1.71s/it]progress:  32%|[34m      [0m| 16/50 [00:28<00:58,  1.71s/it]                                                         Episode 17	 reward: -8.01	 makespan: 792.75	 Mean_loss: 0.15656005,  training time: 1.70
progress:  32%|[34m      [0m| 16/50 [00:30<00:58,  1.71s/it]progress:  34%|[34m      [0m| 17/50 [00:30<00:56,  1.71s/it]                                                         Episode 18	 reward: -7.84	 makespan: 775.75	 Mean_loss: 0.11631185,  training time: 1.68
progress:  34%|[34m      [0m| 17/50 [00:31<00:56,  1.71s/it]progress:  36%|[34m      [0m| 18/50 [00:31<00:54,  1.70s/it]                                                         Episode 19	 reward: -7.80	 makespan: 771.75	 Mean_loss: 0.12940693,  training time: 1.72
progress:  36%|[34m      [0m| 18/50 [00:33<00:54,  1.70s/it]progress:  38%|[34m      [0m| 19/50 [00:33<00:52,  1.70s/it]                                                         Episode 20	 reward: -7.87	 makespan: 778.75	 Mean_loss: 0.10556767,  training time: 1.70
progress:  38%|[34m      [0m| 19/50 [00:35<00:52,  1.70s/it]progress:  40%|[34m      [0m| 20/50 [00:35<00:51,  1.70s/it]                                                         Episode 21	 reward: -7.92	 makespan: 784.50	 Mean_loss: 0.11691255,  training time: 1.68
progress:  40%|[34m      [0m| 20/50 [00:36<00:51,  1.70s/it]progress:  42%|[34m     [0m| 21/50 [00:36<00:49,  1.70s/it]                                                         Episode 22	 reward: -7.79	 makespan: 771.50	 Mean_loss: 0.13341227,  training time: 1.66
progress:  42%|[34m     [0m| 21/50 [00:38<00:49,  1.70s/it]progress:  44%|[34m     [0m| 22/50 [00:38<00:47,  1.69s/it]                                                         Episode 23	 reward: -7.71	 makespan: 763.50	 Mean_loss: 0.10206738,  training time: 1.68
progress:  44%|[34m     [0m| 22/50 [00:40<00:47,  1.69s/it]progress:  46%|[34m     [0m| 23/50 [00:40<00:45,  1.68s/it]                                                         Episode 24	 reward: -8.04	 makespan: 796.00	 Mean_loss: 0.09861659,  training time: 1.68
progress:  46%|[34m     [0m| 23/50 [00:41<00:45,  1.68s/it]progress:  48%|[34m     [0m| 24/50 [00:41<00:43,  1.68s/it]                                                         Episode 25	 reward: -8.33	 makespan: 824.75	 Mean_loss: 0.12041656,  training time: 1.67
progress:  48%|[34m     [0m| 24/50 [00:43<00:43,  1.68s/it]progress:  50%|[34m     [0m| 25/50 [00:43<00:41,  1.68s/it]                                                         Episode 26	 reward: -8.27	 makespan: 818.50	 Mean_loss: 0.10858332,  training time: 1.69
progress:  50%|[34m     [0m| 25/50 [00:45<00:41,  1.68s/it]progress:  52%|[34m    [0m| 26/50 [00:45<00:40,  1.68s/it]                                                         Episode 27	 reward: -8.39	 makespan: 831.00	 Mean_loss: 0.11617452,  training time: 1.68
progress:  52%|[34m    [0m| 26/50 [00:46<00:40,  1.68s/it]progress:  54%|[34m    [0m| 27/50 [00:46<00:38,  1.68s/it]                                                         Episode 28	 reward: -8.59	 makespan: 850.50	 Mean_loss: 0.13666619,  training time: 1.67
progress:  54%|[34m    [0m| 27/50 [00:48<00:38,  1.68s/it]progress:  56%|[34m    [0m| 28/50 [00:48<00:36,  1.68s/it]                                                         Episode 29	 reward: -8.10	 makespan: 802.25	 Mean_loss: 0.21719661,  training time: 1.68
progress:  56%|[34m    [0m| 28/50 [00:50<00:36,  1.68s/it]progress:  58%|[34m    [0m| 29/50 [00:50<00:35,  1.68s/it]                                                         Episode 30	 reward: -8.36	 makespan: 827.25	 Mean_loss: 0.19346067,  training time: 1.69
progress:  58%|[34m    [0m| 29/50 [00:51<00:35,  1.68s/it]progress:  60%|[34m    [0m| 30/50 [00:51<00:33,  1.68s/it]                                                         Episode 31	 reward: -8.24	 makespan: 815.75	 Mean_loss: 0.15063787,  training time: 1.67
progress:  60%|[34m    [0m| 30/50 [00:53<00:33,  1.68s/it]progress:  62%|[34m   [0m| 31/50 [00:53<00:31,  1.68s/it]                                                         Episode 32	 reward: -8.41	 makespan: 832.25	 Mean_loss: 0.15694059,  training time: 1.69
progress:  62%|[34m   [0m| 31/50 [00:55<00:31,  1.68s/it]progress:  64%|[34m   [0m| 32/50 [00:55<00:30,  1.68s/it]                                                         Episode 33	 reward: -8.30	 makespan: 821.25	 Mean_loss: 0.10265826,  training time: 1.70
progress:  64%|[34m   [0m| 32/50 [00:57<00:30,  1.68s/it]progress:  66%|[34m   [0m| 33/50 [00:57<00:28,  1.69s/it]                                                         Episode 34	 reward: -8.40	 makespan: 831.25	 Mean_loss: 0.11279956,  training time: 1.66
progress:  66%|[34m   [0m| 33/50 [00:58<00:28,  1.69s/it]progress:  68%|[34m   [0m| 34/50 [00:58<00:26,  1.68s/it]                                                         Episode 35	 reward: -8.55	 makespan: 846.00	 Mean_loss: 0.18305136,  training time: 1.66
progress:  68%|[34m   [0m| 34/50 [01:00<00:26,  1.68s/it]progress:  70%|[34m   [0m| 35/50 [01:00<00:25,  1.67s/it]                                                         Episode 36	 reward: -8.47	 makespan: 838.25	 Mean_loss: 0.11127317,  training time: 1.67
progress:  70%|[34m   [0m| 35/50 [01:02<00:25,  1.67s/it]progress:  72%|[34m  [0m| 36/50 [01:02<00:23,  1.67s/it]                                                         Episode 37	 reward: -8.91	 makespan: 881.75	 Mean_loss: 0.11764647,  training time: 1.67
progress:  72%|[34m  [0m| 36/50 [01:03<00:23,  1.67s/it]progress:  74%|[34m  [0m| 37/50 [01:03<00:21,  1.67s/it]                                                         Episode 38	 reward: -8.10	 makespan: 801.75	 Mean_loss: 0.16185814,  training time: 1.66
progress:  74%|[34m  [0m| 37/50 [01:05<00:21,  1.67s/it]progress:  76%|[34m  [0m| 38/50 [01:05<00:20,  1.67s/it]                                                         Episode 39	 reward: -8.31	 makespan: 822.50	 Mean_loss: 0.15225604,  training time: 1.66
progress:  76%|[34m  [0m| 38/50 [01:07<00:20,  1.67s/it]progress:  78%|[34m  [0m| 39/50 [01:07<00:18,  1.67s/it]                                                         Episode 40	 reward: -8.09	 makespan: 800.50	 Mean_loss: 0.14312088,  training time: 1.65
progress:  78%|[34m  [0m| 39/50 [01:08<00:18,  1.67s/it]progress:  80%|[34m  [0m| 40/50 [01:08<00:16,  1.66s/it]                                                         Episode 41	 reward: -8.60	 makespan: 851.50	 Mean_loss: 0.14912704,  training time: 1.66
progress:  80%|[34m  [0m| 40/50 [01:10<00:16,  1.66s/it]progress:  82%|[34m [0m| 41/50 [01:10<00:14,  1.66s/it]                                                         Episode 42	 reward: -8.45	 makespan: 836.25	 Mean_loss: 0.13615763,  training time: 1.68
progress:  82%|[34m [0m| 41/50 [01:12<00:14,  1.66s/it]progress:  84%|[34m [0m| 42/50 [01:12<00:13,  1.67s/it]                                                         Episode 43	 reward: -8.35	 makespan: 827.00	 Mean_loss: 0.12855685,  training time: 1.68
progress:  84%|[34m [0m| 42/50 [01:13<00:13,  1.67s/it]progress:  86%|[34m [0m| 43/50 [01:13<00:11,  1.67s/it]                                                         Episode 44	 reward: -8.32	 makespan: 823.50	 Mean_loss: 0.14569238,  training time: 1.67
progress:  86%|[34m [0m| 43/50 [01:15<00:11,  1.67s/it]progress:  88%|[34m [0m| 44/50 [01:15<00:10,  1.67s/it]                                                         Episode 45	 reward: -8.68	 makespan: 859.25	 Mean_loss: 0.12427092,  training time: 1.66
progress:  88%|[34m [0m| 44/50 [01:17<00:10,  1.67s/it]progress:  90%|[34m [0m| 45/50 [01:17<00:08,  1.67s/it]                                                         Episode 46	 reward: -8.20	 makespan: 812.25	 Mean_loss: 0.13397926,  training time: 1.67
progress:  90%|[34m [0m| 45/50 [01:18<00:08,  1.67s/it]progress:  92%|[34m[0m| 46/50 [01:18<00:06,  1.67s/it]                                                         Episode 47	 reward: -8.76	 makespan: 866.75	 Mean_loss: 0.11274096,  training time: 1.67
progress:  92%|[34m[0m| 46/50 [01:20<00:06,  1.67s/it]progress:  94%|[34m[0m| 47/50 [01:20<00:05,  1.67s/it]                                                         Episode 48	 reward: -8.34	 makespan: 825.75	 Mean_loss: 0.12963918,  training time: 1.67
progress:  94%|[34m[0m| 47/50 [01:22<00:05,  1.67s/it]progress:  96%|[34m[0m| 48/50 [01:22<00:03,  1.67s/it]                                                         Episode 49	 reward: -8.58	 makespan: 849.00	 Mean_loss: 0.10241446,  training time: 1.67
progress:  96%|[34m[0m| 48/50 [01:23<00:03,  1.67s/it]progress:  98%|[34m[0m| 49/50 [01:23<00:01,  1.67s/it]                                                         Episode 50	 reward: -7.90	 makespan: 782.25	 Mean_loss: 0.07869613,  training time: 1.66
progress:  98%|[34m[0m| 49/50 [01:25<00:01,  1.67s/it]progress: 100%|[34m[0m| 50/50 [01:25<00:00,  1.67s/it]progress: 100%|[34m[0m| 50/50 [01:25<00:00,  1.71s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x5_10 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -11.67	 makespan: 1155.25	 Mean_loss: 6.97573185,  training time: 3.49
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:50,  3.49s/it]                                                        Episode 2	 reward: -12.39	 makespan: 1227.00	 Mean_loss: 1.48748612,  training time: 2.25
progress:   2%|[34m         [0m| 1/50 [00:05<02:50,  3.49s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:12,  2.76s/it]                                                        Episode 3	 reward: -12.87	 makespan: 1274.25	 Mean_loss: 1.61116481,  training time: 2.29
progress:   4%|[34m         [0m| 2/50 [00:08<02:12,  2.76s/it]progress:   6%|[34m         [0m| 3/50 [00:08<01:59,  2.55s/it]                                                        Episode 4	 reward: -12.09	 makespan: 1196.50	 Mean_loss: 1.23840225,  training time: 2.37
progress:   6%|[34m         [0m| 3/50 [00:10<01:59,  2.55s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:53,  2.48s/it]                                                        Episode 5	 reward: -12.76	 makespan: 1263.50	 Mean_loss: 1.17684174,  training time: 2.33
progress:   8%|[34m         [0m| 4/50 [00:12<01:53,  2.48s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:49,  2.42s/it]                                                        Episode 6	 reward: -12.78	 makespan: 1265.25	 Mean_loss: 1.26955140,  training time: 2.42
progress:  10%|[34m         [0m| 5/50 [00:15<01:49,  2.42s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:46,  2.42s/it]                                                        Episode 7	 reward: -12.62	 makespan: 1249.75	 Mean_loss: 0.96125662,  training time: 2.34
progress:  12%|[34m        [0m| 6/50 [00:17<01:46,  2.42s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:43,  2.40s/it]                                                        Episode 8	 reward: -12.20	 makespan: 1208.00	 Mean_loss: 0.69457501,  training time: 2.38
progress:  14%|[34m        [0m| 7/50 [00:19<01:43,  2.40s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:40,  2.39s/it]                                                        Episode 9	 reward: -12.20	 makespan: 1207.75	 Mean_loss: 0.61627126,  training time: 2.30
progress:  16%|[34m        [0m| 8/50 [00:22<01:40,  2.39s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:36,  2.36s/it]                                                        Episode 10	 reward: -12.38	 makespan: 1225.50	 Mean_loss: 0.83232248,  training time: 2.30
progress:  18%|[34m        [0m| 9/50 [00:24<01:36,  2.36s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:33,  2.34s/it]                                                         Episode 11	 reward: -12.03	 makespan: 1191.00	 Mean_loss: 0.54183120,  training time: 2.29
progress:  20%|[34m        [0m| 10/50 [00:26<01:33,  2.34s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:30,  2.33s/it]                                                         Episode 12	 reward: -12.81	 makespan: 1268.50	 Mean_loss: 0.54879963,  training time: 2.30
progress:  22%|[34m       [0m| 11/50 [00:29<01:30,  2.33s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:28,  2.32s/it]                                                         Episode 13	 reward: -12.80	 makespan: 1267.00	 Mean_loss: 0.55216503,  training time: 2.32
progress:  24%|[34m       [0m| 12/50 [00:31<01:28,  2.32s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:25,  2.32s/it]                                                         Episode 14	 reward: -12.82	 makespan: 1268.75	 Mean_loss: 0.44187576,  training time: 2.30
progress:  26%|[34m       [0m| 13/50 [00:33<01:25,  2.32s/it]progress:  28%|[34m       [0m| 14/50 [00:33<01:23,  2.31s/it]                                                         Episode 15	 reward: -12.02	 makespan: 1189.50	 Mean_loss: 0.48424444,  training time: 2.30
progress:  28%|[34m       [0m| 14/50 [00:35<01:23,  2.31s/it]progress:  30%|[34m       [0m| 15/50 [00:35<01:20,  2.31s/it]                                                         Episode 16	 reward: -12.40	 makespan: 1228.00	 Mean_loss: 0.45740324,  training time: 2.31
progress:  30%|[34m       [0m| 15/50 [00:38<01:20,  2.31s/it]progress:  32%|[34m      [0m| 16/50 [00:38<01:18,  2.31s/it]                                                         Episode 17	 reward: -12.22	 makespan: 1210.00	 Mean_loss: 0.41914746,  training time: 2.37
progress:  32%|[34m      [0m| 16/50 [00:40<01:18,  2.31s/it]progress:  34%|[34m      [0m| 17/50 [00:40<01:16,  2.33s/it]                                                         Episode 18	 reward: -12.10	 makespan: 1197.75	 Mean_loss: 0.49408096,  training time: 2.30
progress:  34%|[34m      [0m| 17/50 [00:42<01:16,  2.33s/it]progress:  36%|[34m      [0m| 18/50 [00:42<01:14,  2.32s/it]                                                         Episode 19	 reward: -12.32	 makespan: 1220.00	 Mean_loss: 0.27806917,  training time: 2.31
progress:  36%|[34m      [0m| 18/50 [00:45<01:14,  2.32s/it]progress:  38%|[34m      [0m| 19/50 [00:45<01:11,  2.32s/it]                                                         Episode 20	 reward: -12.21	 makespan: 1208.50	 Mean_loss: 0.30862579,  training time: 2.32
progress:  38%|[34m      [0m| 19/50 [00:47<01:11,  2.32s/it]progress:  40%|[34m      [0m| 20/50 [00:47<01:09,  2.32s/it]                                                         Episode 21	 reward: -11.72	 makespan: 1160.75	 Mean_loss: 0.30338603,  training time: 2.30
progress:  40%|[34m      [0m| 20/50 [00:49<01:09,  2.32s/it]progress:  42%|[34m     [0m| 21/50 [00:49<01:07,  2.31s/it]                                                         Episode 22	 reward: -12.03	 makespan: 1191.00	 Mean_loss: 0.28331333,  training time: 2.31
progress:  42%|[34m     [0m| 21/50 [00:52<01:07,  2.31s/it]progress:  44%|[34m     [0m| 22/50 [00:52<01:04,  2.31s/it]                                                         Episode 23	 reward: -11.92	 makespan: 1180.50	 Mean_loss: 0.26818293,  training time: 2.30
progress:  44%|[34m     [0m| 22/50 [00:54<01:04,  2.31s/it]progress:  46%|[34m     [0m| 23/50 [00:54<01:02,  2.31s/it]                                                         Episode 24	 reward: -12.18	 makespan: 1206.00	 Mean_loss: 0.19167838,  training time: 2.29
progress:  46%|[34m     [0m| 23/50 [00:56<01:02,  2.31s/it]progress:  48%|[34m     [0m| 24/50 [00:56<00:59,  2.30s/it]                                                         Episode 25	 reward: -11.74	 makespan: 1162.25	 Mean_loss: 0.26079944,  training time: 2.30
progress:  48%|[34m     [0m| 24/50 [00:59<00:59,  2.30s/it]progress:  50%|[34m     [0m| 25/50 [00:59<00:57,  2.30s/it]                                                         Episode 26	 reward: -11.88	 makespan: 1176.25	 Mean_loss: 0.20458968,  training time: 2.30
progress:  50%|[34m     [0m| 25/50 [01:01<00:57,  2.30s/it]progress:  52%|[34m    [0m| 26/50 [01:01<00:55,  2.30s/it]                                                         Episode 27	 reward: -11.95	 makespan: 1183.50	 Mean_loss: 0.19446015,  training time: 2.31
progress:  52%|[34m    [0m| 26/50 [01:03<00:55,  2.30s/it]progress:  54%|[34m    [0m| 27/50 [01:03<00:52,  2.30s/it]                                                         Episode 28	 reward: -11.65	 makespan: 1153.25	 Mean_loss: 0.18453462,  training time: 2.29
progress:  54%|[34m    [0m| 27/50 [01:06<00:52,  2.30s/it]progress:  56%|[34m    [0m| 28/50 [01:06<00:50,  2.30s/it]                                                         Episode 29	 reward: -11.82	 makespan: 1170.00	 Mean_loss: 0.17241925,  training time: 2.32
progress:  56%|[34m    [0m| 28/50 [01:08<00:50,  2.30s/it]progress:  58%|[34m    [0m| 29/50 [01:08<00:48,  2.31s/it]                                                         Episode 30	 reward: -12.14	 makespan: 1202.00	 Mean_loss: 0.19914766,  training time: 2.30
progress:  58%|[34m    [0m| 29/50 [01:10<00:48,  2.31s/it]progress:  60%|[34m    [0m| 30/50 [01:10<00:46,  2.30s/it]                                                         Episode 31	 reward: -11.61	 makespan: 1149.50	 Mean_loss: 0.18010408,  training time: 2.30
progress:  60%|[34m    [0m| 30/50 [01:12<00:46,  2.30s/it]progress:  62%|[34m   [0m| 31/50 [01:12<00:43,  2.30s/it]                                                         Episode 32	 reward: -12.11	 makespan: 1199.25	 Mean_loss: 0.21538822,  training time: 2.30
progress:  62%|[34m   [0m| 31/50 [01:15<00:43,  2.30s/it]progress:  64%|[34m   [0m| 32/50 [01:15<00:41,  2.30s/it]                                                         Episode 33	 reward: -11.89	 makespan: 1177.00	 Mean_loss: 0.18001665,  training time: 2.30
progress:  64%|[34m   [0m| 32/50 [01:17<00:41,  2.30s/it]progress:  66%|[34m   [0m| 33/50 [01:17<00:39,  2.30s/it]                                                         Episode 34	 reward: -11.51	 makespan: 1139.75	 Mean_loss: 0.20845135,  training time: 2.30
progress:  66%|[34m   [0m| 33/50 [01:19<00:39,  2.30s/it]progress:  68%|[34m   [0m| 34/50 [01:19<00:36,  2.30s/it]                                                         Episode 35	 reward: -11.86	 makespan: 1174.50	 Mean_loss: 0.20753838,  training time: 2.29
progress:  68%|[34m   [0m| 34/50 [01:22<00:36,  2.30s/it]progress:  70%|[34m   [0m| 35/50 [01:22<00:34,  2.30s/it]                                                         Episode 36	 reward: -11.77	 makespan: 1165.50	 Mean_loss: 0.15682645,  training time: 2.36
progress:  70%|[34m   [0m| 35/50 [01:24<00:34,  2.30s/it]progress:  72%|[34m  [0m| 36/50 [01:24<00:32,  2.32s/it]                                                         Episode 37	 reward: -11.92	 makespan: 1180.50	 Mean_loss: 0.18268827,  training time: 2.29
progress:  72%|[34m  [0m| 36/50 [01:26<00:32,  2.32s/it]progress:  74%|[34m  [0m| 37/50 [01:26<00:30,  2.31s/it]                                                         Episode 38	 reward: -12.06	 makespan: 1194.25	 Mean_loss: 0.20324723,  training time: 2.32
progress:  74%|[34m  [0m| 37/50 [01:29<00:30,  2.31s/it]progress:  76%|[34m  [0m| 38/50 [01:29<00:27,  2.31s/it]                                                         Episode 39	 reward: -11.51	 makespan: 1139.00	 Mean_loss: 0.15004468,  training time: 2.30
progress:  76%|[34m  [0m| 38/50 [01:31<00:27,  2.31s/it]progress:  78%|[34m  [0m| 39/50 [01:31<00:25,  2.31s/it]                                                         Episode 40	 reward: -12.16	 makespan: 1203.75	 Mean_loss: 0.17148136,  training time: 2.29
progress:  78%|[34m  [0m| 39/50 [01:33<00:25,  2.31s/it]progress:  80%|[34m  [0m| 40/50 [01:33<00:23,  2.30s/it]                                                         Episode 41	 reward: -11.86	 makespan: 1173.75	 Mean_loss: 0.14149907,  training time: 2.27
progress:  80%|[34m  [0m| 40/50 [01:35<00:23,  2.30s/it]progress:  82%|[34m [0m| 41/50 [01:35<00:20,  2.30s/it]                                                         Episode 42	 reward: -11.46	 makespan: 1134.50	 Mean_loss: 0.15081666,  training time: 2.28
progress:  82%|[34m [0m| 41/50 [01:38<00:20,  2.30s/it]progress:  84%|[34m [0m| 42/50 [01:38<00:18,  2.29s/it]                                                         Episode 43	 reward: -11.75	 makespan: 1163.00	 Mean_loss: 0.12852560,  training time: 2.29
progress:  84%|[34m [0m| 42/50 [01:40<00:18,  2.29s/it]progress:  86%|[34m [0m| 43/50 [01:40<00:16,  2.29s/it]                                                         Episode 44	 reward: -12.33	 makespan: 1220.25	 Mean_loss: 0.16598614,  training time: 2.28
progress:  86%|[34m [0m| 43/50 [01:42<00:16,  2.29s/it]progress:  88%|[34m [0m| 44/50 [01:42<00:13,  2.29s/it]                                                         Episode 45	 reward: -11.95	 makespan: 1183.00	 Mean_loss: 0.10894130,  training time: 2.28
progress:  88%|[34m [0m| 44/50 [01:45<00:13,  2.29s/it]progress:  90%|[34m [0m| 45/50 [01:45<00:11,  2.29s/it]                                                         Episode 46	 reward: -11.96	 makespan: 1184.25	 Mean_loss: 0.11906654,  training time: 2.28
progress:  90%|[34m [0m| 45/50 [01:47<00:11,  2.29s/it]progress:  92%|[34m[0m| 46/50 [01:47<00:09,  2.29s/it]                                                         Episode 47	 reward: -11.73	 makespan: 1161.00	 Mean_loss: 0.13864259,  training time: 2.27
progress:  92%|[34m[0m| 46/50 [01:49<00:09,  2.29s/it]progress:  94%|[34m[0m| 47/50 [01:49<00:06,  2.28s/it]                                                         Episode 48	 reward: -11.95	 makespan: 1183.25	 Mean_loss: 0.11080328,  training time: 2.30
progress:  94%|[34m[0m| 47/50 [01:51<00:06,  2.28s/it]progress:  96%|[34m[0m| 48/50 [01:51<00:04,  2.29s/it]                                                         Episode 49	 reward: -11.72	 makespan: 1160.00	 Mean_loss: 0.10491418,  training time: 2.29
progress:  96%|[34m[0m| 48/50 [01:54<00:04,  2.29s/it]progress:  98%|[34m[0m| 49/50 [01:54<00:02,  2.29s/it]                                                         Episode 50	 reward: -11.79	 makespan: 1167.50	 Mean_loss: 0.10417720,  training time: 2.28
progress:  98%|[34m[0m| 49/50 [01:56<00:02,  2.29s/it]progress: 100%|[34m[0m| 50/50 [01:56<00:00,  2.29s/it]progress: 100%|[34m[0m| 50/50 [01:56<00:00,  2.33s/it]
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/maml/finetuning/maml+exp17_1_200_512_3_1/15x5_12 --model_suffix free --finetuning_model maml+exp17_1_200_512_3_1 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 12 --num_envs 4 --hidden_dim_actor 512 --hidden_dim_critic 512 --num_mlp_layers_actor 3 --num_mlp_layers_critic 3 --lr 0.003
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/maml+exp17_1_200_512_3_1.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -14.27	 makespan: 1412.25	 Mean_loss: 7.39904165,  training time: 3.78
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<03:05,  3.78s/it]                                                        Episode 2	 reward: -14.95	 makespan: 1480.00	 Mean_loss: 1.36319602,  training time: 2.83
progress:   2%|[34m         [0m| 1/50 [00:06<03:05,  3.78s/it]progress:   4%|[34m         [0m| 2/50 [00:06<02:34,  3.22s/it]                                                        Episode 3	 reward: -14.46	 makespan: 1431.25	 Mean_loss: 1.69996381,  training time: 2.82
progress:   4%|[34m         [0m| 2/50 [00:09<02:34,  3.22s/it]progress:   6%|[34m         [0m| 3/50 [00:09<02:22,  3.04s/it]                                                        Episode 4	 reward: -15.03	 makespan: 1488.00	 Mean_loss: 1.32598603,  training time: 2.79
progress:   6%|[34m         [0m| 3/50 [00:12<02:22,  3.04s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:15,  2.94s/it]                                                        Episode 5	 reward: -14.68	 makespan: 1453.50	 Mean_loss: 1.32417488,  training time: 2.91
progress:   8%|[34m         [0m| 4/50 [00:15<02:15,  2.94s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:11,  2.93s/it]                                                        Episode 6	 reward: -15.16	 makespan: 1500.50	 Mean_loss: 1.17533767,  training time: 2.82
progress:  10%|[34m         [0m| 5/50 [00:17<02:11,  2.93s/it]progress:  12%|[34m        [0m| 6/50 [00:17<02:07,  2.89s/it]                                                        Episode 7	 reward: -15.09	 makespan: 1493.75	 Mean_loss: 0.88074768,  training time: 2.82
progress:  12%|[34m        [0m| 6/50 [00:20<02:07,  2.89s/it]progress:  14%|[34m        [0m| 7/50 [00:20<02:03,  2.87s/it]                                                        Episode 8	 reward: -14.71	 makespan: 1456.25	 Mean_loss: 0.77801836,  training time: 2.78
progress:  14%|[34m        [0m| 7/50 [00:23<02:03,  2.87s/it]progress:  16%|[34m        [0m| 8/50 [00:23<01:59,  2.84s/it]                                                        Episode 9	 reward: -15.34	 makespan: 1518.50	 Mean_loss: 0.81489027,  training time: 2.74
progress:  16%|[34m        [0m| 8/50 [00:26<01:59,  2.84s/it]progress:  18%|[34m        [0m| 9/50 [00:26<01:55,  2.81s/it]                                                        Episode 10	 reward: -15.35	 makespan: 1519.75	 Mean_loss: 0.57219869,  training time: 2.76
progress:  18%|[34m        [0m| 9/50 [00:29<01:55,  2.81s/it]progress:  20%|[34m        [0m| 10/50 [00:29<01:51,  2.80s/it]                                                         Episode 11	 reward: -15.35	 makespan: 1520.00	 Mean_loss: 0.54521096,  training time: 2.75
progress:  20%|[34m        [0m| 10/50 [00:31<01:51,  2.80s/it]progress:  22%|[34m       [0m| 11/50 [00:31<01:48,  2.78s/it]                                                         Episode 12	 reward: -15.49	 makespan: 1533.50	 Mean_loss: 0.48006845,  training time: 2.76
progress:  22%|[34m       [0m| 11/50 [00:34<01:48,  2.78s/it]progress:  24%|[34m       [0m| 12/50 [00:34<01:45,  2.78s/it]                                                         Episode 13	 reward: -15.41	 makespan: 1525.50	 Mean_loss: 0.45949480,  training time: 2.76
progress:  24%|[34m       [0m| 12/50 [00:37<01:45,  2.78s/it]progress:  26%|[34m       [0m| 13/50 [00:37<01:42,  2.77s/it]                                                         Episode 14	 reward: -14.90	 makespan: 1475.25	 Mean_loss: 0.39778602,  training time: 2.75
progress:  26%|[34m       [0m| 13/50 [00:40<01:42,  2.77s/it]progress:  28%|[34m       [0m| 14/50 [00:40<01:39,  2.77s/it]                                                         Episode 15	 reward: -15.16	 makespan: 1501.00	 Mean_loss: 0.40864938,  training time: 2.76
progress:  28%|[34m       [0m| 14/50 [00:42<01:39,  2.77s/it]progress:  30%|[34m       [0m| 15/50 [00:42<01:36,  2.76s/it]                                                         Episode 16	 reward: -14.82	 makespan: 1467.50	 Mean_loss: 0.33509049,  training time: 2.77
progress:  30%|[34m       [0m| 15/50 [00:45<01:36,  2.76s/it]progress:  32%|[34m      [0m| 16/50 [00:45<01:34,  2.77s/it]                                                         Episode 17	 reward: -15.06	 makespan: 1490.75	 Mean_loss: 0.30653509,  training time: 2.78
progress:  32%|[34m      [0m| 16/50 [00:48<01:34,  2.77s/it]progress:  34%|[34m      [0m| 17/50 [00:48<01:31,  2.77s/it]                                                         Episode 18	 reward: -14.80	 makespan: 1465.00	 Mean_loss: 0.27493775,  training time: 2.91
progress:  34%|[34m      [0m| 17/50 [00:51<01:31,  2.77s/it]progress:  36%|[34m      [0m| 18/50 [00:51<01:29,  2.81s/it]                                                         Episode 19	 reward: -14.70	 makespan: 1455.75	 Mean_loss: 0.30635494,  training time: 2.76
progress:  36%|[34m      [0m| 18/50 [00:54<01:29,  2.81s/it]progress:  38%|[34m      [0m| 19/50 [00:54<01:26,  2.80s/it]                                                         Episode 20	 reward: -14.41	 makespan: 1426.75	 Mean_loss: 0.28137651,  training time: 2.75
progress:  38%|[34m      [0m| 19/50 [00:56<01:26,  2.80s/it]progress:  40%|[34m      [0m| 20/50 [00:56<01:23,  2.78s/it]                                                         Episode 21	 reward: -14.51	 makespan: 1436.50	 Mean_loss: 0.26327151,  training time: 2.74
progress:  40%|[34m      [0m| 20/50 [00:59<01:23,  2.78s/it]progress:  42%|[34m     [0m| 21/50 [00:59<01:20,  2.77s/it]                                                         Episode 22	 reward: -15.19	 makespan: 1503.75	 Mean_loss: 0.25999385,  training time: 2.74
progress:  42%|[34m     [0m| 21/50 [01:02<01:20,  2.77s/it]progress:  44%|[34m     [0m| 22/50 [01:02<01:17,  2.76s/it]                                                         Episode 23	 reward: -15.31	 makespan: 1515.25	 Mean_loss: 0.23008414,  training time: 2.74
progress:  44%|[34m     [0m| 22/50 [01:05<01:17,  2.76s/it]progress:  46%|[34m     [0m| 23/50 [01:05<01:14,  2.76s/it]                                                         Episode 24	 reward: -14.63	 makespan: 1448.75	 Mean_loss: 0.22000457,  training time: 2.74
progress:  46%|[34m     [0m| 23/50 [01:07<01:14,  2.76s/it]progress:  48%|[34m     [0m| 24/50 [01:07<01:11,  2.75s/it]                                                         Episode 25	 reward: -15.15	 makespan: 1499.75	 Mean_loss: 0.20449997,  training time: 2.78
progress:  48%|[34m     [0m| 24/50 [01:10<01:11,  2.75s/it]progress:  50%|[34m     [0m| 25/50 [01:10<01:09,  2.76s/it]                                                         Episode 26	 reward: -14.71	 makespan: 1456.50	 Mean_loss: 0.20035735,  training time: 2.72
progress:  50%|[34m     [0m| 25/50 [01:13<01:09,  2.76s/it]progress:  52%|[34m    [0m| 26/50 [01:13<01:05,  2.75s/it]                                                         Episode 27	 reward: -15.13	 makespan: 1497.50	 Mean_loss: 0.18545021,  training time: 2.73
progress:  52%|[34m    [0m| 26/50 [01:16<01:05,  2.75s/it]progress:  54%|[34m    [0m| 27/50 [01:16<01:03,  2.74s/it]                                                         Episode 28	 reward: -15.60	 makespan: 1544.25	 Mean_loss: 0.21836938,  training time: 2.72
progress:  54%|[34m    [0m| 27/50 [01:18<01:03,  2.74s/it]progress:  56%|[34m    [0m| 28/50 [01:18<01:00,  2.74s/it]                                                         Episode 29	 reward: -15.02	 makespan: 1486.50	 Mean_loss: 0.17827964,  training time: 2.83
progress:  56%|[34m    [0m| 28/50 [01:21<01:00,  2.74s/it]progress:  58%|[34m    [0m| 29/50 [01:21<00:58,  2.77s/it]                                                         Episode 30	 reward: -14.99	 makespan: 1484.25	 Mean_loss: 0.21194717,  training time: 2.72
progress:  58%|[34m    [0m| 29/50 [01:24<00:58,  2.77s/it]progress:  60%|[34m    [0m| 30/50 [01:24<00:55,  2.75s/it]                                                         Episode 31	 reward: -15.17	 makespan: 1501.50	 Mean_loss: 0.16842036,  training time: 2.72
progress:  60%|[34m    [0m| 30/50 [01:27<00:55,  2.75s/it]progress:  62%|[34m   [0m| 31/50 [01:27<00:52,  2.74s/it]                                                         Episode 32	 reward: -15.23	 makespan: 1507.50	 Mean_loss: 0.19464377,  training time: 2.71
progress:  62%|[34m   [0m| 31/50 [01:29<00:52,  2.74s/it]progress:  64%|[34m   [0m| 32/50 [01:29<00:49,  2.73s/it]                                                         Episode 33	 reward: -14.58	 makespan: 1443.50	 Mean_loss: 0.21492635,  training time: 2.71
progress:  64%|[34m   [0m| 32/50 [01:32<00:49,  2.73s/it]progress:  66%|[34m   [0m| 33/50 [01:32<00:46,  2.73s/it]                                                         Episode 34	 reward: -14.64	 makespan: 1449.00	 Mean_loss: 0.18712303,  training time: 2.72
progress:  66%|[34m   [0m| 33/50 [01:35<00:46,  2.73s/it]progress:  68%|[34m   [0m| 34/50 [01:35<00:43,  2.73s/it]                                                         Episode 35	 reward: -14.62	 makespan: 1447.50	 Mean_loss: 0.16798759,  training time: 2.73
progress:  68%|[34m   [0m| 34/50 [01:37<00:43,  2.73s/it]progress:  70%|[34m   [0m| 35/50 [01:37<00:40,  2.73s/it]                                                         Episode 36	 reward: -14.77	 makespan: 1462.50	 Mean_loss: 0.11444286,  training time: 2.71
progress:  70%|[34m   [0m| 35/50 [01:40<00:40,  2.73s/it]progress:  72%|[34m  [0m| 36/50 [01:40<00:38,  2.72s/it]                                                         Episode 37	 reward: -14.42	 makespan: 1428.00	 Mean_loss: 0.18021901,  training time: 2.73
progress:  72%|[34m  [0m| 36/50 [01:43<00:38,  2.72s/it]progress:  74%|[34m  [0m| 37/50 [01:43<00:35,  2.72s/it]                                                         Episode 38	 reward: -14.50	 makespan: 1435.75	 Mean_loss: 0.15540594,  training time: 2.74
progress:  74%|[34m  [0m| 37/50 [01:46<00:35,  2.72s/it]progress:  76%|[34m  [0m| 38/50 [01:46<00:32,  2.73s/it]                                                         Episode 39	 reward: -14.35	 makespan: 1420.25	 Mean_loss: 0.12112847,  training time: 2.71
progress:  76%|[34m  [0m| 38/50 [01:48<00:32,  2.73s/it]progress:  78%|[34m  [0m| 39/50 [01:48<00:29,  2.72s/it]                                                         Episode 40	 reward: -14.59	 makespan: 1444.50	 Mean_loss: 0.11311416,  training time: 2.72
progress:  78%|[34m  [0m| 39/50 [01:51<00:29,  2.72s/it]progress:  80%|[34m  [0m| 40/50 [01:51<00:27,  2.72s/it]                                                         Episode 41	 reward: -14.27	 makespan: 1413.00	 Mean_loss: 0.11273044,  training time: 2.72
progress:  80%|[34m  [0m| 40/50 [01:54<00:27,  2.72s/it]progress:  82%|[34m [0m| 41/50 [01:54<00:24,  2.72s/it]                                                         Episode 42	 reward: -14.44	 makespan: 1429.25	 Mean_loss: 0.11654261,  training time: 2.72
progress:  82%|[34m [0m| 41/50 [01:56<00:24,  2.72s/it]progress:  84%|[34m [0m| 42/50 [01:56<00:21,  2.72s/it]                                                         Episode 43	 reward: -14.57	 makespan: 1442.50	 Mean_loss: 0.12603968,  training time: 2.74
progress:  84%|[34m [0m| 42/50 [01:59<00:21,  2.72s/it]progress:  86%|[34m [0m| 43/50 [01:59<00:19,  2.73s/it]                                                         Episode 44	 reward: -14.99	 makespan: 1484.25	 Mean_loss: 0.10949432,  training time: 2.72
progress:  86%|[34m [0m| 43/50 [02:02<00:19,  2.73s/it]progress:  88%|[34m [0m| 44/50 [02:02<00:16,  2.73s/it]                                                         Episode 45	 reward: -14.77	 makespan: 1462.50	 Mean_loss: 0.13225278,  training time: 2.71
progress:  88%|[34m [0m| 44/50 [02:05<00:16,  2.73s/it]progress:  90%|[34m [0m| 45/50 [02:05<00:13,  2.72s/it]                                                         Episode 46	 reward: -14.98	 makespan: 1483.50	 Mean_loss: 0.14665607,  training time: 2.72
progress:  90%|[34m [0m| 45/50 [02:07<00:13,  2.72s/it]progress:  92%|[34m[0m| 46/50 [02:07<00:10,  2.72s/it]                                                         Episode 47	 reward: -15.04	 makespan: 1488.50	 Mean_loss: 0.19184950,  training time: 2.71
progress:  92%|[34m[0m| 46/50 [02:10<00:10,  2.72s/it]progress:  94%|[34m[0m| 47/50 [02:10<00:08,  2.72s/it]                                                         Episode 48	 reward: -14.77	 makespan: 1462.50	 Mean_loss: 0.13964297,  training time: 2.72
progress:  94%|[34m[0m| 47/50 [02:13<00:08,  2.72s/it]progress:  96%|[34m[0m| 48/50 [02:13<00:05,  2.72s/it]                                                         Episode 49	 reward: -15.26	 makespan: 1510.50	 Mean_loss: 0.14881720,  training time: 2.72
progress:  96%|[34m[0m| 48/50 [02:16<00:05,  2.72s/it]progress:  98%|[34m[0m| 49/50 [02:16<00:02,  2.72s/it]                                                         Episode 50	 reward: -14.69	 makespan: 1454.00	 Mean_loss: 0.18048050,  training time: 2.73
progress:  98%|[34m[0m| 49/50 [02:18<00:02,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:18<00:00,  2.72s/it]progress: 100%|[34m[0m| 50/50 [02:18<00:00,  2.77s/it]

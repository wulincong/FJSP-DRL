+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/check.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/check.sh
++++ export CHECK_HOME=/opt/hpc/setfreq/
++++ CHECK_HOME=/opt/hpc/setfreq/
++++ export PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 51756 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/profile_pmix.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/profile_pmix.sh
++++ export PMIX_HOME=/opt/gridview/pmix
++++ PMIX_HOME=/opt/gridview/pmix
++++ export PATH=/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq/:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/pmix/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/pmix/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/pmix/share/pmix:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/pmix/share/pmix:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/pmix/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/pmix/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=false
++++ SLURM_PMIX_DIRECT_CONN_UCX=false
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=false
++++ SLURM_PMIX_DIRECT_CONN_EARLY=false
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/pmix/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/pmix/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/pmix/bin:/opt/gridview/pmix/sbin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/opt/hpc/setfreq:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ exp=exp17_1
+ echo exp17_1
exp17_1
+ cat

->  op_per_job ->
+ n_j_options='15 15 15 15'
+ n_m_options='13 10 7 5'
+ op_per_job_options='4 7 10 12'
+ logdir=./runs/exp17_1
+ hidden_dim_actor=512
+ hidden_dim_critic=512
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ meta_iterations=200
+ max_updates_maml=500
+ num_tasks=4
+ max_updates_finetune=50
+ lr=0.003
+ data='13,4 10,7 7,10 5,12'
+ logdir_dan=./runs/exp17_1/DAN
+ python train/DAN.py --n_j 15 --n_m 13 --op_per_job 4 --data_source SD2 --model_suffix SD2_4 --logdir ./runs/exp17_1/DAN/train_model/15x13x4 --max_updates 300
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+SD2_4
-------------------------Training Setting-------------------------
source : SD2
model name :15x13+mix+SD2_4
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/300 [00:00<?, ?it/s]                                                 Episode 1	 reward: -3.61	 makespan: 357.60	 Mean_loss: 0.95955282,  training time: 2.54
progress:   0%|[34m          [0m| 0/300 [00:02<?, ?it/s]progress:   0%|[34m          [0m| 1/300 [00:02<12:39,  2.54s/it]                                                         Episode 2	 reward: -3.64	 makespan: 360.05	 Mean_loss: 0.62375832,  training time: 1.36
progress:   0%|[34m          [0m| 1/300 [00:03<12:39,  2.54s/it]progress:   1%|[34m          [0m| 2/300 [00:03<09:10,  1.85s/it]                                                         Episode 3	 reward: -3.47	 makespan: 343.75	 Mean_loss: 0.50179309,  training time: 1.38
progress:   1%|[34m          [0m| 2/300 [00:05<09:10,  1.85s/it]progress:   1%|[34m          [0m| 3/300 [00:05<08:05,  1.63s/it]                                                         Episode 4	 reward: -3.50	 makespan: 346.50	 Mean_loss: 0.35481498,  training time: 1.37
progress:   1%|[34m          [0m| 3/300 [00:06<08:05,  1.63s/it]progress:   1%|[34m         [0m| 4/300 [00:06<07:33,  1.53s/it]                                                         Episode 5	 reward: -3.43	 makespan: 339.90	 Mean_loss: 0.30524015,  training time: 1.29
progress:   1%|[34m         [0m| 4/300 [00:07<07:33,  1.53s/it]progress:   2%|[34m         [0m| 5/300 [00:07<07:06,  1.45s/it]                                                         Episode 6	 reward: -3.41	 makespan: 337.80	 Mean_loss: 0.13913848,  training time: 1.36
progress:   2%|[34m         [0m| 5/300 [00:09<07:06,  1.45s/it]progress:   2%|[34m         [0m| 6/300 [00:09<06:56,  1.42s/it]                                                         Episode 7	 reward: -3.52	 makespan: 348.15	 Mean_loss: 0.24050924,  training time: 1.35
progress:   2%|[34m         [0m| 6/300 [00:10<06:56,  1.42s/it]progress:   2%|[34m         [0m| 7/300 [00:10<06:49,  1.40s/it]                                                         Episode 8	 reward: -3.66	 makespan: 362.55	 Mean_loss: 0.27238366,  training time: 1.31
progress:   2%|[34m         [0m| 7/300 [00:11<06:49,  1.40s/it]progress:   3%|[34m         [0m| 8/300 [00:11<06:40,  1.37s/it]                                                         Episode 9	 reward: -3.38	 makespan: 334.35	 Mean_loss: 0.22307643,  training time: 1.30
progress:   3%|[34m         [0m| 8/300 [00:13<06:40,  1.37s/it]progress:   3%|[34m         [0m| 9/300 [00:13<06:32,  1.35s/it]                                                         Episode 10	 reward: -3.37	 makespan: 333.15	 Mean_loss: 0.20387480,  training time: 1.29
progress:   3%|[34m         [0m| 9/300 [00:14<06:32,  1.35s/it]progress:   3%|[34m         [0m| 10/300 [00:14<06:25,  1.33s/it]                                                          Episode 11	 reward: -3.43	 makespan: 339.35	 Mean_loss: 0.17419621,  training time: 1.35
progress:   3%|[34m         [0m| 10/300 [00:15<06:25,  1.33s/it]progress:   4%|[34m         [0m| 11/300 [00:15<06:26,  1.34s/it]                                                          Episode 12	 reward: -3.40	 makespan: 336.65	 Mean_loss: 0.18290867,  training time: 1.33
progress:   4%|[34m         [0m| 11/300 [00:17<06:26,  1.34s/it]progress:   4%|[34m         [0m| 12/300 [00:17<06:24,  1.34s/it]                                                          Episode 13	 reward: -3.26	 makespan: 322.55	 Mean_loss: 0.13800067,  training time: 1.38
progress:   4%|[34m         [0m| 12/300 [00:18<06:24,  1.34s/it]progress:   4%|[34m         [0m| 13/300 [00:18<06:27,  1.35s/it]                                                          Episode 14	 reward: -3.57	 makespan: 353.35	 Mean_loss: 0.20803483,  training time: 1.34
progress:   4%|[34m         [0m| 13/300 [00:19<06:27,  1.35s/it]progress:   5%|[34m         [0m| 14/300 [00:19<06:25,  1.35s/it]                                                          Episode 15	 reward: -3.34	 makespan: 331.15	 Mean_loss: 0.19233620,  training time: 1.34
progress:   5%|[34m         [0m| 14/300 [00:21<06:25,  1.35s/it]progress:   5%|[34m         [0m| 15/300 [00:21<06:23,  1.35s/it]                                                          Episode 16	 reward: -3.56	 makespan: 352.40	 Mean_loss: 0.18100300,  training time: 1.41
progress:   5%|[34m         [0m| 15/300 [00:22<06:23,  1.35s/it]progress:   5%|[34m         [0m| 16/300 [00:22<06:28,  1.37s/it]                                                          Episode 17	 reward: -3.35	 makespan: 331.45	 Mean_loss: 0.20565188,  training time: 1.39
progress:   5%|[34m         [0m| 16/300 [00:24<06:28,  1.37s/it]progress:   6%|[34m         [0m| 17/300 [00:24<06:29,  1.38s/it]                                                          Episode 18	 reward: -3.49	 makespan: 345.60	 Mean_loss: 0.18188913,  training time: 1.36
progress:   6%|[34m         [0m| 17/300 [00:25<06:29,  1.38s/it]progress:   6%|[34m         [0m| 18/300 [00:25<06:26,  1.37s/it]                                                          Episode 19	 reward: -3.25	 makespan: 321.45	 Mean_loss: 0.12075894,  training time: 1.35
progress:   6%|[34m         [0m| 18/300 [00:26<06:26,  1.37s/it]progress:   6%|[34m         [0m| 19/300 [00:26<06:23,  1.37s/it]                                                          Episode 20	 reward: -3.34	 makespan: 330.70	 Mean_loss: 0.10441932,  training time: 1.38
progress:   6%|[34m         [0m| 19/300 [00:28<06:23,  1.37s/it]progress:   7%|[34m         [0m| 20/300 [00:28<06:23,  1.37s/it]                                                          Episode 21	 reward: -3.29	 makespan: 325.70	 Mean_loss: 0.10025205,  training time: 1.36
progress:   7%|[34m         [0m| 20/300 [00:29<06:23,  1.37s/it]progress:   7%|[34m         [0m| 21/300 [00:29<06:21,  1.37s/it]                                                          Episode 22	 reward: -3.34	 makespan: 330.70	 Mean_loss: 0.07646488,  training time: 1.35
progress:   7%|[34m         [0m| 21/300 [00:30<06:21,  1.37s/it]progress:   7%|[34m         [0m| 22/300 [00:30<06:18,  1.36s/it]                                                          Episode 23	 reward: -3.32	 makespan: 328.80	 Mean_loss: 0.08844374,  training time: 1.34
progress:   7%|[34m         [0m| 22/300 [00:32<06:18,  1.36s/it]progress:   8%|[34m         [0m| 23/300 [00:32<06:14,  1.35s/it]                                                          Episode 24	 reward: -3.24	 makespan: 320.85	 Mean_loss: 0.11243626,  training time: 1.35
progress:   8%|[34m         [0m| 23/300 [00:33<06:14,  1.35s/it]progress:   8%|[34m         [0m| 24/300 [00:33<06:13,  1.35s/it]                                                          Episode 25	 reward: -3.42	 makespan: 338.25	 Mean_loss: 0.09256323,  training time: 1.30
progress:   8%|[34m         [0m| 24/300 [00:34<06:13,  1.35s/it]progress:   8%|[34m         [0m| 25/300 [00:34<06:07,  1.34s/it]                                                          Episode 26	 reward: -3.22	 makespan: 319.10	 Mean_loss: 0.06850513,  training time: 1.37
progress:   8%|[34m         [0m| 25/300 [00:36<06:07,  1.34s/it]progress:   9%|[34m         [0m| 26/300 [00:36<06:09,  1.35s/it]                                                          Episode 27	 reward: -3.22	 makespan: 318.60	 Mean_loss: 0.07100213,  training time: 1.35
progress:   9%|[34m         [0m| 26/300 [00:37<06:09,  1.35s/it]progress:   9%|[34m         [0m| 27/300 [00:37<06:07,  1.35s/it]                                                          Episode 28	 reward: -3.21	 makespan: 317.55	 Mean_loss: 0.08480144,  training time: 1.34
progress:   9%|[34m         [0m| 27/300 [00:38<06:07,  1.35s/it]progress:   9%|[34m         [0m| 28/300 [00:38<06:06,  1.35s/it]                                                          Episode 29	 reward: -3.21	 makespan: 317.65	 Mean_loss: 0.07951297,  training time: 1.32
progress:   9%|[34m         [0m| 28/300 [00:40<06:06,  1.35s/it]progress:  10%|[34m         [0m| 29/300 [00:40<06:03,  1.34s/it]                                                          Episode 30	 reward: -3.18	 makespan: 314.60	 Mean_loss: 0.04466092,  training time: 1.28
progress:  10%|[34m         [0m| 29/300 [00:41<06:03,  1.34s/it]progress:  10%|[34m         [0m| 30/300 [00:41<05:56,  1.32s/it]                                                          Episode 31	 reward: -2.97	 makespan: 294.25	 Mean_loss: 0.04886863,  training time: 1.43
progress:  10%|[34m         [0m| 30/300 [00:43<05:56,  1.32s/it]progress:  10%|[34m         [0m| 31/300 [00:43<06:04,  1.35s/it]                                                          Episode 32	 reward: -2.99	 makespan: 296.40	 Mean_loss: 0.07251833,  training time: 1.37
progress:  10%|[34m         [0m| 31/300 [00:44<06:04,  1.35s/it]progress:  11%|[34m         [0m| 32/300 [00:44<06:03,  1.36s/it]                                                          Episode 33	 reward: -3.18	 makespan: 315.25	 Mean_loss: 0.08253554,  training time: 1.32
progress:  11%|[34m         [0m| 32/300 [00:45<06:03,  1.36s/it]progress:  11%|[34m         [0m| 33/300 [00:45<05:59,  1.35s/it]                                                          Episode 34	 reward: -3.02	 makespan: 298.75	 Mean_loss: 0.06131842,  training time: 1.44
progress:  11%|[34m         [0m| 33/300 [00:47<05:59,  1.35s/it]progress:  11%|[34m        [0m| 34/300 [00:47<06:05,  1.37s/it]                                                          Episode 35	 reward: -3.09	 makespan: 306.00	 Mean_loss: 0.06592875,  training time: 1.27
progress:  11%|[34m        [0m| 34/300 [00:48<06:05,  1.37s/it]progress:  12%|[34m        [0m| 35/300 [00:48<05:55,  1.34s/it]                                                          Episode 36	 reward: -3.08	 makespan: 304.60	 Mean_loss: 0.07424355,  training time: 1.30
progress:  12%|[34m        [0m| 35/300 [00:49<05:55,  1.34s/it]progress:  12%|[34m        [0m| 36/300 [00:49<05:50,  1.33s/it]                                                          Episode 37	 reward: -3.11	 makespan: 308.05	 Mean_loss: 0.12938684,  training time: 1.30
progress:  12%|[34m        [0m| 36/300 [00:51<05:50,  1.33s/it]progress:  12%|[34m        [0m| 37/300 [00:51<05:47,  1.32s/it]                                                          Episode 38	 reward: -3.11	 makespan: 307.75	 Mean_loss: 0.04903817,  training time: 1.40
progress:  12%|[34m        [0m| 37/300 [00:52<05:47,  1.32s/it]progress:  13%|[34m        [0m| 38/300 [00:52<05:52,  1.35s/it]                                                          Episode 39	 reward: -3.25	 makespan: 322.00	 Mean_loss: 0.05150907,  training time: 1.32
progress:  13%|[34m        [0m| 38/300 [00:53<05:52,  1.35s/it]progress:  13%|[34m        [0m| 39/300 [00:53<05:49,  1.34s/it]                                                          Episode 40	 reward: -3.04	 makespan: 301.30	 Mean_loss: 0.04583213,  training time: 1.28
progress:  13%|[34m        [0m| 39/300 [00:55<05:49,  1.34s/it]progress:  13%|[34m        [0m| 40/300 [00:55<05:43,  1.32s/it]                                                          Episode 41	 reward: -2.86	 makespan: 282.85	 Mean_loss: 0.07284497,  training time: 1.43
progress:  13%|[34m        [0m| 40/300 [00:56<05:43,  1.32s/it]progress:  14%|[34m        [0m| 41/300 [00:56<05:51,  1.36s/it]                                                          Episode 42	 reward: -2.69	 makespan: 266.80	 Mean_loss: 0.02353624,  training time: 1.35
progress:  14%|[34m        [0m| 41/300 [00:57<05:51,  1.36s/it]progress:  14%|[34m        [0m| 42/300 [00:57<05:49,  1.35s/it]                                                          Episode 43	 reward: -2.72	 makespan: 269.15	 Mean_loss: 0.03318983,  training time: 1.27
progress:  14%|[34m        [0m| 42/300 [00:59<05:49,  1.35s/it]progress:  14%|[34m        [0m| 43/300 [00:59<05:41,  1.33s/it]                                                          Episode 44	 reward: -2.68	 makespan: 265.75	 Mean_loss: 0.05054331,  training time: 1.40
progress:  14%|[34m        [0m| 43/300 [01:00<05:41,  1.33s/it]progress:  15%|[34m        [0m| 44/300 [01:00<05:46,  1.35s/it]                                                          Episode 45	 reward: -2.69	 makespan: 266.40	 Mean_loss: 0.05920937,  training time: 1.35
progress:  15%|[34m        [0m| 44/300 [01:01<05:46,  1.35s/it]progress:  15%|[34m        [0m| 45/300 [01:01<05:44,  1.35s/it]                                                          Episode 46	 reward: -2.63	 makespan: 260.45	 Mean_loss: 0.03668442,  training time: 1.29
progress:  15%|[34m        [0m| 45/300 [01:03<05:44,  1.35s/it]progress:  15%|[34m        [0m| 46/300 [01:03<05:38,  1.33s/it]                                                          Episode 47	 reward: -2.64	 makespan: 261.60	 Mean_loss: 0.03548801,  training time: 1.36
progress:  15%|[34m        [0m| 46/300 [01:04<05:38,  1.33s/it]progress:  16%|[34m        [0m| 47/300 [01:04<05:39,  1.34s/it]                                                          Episode 48	 reward: -2.64	 makespan: 261.65	 Mean_loss: 0.08060664,  training time: 1.27
progress:  16%|[34m        [0m| 47/300 [01:05<05:39,  1.34s/it]progress:  16%|[34m        [0m| 48/300 [01:05<05:32,  1.32s/it]                                                          Episode 49	 reward: -2.65	 makespan: 262.60	 Mean_loss: 0.01877845,  training time: 1.34
progress:  16%|[34m        [0m| 48/300 [01:07<05:32,  1.32s/it]progress:  16%|[34m        [0m| 49/300 [01:07<05:32,  1.33s/it]                                                          Episode 50	 reward: -2.58	 makespan: 255.00	 Mean_loss: 0.03587904,  training time: 1.33
progress:  16%|[34m        [0m| 49/300 [01:08<05:32,  1.33s/it]progress:  17%|[34m        [0m| 50/300 [01:08<05:31,  1.33s/it]                                                          Episode 51	 reward: -2.68	 makespan: 265.75	 Mean_loss: 0.04345326,  training time: 1.28
progress:  17%|[34m        [0m| 50/300 [01:09<05:31,  1.33s/it]progress:  17%|[34m        [0m| 51/300 [01:09<05:26,  1.31s/it]                                                          Episode 52	 reward: -2.67	 makespan: 264.80	 Mean_loss: 0.04267742,  training time: 1.35
progress:  17%|[34m        [0m| 51/300 [01:11<05:26,  1.31s/it]progress:  17%|[34m        [0m| 52/300 [01:11<05:28,  1.32s/it]                                                          Episode 53	 reward: -2.64	 makespan: 261.55	 Mean_loss: 0.03507437,  training time: 1.34
progress:  17%|[34m        [0m| 52/300 [01:12<05:28,  1.32s/it]progress:  18%|[34m        [0m| 53/300 [01:12<05:28,  1.33s/it]                                                          Episode 54	 reward: -2.63	 makespan: 260.45	 Mean_loss: 0.04698932,  training time: 1.35
progress:  18%|[34m        [0m| 53/300 [01:13<05:28,  1.33s/it]progress:  18%|[34m        [0m| 54/300 [01:13<05:28,  1.34s/it]                                                          Episode 55	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.04065934,  training time: 1.35
progress:  18%|[34m        [0m| 54/300 [01:15<05:28,  1.34s/it]progress:  18%|[34m        [0m| 55/300 [01:15<05:28,  1.34s/it]                                                          Episode 56	 reward: -2.62	 makespan: 259.35	 Mean_loss: 0.02798653,  training time: 1.36
progress:  18%|[34m        [0m| 55/300 [01:16<05:28,  1.34s/it]progress:  19%|[34m        [0m| 56/300 [01:16<05:28,  1.35s/it]                                                          Episode 57	 reward: -2.65	 makespan: 262.55	 Mean_loss: 0.00872720,  training time: 1.36
progress:  19%|[34m        [0m| 56/300 [01:17<05:28,  1.35s/it]progress:  19%|[34m        [0m| 57/300 [01:17<05:28,  1.35s/it]                                                          Episode 58	 reward: -2.61	 makespan: 258.40	 Mean_loss: 0.05567545,  training time: 1.33
progress:  19%|[34m        [0m| 57/300 [01:19<05:28,  1.35s/it]progress:  19%|[34m        [0m| 58/300 [01:19<05:25,  1.35s/it]                                                          Episode 59	 reward: -2.60	 makespan: 257.85	 Mean_loss: 0.04814290,  training time: 1.30
progress:  19%|[34m        [0m| 58/300 [01:20<05:25,  1.35s/it]progress:  20%|[34m        [0m| 59/300 [01:20<05:21,  1.33s/it]                                                          Episode 60	 reward: -2.55	 makespan: 252.55	 Mean_loss: 0.06040491,  training time: 1.37
progress:  20%|[34m        [0m| 59/300 [01:21<05:21,  1.33s/it]progress:  20%|[34m        [0m| 60/300 [01:21<05:22,  1.34s/it]                                                          Episode 61	 reward: -2.71	 makespan: 268.65	 Mean_loss: 0.02142158,  training time: 1.38
progress:  20%|[34m        [0m| 60/300 [01:23<05:22,  1.34s/it]progress:  20%|[34m        [0m| 61/300 [01:23<05:23,  1.35s/it]                                                          Episode 62	 reward: -2.63	 makespan: 260.25	 Mean_loss: 0.07015228,  training time: 1.30
progress:  20%|[34m        [0m| 61/300 [01:24<05:23,  1.35s/it]progress:  21%|[34m        [0m| 62/300 [01:24<05:18,  1.34s/it]                                                          Episode 63	 reward: -2.66	 makespan: 263.75	 Mean_loss: 0.05079038,  training time: 1.31
progress:  21%|[34m        [0m| 62/300 [01:25<05:18,  1.34s/it]progress:  21%|[34m        [0m| 63/300 [01:25<05:15,  1.33s/it]                                                          Episode 64	 reward: -2.65	 makespan: 261.95	 Mean_loss: 0.03438309,  training time: 1.35
progress:  21%|[34m        [0m| 63/300 [01:27<05:15,  1.33s/it]progress:  21%|[34m       [0m| 64/300 [01:27<05:15,  1.34s/it]                                                          Episode 65	 reward: -2.65	 makespan: 262.65	 Mean_loss: 0.03343712,  training time: 1.35
progress:  21%|[34m       [0m| 64/300 [01:28<05:15,  1.34s/it]progress:  22%|[34m       [0m| 65/300 [01:28<05:15,  1.34s/it]                                                          Episode 66	 reward: -2.79	 makespan: 276.55	 Mean_loss: 0.06180704,  training time: 1.36
progress:  22%|[34m       [0m| 65/300 [01:29<05:15,  1.34s/it]progress:  22%|[34m       [0m| 66/300 [01:29<05:15,  1.35s/it]                                                          Episode 67	 reward: -2.65	 makespan: 262.00	 Mean_loss: 0.03699914,  training time: 1.37
progress:  22%|[34m       [0m| 66/300 [01:31<05:15,  1.35s/it]progress:  22%|[34m       [0m| 67/300 [01:31<05:15,  1.35s/it]                                                          Episode 68	 reward: -2.67	 makespan: 264.45	 Mean_loss: 0.02807174,  training time: 1.35
progress:  22%|[34m       [0m| 67/300 [01:32<05:15,  1.35s/it]progress:  23%|[34m       [0m| 68/300 [01:32<05:13,  1.35s/it]                                                          Episode 69	 reward: -2.62	 makespan: 259.10	 Mean_loss: 0.04463895,  training time: 1.33
progress:  23%|[34m       [0m| 68/300 [01:33<05:13,  1.35s/it]progress:  23%|[34m       [0m| 69/300 [01:33<05:11,  1.35s/it]                                                          Episode 70	 reward: -2.78	 makespan: 275.20	 Mean_loss: 0.06520356,  training time: 1.32
progress:  23%|[34m       [0m| 69/300 [01:35<05:11,  1.35s/it]progress:  23%|[34m       [0m| 70/300 [01:35<05:07,  1.34s/it]                                                          Episode 71	 reward: -2.64	 makespan: 261.70	 Mean_loss: 0.05129148,  training time: 1.32
progress:  23%|[34m       [0m| 70/300 [01:36<05:07,  1.34s/it]progress:  24%|[34m       [0m| 71/300 [01:36<05:05,  1.33s/it]                                                          Episode 72	 reward: -2.72	 makespan: 269.30	 Mean_loss: 0.06533995,  training time: 1.33
progress:  24%|[34m       [0m| 71/300 [01:37<05:05,  1.33s/it]progress:  24%|[34m       [0m| 72/300 [01:37<05:03,  1.33s/it]                                                          Episode 73	 reward: -2.69	 makespan: 266.00	 Mean_loss: 0.04274300,  training time: 1.35
progress:  24%|[34m       [0m| 72/300 [01:39<05:03,  1.33s/it]progress:  24%|[34m       [0m| 73/300 [01:39<05:03,  1.34s/it]                                                          Episode 74	 reward: -2.68	 makespan: 265.00	 Mean_loss: 0.04328836,  training time: 1.28
progress:  24%|[34m       [0m| 73/300 [01:40<05:03,  1.34s/it]progress:  25%|[34m       [0m| 74/300 [01:40<04:58,  1.32s/it]                                                          Episode 75	 reward: -2.63	 makespan: 260.40	 Mean_loss: 0.07669490,  training time: 1.28
progress:  25%|[34m       [0m| 74/300 [01:41<04:58,  1.32s/it]progress:  25%|[34m       [0m| 75/300 [01:41<04:54,  1.31s/it]                                                          Episode 76	 reward: -2.73	 makespan: 270.20	 Mean_loss: 0.02238702,  training time: 1.38
progress:  25%|[34m       [0m| 75/300 [01:43<04:54,  1.31s/it]progress:  25%|[34m       [0m| 76/300 [01:43<04:57,  1.33s/it]                                                          Episode 77	 reward: -2.73	 makespan: 270.40	 Mean_loss: 0.03447800,  training time: 1.36
progress:  25%|[34m       [0m| 76/300 [01:44<04:57,  1.33s/it]progress:  26%|[34m       [0m| 77/300 [01:44<04:58,  1.34s/it]                                                          Episode 78	 reward: -2.66	 makespan: 263.25	 Mean_loss: 0.04145316,  training time: 1.36
progress:  26%|[34m       [0m| 77/300 [01:45<04:58,  1.34s/it]progress:  26%|[34m       [0m| 78/300 [01:45<04:58,  1.35s/it]                                                          Episode 79	 reward: -2.63	 makespan: 259.90	 Mean_loss: 0.05206434,  training time: 1.28
progress:  26%|[34m       [0m| 78/300 [01:47<04:58,  1.35s/it]progress:  26%|[34m       [0m| 79/300 [01:47<04:53,  1.33s/it]                                                          Episode 80	 reward: -2.66	 makespan: 263.15	 Mean_loss: 0.06138218,  training time: 1.32
progress:  26%|[34m       [0m| 79/300 [01:48<04:53,  1.33s/it]progress:  27%|[34m       [0m| 80/300 [01:48<04:51,  1.32s/it]                                                          Episode 81	 reward: -2.55	 makespan: 252.75	 Mean_loss: 0.05490259,  training time: 1.40
progress:  27%|[34m       [0m| 80/300 [01:49<04:51,  1.32s/it]progress:  27%|[34m       [0m| 81/300 [01:49<04:55,  1.35s/it]                                                          Episode 82	 reward: -2.46	 makespan: 243.25	 Mean_loss: 0.05356460,  training time: 1.33
progress:  27%|[34m       [0m| 81/300 [01:51<04:55,  1.35s/it]progress:  27%|[34m       [0m| 82/300 [01:51<04:52,  1.34s/it]                                                          Episode 83	 reward: -2.49	 makespan: 246.15	 Mean_loss: 0.01500893,  training time: 1.33
progress:  27%|[34m       [0m| 82/300 [01:52<04:52,  1.34s/it]progress:  28%|[34m       [0m| 83/300 [01:52<04:50,  1.34s/it]                                                          Episode 84	 reward: -2.53	 makespan: 250.20	 Mean_loss: 0.00420692,  training time: 1.33
progress:  28%|[34m       [0m| 83/300 [01:53<04:50,  1.34s/it]progress:  28%|[34m       [0m| 84/300 [01:53<04:48,  1.34s/it]                                                          Episode 85	 reward: -2.46	 makespan: 243.40	 Mean_loss: 0.02664773,  training time: 1.41
progress:  28%|[34m       [0m| 84/300 [01:55<04:48,  1.34s/it]progress:  28%|[34m       [0m| 85/300 [01:55<04:52,  1.36s/it]                                                          Episode 86	 reward: -2.50	 makespan: 247.05	 Mean_loss: 0.01862443,  training time: 1.37
progress:  28%|[34m       [0m| 85/300 [01:56<04:52,  1.36s/it]progress:  29%|[34m       [0m| 86/300 [01:56<04:52,  1.37s/it]                                                          Episode 87	 reward: -2.51	 makespan: 248.70	 Mean_loss: 0.02709227,  training time: 1.37
progress:  29%|[34m       [0m| 86/300 [01:58<04:52,  1.37s/it]progress:  29%|[34m       [0m| 87/300 [01:58<04:51,  1.37s/it]                                                          Episode 88	 reward: -2.49	 makespan: 246.65	 Mean_loss: -0.00839851,  training time: 1.31
progress:  29%|[34m       [0m| 87/300 [01:59<04:51,  1.37s/it]progress:  29%|[34m       [0m| 88/300 [01:59<04:46,  1.35s/it]                                                          Episode 89	 reward: -2.51	 makespan: 248.55	 Mean_loss: 0.01546784,  training time: 1.37
progress:  29%|[34m       [0m| 88/300 [02:00<04:46,  1.35s/it]progress:  30%|[34m       [0m| 89/300 [02:00<04:46,  1.36s/it]                                                          Episode 90	 reward: -2.53	 makespan: 250.15	 Mean_loss: 0.01288094,  training time: 1.37
progress:  30%|[34m       [0m| 89/300 [02:02<04:46,  1.36s/it]progress:  30%|[34m       [0m| 90/300 [02:02<04:46,  1.36s/it]                                                          Episode 91	 reward: -2.48	 makespan: 245.20	 Mean_loss: 0.02797861,  training time: 1.39
progress:  30%|[34m       [0m| 90/300 [02:03<04:46,  1.36s/it]progress:  30%|[34m       [0m| 91/300 [02:03<04:46,  1.37s/it]                                                          Episode 92	 reward: -2.44	 makespan: 241.10	 Mean_loss: 0.00027161,  training time: 1.38
progress:  30%|[34m       [0m| 91/300 [02:04<04:46,  1.37s/it]progress:  31%|[34m       [0m| 92/300 [02:04<04:46,  1.38s/it]                                                          Episode 93	 reward: -2.43	 makespan: 240.10	 Mean_loss: 0.02319459,  training time: 1.31
progress:  31%|[34m       [0m| 92/300 [02:06<04:46,  1.38s/it]progress:  31%|[34m       [0m| 93/300 [02:06<04:40,  1.36s/it]                                                          Episode 94	 reward: -2.43	 makespan: 240.35	 Mean_loss: 0.04407641,  training time: 1.28
progress:  31%|[34m       [0m| 93/300 [02:07<04:40,  1.36s/it]progress:  31%|[34m      [0m| 94/300 [02:07<04:34,  1.33s/it]                                                          Episode 95	 reward: -2.51	 makespan: 248.15	 Mean_loss: -0.00821995,  training time: 1.36
progress:  31%|[34m      [0m| 94/300 [02:08<04:34,  1.33s/it]progress:  32%|[34m      [0m| 95/300 [02:08<04:35,  1.34s/it]                                                          Episode 96	 reward: -2.46	 makespan: 243.60	 Mean_loss: 0.00741367,  training time: 1.35
progress:  32%|[34m      [0m| 95/300 [02:10<04:35,  1.34s/it]progress:  32%|[34m      [0m| 96/300 [02:10<04:34,  1.34s/it]                                                          Episode 97	 reward: -2.54	 makespan: 251.60	 Mean_loss: 0.00486153,  training time: 1.35
progress:  32%|[34m      [0m| 96/300 [02:11<04:34,  1.34s/it]progress:  32%|[34m      [0m| 97/300 [02:11<04:33,  1.35s/it]                                                          Episode 98	 reward: -2.45	 makespan: 242.30	 Mean_loss: 0.02421039,  training time: 1.37
progress:  32%|[34m      [0m| 97/300 [02:12<04:33,  1.35s/it]progress:  33%|[34m      [0m| 98/300 [02:12<04:33,  1.35s/it]                                                          Episode 99	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.00621744,  training time: 1.35
progress:  33%|[34m      [0m| 98/300 [02:14<04:33,  1.35s/it]progress:  33%|[34m      [0m| 99/300 [02:14<04:31,  1.35s/it]                                                          Episode 100	 reward: -2.54	 makespan: 251.40	 Mean_loss: 0.02066853,  training time: 1.30
progress:  33%|[34m      [0m| 99/300 [02:15<04:31,  1.35s/it]progress:  33%|[34m      [0m| 100/300 [02:15<04:27,  1.34s/it]                                                           Episode 101	 reward: -2.66	 makespan: 263.30	 Mean_loss: 0.04131294,  training time: 1.35
progress:  33%|[34m      [0m| 100/300 [02:16<04:27,  1.34s/it]progress:  34%|[34m      [0m| 101/300 [02:16<04:26,  1.34s/it]                                                           Episode 102	 reward: -2.59	 makespan: 256.85	 Mean_loss: 0.00757650,  training time: 1.35
progress:  34%|[34m      [0m| 101/300 [02:18<04:26,  1.34s/it]progress:  34%|[34m      [0m| 102/300 [02:18<04:26,  1.35s/it]                                                           Episode 103	 reward: -2.68	 makespan: 265.65	 Mean_loss: 0.04958989,  training time: 1.35
progress:  34%|[34m      [0m| 102/300 [02:19<04:26,  1.35s/it]progress:  34%|[34m      [0m| 103/300 [02:19<04:25,  1.35s/it]                                                           Episode 104	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.01482266,  training time: 1.37
progress:  34%|[34m      [0m| 103/300 [02:21<04:25,  1.35s/it]progress:  35%|[34m      [0m| 104/300 [02:21<04:25,  1.36s/it]                                                           Episode 105	 reward: -2.65	 makespan: 262.80	 Mean_loss: 0.03663265,  training time: 1.35
progress:  35%|[34m      [0m| 104/300 [02:22<04:25,  1.36s/it]progress:  35%|[34m      [0m| 105/300 [02:22<04:23,  1.35s/it]                                                           Episode 106	 reward: -2.66	 makespan: 263.55	 Mean_loss: 0.07786853,  training time: 1.33
progress:  35%|[34m      [0m| 105/300 [02:23<04:23,  1.35s/it]progress:  35%|[34m      [0m| 106/300 [02:23<04:21,  1.35s/it]                                                           Episode 107	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.04375427,  training time: 1.34
progress:  35%|[34m      [0m| 106/300 [02:25<04:21,  1.35s/it]progress:  36%|[34m      [0m| 107/300 [02:25<04:19,  1.34s/it]                                                           Episode 108	 reward: -2.54	 makespan: 251.70	 Mean_loss: 0.01236334,  training time: 1.28
progress:  36%|[34m      [0m| 107/300 [02:26<04:19,  1.34s/it]progress:  36%|[34m      [0m| 108/300 [02:26<04:14,  1.32s/it]                                                           Episode 109	 reward: -2.63	 makespan: 259.95	 Mean_loss: 0.03296545,  training time: 1.41
progress:  36%|[34m      [0m| 108/300 [02:27<04:14,  1.32s/it]progress:  36%|[34m      [0m| 109/300 [02:27<04:18,  1.35s/it]                                                           Episode 110	 reward: -2.69	 makespan: 266.45	 Mean_loss: 0.03374705,  training time: 1.38
progress:  36%|[34m      [0m| 109/300 [02:29<04:18,  1.35s/it]progress:  37%|[34m      [0m| 110/300 [02:29<04:18,  1.36s/it]                                                           Episode 111	 reward: -2.60	 makespan: 257.15	 Mean_loss: 0.03847938,  training time: 1.29
progress:  37%|[34m      [0m| 110/300 [02:30<04:18,  1.36s/it]progress:  37%|[34m      [0m| 111/300 [02:30<04:13,  1.34s/it]                                                           Episode 112	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.03020280,  training time: 1.36
progress:  37%|[34m      [0m| 111/300 [02:31<04:13,  1.34s/it]progress:  37%|[34m      [0m| 112/300 [02:31<04:12,  1.34s/it]                                                           Episode 113	 reward: -2.53	 makespan: 250.35	 Mean_loss: 0.02401002,  training time: 1.27
progress:  37%|[34m      [0m| 112/300 [02:33<04:12,  1.34s/it]progress:  38%|[34m      [0m| 113/300 [02:33<04:07,  1.32s/it]                                                           Episode 114	 reward: -2.67	 makespan: 264.55	 Mean_loss: 0.06069526,  training time: 1.33
progress:  38%|[34m      [0m| 113/300 [02:34<04:07,  1.32s/it]progress:  38%|[34m      [0m| 114/300 [02:34<04:06,  1.33s/it]                                                           Episode 115	 reward: -2.57	 makespan: 254.10	 Mean_loss: 0.03002219,  training time: 1.32
progress:  38%|[34m      [0m| 114/300 [02:35<04:06,  1.33s/it]progress:  38%|[34m      [0m| 115/300 [02:35<04:04,  1.32s/it]                                                           Episode 116	 reward: -2.65	 makespan: 262.10	 Mean_loss: 0.02044510,  training time: 1.29
progress:  38%|[34m      [0m| 115/300 [02:36<04:04,  1.32s/it]progress:  39%|[34m      [0m| 116/300 [02:36<04:01,  1.31s/it]                                                           Episode 117	 reward: -2.60	 makespan: 257.45	 Mean_loss: 0.02103843,  training time: 1.32
progress:  39%|[34m      [0m| 116/300 [02:38<04:01,  1.31s/it]progress:  39%|[34m      [0m| 117/300 [02:38<04:01,  1.32s/it]                                                           Episode 118	 reward: -2.54	 makespan: 251.80	 Mean_loss: 0.01490104,  training time: 1.44
progress:  39%|[34m      [0m| 117/300 [02:39<04:01,  1.32s/it]progress:  39%|[34m      [0m| 118/300 [02:39<04:06,  1.36s/it]                                                           Episode 119	 reward: -2.66	 makespan: 263.40	 Mean_loss: 0.04904776,  training time: 1.31
progress:  39%|[34m      [0m| 118/300 [02:41<04:06,  1.36s/it]progress:  40%|[34m      [0m| 119/300 [02:41<04:03,  1.34s/it]                                                           Episode 120	 reward: -2.65	 makespan: 262.25	 Mean_loss: 0.02965258,  training time: 1.36
progress:  40%|[34m      [0m| 119/300 [02:42<04:03,  1.34s/it]progress:  40%|[34m      [0m| 120/300 [02:42<04:02,  1.35s/it]                                                           Episode 121	 reward: -2.55	 makespan: 252.65	 Mean_loss: 0.04114680,  training time: 1.46
progress:  40%|[34m      [0m| 120/300 [02:43<04:02,  1.35s/it]progress:  40%|[34m      [0m| 121/300 [02:43<04:07,  1.38s/it]                                                           Episode 122	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.02850017,  training time: 1.34
progress:  40%|[34m      [0m| 121/300 [02:45<04:07,  1.38s/it]progress:  41%|[34m      [0m| 122/300 [02:45<04:03,  1.37s/it]                                                           Episode 123	 reward: -2.53	 makespan: 250.50	 Mean_loss: 0.03597239,  training time: 1.30
progress:  41%|[34m      [0m| 122/300 [02:46<04:03,  1.37s/it]progress:  41%|[34m      [0m| 123/300 [02:46<03:58,  1.35s/it]                                                           Episode 124	 reward: -2.56	 makespan: 253.00	 Mean_loss: 0.02972440,  training time: 1.33
progress:  41%|[34m      [0m| 123/300 [02:47<03:58,  1.35s/it]progress:  41%|[34m     [0m| 124/300 [02:47<03:56,  1.34s/it]                                                           Episode 125	 reward: -2.48	 makespan: 246.00	 Mean_loss: 0.01667690,  training time: 1.30
progress:  41%|[34m     [0m| 124/300 [02:49<03:56,  1.34s/it]progress:  42%|[34m     [0m| 125/300 [02:49<03:52,  1.33s/it]                                                           Episode 126	 reward: -2.48	 makespan: 245.40	 Mean_loss: 0.02109066,  training time: 1.40
progress:  42%|[34m     [0m| 125/300 [02:50<03:52,  1.33s/it]progress:  42%|[34m     [0m| 126/300 [02:50<03:55,  1.35s/it]                                                           Episode 127	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.01541509,  training time: 1.38
progress:  42%|[34m     [0m| 126/300 [02:51<03:55,  1.35s/it]progress:  42%|[34m     [0m| 127/300 [02:51<03:55,  1.36s/it]                                                           Episode 128	 reward: -2.45	 makespan: 242.55	 Mean_loss: 0.00866467,  training time: 1.42
progress:  42%|[34m     [0m| 127/300 [02:53<03:55,  1.36s/it]progress:  43%|[34m     [0m| 128/300 [02:53<03:56,  1.38s/it]                                                           Episode 129	 reward: -2.60	 makespan: 257.00	 Mean_loss: 0.01943521,  training time: 1.37
progress:  43%|[34m     [0m| 128/300 [02:54<03:56,  1.38s/it]progress:  43%|[34m     [0m| 129/300 [02:54<03:55,  1.38s/it]                                                           Episode 130	 reward: -2.42	 makespan: 239.90	 Mean_loss: 0.02509215,  training time: 1.50
progress:  43%|[34m     [0m| 129/300 [02:56<03:55,  1.38s/it]progress:  43%|[34m     [0m| 130/300 [02:56<04:00,  1.41s/it]                                                           Episode 131	 reward: -2.42	 makespan: 240.05	 Mean_loss: 0.00318590,  training time: 1.32
progress:  43%|[34m     [0m| 130/300 [02:57<04:00,  1.41s/it]progress:  44%|[34m     [0m| 131/300 [02:57<03:53,  1.38s/it]                                                           Episode 132	 reward: -2.37	 makespan: 235.05	 Mean_loss: 0.01026925,  training time: 1.28
progress:  44%|[34m     [0m| 131/300 [02:58<03:53,  1.38s/it]progress:  44%|[34m     [0m| 132/300 [02:58<03:47,  1.35s/it]                                                           Episode 133	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.03000362,  training time: 1.36
progress:  44%|[34m     [0m| 132/300 [03:00<03:47,  1.35s/it]progress:  44%|[34m     [0m| 133/300 [03:00<03:46,  1.36s/it]                                                           Episode 134	 reward: -2.51	 makespan: 248.70	 Mean_loss: 0.00735780,  training time: 1.33
progress:  44%|[34m     [0m| 133/300 [03:01<03:46,  1.36s/it]progress:  45%|[34m     [0m| 134/300 [03:01<03:43,  1.35s/it]                                                           Episode 135	 reward: -2.46	 makespan: 243.45	 Mean_loss: -0.00508457,  training time: 1.32
progress:  45%|[34m     [0m| 134/300 [03:02<03:43,  1.35s/it]progress:  45%|[34m     [0m| 135/300 [03:02<03:41,  1.34s/it]                                                           Episode 136	 reward: -2.53	 makespan: 250.00	 Mean_loss: 0.03034483,  training time: 1.35
progress:  45%|[34m     [0m| 135/300 [03:04<03:41,  1.34s/it]progress:  45%|[34m     [0m| 136/300 [03:04<03:40,  1.34s/it]                                                           Episode 137	 reward: -2.44	 makespan: 241.10	 Mean_loss: -0.00310464,  training time: 1.31
progress:  45%|[34m     [0m| 136/300 [03:05<03:40,  1.34s/it]progress:  46%|[34m     [0m| 137/300 [03:05<03:37,  1.33s/it]                                                           Episode 138	 reward: -2.55	 makespan: 252.30	 Mean_loss: 0.03239258,  training time: 1.38
progress:  46%|[34m     [0m| 137/300 [03:06<03:37,  1.33s/it]progress:  46%|[34m     [0m| 138/300 [03:06<03:38,  1.35s/it]                                                           Episode 139	 reward: -2.44	 makespan: 241.30	 Mean_loss: 0.02393154,  training time: 1.33
progress:  46%|[34m     [0m| 138/300 [03:08<03:38,  1.35s/it]progress:  46%|[34m     [0m| 139/300 [03:08<03:36,  1.34s/it]                                                           Episode 140	 reward: -2.34	 makespan: 231.25	 Mean_loss: 0.00542906,  training time: 1.36
progress:  46%|[34m     [0m| 139/300 [03:09<03:36,  1.34s/it]progress:  47%|[34m     [0m| 140/300 [03:09<03:35,  1.35s/it]                                                           Episode 141	 reward: -2.50	 makespan: 247.30	 Mean_loss: 0.04179476,  training time: 1.41
progress:  47%|[34m     [0m| 140/300 [03:10<03:35,  1.35s/it]progress:  47%|[34m     [0m| 141/300 [03:10<03:37,  1.37s/it]                                                           Episode 142	 reward: -2.63	 makespan: 260.05	 Mean_loss: 0.04342607,  training time: 1.49
progress:  47%|[34m     [0m| 141/300 [03:12<03:37,  1.37s/it]progress:  47%|[34m     [0m| 142/300 [03:12<03:42,  1.41s/it]                                                           Episode 143	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.01952088,  training time: 1.38
progress:  47%|[34m     [0m| 142/300 [03:13<03:42,  1.41s/it]progress:  48%|[34m     [0m| 143/300 [03:13<03:39,  1.40s/it]                                                           Episode 144	 reward: -2.65	 makespan: 262.35	 Mean_loss: 0.03214633,  training time: 1.36
progress:  48%|[34m     [0m| 143/300 [03:15<03:39,  1.40s/it]progress:  48%|[34m     [0m| 144/300 [03:15<03:36,  1.39s/it]                                                           Episode 145	 reward: -2.47	 makespan: 244.50	 Mean_loss: 0.02162845,  training time: 1.39
progress:  48%|[34m     [0m| 144/300 [03:16<03:36,  1.39s/it]progress:  48%|[34m     [0m| 145/300 [03:16<03:34,  1.39s/it]                                                           Episode 146	 reward: -2.58	 makespan: 255.70	 Mean_loss: 0.04755019,  training time: 1.37
progress:  48%|[34m     [0m| 145/300 [03:17<03:34,  1.39s/it]progress:  49%|[34m     [0m| 146/300 [03:17<03:32,  1.38s/it]                                                           Episode 147	 reward: -2.51	 makespan: 248.15	 Mean_loss: 0.02291643,  training time: 1.31
progress:  49%|[34m     [0m| 146/300 [03:19<03:32,  1.38s/it]progress:  49%|[34m     [0m| 147/300 [03:19<03:28,  1.36s/it]                                                           Episode 148	 reward: -2.66	 makespan: 262.85	 Mean_loss: 0.04384731,  training time: 1.35
progress:  49%|[34m     [0m| 147/300 [03:20<03:28,  1.36s/it]progress:  49%|[34m     [0m| 148/300 [03:20<03:26,  1.36s/it]                                                           Episode 149	 reward: -2.56	 makespan: 253.55	 Mean_loss: 0.05523135,  training time: 1.40
progress:  49%|[34m     [0m| 148/300 [03:22<03:26,  1.36s/it]progress:  50%|[34m     [0m| 149/300 [03:22<03:27,  1.37s/it]                                                           Episode 150	 reward: -2.55	 makespan: 252.30	 Mean_loss: 0.02277700,  training time: 1.34
progress:  50%|[34m     [0m| 149/300 [03:23<03:27,  1.37s/it]progress:  50%|[34m     [0m| 150/300 [03:23<03:24,  1.36s/it]                                                           Episode 151	 reward: -2.50	 makespan: 247.80	 Mean_loss: 0.00632597,  training time: 1.33
progress:  50%|[34m     [0m| 150/300 [03:24<03:24,  1.36s/it]progress:  50%|[34m     [0m| 151/300 [03:24<03:21,  1.35s/it]                                                           Episode 152	 reward: -2.51	 makespan: 248.50	 Mean_loss: 0.03325059,  training time: 1.32
progress:  50%|[34m     [0m| 151/300 [03:26<03:21,  1.35s/it]progress:  51%|[34m     [0m| 152/300 [03:26<03:18,  1.34s/it]                                                           Episode 153	 reward: -2.46	 makespan: 243.50	 Mean_loss: 0.01998041,  training time: 1.40
progress:  51%|[34m     [0m| 152/300 [03:27<03:18,  1.34s/it]progress:  51%|[34m     [0m| 153/300 [03:27<03:19,  1.36s/it]                                                           Episode 154	 reward: -2.64	 makespan: 261.60	 Mean_loss: 0.02027257,  training time: 1.29
progress:  51%|[34m     [0m| 153/300 [03:28<03:19,  1.36s/it]progress:  51%|[34m    [0m| 154/300 [03:28<03:15,  1.34s/it]                                                           Episode 155	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.00577648,  training time: 1.31
progress:  51%|[34m    [0m| 154/300 [03:30<03:15,  1.34s/it]progress:  52%|[34m    [0m| 155/300 [03:30<03:12,  1.33s/it]                                                           Episode 156	 reward: -2.61	 makespan: 258.80	 Mean_loss: 0.03158560,  training time: 1.30
progress:  52%|[34m    [0m| 155/300 [03:31<03:12,  1.33s/it]progress:  52%|[34m    [0m| 156/300 [03:31<03:10,  1.32s/it]                                                           Episode 157	 reward: -2.50	 makespan: 247.05	 Mean_loss: 0.00800874,  training time: 1.36
progress:  52%|[34m    [0m| 156/300 [03:32<03:10,  1.32s/it]progress:  52%|[34m    [0m| 157/300 [03:32<03:10,  1.33s/it]                                                           Episode 158	 reward: -2.54	 makespan: 251.15	 Mean_loss: 0.01866103,  training time: 1.37
progress:  52%|[34m    [0m| 157/300 [03:34<03:10,  1.33s/it]progress:  53%|[34m    [0m| 158/300 [03:34<03:10,  1.34s/it]                                                           Episode 159	 reward: -2.54	 makespan: 251.05	 Mean_loss: 0.00517610,  training time: 1.35
progress:  53%|[34m    [0m| 158/300 [03:35<03:10,  1.34s/it]progress:  53%|[34m    [0m| 159/300 [03:35<03:09,  1.35s/it]                                                           Episode 160	 reward: -2.55	 makespan: 252.45	 Mean_loss: 0.00259418,  training time: 1.38
progress:  53%|[34m    [0m| 159/300 [03:36<03:09,  1.35s/it]progress:  53%|[34m    [0m| 160/300 [03:36<03:10,  1.36s/it]                                                           Episode 161	 reward: -2.54	 makespan: 251.60	 Mean_loss: 0.03198572,  training time: 1.40
progress:  53%|[34m    [0m| 160/300 [03:38<03:10,  1.36s/it]progress:  54%|[34m    [0m| 161/300 [03:38<03:10,  1.37s/it]                                                           Episode 162	 reward: -2.43	 makespan: 240.65	 Mean_loss: 0.04964688,  training time: 1.36
progress:  54%|[34m    [0m| 161/300 [03:39<03:10,  1.37s/it]progress:  54%|[34m    [0m| 162/300 [03:39<03:08,  1.37s/it]                                                           Episode 163	 reward: -2.45	 makespan: 242.95	 Mean_loss: 0.03221859,  training time: 1.36
progress:  54%|[34m    [0m| 162/300 [03:40<03:08,  1.37s/it]progress:  54%|[34m    [0m| 163/300 [03:40<03:07,  1.37s/it]                                                           Episode 164	 reward: -2.56	 makespan: 253.65	 Mean_loss: 0.03421230,  training time: 1.34
progress:  54%|[34m    [0m| 163/300 [03:42<03:07,  1.37s/it]progress:  55%|[34m    [0m| 164/300 [03:42<03:04,  1.36s/it]                                                           Episode 165	 reward: -2.48	 makespan: 245.10	 Mean_loss: 0.06269146,  training time: 1.35
progress:  55%|[34m    [0m| 164/300 [03:43<03:04,  1.36s/it]progress:  55%|[34m    [0m| 165/300 [03:43<03:03,  1.36s/it]                                                           Episode 166	 reward: -2.43	 makespan: 240.15	 Mean_loss: 0.02082050,  training time: 1.37
progress:  55%|[34m    [0m| 165/300 [03:44<03:03,  1.36s/it]progress:  55%|[34m    [0m| 166/300 [03:44<03:02,  1.36s/it]                                                           Episode 167	 reward: -2.54	 makespan: 251.40	 Mean_loss: 0.05621774,  training time: 1.35
progress:  55%|[34m    [0m| 166/300 [03:46<03:02,  1.36s/it]progress:  56%|[34m    [0m| 167/300 [03:46<03:00,  1.36s/it]                                                           Episode 168	 reward: -2.45	 makespan: 243.00	 Mean_loss: 0.04967865,  training time: 1.34
progress:  56%|[34m    [0m| 167/300 [03:47<03:00,  1.36s/it]progress:  56%|[34m    [0m| 168/300 [03:47<02:58,  1.35s/it]                                                           Episode 169	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.02415628,  training time: 1.36
progress:  56%|[34m    [0m| 168/300 [03:49<02:58,  1.35s/it]progress:  56%|[34m    [0m| 169/300 [03:49<02:57,  1.35s/it]                                                           Episode 170	 reward: -2.48	 makespan: 245.50	 Mean_loss: 0.04923182,  training time: 1.38
progress:  56%|[34m    [0m| 169/300 [03:50<02:57,  1.35s/it]progress:  57%|[34m    [0m| 170/300 [03:50<02:57,  1.36s/it]                                                           Episode 171	 reward: -2.57	 makespan: 254.90	 Mean_loss: 0.03489024,  training time: 1.36
progress:  57%|[34m    [0m| 170/300 [03:51<02:57,  1.36s/it]progress:  57%|[34m    [0m| 171/300 [03:51<02:55,  1.36s/it]                                                           Episode 172	 reward: -2.63	 makespan: 260.50	 Mean_loss: 0.05393575,  training time: 1.34
progress:  57%|[34m    [0m| 171/300 [03:53<02:55,  1.36s/it]progress:  57%|[34m    [0m| 172/300 [03:53<02:53,  1.36s/it]                                                           Episode 173	 reward: -2.57	 makespan: 254.05	 Mean_loss: 0.04511121,  training time: 1.35
progress:  57%|[34m    [0m| 172/300 [03:54<02:53,  1.36s/it]progress:  58%|[34m    [0m| 173/300 [03:54<02:51,  1.35s/it]                                                           Episode 174	 reward: -2.62	 makespan: 259.15	 Mean_loss: 0.01954490,  training time: 1.37
progress:  58%|[34m    [0m| 173/300 [03:55<02:51,  1.35s/it]progress:  58%|[34m    [0m| 174/300 [03:55<02:51,  1.36s/it]                                                           Episode 175	 reward: -2.59	 makespan: 256.70	 Mean_loss: 0.02456307,  training time: 1.35
progress:  58%|[34m    [0m| 174/300 [03:57<02:51,  1.36s/it]progress:  58%|[34m    [0m| 175/300 [03:57<02:49,  1.36s/it]                                                           Episode 176	 reward: -2.53	 makespan: 250.40	 Mean_loss: 0.03490429,  training time: 1.40
progress:  58%|[34m    [0m| 175/300 [03:58<02:49,  1.36s/it]progress:  59%|[34m    [0m| 176/300 [03:58<02:49,  1.37s/it]                                                           Episode 177	 reward: -2.55	 makespan: 252.10	 Mean_loss: 0.03684031,  training time: 1.39
progress:  59%|[34m    [0m| 176/300 [03:59<02:49,  1.37s/it]progress:  59%|[34m    [0m| 177/300 [03:59<02:49,  1.38s/it]                                                           Episode 178	 reward: -2.53	 makespan: 250.70	 Mean_loss: 0.04279566,  training time: 1.38
progress:  59%|[34m    [0m| 177/300 [04:01<02:49,  1.38s/it]progress:  59%|[34m    [0m| 178/300 [04:01<02:48,  1.38s/it]                                                           Episode 179	 reward: -2.56	 makespan: 253.70	 Mean_loss: 0.05609414,  training time: 1.41
progress:  59%|[34m    [0m| 178/300 [04:02<02:48,  1.38s/it]progress:  60%|[34m    [0m| 179/300 [04:02<02:47,  1.39s/it]                                                           Episode 180	 reward: -2.47	 makespan: 244.65	 Mean_loss: 0.04571059,  training time: 1.37
progress:  60%|[34m    [0m| 179/300 [04:04<02:47,  1.39s/it]progress:  60%|[34m    [0m| 180/300 [04:04<02:45,  1.38s/it]                                                           Episode 181	 reward: -2.55	 makespan: 252.90	 Mean_loss: 0.04182199,  training time: 1.42
progress:  60%|[34m    [0m| 180/300 [04:05<02:45,  1.38s/it]progress:  60%|[34m    [0m| 181/300 [04:05<02:45,  1.39s/it]                                                           Episode 182	 reward: -2.56	 makespan: 253.25	 Mean_loss: 0.01976470,  training time: 1.43
progress:  60%|[34m    [0m| 181/300 [04:06<02:45,  1.39s/it]progress:  61%|[34m    [0m| 182/300 [04:06<02:45,  1.40s/it]                                                           Episode 183	 reward: -2.66	 makespan: 263.10	 Mean_loss: 0.06702111,  training time: 1.43
progress:  61%|[34m    [0m| 182/300 [04:08<02:45,  1.40s/it]progress:  61%|[34m    [0m| 183/300 [04:08<02:45,  1.41s/it]                                                           Episode 184	 reward: -2.61	 makespan: 258.15	 Mean_loss: 0.03364063,  training time: 1.35
progress:  61%|[34m    [0m| 183/300 [04:09<02:45,  1.41s/it]progress:  61%|[34m   [0m| 184/300 [04:09<02:41,  1.39s/it]                                                           Episode 185	 reward: -2.62	 makespan: 259.20	 Mean_loss: 0.04950052,  training time: 1.34
progress:  61%|[34m   [0m| 184/300 [04:11<02:41,  1.39s/it]progress:  62%|[34m   [0m| 185/300 [04:11<02:38,  1.38s/it]                                                           Episode 186	 reward: -2.62	 makespan: 259.45	 Mean_loss: 0.02496651,  training time: 1.36
progress:  62%|[34m   [0m| 185/300 [04:12<02:38,  1.38s/it]progress:  62%|[34m   [0m| 186/300 [04:12<02:36,  1.37s/it]                                                           Episode 187	 reward: -2.66	 makespan: 263.80	 Mean_loss: 0.04508608,  training time: 1.35
progress:  62%|[34m   [0m| 186/300 [04:13<02:36,  1.37s/it]progress:  62%|[34m   [0m| 187/300 [04:13<02:34,  1.37s/it]                                                           Episode 188	 reward: -2.59	 makespan: 256.10	 Mean_loss: 0.05054632,  training time: 1.35
progress:  62%|[34m   [0m| 187/300 [04:15<02:34,  1.37s/it]progress:  63%|[34m   [0m| 188/300 [04:15<02:32,  1.36s/it]                                                           Episode 189	 reward: -2.58	 makespan: 255.35	 Mean_loss: 0.02430965,  training time: 1.36
progress:  63%|[34m   [0m| 188/300 [04:16<02:32,  1.36s/it]progress:  63%|[34m   [0m| 189/300 [04:16<02:31,  1.36s/it]                                                           Episode 190	 reward: -2.67	 makespan: 264.45	 Mean_loss: 0.04213835,  training time: 1.42
progress:  63%|[34m   [0m| 189/300 [04:17<02:31,  1.36s/it]progress:  63%|[34m   [0m| 190/300 [04:17<02:31,  1.38s/it]                                                           Episode 191	 reward: -2.65	 makespan: 262.15	 Mean_loss: 0.01555605,  training time: 1.36
progress:  63%|[34m   [0m| 190/300 [04:19<02:31,  1.38s/it]progress:  64%|[34m   [0m| 191/300 [04:19<02:29,  1.38s/it]                                                           Episode 192	 reward: -2.65	 makespan: 262.45	 Mean_loss: 0.03487076,  training time: 1.37
progress:  64%|[34m   [0m| 191/300 [04:20<02:29,  1.38s/it]progress:  64%|[34m   [0m| 192/300 [04:20<02:28,  1.37s/it]                                                           Episode 193	 reward: -2.59	 makespan: 256.85	 Mean_loss: 0.02612035,  training time: 1.43
progress:  64%|[34m   [0m| 192/300 [04:22<02:28,  1.37s/it]progress:  64%|[34m   [0m| 193/300 [04:22<02:28,  1.39s/it]                                                           Episode 194	 reward: -2.58	 makespan: 255.30	 Mean_loss: 0.04873649,  training time: 1.39
progress:  64%|[34m   [0m| 193/300 [04:23<02:28,  1.39s/it]progress:  65%|[34m   [0m| 194/300 [04:23<02:27,  1.39s/it]                                                           Episode 195	 reward: -2.58	 makespan: 255.30	 Mean_loss: 0.04043835,  training time: 1.36
progress:  65%|[34m   [0m| 194/300 [04:24<02:27,  1.39s/it]progress:  65%|[34m   [0m| 195/300 [04:24<02:25,  1.38s/it]                                                           Episode 196	 reward: -2.59	 makespan: 256.65	 Mean_loss: 0.03454080,  training time: 1.35
progress:  65%|[34m   [0m| 195/300 [04:26<02:25,  1.38s/it]progress:  65%|[34m   [0m| 196/300 [04:26<02:22,  1.37s/it]                                                           Episode 197	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.05865373,  training time: 1.38
progress:  65%|[34m   [0m| 196/300 [04:27<02:22,  1.37s/it]progress:  66%|[34m   [0m| 197/300 [04:27<02:21,  1.37s/it]                                                           Episode 198	 reward: -2.54	 makespan: 251.30	 Mean_loss: 0.03117134,  training time: 1.32
progress:  66%|[34m   [0m| 197/300 [04:28<02:21,  1.37s/it]progress:  66%|[34m   [0m| 198/300 [04:28<02:18,  1.36s/it]                                                           Episode 199	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.02038156,  training time: 1.34
progress:  66%|[34m   [0m| 198/300 [04:30<02:18,  1.36s/it]progress:  66%|[34m   [0m| 199/300 [04:30<02:16,  1.35s/it]                                                           Episode 200	 reward: -2.63	 makespan: 260.70	 Mean_loss: 0.01719381,  training time: 1.34
progress:  66%|[34m   [0m| 199/300 [04:31<02:16,  1.35s/it]progress:  67%|[34m   [0m| 200/300 [04:31<02:14,  1.35s/it]                                                           Episode 201	 reward: -2.63	 makespan: 260.00	 Mean_loss: 0.00246385,  training time: 1.38
progress:  67%|[34m   [0m| 200/300 [04:33<02:14,  1.35s/it]progress:  67%|[34m   [0m| 201/300 [04:33<02:14,  1.36s/it]                                                           Episode 202	 reward: -2.61	 makespan: 258.00	 Mean_loss: 0.02925555,  training time: 1.30
progress:  67%|[34m   [0m| 201/300 [04:34<02:14,  1.36s/it]progress:  67%|[34m   [0m| 202/300 [04:34<02:11,  1.34s/it]                                                           Episode 203	 reward: -2.59	 makespan: 256.25	 Mean_loss: 0.00789190,  training time: 1.33
progress:  67%|[34m   [0m| 202/300 [04:35<02:11,  1.34s/it]progress:  68%|[34m   [0m| 203/300 [04:35<02:10,  1.34s/it]                                                           Episode 204	 reward: -2.65	 makespan: 262.80	 Mean_loss: 0.00268585,  training time: 1.29
progress:  68%|[34m   [0m| 203/300 [04:36<02:10,  1.34s/it]progress:  68%|[34m   [0m| 204/300 [04:36<02:07,  1.33s/it]                                                           Episode 205	 reward: -2.59	 makespan: 256.50	 Mean_loss: 0.00084127,  training time: 1.34
progress:  68%|[34m   [0m| 204/300 [04:38<02:07,  1.33s/it]progress:  68%|[34m   [0m| 205/300 [04:38<02:06,  1.33s/it]                                                           Episode 206	 reward: -2.58	 makespan: 255.45	 Mean_loss: 0.01888653,  training time: 1.30
progress:  68%|[34m   [0m| 205/300 [04:39<02:06,  1.33s/it]progress:  69%|[34m   [0m| 206/300 [04:39<02:04,  1.32s/it]                                                           Episode 207	 reward: -2.59	 makespan: 256.40	 Mean_loss: 0.00748037,  training time: 1.32
progress:  69%|[34m   [0m| 206/300 [04:40<02:04,  1.32s/it]progress:  69%|[34m   [0m| 207/300 [04:40<02:03,  1.32s/it]                                                           Episode 208	 reward: -2.60	 makespan: 257.20	 Mean_loss: 0.00915488,  training time: 1.30
progress:  69%|[34m   [0m| 207/300 [04:42<02:03,  1.32s/it]progress:  69%|[34m   [0m| 208/300 [04:42<02:01,  1.32s/it]                                                           Episode 209	 reward: -2.55	 makespan: 252.15	 Mean_loss: 0.00106964,  training time: 1.34
progress:  69%|[34m   [0m| 208/300 [04:43<02:01,  1.32s/it]progress:  70%|[34m   [0m| 209/300 [04:43<02:00,  1.32s/it]                                                           Episode 210	 reward: -2.55	 makespan: 252.70	 Mean_loss: 0.00813984,  training time: 1.31
progress:  70%|[34m   [0m| 209/300 [04:44<02:00,  1.32s/it]progress:  70%|[34m   [0m| 210/300 [04:44<01:58,  1.32s/it]                                                           Episode 211	 reward: -2.66	 makespan: 263.65	 Mean_loss: 0.02650536,  training time: 1.29
progress:  70%|[34m   [0m| 210/300 [04:46<01:58,  1.32s/it]progress:  70%|[34m   [0m| 211/300 [04:46<01:56,  1.31s/it]                                                           Episode 212	 reward: -2.58	 makespan: 255.35	 Mean_loss: 0.00902877,  training time: 1.34
progress:  70%|[34m   [0m| 211/300 [04:47<01:56,  1.31s/it]progress:  71%|[34m   [0m| 212/300 [04:47<01:56,  1.32s/it]                                                           Episode 213	 reward: -2.58	 makespan: 255.10	 Mean_loss: -0.01163743,  training time: 1.39
progress:  71%|[34m   [0m| 212/300 [04:48<01:56,  1.32s/it]progress:  71%|[34m   [0m| 213/300 [04:48<01:56,  1.34s/it]                                                           Episode 214	 reward: -2.55	 makespan: 252.05	 Mean_loss: 0.01607708,  training time: 1.31
progress:  71%|[34m   [0m| 213/300 [04:50<01:56,  1.34s/it]progress:  71%|[34m  [0m| 214/300 [04:50<01:54,  1.33s/it]                                                           Episode 215	 reward: -2.57	 makespan: 254.55	 Mean_loss: 0.01602826,  training time: 1.36
progress:  71%|[34m  [0m| 214/300 [04:51<01:54,  1.33s/it]progress:  72%|[34m  [0m| 215/300 [04:51<01:53,  1.34s/it]                                                           Episode 216	 reward: -2.54	 makespan: 251.65	 Mean_loss: -0.01204816,  training time: 1.41
progress:  72%|[34m  [0m| 215/300 [04:52<01:53,  1.34s/it]progress:  72%|[34m  [0m| 216/300 [04:52<01:54,  1.36s/it]                                                           Episode 217	 reward: -2.67	 makespan: 264.20	 Mean_loss: 0.02773223,  training time: 1.44
progress:  72%|[34m  [0m| 216/300 [04:54<01:54,  1.36s/it]progress:  72%|[34m  [0m| 217/300 [04:54<01:55,  1.39s/it]                                                           Episode 218	 reward: -2.67	 makespan: 264.20	 Mean_loss: 0.01486000,  training time: 1.32
progress:  72%|[34m  [0m| 217/300 [04:55<01:55,  1.39s/it]progress:  73%|[34m  [0m| 218/300 [04:55<01:52,  1.37s/it]                                                           Episode 219	 reward: -2.62	 makespan: 259.05	 Mean_loss: 0.00035482,  training time: 1.37
progress:  73%|[34m  [0m| 218/300 [04:57<01:52,  1.37s/it]progress:  73%|[34m  [0m| 219/300 [04:57<01:50,  1.37s/it]                                                           Episode 220	 reward: -2.58	 makespan: 255.55	 Mean_loss: 0.00321651,  training time: 1.37
progress:  73%|[34m  [0m| 219/300 [04:58<01:50,  1.37s/it]progress:  73%|[34m  [0m| 220/300 [04:58<01:49,  1.37s/it]                                                           Episode 221	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.02797823,  training time: 1.35
progress:  73%|[34m  [0m| 220/300 [04:59<01:49,  1.37s/it]progress:  74%|[34m  [0m| 221/300 [04:59<01:47,  1.36s/it]                                                           Episode 222	 reward: -2.46	 makespan: 243.65	 Mean_loss: 0.05330762,  training time: 1.27
progress:  74%|[34m  [0m| 221/300 [05:01<01:47,  1.36s/it]progress:  74%|[34m  [0m| 222/300 [05:01<01:44,  1.34s/it]                                                           Episode 223	 reward: -2.50	 makespan: 247.35	 Mean_loss: 0.00536965,  training time: 1.45
progress:  74%|[34m  [0m| 222/300 [05:02<01:44,  1.34s/it]progress:  74%|[34m  [0m| 223/300 [05:02<01:45,  1.37s/it]                                                           Episode 224	 reward: -2.58	 makespan: 255.15	 Mean_loss: 0.03866633,  training time: 1.37
progress:  74%|[34m  [0m| 223/300 [05:03<01:45,  1.37s/it]progress:  75%|[34m  [0m| 224/300 [05:03<01:44,  1.37s/it]                                                           Episode 225	 reward: -2.49	 makespan: 246.10	 Mean_loss: 0.01999679,  training time: 1.29
progress:  75%|[34m  [0m| 224/300 [05:05<01:44,  1.37s/it]progress:  75%|[34m  [0m| 225/300 [05:05<01:40,  1.35s/it]                                                           Episode 226	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.01089951,  training time: 1.34
progress:  75%|[34m  [0m| 225/300 [05:06<01:40,  1.35s/it]progress:  75%|[34m  [0m| 226/300 [05:06<01:39,  1.34s/it]                                                           Episode 227	 reward: -2.57	 makespan: 254.75	 Mean_loss: 0.01918116,  training time: 1.38
progress:  75%|[34m  [0m| 226/300 [05:07<01:39,  1.34s/it]progress:  76%|[34m  [0m| 227/300 [05:07<01:38,  1.36s/it]                                                           Episode 228	 reward: -2.44	 makespan: 241.50	 Mean_loss: -0.00022220,  training time: 1.40
progress:  76%|[34m  [0m| 227/300 [05:09<01:38,  1.36s/it]progress:  76%|[34m  [0m| 228/300 [05:09<01:38,  1.37s/it]                                                           Episode 229	 reward: -2.44	 makespan: 241.15	 Mean_loss: 0.02643627,  training time: 1.36
progress:  76%|[34m  [0m| 228/300 [05:10<01:38,  1.37s/it]progress:  76%|[34m  [0m| 229/300 [05:10<01:37,  1.37s/it]                                                           Episode 230	 reward: -2.52	 makespan: 249.20	 Mean_loss: 0.02928683,  training time: 1.29
progress:  76%|[34m  [0m| 229/300 [05:11<01:37,  1.37s/it]progress:  77%|[34m  [0m| 230/300 [05:11<01:34,  1.34s/it]                                                           Episode 231	 reward: -2.55	 makespan: 252.90	 Mean_loss: 0.02157064,  training time: 1.28
progress:  77%|[34m  [0m| 230/300 [05:13<01:34,  1.34s/it]progress:  77%|[34m  [0m| 231/300 [05:13<01:31,  1.32s/it]                                                           Episode 232	 reward: -2.46	 makespan: 243.05	 Mean_loss: -0.00610451,  training time: 1.35
progress:  77%|[34m  [0m| 231/300 [05:14<01:31,  1.32s/it]progress:  77%|[34m  [0m| 232/300 [05:14<01:30,  1.33s/it]                                                           Episode 233	 reward: -2.49	 makespan: 246.90	 Mean_loss: -0.00325976,  training time: 1.28
progress:  77%|[34m  [0m| 232/300 [05:15<01:30,  1.33s/it]progress:  78%|[34m  [0m| 233/300 [05:15<01:28,  1.32s/it]                                                           Episode 234	 reward: -2.39	 makespan: 236.70	 Mean_loss: 0.02926390,  training time: 1.37
progress:  78%|[34m  [0m| 233/300 [05:17<01:28,  1.32s/it]progress:  78%|[34m  [0m| 234/300 [05:17<01:28,  1.33s/it]                                                           Episode 235	 reward: -2.56	 makespan: 253.15	 Mean_loss: 0.04821572,  training time: 1.35
progress:  78%|[34m  [0m| 234/300 [05:18<01:28,  1.33s/it]progress:  78%|[34m  [0m| 235/300 [05:18<01:27,  1.34s/it]                                                           Episode 236	 reward: -2.41	 makespan: 238.95	 Mean_loss: 0.00996284,  training time: 1.35
progress:  78%|[34m  [0m| 235/300 [05:19<01:27,  1.34s/it]progress:  79%|[34m  [0m| 236/300 [05:19<01:26,  1.34s/it]                                                           Episode 237	 reward: -2.52	 makespan: 249.90	 Mean_loss: 0.02144324,  training time: 1.28
progress:  79%|[34m  [0m| 236/300 [05:21<01:26,  1.34s/it]progress:  79%|[34m  [0m| 237/300 [05:21<01:23,  1.33s/it]                                                           Episode 238	 reward: -2.51	 makespan: 248.80	 Mean_loss: 0.04336273,  training time: 1.34
progress:  79%|[34m  [0m| 237/300 [05:22<01:23,  1.33s/it]progress:  79%|[34m  [0m| 238/300 [05:22<01:22,  1.33s/it]                                                           Episode 239	 reward: -2.36	 makespan: 233.60	 Mean_loss: 0.01177412,  training time: 1.28
progress:  79%|[34m  [0m| 238/300 [05:23<01:22,  1.33s/it]progress:  80%|[34m  [0m| 239/300 [05:23<01:20,  1.32s/it]                                                           Episode 240	 reward: -2.46	 makespan: 243.55	 Mean_loss: 0.04243231,  training time: 1.36
progress:  80%|[34m  [0m| 239/300 [05:25<01:20,  1.32s/it]progress:  80%|[34m  [0m| 240/300 [05:25<01:19,  1.33s/it]                                                           Episode 241	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.03818158,  training time: 1.41
progress:  80%|[34m  [0m| 240/300 [05:26<01:19,  1.33s/it]progress:  80%|[34m  [0m| 241/300 [05:26<01:19,  1.35s/it]                                                           Episode 242	 reward: -2.45	 makespan: 242.15	 Mean_loss: 0.03884682,  training time: 1.32
progress:  80%|[34m  [0m| 241/300 [05:27<01:19,  1.35s/it]progress:  81%|[34m  [0m| 242/300 [05:27<01:17,  1.34s/it]                                                           Episode 243	 reward: -2.46	 makespan: 244.00	 Mean_loss: 0.03095153,  training time: 1.32
progress:  81%|[34m  [0m| 242/300 [05:29<01:17,  1.34s/it]progress:  81%|[34m  [0m| 243/300 [05:29<01:16,  1.34s/it]                                                           Episode 244	 reward: -2.45	 makespan: 242.20	 Mean_loss: 0.02504858,  training time: 1.34
progress:  81%|[34m  [0m| 243/300 [05:30<01:16,  1.34s/it]progress:  81%|[34m [0m| 244/300 [05:30<01:14,  1.34s/it]                                                           Episode 245	 reward: -2.51	 makespan: 248.05	 Mean_loss: 0.02030797,  training time: 1.34
progress:  81%|[34m [0m| 244/300 [05:31<01:14,  1.34s/it]progress:  82%|[34m [0m| 245/300 [05:31<01:13,  1.34s/it]                                                           Episode 246	 reward: -2.45	 makespan: 242.30	 Mean_loss: 0.02574945,  training time: 1.28
progress:  82%|[34m [0m| 245/300 [05:33<01:13,  1.34s/it]progress:  82%|[34m [0m| 246/300 [05:33<01:11,  1.32s/it]                                                           Episode 247	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.01909608,  training time: 1.34
progress:  82%|[34m [0m| 246/300 [05:34<01:11,  1.32s/it]progress:  82%|[34m [0m| 247/300 [05:34<01:10,  1.33s/it]                                                           Episode 248	 reward: -2.45	 makespan: 242.75	 Mean_loss: 0.01732831,  training time: 1.28
progress:  82%|[34m [0m| 247/300 [05:35<01:10,  1.33s/it]progress:  83%|[34m [0m| 248/300 [05:35<01:08,  1.31s/it]                                                           Episode 249	 reward: -2.54	 makespan: 251.00	 Mean_loss: 0.02697007,  training time: 1.34
progress:  83%|[34m [0m| 248/300 [05:37<01:08,  1.31s/it]progress:  83%|[34m [0m| 249/300 [05:37<01:07,  1.32s/it]                                                           Episode 250	 reward: -2.47	 makespan: 244.85	 Mean_loss: 0.02229749,  training time: 1.38
progress:  83%|[34m [0m| 249/300 [05:38<01:07,  1.32s/it]progress:  83%|[34m [0m| 250/300 [05:38<01:06,  1.34s/it]                                                           Episode 251	 reward: -2.60	 makespan: 257.80	 Mean_loss: 0.01907813,  training time: 1.30
progress:  83%|[34m [0m| 250/300 [05:39<01:06,  1.34s/it]progress:  84%|[34m [0m| 251/300 [05:39<01:04,  1.33s/it]                                                           Episode 252	 reward: -2.48	 makespan: 245.40	 Mean_loss: 0.02124176,  training time: 1.31
progress:  84%|[34m [0m| 251/300 [05:41<01:04,  1.33s/it]progress:  84%|[34m [0m| 252/300 [05:41<01:03,  1.32s/it]                                                           Episode 253	 reward: -2.49	 makespan: 246.75	 Mean_loss: 0.01047661,  training time: 1.40
progress:  84%|[34m [0m| 252/300 [05:42<01:03,  1.32s/it]progress:  84%|[34m [0m| 253/300 [05:42<01:03,  1.35s/it]                                                           Episode 254	 reward: -2.45	 makespan: 242.50	 Mean_loss: 0.03678476,  training time: 1.35
progress:  84%|[34m [0m| 253/300 [05:43<01:03,  1.35s/it]progress:  85%|[34m [0m| 254/300 [05:43<01:01,  1.35s/it]                                                           Episode 255	 reward: -2.46	 makespan: 243.45	 Mean_loss: 0.03761500,  training time: 1.30
progress:  85%|[34m [0m| 254/300 [05:45<01:01,  1.35s/it]progress:  85%|[34m [0m| 255/300 [05:45<00:59,  1.33s/it]                                                           Episode 256	 reward: -2.42	 makespan: 239.50	 Mean_loss: 0.01464200,  training time: 1.28
progress:  85%|[34m [0m| 255/300 [05:46<00:59,  1.33s/it]progress:  85%|[34m [0m| 256/300 [05:46<00:57,  1.32s/it]                                                           Episode 257	 reward: -2.47	 makespan: 244.60	 Mean_loss: 0.01860620,  training time: 1.33
progress:  85%|[34m [0m| 256/300 [05:47<00:57,  1.32s/it]progress:  86%|[34m [0m| 257/300 [05:47<00:56,  1.32s/it]                                                           Episode 258	 reward: -2.53	 makespan: 250.15	 Mean_loss: 0.03294506,  training time: 1.35
progress:  86%|[34m [0m| 257/300 [05:49<00:56,  1.32s/it]progress:  86%|[34m [0m| 258/300 [05:49<00:55,  1.33s/it]                                                           Episode 259	 reward: -2.50	 makespan: 247.65	 Mean_loss: 0.01786495,  training time: 1.30
progress:  86%|[34m [0m| 258/300 [05:50<00:55,  1.33s/it]progress:  86%|[34m [0m| 259/300 [05:50<00:54,  1.32s/it]                                                           Episode 260	 reward: -2.41	 makespan: 239.05	 Mean_loss: -0.00734694,  training time: 1.35
progress:  86%|[34m [0m| 259/300 [05:51<00:54,  1.32s/it]progress:  87%|[34m [0m| 260/300 [05:51<00:53,  1.33s/it]                                                           Episode 261	 reward: -2.48	 makespan: 245.05	 Mean_loss: 0.05856788,  training time: 1.40
progress:  87%|[34m [0m| 260/300 [05:53<00:53,  1.33s/it]progress:  87%|[34m [0m| 261/300 [05:53<00:52,  1.35s/it]                                                           Episode 262	 reward: -2.56	 makespan: 253.90	 Mean_loss: 0.03622349,  training time: 1.35
progress:  87%|[34m [0m| 261/300 [05:54<00:52,  1.35s/it]progress:  87%|[34m [0m| 262/300 [05:54<00:51,  1.35s/it]                                                           Episode 263	 reward: -2.54	 makespan: 251.50	 Mean_loss: 0.02144111,  training time: 1.28
progress:  87%|[34m [0m| 262/300 [05:55<00:51,  1.35s/it]progress:  88%|[34m [0m| 263/300 [05:55<00:49,  1.33s/it]                                                           Episode 264	 reward: -2.57	 makespan: 254.20	 Mean_loss: 0.07936625,  training time: 1.35
progress:  88%|[34m [0m| 263/300 [05:57<00:49,  1.33s/it]progress:  88%|[34m [0m| 264/300 [05:57<00:48,  1.34s/it]                                                           Episode 265	 reward: -2.49	 makespan: 246.60	 Mean_loss: 0.02824869,  training time: 1.29
progress:  88%|[34m [0m| 264/300 [05:58<00:48,  1.34s/it]progress:  88%|[34m [0m| 265/300 [05:58<00:46,  1.32s/it]                                                           Episode 266	 reward: -2.58	 makespan: 255.70	 Mean_loss: 0.04467317,  training time: 1.30
progress:  88%|[34m [0m| 265/300 [05:59<00:46,  1.32s/it]progress:  89%|[34m [0m| 266/300 [05:59<00:44,  1.31s/it]                                                           Episode 267	 reward: -2.58	 makespan: 255.90	 Mean_loss: 0.04048063,  training time: 1.41
progress:  89%|[34m [0m| 266/300 [06:01<00:44,  1.31s/it]progress:  89%|[34m [0m| 267/300 [06:01<00:44,  1.34s/it]                                                           Episode 268	 reward: -2.54	 makespan: 251.00	 Mean_loss: 0.05316020,  training time: 1.27
progress:  89%|[34m [0m| 267/300 [06:02<00:44,  1.34s/it]progress:  89%|[34m [0m| 268/300 [06:02<00:42,  1.32s/it]                                                           Episode 269	 reward: -2.61	 makespan: 258.30	 Mean_loss: 0.03830019,  training time: 1.40
progress:  89%|[34m [0m| 268/300 [06:03<00:42,  1.32s/it]progress:  90%|[34m [0m| 269/300 [06:03<00:41,  1.35s/it]                                                           Episode 270	 reward: -2.49	 makespan: 246.15	 Mean_loss: 0.03927302,  training time: 1.33
progress:  90%|[34m [0m| 269/300 [06:05<00:41,  1.35s/it]progress:  90%|[34m [0m| 270/300 [06:05<00:40,  1.34s/it]                                                           Episode 271	 reward: -2.47	 makespan: 244.80	 Mean_loss: 0.02767701,  training time: 1.38
progress:  90%|[34m [0m| 270/300 [06:06<00:40,  1.34s/it]progress:  90%|[34m [0m| 271/300 [06:06<00:39,  1.36s/it]                                                           Episode 272	 reward: -2.53	 makespan: 250.10	 Mean_loss: 0.04221074,  training time: 1.47
progress:  90%|[34m [0m| 271/300 [06:08<00:39,  1.36s/it]progress:  91%|[34m [0m| 272/300 [06:08<00:38,  1.39s/it]                                                           Episode 273	 reward: -2.41	 makespan: 238.80	 Mean_loss: 0.04648020,  training time: 1.38
progress:  91%|[34m [0m| 272/300 [06:09<00:38,  1.39s/it]progress:  91%|[34m [0m| 273/300 [06:09<00:37,  1.39s/it]                                                           Episode 274	 reward: -2.51	 makespan: 248.75	 Mean_loss: 0.08274285,  training time: 1.41
progress:  91%|[34m [0m| 273/300 [06:10<00:37,  1.39s/it]progress:  91%|[34m[0m| 274/300 [06:10<00:36,  1.39s/it]                                                           Episode 275	 reward: -2.54	 makespan: 251.50	 Mean_loss: 0.04893445,  training time: 1.35
progress:  91%|[34m[0m| 274/300 [06:12<00:36,  1.39s/it]progress:  92%|[34m[0m| 275/300 [06:12<00:34,  1.38s/it]                                                           Episode 276	 reward: -2.60	 makespan: 257.15	 Mean_loss: 0.05724899,  training time: 1.36
progress:  92%|[34m[0m| 275/300 [06:13<00:34,  1.38s/it]progress:  92%|[34m[0m| 276/300 [06:13<00:33,  1.38s/it]                                                           Episode 277	 reward: -2.49	 makespan: 246.95	 Mean_loss: 0.06563666,  training time: 1.35
progress:  92%|[34m[0m| 276/300 [06:14<00:33,  1.38s/it]progress:  92%|[34m[0m| 277/300 [06:14<00:31,  1.37s/it]                                                           Episode 278	 reward: -2.57	 makespan: 254.25	 Mean_loss: 0.03102925,  training time: 1.36
progress:  92%|[34m[0m| 277/300 [06:16<00:31,  1.37s/it]progress:  93%|[34m[0m| 278/300 [06:16<00:30,  1.37s/it]                                                           Episode 279	 reward: -2.58	 makespan: 255.10	 Mean_loss: 0.06142269,  training time: 1.35
progress:  93%|[34m[0m| 278/300 [06:17<00:30,  1.37s/it]progress:  93%|[34m[0m| 279/300 [06:17<00:28,  1.36s/it]                                                           Episode 280	 reward: -2.49	 makespan: 246.10	 Mean_loss: 0.03221605,  training time: 1.35
progress:  93%|[34m[0m| 279/300 [06:19<00:28,  1.36s/it]progress:  93%|[34m[0m| 280/300 [06:19<00:27,  1.36s/it]                                                           Episode 281	 reward: -2.54	 makespan: 251.80	 Mean_loss: 0.03753761,  training time: 1.34
progress:  93%|[34m[0m| 280/300 [06:20<00:27,  1.36s/it]progress:  94%|[34m[0m| 281/300 [06:20<00:25,  1.35s/it]                                                           Episode 282	 reward: -2.59	 makespan: 256.30	 Mean_loss: 0.04272883,  training time: 1.30
progress:  94%|[34m[0m| 281/300 [06:21<00:25,  1.35s/it]progress:  94%|[34m[0m| 282/300 [06:21<00:24,  1.34s/it]                                                           Episode 283	 reward: -2.66	 makespan: 263.20	 Mean_loss: 0.05472729,  training time: 1.47
progress:  94%|[34m[0m| 282/300 [06:23<00:24,  1.34s/it]progress:  94%|[34m[0m| 283/300 [06:23<00:23,  1.38s/it]                                                           Episode 284	 reward: -2.50	 makespan: 247.30	 Mean_loss: 0.01671523,  training time: 1.37
progress:  94%|[34m[0m| 283/300 [06:24<00:23,  1.38s/it]progress:  95%|[34m[0m| 284/300 [06:24<00:22,  1.38s/it]                                                           Episode 285	 reward: -2.54	 makespan: 251.15	 Mean_loss: 0.03505917,  training time: 1.37
progress:  95%|[34m[0m| 284/300 [06:25<00:22,  1.38s/it]progress:  95%|[34m[0m| 285/300 [06:25<00:20,  1.37s/it]                                                           Episode 286	 reward: -2.57	 makespan: 254.85	 Mean_loss: 0.06321464,  training time: 1.40
progress:  95%|[34m[0m| 285/300 [06:27<00:20,  1.37s/it]progress:  95%|[34m[0m| 286/300 [06:27<00:19,  1.38s/it]                                                           Episode 287	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.04128942,  training time: 1.29
progress:  95%|[34m[0m| 286/300 [06:28<00:19,  1.38s/it]progress:  96%|[34m[0m| 287/300 [06:28<00:17,  1.36s/it]                                                           Episode 288	 reward: -2.61	 makespan: 258.35	 Mean_loss: 0.04819540,  training time: 1.28
progress:  96%|[34m[0m| 287/300 [06:29<00:17,  1.36s/it]progress:  96%|[34m[0m| 288/300 [06:29<00:15,  1.33s/it]                                                           Episode 289	 reward: -2.65	 makespan: 261.95	 Mean_loss: 0.01669517,  training time: 1.31
progress:  96%|[34m[0m| 288/300 [06:31<00:15,  1.33s/it]progress:  96%|[34m[0m| 289/300 [06:31<00:14,  1.33s/it]                                                           Episode 290	 reward: -2.60	 makespan: 257.65	 Mean_loss: 0.03821478,  training time: 1.47
progress:  96%|[34m[0m| 289/300 [06:32<00:14,  1.33s/it]progress:  97%|[34m[0m| 290/300 [06:32<00:13,  1.37s/it]                                                           Episode 291	 reward: -2.55	 makespan: 252.10	 Mean_loss: 0.02562712,  training time: 1.38
progress:  97%|[34m[0m| 290/300 [06:34<00:13,  1.37s/it]progress:  97%|[34m[0m| 291/300 [06:34<00:12,  1.37s/it]                                                           Episode 292	 reward: -2.54	 makespan: 251.20	 Mean_loss: 0.05634262,  training time: 1.37
progress:  97%|[34m[0m| 291/300 [06:35<00:12,  1.37s/it]progress:  97%|[34m[0m| 292/300 [06:35<00:10,  1.37s/it]                                                           Episode 293	 reward: -2.53	 makespan: 250.65	 Mean_loss: 0.02848350,  training time: 1.38
progress:  97%|[34m[0m| 292/300 [06:36<00:10,  1.37s/it]progress:  98%|[34m[0m| 293/300 [06:36<00:09,  1.38s/it]                                                           Episode 294	 reward: -2.52	 makespan: 249.50	 Mean_loss: 0.01589919,  training time: 1.38
progress:  98%|[34m[0m| 293/300 [06:38<00:09,  1.38s/it]progress:  98%|[34m[0m| 294/300 [06:38<00:08,  1.38s/it]                                                           Episode 295	 reward: -2.51	 makespan: 248.45	 Mean_loss: 0.05491237,  training time: 1.38
progress:  98%|[34m[0m| 294/300 [06:39<00:08,  1.38s/it]progress:  98%|[34m[0m| 295/300 [06:39<00:06,  1.38s/it]                                                           Episode 296	 reward: -2.60	 makespan: 257.50	 Mean_loss: 0.03517814,  training time: 1.53
progress:  98%|[34m[0m| 295/300 [06:41<00:06,  1.38s/it]progress:  99%|[34m[0m| 296/300 [06:41<00:05,  1.42s/it]                                                           Episode 297	 reward: -2.74	 makespan: 270.80	 Mean_loss: 0.02636559,  training time: 1.35
progress:  99%|[34m[0m| 296/300 [06:42<00:05,  1.42s/it]progress:  99%|[34m[0m| 297/300 [06:42<00:04,  1.40s/it]                                                           Episode 298	 reward: -2.60	 makespan: 257.75	 Mean_loss: 0.05046508,  training time: 1.35
progress:  99%|[34m[0m| 297/300 [06:43<00:04,  1.40s/it]progress:  99%|[34m[0m| 298/300 [06:43<00:02,  1.39s/it]                                                           Episode 299	 reward: -2.65	 makespan: 262.25	 Mean_loss: 0.01526794,  training time: 1.34
progress:  99%|[34m[0m| 298/300 [06:45<00:02,  1.39s/it]progress: 100%|[34m[0m| 299/300 [06:45<00:01,  1.38s/it]                                                           Episode 300	 reward: -2.65	 makespan: 262.40	 Mean_loss: 0.05679302,  training time: 1.37
progress: 100%|[34m[0m| 299/300 [06:46<00:01,  1.38s/it]progress: 100%|[34m[0m| 300/300 [06:46<00:00,  1.37s/it]progress: 100%|[34m[0m| 300/300 [06:46<00:00,  1.36s/it]
+ n_j=15
+ for model in 15x13+mix+SD2_4
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x13_4 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -2.67	 makespan: 264.00	 Mean_loss: 0.03153924,  training time: 2.44
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:59,  2.45s/it]                                                        Episode 2	 reward: -2.61	 makespan: 258.05	 Mean_loss: 0.03981853,  training time: 1.35
progress:   2%|[34m         [0m| 1/50 [00:03<01:59,  2.45s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:26,  1.81s/it]                                                        Episode 3	 reward: -2.61	 makespan: 257.90	 Mean_loss: 0.04110729,  training time: 1.33
progress:   4%|[34m         [0m| 2/50 [00:05<01:26,  1.81s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:14,  1.59s/it]                                                        Episode 4	 reward: -2.66	 makespan: 263.40	 Mean_loss: 0.04961417,  training time: 1.32
progress:   6%|[34m         [0m| 3/50 [00:06<01:14,  1.59s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:08,  1.49s/it]                                                        Episode 5	 reward: -2.63	 makespan: 260.50	 Mean_loss: 0.04081910,  training time: 1.37
progress:   8%|[34m         [0m| 4/50 [00:07<01:08,  1.49s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:05,  1.45s/it]                                                        Episode 6	 reward: -2.52	 makespan: 249.95	 Mean_loss: 0.03317314,  training time: 1.36
progress:  10%|[34m         [0m| 5/50 [00:09<01:05,  1.45s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:02,  1.42s/it]                                                        Episode 7	 reward: -2.52	 makespan: 249.75	 Mean_loss: 0.04154974,  training time: 1.36
progress:  12%|[34m        [0m| 6/50 [00:10<01:02,  1.42s/it]progress:  14%|[34m        [0m| 7/50 [00:10<01:00,  1.40s/it]                                                        Episode 8	 reward: -2.56	 makespan: 253.25	 Mean_loss: 0.03501503,  training time: 1.35
progress:  14%|[34m        [0m| 7/50 [00:11<01:00,  1.40s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:58,  1.39s/it]                                                        Episode 9	 reward: -2.54	 makespan: 251.80	 Mean_loss: 0.03146898,  training time: 1.40
progress:  16%|[34m        [0m| 8/50 [00:13<00:58,  1.39s/it]progress:  18%|[34m        [0m| 9/50 [00:13<00:57,  1.39s/it]                                                        Episode 10	 reward: -2.58	 makespan: 255.25	 Mean_loss: 0.03117234,  training time: 1.37
progress:  18%|[34m        [0m| 9/50 [00:14<00:57,  1.39s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:55,  1.39s/it]                                                         Episode 11	 reward: -2.57	 makespan: 254.85	 Mean_loss: 0.03095749,  training time: 1.42
progress:  20%|[34m        [0m| 10/50 [00:16<00:55,  1.39s/it]progress:  22%|[34m       [0m| 11/50 [00:16<00:54,  1.40s/it]                                                         Episode 12	 reward: -2.59	 makespan: 256.60	 Mean_loss: 0.03371520,  training time: 1.49
progress:  22%|[34m       [0m| 11/50 [00:17<00:54,  1.40s/it]progress:  24%|[34m       [0m| 12/50 [00:17<00:54,  1.43s/it]                                                         Episode 13	 reward: -2.59	 makespan: 256.15	 Mean_loss: 0.03746944,  training time: 1.30
progress:  24%|[34m       [0m| 12/50 [00:18<00:54,  1.43s/it]progress:  26%|[34m       [0m| 13/50 [00:18<00:51,  1.39s/it]                                                         Episode 14	 reward: -2.61	 makespan: 258.65	 Mean_loss: 0.04838240,  training time: 1.30
progress:  26%|[34m       [0m| 13/50 [00:20<00:51,  1.39s/it]progress:  28%|[34m       [0m| 14/50 [00:20<00:49,  1.37s/it]                                                         Episode 15	 reward: -2.53	 makespan: 250.80	 Mean_loss: 0.01609692,  training time: 1.46
progress:  28%|[34m       [0m| 14/50 [00:21<00:49,  1.37s/it]progress:  30%|[34m       [0m| 15/50 [00:21<00:48,  1.40s/it]                                                         Episode 16	 reward: -2.53	 makespan: 250.25	 Mean_loss: 0.03168748,  training time: 1.30
progress:  30%|[34m       [0m| 15/50 [00:23<00:48,  1.40s/it]progress:  32%|[34m      [0m| 16/50 [00:23<00:46,  1.37s/it]                                                         Episode 17	 reward: -2.59	 makespan: 256.05	 Mean_loss: 0.04036080,  training time: 1.28
progress:  32%|[34m      [0m| 16/50 [00:24<00:46,  1.37s/it]progress:  34%|[34m      [0m| 17/50 [00:24<00:44,  1.34s/it]                                                         Episode 18	 reward: -2.63	 makespan: 260.80	 Mean_loss: 0.03118263,  training time: 1.30
progress:  34%|[34m      [0m| 17/50 [00:25<00:44,  1.34s/it]progress:  36%|[34m      [0m| 18/50 [00:25<00:42,  1.33s/it]                                                         Episode 19	 reward: -2.49	 makespan: 246.95	 Mean_loss: 0.03448132,  training time: 1.33
progress:  36%|[34m      [0m| 18/50 [00:26<00:42,  1.33s/it]progress:  38%|[34m      [0m| 19/50 [00:26<00:41,  1.34s/it]                                                         Episode 20	 reward: -2.58	 makespan: 255.80	 Mean_loss: 0.06572405,  training time: 1.34
progress:  38%|[34m      [0m| 19/50 [00:28<00:41,  1.34s/it]progress:  40%|[34m      [0m| 20/50 [00:28<00:40,  1.34s/it]                                                         Episode 21	 reward: -2.45	 makespan: 242.30	 Mean_loss: 0.03692738,  training time: 1.34
progress:  40%|[34m      [0m| 20/50 [00:29<00:40,  1.34s/it]progress:  42%|[34m     [0m| 21/50 [00:29<00:38,  1.34s/it]                                                         Episode 22	 reward: -2.38	 makespan: 236.00	 Mean_loss: 0.01209460,  training time: 1.49
progress:  42%|[34m     [0m| 21/50 [00:31<00:38,  1.34s/it]progress:  44%|[34m     [0m| 22/50 [00:31<00:38,  1.39s/it]                                                         Episode 23	 reward: -2.66	 makespan: 263.50	 Mean_loss: 0.06309956,  training time: 1.37
progress:  44%|[34m     [0m| 22/50 [00:32<00:38,  1.39s/it]progress:  46%|[34m     [0m| 23/50 [00:32<00:37,  1.38s/it]                                                         Episode 24	 reward: -2.43	 makespan: 240.60	 Mean_loss: 0.00140163,  training time: 1.33
progress:  46%|[34m     [0m| 23/50 [00:33<00:37,  1.38s/it]progress:  48%|[34m     [0m| 24/50 [00:33<00:35,  1.37s/it]                                                         Episode 25	 reward: -2.51	 makespan: 248.80	 Mean_loss: 0.02787788,  training time: 1.38
progress:  48%|[34m     [0m| 24/50 [00:35<00:35,  1.37s/it]progress:  50%|[34m     [0m| 25/50 [00:35<00:34,  1.37s/it]                                                         Episode 26	 reward: -2.69	 makespan: 265.90	 Mean_loss: 0.06038651,  training time: 1.33
progress:  50%|[34m     [0m| 25/50 [00:36<00:34,  1.37s/it]progress:  52%|[34m    [0m| 26/50 [00:36<00:32,  1.36s/it]                                                         Episode 27	 reward: -2.69	 makespan: 265.95	 Mean_loss: 0.02574277,  training time: 1.34
progress:  52%|[34m    [0m| 26/50 [00:37<00:32,  1.36s/it]progress:  54%|[34m    [0m| 27/50 [00:37<00:31,  1.36s/it]                                                         Episode 28	 reward: -2.56	 makespan: 253.35	 Mean_loss: 0.02011560,  training time: 1.39
progress:  54%|[34m    [0m| 27/50 [00:39<00:31,  1.36s/it]progress:  56%|[34m    [0m| 28/50 [00:39<00:30,  1.37s/it]                                                         Episode 29	 reward: -2.52	 makespan: 249.95	 Mean_loss: 0.02896534,  training time: 1.36
progress:  56%|[34m    [0m| 28/50 [00:40<00:30,  1.37s/it]progress:  58%|[34m    [0m| 29/50 [00:40<00:28,  1.37s/it]                                                         Episode 30	 reward: -2.60	 makespan: 257.05	 Mean_loss: 0.02773089,  training time: 1.35
progress:  58%|[34m    [0m| 29/50 [00:42<00:28,  1.37s/it]progress:  60%|[34m    [0m| 30/50 [00:42<00:27,  1.36s/it]                                                         Episode 31	 reward: -2.57	 makespan: 254.10	 Mean_loss: 0.01333402,  training time: 1.35
progress:  60%|[34m    [0m| 30/50 [00:43<00:27,  1.36s/it]progress:  62%|[34m   [0m| 31/50 [00:43<00:25,  1.36s/it]                                                         Episode 32	 reward: -2.51	 makespan: 248.60	 Mean_loss: 0.02089940,  training time: 1.35
progress:  62%|[34m   [0m| 31/50 [00:44<00:25,  1.36s/it]progress:  64%|[34m   [0m| 32/50 [00:44<00:24,  1.36s/it]                                                         Episode 33	 reward: -2.48	 makespan: 245.55	 Mean_loss: 0.04180712,  training time: 1.36
progress:  64%|[34m   [0m| 32/50 [00:46<00:24,  1.36s/it]progress:  66%|[34m   [0m| 33/50 [00:46<00:23,  1.36s/it]                                                         Episode 34	 reward: -2.60	 makespan: 257.40	 Mean_loss: 0.03446245,  training time: 1.34
progress:  66%|[34m   [0m| 33/50 [00:47<00:23,  1.36s/it]progress:  68%|[34m   [0m| 34/50 [00:47<00:21,  1.35s/it]                                                         Episode 35	 reward: -2.58	 makespan: 255.10	 Mean_loss: 0.02260996,  training time: 1.34
progress:  68%|[34m   [0m| 34/50 [00:48<00:21,  1.35s/it]progress:  70%|[34m   [0m| 35/50 [00:48<00:20,  1.35s/it]                                                         Episode 36	 reward: -2.62	 makespan: 259.25	 Mean_loss: 0.04821434,  training time: 1.36
progress:  70%|[34m   [0m| 35/50 [00:50<00:20,  1.35s/it]progress:  72%|[34m  [0m| 36/50 [00:50<00:18,  1.35s/it]                                                         Episode 37	 reward: -2.41	 makespan: 238.80	 Mean_loss: 0.01055714,  training time: 1.33
progress:  72%|[34m  [0m| 36/50 [00:51<00:18,  1.35s/it]progress:  74%|[34m  [0m| 37/50 [00:51<00:17,  1.35s/it]                                                         Episode 38	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.03705335,  training time: 1.34
progress:  74%|[34m  [0m| 37/50 [00:52<00:17,  1.35s/it]progress:  76%|[34m  [0m| 38/50 [00:52<00:16,  1.35s/it]                                                         Episode 39	 reward: -2.57	 makespan: 254.00	 Mean_loss: 0.06027677,  training time: 1.35
progress:  76%|[34m  [0m| 38/50 [00:54<00:16,  1.35s/it]progress:  78%|[34m  [0m| 39/50 [00:54<00:14,  1.35s/it]                                                         Episode 40	 reward: -2.49	 makespan: 246.40	 Mean_loss: 0.01494318,  training time: 1.34
progress:  78%|[34m  [0m| 39/50 [00:55<00:14,  1.35s/it]progress:  80%|[34m  [0m| 40/50 [00:55<00:13,  1.35s/it]                                                         Episode 41	 reward: -2.48	 makespan: 245.30	 Mean_loss: 0.02065505,  training time: 1.34
progress:  80%|[34m  [0m| 40/50 [00:56<00:13,  1.35s/it]progress:  82%|[34m [0m| 41/50 [00:56<00:12,  1.35s/it]                                                         Episode 42	 reward: -2.65	 makespan: 262.00	 Mean_loss: 0.03636049,  training time: 1.31
progress:  82%|[34m [0m| 41/50 [00:58<00:12,  1.35s/it]progress:  84%|[34m [0m| 42/50 [00:58<00:10,  1.34s/it]                                                         Episode 43	 reward: -2.65	 makespan: 262.20	 Mean_loss: 0.06285596,  training time: 1.35
progress:  84%|[34m [0m| 42/50 [00:59<00:10,  1.34s/it]progress:  86%|[34m [0m| 43/50 [00:59<00:09,  1.34s/it]                                                         Episode 44	 reward: -2.47	 makespan: 244.15	 Mean_loss: 0.02811870,  training time: 1.36
progress:  86%|[34m [0m| 43/50 [01:00<00:09,  1.34s/it]progress:  88%|[34m [0m| 44/50 [01:00<00:08,  1.35s/it]                                                         Episode 45	 reward: -2.49	 makespan: 247.00	 Mean_loss: 0.04831278,  training time: 1.36
progress:  88%|[34m [0m| 44/50 [01:02<00:08,  1.35s/it]progress:  90%|[34m [0m| 45/50 [01:02<00:06,  1.35s/it]                                                         Episode 46	 reward: -2.57	 makespan: 254.10	 Mean_loss: 0.03336567,  training time: 1.34
progress:  90%|[34m [0m| 45/50 [01:03<00:06,  1.35s/it]progress:  92%|[34m[0m| 46/50 [01:03<00:05,  1.35s/it]                                                         Episode 47	 reward: -2.56	 makespan: 253.30	 Mean_loss: 0.03561586,  training time: 1.36
progress:  92%|[34m[0m| 46/50 [01:04<00:05,  1.35s/it]progress:  94%|[34m[0m| 47/50 [01:04<00:04,  1.35s/it]                                                         Episode 48	 reward: -2.46	 makespan: 243.80	 Mean_loss: 0.03780545,  training time: 1.33
progress:  94%|[34m[0m| 47/50 [01:06<00:04,  1.35s/it]progress:  96%|[34m[0m| 48/50 [01:06<00:02,  1.35s/it]                                                         Episode 49	 reward: -2.54	 makespan: 251.85	 Mean_loss: 0.03756369,  training time: 1.39
progress:  96%|[34m[0m| 48/50 [01:07<00:02,  1.35s/it]progress:  98%|[34m[0m| 49/50 [01:07<00:01,  1.36s/it]                                                         Episode 50	 reward: -2.53	 makespan: 250.35	 Mean_loss: 0.03650843,  training time: 1.42
progress:  98%|[34m[0m| 49/50 [01:09<00:01,  1.36s/it]progress: 100%|[34m[0m| 50/50 [01:09<00:00,  1.38s/it]progress: 100%|[34m[0m| 50/50 [01:09<00:00,  1.38s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x13_7 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.39	 makespan: 434.80	 Mean_loss: -0.65364808,  training time: 3.56
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:54,  3.57s/it]                                                        Episode 2	 reward: -4.29	 makespan: 424.90	 Mean_loss: -0.54758000,  training time: 2.40
progress:   2%|[34m         [0m| 1/50 [00:05<02:54,  3.57s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:18,  2.88s/it]                                                        Episode 3	 reward: -4.38	 makespan: 433.70	 Mean_loss: -0.57920015,  training time: 2.46
progress:   4%|[34m         [0m| 2/50 [00:08<02:18,  2.88s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:06,  2.69s/it]                                                        Episode 4	 reward: -4.35	 makespan: 430.70	 Mean_loss: -0.57875872,  training time: 2.47
progress:   6%|[34m         [0m| 3/50 [00:10<02:06,  2.69s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:59,  2.61s/it]                                                        Episode 5	 reward: -4.29	 makespan: 425.20	 Mean_loss: -0.67231756,  training time: 2.38
progress:   8%|[34m         [0m| 4/50 [00:13<01:59,  2.61s/it]progress:  10%|[34m         [0m| 5/50 [00:13<01:53,  2.53s/it]                                                        Episode 6	 reward: -4.29	 makespan: 424.55	 Mean_loss: -0.02968905,  training time: 2.42
progress:  10%|[34m         [0m| 5/50 [00:15<01:53,  2.53s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:49,  2.49s/it]                                                        Episode 7	 reward: -4.46	 makespan: 441.75	 Mean_loss: -0.11030975,  training time: 2.36
progress:  12%|[34m        [0m| 6/50 [00:18<01:49,  2.49s/it]progress:  14%|[34m        [0m| 7/50 [00:18<01:45,  2.45s/it]                                                        Episode 8	 reward: -4.28	 makespan: 423.35	 Mean_loss: -0.40193003,  training time: 2.38
progress:  14%|[34m        [0m| 7/50 [00:20<01:45,  2.45s/it]progress:  16%|[34m        [0m| 8/50 [00:20<01:42,  2.43s/it]                                                        Episode 9	 reward: -4.36	 makespan: 431.65	 Mean_loss: -0.62139845,  training time: 2.39
progress:  16%|[34m        [0m| 8/50 [00:22<01:42,  2.43s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:39,  2.42s/it]                                                        Episode 10	 reward: -4.31	 makespan: 426.50	 Mean_loss: -0.07881693,  training time: 2.52
progress:  18%|[34m        [0m| 9/50 [00:25<01:39,  2.42s/it]progress:  20%|[34m        [0m| 10/50 [00:25<01:38,  2.45s/it]                                                         Episode 11	 reward: -4.42	 makespan: 437.40	 Mean_loss: -0.62171096,  training time: 2.39
progress:  20%|[34m        [0m| 10/50 [00:27<01:38,  2.45s/it]progress:  22%|[34m       [0m| 11/50 [00:27<01:34,  2.43s/it]                                                         Episode 12	 reward: -4.37	 makespan: 433.00	 Mean_loss: -0.04239592,  training time: 2.51
progress:  22%|[34m       [0m| 11/50 [00:30<01:34,  2.43s/it]progress:  24%|[34m       [0m| 12/50 [00:30<01:33,  2.46s/it]                                                         Episode 13	 reward: -4.35	 makespan: 430.25	 Mean_loss: -0.31286198,  training time: 2.58
progress:  24%|[34m       [0m| 12/50 [00:32<01:33,  2.46s/it]progress:  26%|[34m       [0m| 13/50 [00:32<01:32,  2.50s/it]                                                         Episode 14	 reward: -4.35	 makespan: 430.50	 Mean_loss: -0.21311802,  training time: 2.36
progress:  26%|[34m       [0m| 13/50 [00:35<01:32,  2.50s/it]progress:  28%|[34m       [0m| 14/50 [00:35<01:28,  2.46s/it]                                                         Episode 15	 reward: -4.42	 makespan: 437.60	 Mean_loss: -0.41920912,  training time: 2.39
progress:  28%|[34m       [0m| 14/50 [00:37<01:28,  2.46s/it]progress:  30%|[34m       [0m| 15/50 [00:37<01:25,  2.44s/it]                                                         Episode 16	 reward: -4.37	 makespan: 432.40	 Mean_loss: -0.06160126,  training time: 2.46
progress:  30%|[34m       [0m| 15/50 [00:40<01:25,  2.44s/it]progress:  32%|[34m      [0m| 16/50 [00:40<01:23,  2.45s/it]                                                         Episode 17	 reward: -4.22	 makespan: 417.70	 Mean_loss: 0.02564420,  training time: 2.41
progress:  32%|[34m      [0m| 16/50 [00:42<01:23,  2.45s/it]progress:  34%|[34m      [0m| 17/50 [00:42<01:20,  2.44s/it]                                                         Episode 18	 reward: -4.25	 makespan: 421.10	 Mean_loss: -0.28399307,  training time: 2.38
progress:  34%|[34m      [0m| 17/50 [00:44<01:20,  2.44s/it]progress:  36%|[34m      [0m| 18/50 [00:44<01:17,  2.42s/it]                                                         Episode 19	 reward: -4.35	 makespan: 430.45	 Mean_loss: -0.21772270,  training time: 2.37
progress:  36%|[34m      [0m| 18/50 [00:47<01:17,  2.42s/it]progress:  38%|[34m      [0m| 19/50 [00:47<01:14,  2.41s/it]                                                         Episode 20	 reward: -4.34	 makespan: 429.65	 Mean_loss: -0.37993830,  training time: 2.43
progress:  38%|[34m      [0m| 19/50 [00:49<01:14,  2.41s/it]progress:  40%|[34m      [0m| 20/50 [00:49<01:12,  2.42s/it]                                                         Episode 21	 reward: -4.28	 makespan: 423.50	 Mean_loss: -0.50567162,  training time: 2.36
progress:  40%|[34m      [0m| 20/50 [00:52<01:12,  2.42s/it]progress:  42%|[34m     [0m| 21/50 [00:52<01:09,  2.40s/it]                                                         Episode 22	 reward: -4.26	 makespan: 422.15	 Mean_loss: -0.44442892,  training time: 2.35
progress:  42%|[34m     [0m| 21/50 [00:54<01:09,  2.40s/it]progress:  44%|[34m     [0m| 22/50 [00:54<01:06,  2.39s/it]                                                         Episode 23	 reward: -4.33	 makespan: 429.00	 Mean_loss: -0.03885183,  training time: 2.36
progress:  44%|[34m     [0m| 22/50 [00:56<01:06,  2.39s/it]progress:  46%|[34m     [0m| 23/50 [00:56<01:04,  2.38s/it]                                                         Episode 24	 reward: -4.25	 makespan: 421.05	 Mean_loss: -0.55405545,  training time: 2.37
progress:  46%|[34m     [0m| 23/50 [00:59<01:04,  2.38s/it]progress:  48%|[34m     [0m| 24/50 [00:59<01:01,  2.38s/it]                                                         Episode 25	 reward: -4.38	 makespan: 433.55	 Mean_loss: -0.55250013,  training time: 2.36
progress:  48%|[34m     [0m| 24/50 [01:01<01:01,  2.38s/it]progress:  50%|[34m     [0m| 25/50 [01:01<00:59,  2.37s/it]                                                         Episode 26	 reward: -4.31	 makespan: 427.10	 Mean_loss: -0.48347247,  training time: 2.43
progress:  50%|[34m     [0m| 25/50 [01:03<00:59,  2.37s/it]progress:  52%|[34m    [0m| 26/50 [01:03<00:57,  2.39s/it]                                                         Episode 27	 reward: -4.36	 makespan: 432.05	 Mean_loss: 0.38044733,  training time: 2.40
progress:  52%|[34m    [0m| 26/50 [01:06<00:57,  2.39s/it]progress:  54%|[34m    [0m| 27/50 [01:06<00:55,  2.40s/it]                                                         Episode 28	 reward: -4.33	 makespan: 428.20	 Mean_loss: -0.22486103,  training time: 2.45
progress:  54%|[34m    [0m| 27/50 [01:08<00:55,  2.40s/it]progress:  56%|[34m    [0m| 28/50 [01:08<00:53,  2.41s/it]                                                         Episode 29	 reward: -4.37	 makespan: 432.20	 Mean_loss: -0.72494030,  training time: 2.42
progress:  56%|[34m    [0m| 28/50 [01:11<00:53,  2.41s/it]progress:  58%|[34m    [0m| 29/50 [01:11<00:50,  2.42s/it]                                                         Episode 30	 reward: -4.37	 makespan: 432.35	 Mean_loss: -0.55482143,  training time: 2.49
progress:  58%|[34m    [0m| 29/50 [01:13<00:50,  2.42s/it]progress:  60%|[34m    [0m| 30/50 [01:13<00:48,  2.44s/it]                                                         Episode 31	 reward: -4.23	 makespan: 419.05	 Mean_loss: -0.58372247,  training time: 2.40
progress:  60%|[34m    [0m| 30/50 [01:16<00:48,  2.44s/it]progress:  62%|[34m   [0m| 31/50 [01:16<00:46,  2.43s/it]                                                         Episode 32	 reward: -4.23	 makespan: 418.35	 Mean_loss: -0.36963519,  training time: 2.40
progress:  62%|[34m   [0m| 31/50 [01:18<00:46,  2.43s/it]progress:  64%|[34m   [0m| 32/50 [01:18<00:43,  2.42s/it]                                                         Episode 33	 reward: -4.24	 makespan: 419.75	 Mean_loss: -0.08971065,  training time: 2.38
progress:  64%|[34m   [0m| 32/50 [01:20<00:43,  2.42s/it]progress:  66%|[34m   [0m| 33/50 [01:20<00:41,  2.41s/it]                                                         Episode 34	 reward: -4.37	 makespan: 432.90	 Mean_loss: -0.25739184,  training time: 2.40
progress:  66%|[34m   [0m| 33/50 [01:23<00:41,  2.41s/it]progress:  68%|[34m   [0m| 34/50 [01:23<00:38,  2.41s/it]                                                         Episode 35	 reward: -4.30	 makespan: 425.65	 Mean_loss: -0.38174522,  training time: 2.36
progress:  68%|[34m   [0m| 34/50 [01:25<00:38,  2.41s/it]progress:  70%|[34m   [0m| 35/50 [01:25<00:35,  2.40s/it]                                                         Episode 36	 reward: -4.20	 makespan: 415.45	 Mean_loss: -0.39667809,  training time: 2.36
progress:  70%|[34m   [0m| 35/50 [01:28<00:35,  2.40s/it]progress:  72%|[34m  [0m| 36/50 [01:28<00:33,  2.39s/it]                                                         Episode 37	 reward: -4.32	 makespan: 427.25	 Mean_loss: -0.54374075,  training time: 2.39
progress:  72%|[34m  [0m| 36/50 [01:30<00:33,  2.39s/it]progress:  74%|[34m  [0m| 37/50 [01:30<00:31,  2.39s/it]                                                         Episode 38	 reward: -4.34	 makespan: 429.45	 Mean_loss: 0.26741904,  training time: 2.39
progress:  74%|[34m  [0m| 37/50 [01:32<00:31,  2.39s/it]progress:  76%|[34m  [0m| 38/50 [01:32<00:28,  2.39s/it]                                                         Episode 39	 reward: -4.43	 makespan: 438.20	 Mean_loss: 0.07315886,  training time: 2.36
progress:  76%|[34m  [0m| 38/50 [01:35<00:28,  2.39s/it]progress:  78%|[34m  [0m| 39/50 [01:35<00:26,  2.38s/it]                                                         Episode 40	 reward: -4.33	 makespan: 428.60	 Mean_loss: -0.52943057,  training time: 2.36
progress:  78%|[34m  [0m| 39/50 [01:37<00:26,  2.38s/it]progress:  80%|[34m  [0m| 40/50 [01:37<00:23,  2.38s/it]                                                         Episode 41	 reward: -4.16	 makespan: 411.60	 Mean_loss: -0.64649904,  training time: 2.44
progress:  80%|[34m  [0m| 40/50 [01:40<00:23,  2.38s/it]progress:  82%|[34m [0m| 41/50 [01:40<00:21,  2.40s/it]                                                         Episode 42	 reward: -4.26	 makespan: 421.65	 Mean_loss: -0.06047466,  training time: 2.42
progress:  82%|[34m [0m| 41/50 [01:42<00:21,  2.40s/it]progress:  84%|[34m [0m| 42/50 [01:42<00:19,  2.41s/it]                                                         Episode 43	 reward: -4.35	 makespan: 430.25	 Mean_loss: -0.02042869,  training time: 2.50
progress:  84%|[34m [0m| 42/50 [01:45<00:19,  2.41s/it]progress:  86%|[34m [0m| 43/50 [01:45<00:17,  2.44s/it]                                                         Episode 44	 reward: -4.26	 makespan: 421.45	 Mean_loss: 0.15930939,  training time: 2.54
progress:  86%|[34m [0m| 43/50 [01:47<00:17,  2.44s/it]progress:  88%|[34m [0m| 44/50 [01:47<00:14,  2.47s/it]                                                         Episode 45	 reward: -4.33	 makespan: 428.25	 Mean_loss: -0.19976270,  training time: 2.51
progress:  88%|[34m [0m| 44/50 [01:50<00:14,  2.47s/it]progress:  90%|[34m [0m| 45/50 [01:50<00:12,  2.48s/it]                                                         Episode 46	 reward: -4.35	 makespan: 430.55	 Mean_loss: -0.26794606,  training time: 2.50
progress:  90%|[34m [0m| 45/50 [01:52<00:12,  2.48s/it]progress:  92%|[34m[0m| 46/50 [01:52<00:09,  2.49s/it]                                                         Episode 47	 reward: -4.31	 makespan: 426.50	 Mean_loss: -0.14605518,  training time: 2.38
progress:  92%|[34m[0m| 46/50 [01:54<00:09,  2.49s/it]progress:  94%|[34m[0m| 47/50 [01:54<00:07,  2.46s/it]                                                         Episode 48	 reward: -4.40	 makespan: 435.35	 Mean_loss: -0.44656378,  training time: 2.37
progress:  94%|[34m[0m| 47/50 [01:57<00:07,  2.46s/it]progress:  96%|[34m[0m| 48/50 [01:57<00:04,  2.43s/it]                                                         Episode 49	 reward: -4.30	 makespan: 425.90	 Mean_loss: -0.44451845,  training time: 2.35
progress:  96%|[34m[0m| 48/50 [01:59<00:04,  2.43s/it]progress:  98%|[34m[0m| 49/50 [01:59<00:02,  2.41s/it]                                                         Episode 50	 reward: -4.19	 makespan: 414.75	 Mean_loss: 0.26651937,  training time: 2.37
progress:  98%|[34m[0m| 49/50 [02:02<00:02,  2.41s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.40s/it]progress: 100%|[34m[0m| 50/50 [02:02<00:00,  2.44s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x13_10 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.06	 makespan: 599.75	 Mean_loss: 0.30254611,  training time: 4.58
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:44,  4.59s/it]                                                        Episode 2	 reward: -6.04	 makespan: 598.20	 Mean_loss: 0.37724647,  training time: 3.36
progress:   2%|[34m         [0m| 1/50 [00:07<03:44,  4.59s/it]progress:   4%|[34m         [0m| 2/50 [00:07<03:05,  3.87s/it]                                                        Episode 3	 reward: -5.94	 makespan: 588.10	 Mean_loss: 0.39157680,  training time: 3.34
progress:   4%|[34m         [0m| 2/50 [00:11<03:05,  3.87s/it]progress:   6%|[34m         [0m| 3/50 [00:11<02:50,  3.63s/it]                                                        Episode 4	 reward: -5.95	 makespan: 589.05	 Mean_loss: 0.41357598,  training time: 3.54
progress:   6%|[34m         [0m| 3/50 [00:14<02:50,  3.63s/it]progress:   8%|[34m         [0m| 4/50 [00:14<02:45,  3.60s/it]                                                        Episode 5	 reward: -5.95	 makespan: 588.60	 Mean_loss: 0.32267910,  training time: 3.44
progress:   8%|[34m         [0m| 4/50 [00:18<02:45,  3.60s/it]progress:  10%|[34m         [0m| 5/50 [00:18<02:39,  3.54s/it]                                                        Episode 6	 reward: -6.05	 makespan: 599.35	 Mean_loss: 0.33578327,  training time: 3.65
progress:  10%|[34m         [0m| 5/50 [00:21<02:39,  3.54s/it]progress:  12%|[34m        [0m| 6/50 [00:21<02:37,  3.58s/it]                                                        Episode 7	 reward: -6.06	 makespan: 599.55	 Mean_loss: 0.26493225,  training time: 3.46
progress:  12%|[34m        [0m| 6/50 [00:25<02:37,  3.58s/it]progress:  14%|[34m        [0m| 7/50 [00:25<02:32,  3.54s/it]                                                        Episode 8	 reward: -5.89	 makespan: 582.90	 Mean_loss: 0.31225660,  training time: 3.39
progress:  14%|[34m        [0m| 7/50 [00:28<02:32,  3.54s/it]progress:  16%|[34m        [0m| 8/50 [00:28<02:26,  3.49s/it]                                                        Episode 9	 reward: -6.05	 makespan: 598.80	 Mean_loss: 0.26353642,  training time: 3.37
progress:  16%|[34m        [0m| 8/50 [00:32<02:26,  3.49s/it]progress:  18%|[34m        [0m| 9/50 [00:32<02:21,  3.46s/it]                                                        Episode 10	 reward: -5.99	 makespan: 593.05	 Mean_loss: 0.21825379,  training time: 3.34
progress:  18%|[34m        [0m| 9/50 [00:35<02:21,  3.46s/it]progress:  20%|[34m        [0m| 10/50 [00:35<02:16,  3.42s/it]                                                         Episode 11	 reward: -6.11	 makespan: 605.15	 Mean_loss: 0.22921874,  training time: 3.34
progress:  20%|[34m        [0m| 10/50 [00:38<02:16,  3.42s/it]progress:  22%|[34m       [0m| 11/50 [00:38<02:12,  3.40s/it]                                                         Episode 12	 reward: -5.91	 makespan: 585.30	 Mean_loss: 0.18166856,  training time: 3.34
progress:  22%|[34m       [0m| 11/50 [00:42<02:12,  3.40s/it]progress:  24%|[34m       [0m| 12/50 [00:42<02:08,  3.38s/it]                                                         Episode 13	 reward: -5.97	 makespan: 590.55	 Mean_loss: 0.15325430,  training time: 3.35
progress:  24%|[34m       [0m| 12/50 [00:45<02:08,  3.38s/it]progress:  26%|[34m       [0m| 13/50 [00:45<02:04,  3.37s/it]                                                         Episode 14	 reward: -6.02	 makespan: 595.80	 Mean_loss: 0.17013571,  training time: 3.36
progress:  26%|[34m       [0m| 13/50 [00:48<02:04,  3.37s/it]progress:  28%|[34m       [0m| 14/50 [00:48<02:01,  3.37s/it]                                                         Episode 15	 reward: -5.88	 makespan: 582.25	 Mean_loss: 0.13764580,  training time: 3.34
progress:  28%|[34m       [0m| 14/50 [00:52<02:01,  3.37s/it]progress:  30%|[34m       [0m| 15/50 [00:52<01:57,  3.36s/it]                                                         Episode 16	 reward: -5.80	 makespan: 574.10	 Mean_loss: 0.14600915,  training time: 3.44
progress:  30%|[34m       [0m| 15/50 [00:55<01:57,  3.36s/it]progress:  32%|[34m      [0m| 16/50 [00:55<01:55,  3.39s/it]                                                         Episode 17	 reward: -5.89	 makespan: 583.45	 Mean_loss: 0.14557081,  training time: 3.39
progress:  32%|[34m      [0m| 16/50 [00:59<01:55,  3.39s/it]progress:  34%|[34m      [0m| 17/50 [00:59<01:51,  3.39s/it]                                                         Episode 18	 reward: -5.88	 makespan: 581.75	 Mean_loss: 0.15344854,  training time: 3.35
progress:  34%|[34m      [0m| 17/50 [01:02<01:51,  3.39s/it]progress:  36%|[34m      [0m| 18/50 [01:02<01:48,  3.38s/it]                                                         Episode 19	 reward: -5.90	 makespan: 584.30	 Mean_loss: 0.12705290,  training time: 3.34
progress:  36%|[34m      [0m| 18/50 [01:05<01:48,  3.38s/it]progress:  38%|[34m      [0m| 19/50 [01:05<01:44,  3.37s/it]                                                         Episode 20	 reward: -6.00	 makespan: 593.90	 Mean_loss: 0.11352454,  training time: 3.34
progress:  38%|[34m      [0m| 19/50 [01:09<01:44,  3.37s/it]progress:  40%|[34m      [0m| 20/50 [01:09<01:40,  3.36s/it]                                                         Episode 21	 reward: -6.03	 makespan: 597.20	 Mean_loss: 0.14217478,  training time: 3.34
progress:  40%|[34m      [0m| 20/50 [01:12<01:40,  3.36s/it]progress:  42%|[34m     [0m| 21/50 [01:12<01:37,  3.36s/it]                                                         Episode 22	 reward: -5.85	 makespan: 579.50	 Mean_loss: 0.13637610,  training time: 3.34
progress:  42%|[34m     [0m| 21/50 [01:15<01:37,  3.36s/it]progress:  44%|[34m     [0m| 22/50 [01:15<01:33,  3.35s/it]                                                         Episode 23	 reward: -5.90	 makespan: 584.05	 Mean_loss: 0.13129833,  training time: 3.34
progress:  44%|[34m     [0m| 22/50 [01:19<01:33,  3.35s/it]progress:  46%|[34m     [0m| 23/50 [01:19<01:30,  3.35s/it]                                                         Episode 24	 reward: -5.93	 makespan: 587.15	 Mean_loss: 0.12275575,  training time: 3.33
progress:  46%|[34m     [0m| 23/50 [01:22<01:30,  3.35s/it]progress:  48%|[34m     [0m| 24/50 [01:22<01:27,  3.35s/it]                                                         Episode 25	 reward: -5.88	 makespan: 582.60	 Mean_loss: 0.11641043,  training time: 3.35
progress:  48%|[34m     [0m| 24/50 [01:25<01:27,  3.35s/it]progress:  50%|[34m     [0m| 25/50 [01:25<01:23,  3.35s/it]                                                         Episode 26	 reward: -6.02	 makespan: 595.85	 Mean_loss: 0.12519827,  training time: 3.39
progress:  50%|[34m     [0m| 25/50 [01:29<01:23,  3.35s/it]progress:  52%|[34m    [0m| 26/50 [01:29<01:20,  3.36s/it]                                                         Episode 27	 reward: -5.94	 makespan: 588.45	 Mean_loss: 0.14008692,  training time: 3.36
progress:  52%|[34m    [0m| 26/50 [01:32<01:20,  3.36s/it]progress:  54%|[34m    [0m| 27/50 [01:32<01:17,  3.36s/it]                                                         Episode 28	 reward: -5.81	 makespan: 575.00	 Mean_loss: 0.13713458,  training time: 3.45
progress:  54%|[34m    [0m| 27/50 [01:36<01:17,  3.36s/it]progress:  56%|[34m    [0m| 28/50 [01:36<01:14,  3.39s/it]                                                         Episode 29	 reward: -5.97	 makespan: 590.85	 Mean_loss: 0.09783284,  training time: 3.53
progress:  56%|[34m    [0m| 28/50 [01:39<01:14,  3.39s/it]progress:  58%|[34m    [0m| 29/50 [01:39<01:12,  3.43s/it]                                                         Episode 30	 reward: -6.12	 makespan: 605.90	 Mean_loss: 0.11866169,  training time: 3.37
progress:  58%|[34m    [0m| 29/50 [01:42<01:12,  3.43s/it]progress:  60%|[34m    [0m| 30/50 [01:42<01:08,  3.41s/it]                                                         Episode 31	 reward: -5.93	 makespan: 587.10	 Mean_loss: 0.13105422,  training time: 3.31
progress:  60%|[34m    [0m| 30/50 [01:46<01:08,  3.41s/it]progress:  62%|[34m   [0m| 31/50 [01:46<01:04,  3.39s/it]                                                         Episode 32	 reward: -5.95	 makespan: 588.85	 Mean_loss: 0.10759337,  training time: 3.32
progress:  62%|[34m   [0m| 31/50 [01:49<01:04,  3.39s/it]progress:  64%|[34m   [0m| 32/50 [01:49<01:00,  3.37s/it]                                                         Episode 33	 reward: -6.08	 makespan: 601.90	 Mean_loss: 0.12891909,  training time: 3.31
progress:  64%|[34m   [0m| 32/50 [01:52<01:00,  3.37s/it]progress:  66%|[34m   [0m| 33/50 [01:52<00:56,  3.35s/it]                                                         Episode 34	 reward: -5.85	 makespan: 579.40	 Mean_loss: 0.12159491,  training time: 3.38
progress:  66%|[34m   [0m| 33/50 [01:56<00:56,  3.35s/it]progress:  68%|[34m   [0m| 34/50 [01:56<00:53,  3.36s/it]                                                         Episode 35	 reward: -6.12	 makespan: 605.45	 Mean_loss: 0.11225037,  training time: 3.35
progress:  68%|[34m   [0m| 34/50 [01:59<00:53,  3.36s/it]progress:  70%|[34m   [0m| 35/50 [01:59<00:50,  3.36s/it]                                                         Episode 36	 reward: -6.02	 makespan: 595.65	 Mean_loss: 0.11959702,  training time: 3.33
progress:  70%|[34m   [0m| 35/50 [02:03<00:50,  3.36s/it]progress:  72%|[34m  [0m| 36/50 [02:03<00:46,  3.35s/it]                                                         Episode 37	 reward: -5.83	 makespan: 577.45	 Mean_loss: 0.11347728,  training time: 3.33
progress:  72%|[34m  [0m| 36/50 [02:06<00:46,  3.35s/it]progress:  74%|[34m  [0m| 37/50 [02:06<00:43,  3.35s/it]                                                         Episode 38	 reward: -5.89	 makespan: 582.85	 Mean_loss: 0.10637626,  training time: 3.36
progress:  74%|[34m  [0m| 37/50 [02:09<00:43,  3.35s/it]progress:  76%|[34m  [0m| 38/50 [02:09<00:40,  3.35s/it]                                                         Episode 39	 reward: -5.98	 makespan: 592.35	 Mean_loss: 0.12407525,  training time: 3.33
progress:  76%|[34m  [0m| 38/50 [02:13<00:40,  3.35s/it]progress:  78%|[34m  [0m| 39/50 [02:13<00:36,  3.35s/it]                                                         Episode 40	 reward: -6.00	 makespan: 593.60	 Mean_loss: 0.09456529,  training time: 3.41
progress:  78%|[34m  [0m| 39/50 [02:16<00:36,  3.35s/it]progress:  80%|[34m  [0m| 40/50 [02:16<00:33,  3.37s/it]                                                         Episode 41	 reward: -5.93	 makespan: 586.60	 Mean_loss: 0.08467485,  training time: 3.28
progress:  80%|[34m  [0m| 40/50 [02:19<00:33,  3.37s/it]progress:  82%|[34m [0m| 41/50 [02:19<00:30,  3.34s/it]                                                         Episode 42	 reward: -6.02	 makespan: 596.05	 Mean_loss: 0.11412434,  training time: 3.32
progress:  82%|[34m [0m| 41/50 [02:23<00:30,  3.34s/it]progress:  84%|[34m [0m| 42/50 [02:23<00:26,  3.34s/it]                                                         Episode 43	 reward: -6.02	 makespan: 595.90	 Mean_loss: 0.10818135,  training time: 3.33
progress:  84%|[34m [0m| 42/50 [02:26<00:26,  3.34s/it]progress:  86%|[34m [0m| 43/50 [02:26<00:23,  3.34s/it]                                                         Episode 44	 reward: -5.97	 makespan: 591.20	 Mean_loss: 0.11156929,  training time: 3.32
progress:  86%|[34m [0m| 43/50 [02:29<00:23,  3.34s/it]progress:  88%|[34m [0m| 44/50 [02:29<00:20,  3.33s/it]                                                         Episode 45	 reward: -6.07	 makespan: 600.70	 Mean_loss: 0.11086395,  training time: 3.33
progress:  88%|[34m [0m| 44/50 [02:33<00:20,  3.33s/it]progress:  90%|[34m [0m| 45/50 [02:33<00:16,  3.33s/it]                                                         Episode 46	 reward: -5.97	 makespan: 590.70	 Mean_loss: 0.10561069,  training time: 3.32
progress:  90%|[34m [0m| 45/50 [02:36<00:16,  3.33s/it]progress:  92%|[34m[0m| 46/50 [02:36<00:13,  3.33s/it]                                                         Episode 47	 reward: -5.97	 makespan: 591.20	 Mean_loss: 0.12353595,  training time: 3.32
progress:  92%|[34m[0m| 46/50 [02:39<00:13,  3.33s/it]progress:  94%|[34m[0m| 47/50 [02:39<00:09,  3.33s/it]                                                         Episode 48	 reward: -5.86	 makespan: 580.30	 Mean_loss: 0.12948662,  training time: 3.33
progress:  94%|[34m[0m| 47/50 [02:43<00:09,  3.33s/it]progress:  96%|[34m[0m| 48/50 [02:43<00:06,  3.33s/it]                                                         Episode 49	 reward: -5.93	 makespan: 587.45	 Mean_loss: 0.10451130,  training time: 3.45
progress:  96%|[34m[0m| 48/50 [02:46<00:06,  3.33s/it]progress:  98%|[34m[0m| 49/50 [02:46<00:03,  3.37s/it]                                                         Episode 50	 reward: -5.93	 makespan: 587.40	 Mean_loss: 0.11996775,  training time: 3.38
progress:  98%|[34m[0m| 49/50 [02:49<00:03,  3.37s/it]progress: 100%|[34m[0m| 50/50 [02:49<00:00,  3.38s/it]progress: 100%|[34m[0m| 50/50 [02:49<00:00,  3.40s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x13_12 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.99	 makespan: 692.15	 Mean_loss: 0.47610041,  training time: 5.60
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:34,  5.60s/it]                                                        Episode 2	 reward: -7.08	 makespan: 701.25	 Mean_loss: 0.59858763,  training time: 4.26
progress:   2%|[34m         [0m| 1/50 [00:09<04:34,  5.60s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:51,  4.81s/it]                                                        Episode 3	 reward: -7.01	 makespan: 694.25	 Mean_loss: 0.68571866,  training time: 4.44
progress:   4%|[34m         [0m| 2/50 [00:14<03:51,  4.81s/it]progress:   6%|[34m         [0m| 3/50 [00:14<03:38,  4.65s/it]                                                        Episode 4	 reward: -7.11	 makespan: 704.00	 Mean_loss: 0.70267349,  training time: 4.53
progress:   6%|[34m         [0m| 3/50 [00:18<03:38,  4.65s/it]progress:   8%|[34m         [0m| 4/50 [00:18<03:31,  4.60s/it]                                                        Episode 5	 reward: -6.99	 makespan: 691.80	 Mean_loss: 0.59934413,  training time: 4.50
progress:   8%|[34m         [0m| 4/50 [00:23<03:31,  4.60s/it]progress:  10%|[34m         [0m| 5/50 [00:23<03:25,  4.57s/it]                                                        Episode 6	 reward: -6.98	 makespan: 691.15	 Mean_loss: 0.63090581,  training time: 4.48
progress:  10%|[34m         [0m| 5/50 [00:27<03:25,  4.57s/it]progress:  12%|[34m        [0m| 6/50 [00:27<03:19,  4.54s/it]                                                        Episode 7	 reward: -7.04	 makespan: 697.00	 Mean_loss: 0.55062592,  training time: 4.36
progress:  12%|[34m        [0m| 6/50 [00:32<03:19,  4.54s/it]progress:  14%|[34m        [0m| 7/50 [00:32<03:12,  4.48s/it]                                                        Episode 8	 reward: -6.95	 makespan: 688.30	 Mean_loss: 0.51933908,  training time: 4.20
progress:  14%|[34m        [0m| 7/50 [00:36<03:12,  4.48s/it]progress:  16%|[34m        [0m| 8/50 [00:36<03:04,  4.39s/it]                                                        Episode 9	 reward: -6.97	 makespan: 690.35	 Mean_loss: 0.47067750,  training time: 4.37
progress:  16%|[34m        [0m| 8/50 [00:40<03:04,  4.39s/it]progress:  18%|[34m        [0m| 9/50 [00:40<02:59,  4.39s/it]                                                        Episode 10	 reward: -7.13	 makespan: 705.55	 Mean_loss: 0.43390310,  training time: 4.24
progress:  18%|[34m        [0m| 9/50 [00:45<02:59,  4.39s/it]progress:  20%|[34m        [0m| 10/50 [00:45<02:53,  4.34s/it]                                                         Episode 11	 reward: -7.19	 makespan: 711.60	 Mean_loss: 0.34594637,  training time: 4.21
progress:  20%|[34m        [0m| 10/50 [00:49<02:53,  4.34s/it]progress:  22%|[34m       [0m| 11/50 [00:49<02:47,  4.30s/it]                                                         Episode 12	 reward: -6.93	 makespan: 686.35	 Mean_loss: 0.29133981,  training time: 4.27
progress:  22%|[34m       [0m| 11/50 [00:53<02:47,  4.30s/it]progress:  24%|[34m       [0m| 12/50 [00:53<02:43,  4.30s/it]                                                         Episode 13	 reward: -7.08	 makespan: 700.85	 Mean_loss: 0.30404568,  training time: 4.22
progress:  24%|[34m       [0m| 12/50 [00:57<02:43,  4.30s/it]progress:  26%|[34m       [0m| 13/50 [00:57<02:38,  4.27s/it]                                                         Episode 14	 reward: -7.05	 makespan: 697.55	 Mean_loss: 0.28450325,  training time: 4.25
progress:  26%|[34m       [0m| 13/50 [01:01<02:38,  4.27s/it]progress:  28%|[34m       [0m| 14/50 [01:02<02:33,  4.27s/it]                                                         Episode 15	 reward: -6.98	 makespan: 691.25	 Mean_loss: 0.36540508,  training time: 4.46
progress:  28%|[34m       [0m| 14/50 [01:06<02:33,  4.27s/it]progress:  30%|[34m       [0m| 15/50 [01:06<02:31,  4.33s/it]                                                         Episode 16	 reward: -7.03	 makespan: 695.70	 Mean_loss: 0.30544388,  training time: 4.26
progress:  30%|[34m       [0m| 15/50 [01:10<02:31,  4.33s/it]progress:  32%|[34m      [0m| 16/50 [01:10<02:26,  4.31s/it]                                                         Episode 17	 reward: -6.92	 makespan: 685.05	 Mean_loss: 0.23665749,  training time: 4.36
progress:  32%|[34m      [0m| 16/50 [01:15<02:26,  4.31s/it]progress:  34%|[34m      [0m| 17/50 [01:15<02:22,  4.33s/it]                                                         Episode 18	 reward: -7.05	 makespan: 697.80	 Mean_loss: 0.26780719,  training time: 4.45
progress:  34%|[34m      [0m| 17/50 [01:19<02:22,  4.33s/it]progress:  36%|[34m      [0m| 18/50 [01:19<02:19,  4.36s/it]                                                         Episode 19	 reward: -7.04	 makespan: 697.35	 Mean_loss: 0.28404495,  training time: 4.32
progress:  36%|[34m      [0m| 18/50 [01:23<02:19,  4.36s/it]progress:  38%|[34m      [0m| 19/50 [01:23<02:14,  4.35s/it]                                                         Episode 20	 reward: -7.03	 makespan: 696.25	 Mean_loss: 0.28046584,  training time: 4.30
progress:  38%|[34m      [0m| 19/50 [01:28<02:14,  4.35s/it]progress:  40%|[34m      [0m| 20/50 [01:28<02:10,  4.34s/it]                                                         Episode 21	 reward: -7.03	 makespan: 695.75	 Mean_loss: 0.22911009,  training time: 4.25
progress:  40%|[34m      [0m| 20/50 [01:32<02:10,  4.34s/it]progress:  42%|[34m     [0m| 21/50 [01:32<02:05,  4.31s/it]                                                         Episode 22	 reward: -6.87	 makespan: 680.10	 Mean_loss: 0.22902948,  training time: 4.21
progress:  42%|[34m     [0m| 21/50 [01:36<02:05,  4.31s/it]progress:  44%|[34m     [0m| 22/50 [01:36<01:59,  4.29s/it]                                                         Episode 23	 reward: -6.96	 makespan: 689.35	 Mean_loss: 0.20485875,  training time: 4.22
progress:  44%|[34m     [0m| 22/50 [01:40<01:59,  4.29s/it]progress:  46%|[34m     [0m| 23/50 [01:40<01:55,  4.27s/it]                                                         Episode 24	 reward: -6.97	 makespan: 690.30	 Mean_loss: 0.22139801,  training time: 4.20
progress:  46%|[34m     [0m| 23/50 [01:45<01:55,  4.27s/it]progress:  48%|[34m     [0m| 24/50 [01:45<01:50,  4.25s/it]                                                         Episode 25	 reward: -6.89	 makespan: 682.15	 Mean_loss: 0.19843847,  training time: 4.35
progress:  48%|[34m     [0m| 24/50 [01:49<01:50,  4.25s/it]progress:  50%|[34m     [0m| 25/50 [01:49<01:47,  4.28s/it]                                                         Episode 26	 reward: -6.90	 makespan: 682.85	 Mean_loss: 0.20568146,  training time: 4.28
progress:  50%|[34m     [0m| 25/50 [01:53<01:47,  4.28s/it]progress:  52%|[34m    [0m| 26/50 [01:53<01:42,  4.28s/it]                                                         Episode 27	 reward: -6.98	 makespan: 691.00	 Mean_loss: 0.21678124,  training time: 4.23
progress:  52%|[34m    [0m| 26/50 [01:57<01:42,  4.28s/it]progress:  54%|[34m    [0m| 27/50 [01:57<01:38,  4.27s/it]                                                         Episode 28	 reward: -7.05	 makespan: 697.75	 Mean_loss: 0.21526723,  training time: 4.28
progress:  54%|[34m    [0m| 27/50 [02:02<01:38,  4.27s/it]progress:  56%|[34m    [0m| 28/50 [02:02<01:34,  4.28s/it]                                                         Episode 29	 reward: -6.88	 makespan: 681.45	 Mean_loss: 0.21294849,  training time: 4.37
progress:  56%|[34m    [0m| 28/50 [02:06<01:34,  4.28s/it]progress:  58%|[34m    [0m| 29/50 [02:06<01:30,  4.31s/it]                                                         Episode 30	 reward: -6.98	 makespan: 690.85	 Mean_loss: 0.19740465,  training time: 4.46
progress:  58%|[34m    [0m| 29/50 [02:11<01:30,  4.31s/it]progress:  60%|[34m    [0m| 30/50 [02:11<01:27,  4.35s/it]                                                         Episode 31	 reward: -6.86	 makespan: 678.80	 Mean_loss: 0.23350456,  training time: 4.39
progress:  60%|[34m    [0m| 30/50 [02:15<01:27,  4.35s/it]progress:  62%|[34m   [0m| 31/50 [02:15<01:22,  4.37s/it]                                                         Episode 32	 reward: -6.96	 makespan: 688.75	 Mean_loss: 0.19847320,  training time: 4.53
progress:  62%|[34m   [0m| 31/50 [02:20<01:22,  4.37s/it]progress:  64%|[34m   [0m| 32/50 [02:20<01:19,  4.42s/it]                                                         Episode 33	 reward: -7.04	 makespan: 696.95	 Mean_loss: 0.18628018,  training time: 4.38
progress:  64%|[34m   [0m| 32/50 [02:24<01:19,  4.42s/it]progress:  66%|[34m   [0m| 33/50 [02:24<01:14,  4.41s/it]                                                         Episode 34	 reward: -6.99	 makespan: 692.35	 Mean_loss: 0.18879497,  training time: 4.50
progress:  66%|[34m   [0m| 33/50 [02:28<01:14,  4.41s/it]progress:  68%|[34m   [0m| 34/50 [02:28<01:10,  4.44s/it]                                                         Episode 35	 reward: -7.06	 makespan: 698.90	 Mean_loss: 0.21144910,  training time: 4.27
progress:  68%|[34m   [0m| 34/50 [02:33<01:10,  4.44s/it]progress:  70%|[34m   [0m| 35/50 [02:33<01:05,  4.39s/it]                                                         Episode 36	 reward: -6.77	 makespan: 670.15	 Mean_loss: 0.17721741,  training time: 4.22
progress:  70%|[34m   [0m| 35/50 [02:37<01:05,  4.39s/it]progress:  72%|[34m  [0m| 36/50 [02:37<01:00,  4.34s/it]                                                         Episode 37	 reward: -6.88	 makespan: 681.40	 Mean_loss: 0.19073749,  training time: 4.22
progress:  72%|[34m  [0m| 36/50 [02:41<01:00,  4.34s/it]progress:  74%|[34m  [0m| 37/50 [02:41<00:55,  4.31s/it]                                                         Episode 38	 reward: -6.77	 makespan: 670.45	 Mean_loss: 0.16924094,  training time: 4.24
progress:  74%|[34m  [0m| 37/50 [02:45<00:55,  4.31s/it]progress:  76%|[34m  [0m| 38/50 [02:45<00:51,  4.29s/it]                                                         Episode 39	 reward: -7.04	 makespan: 696.80	 Mean_loss: 0.20224319,  training time: 4.25
progress:  76%|[34m  [0m| 38/50 [02:50<00:51,  4.29s/it]progress:  78%|[34m  [0m| 39/50 [02:50<00:47,  4.28s/it]                                                         Episode 40	 reward: -6.90	 makespan: 683.40	 Mean_loss: 0.19314277,  training time: 4.27
progress:  78%|[34m  [0m| 39/50 [02:54<00:47,  4.28s/it]progress:  80%|[34m  [0m| 40/50 [02:54<00:42,  4.28s/it]                                                         Episode 41	 reward: -6.88	 makespan: 681.05	 Mean_loss: 0.22137509,  training time: 4.36
progress:  80%|[34m  [0m| 40/50 [02:58<00:42,  4.28s/it]progress:  82%|[34m [0m| 41/50 [02:58<00:38,  4.30s/it]                                                         Episode 42	 reward: -6.90	 makespan: 682.65	 Mean_loss: 0.18802989,  training time: 4.22
progress:  82%|[34m [0m| 41/50 [03:03<00:38,  4.30s/it]progress:  84%|[34m [0m| 42/50 [03:03<00:34,  4.28s/it]                                                         Episode 43	 reward: -6.98	 makespan: 691.10	 Mean_loss: 0.16878602,  training time: 4.36
progress:  84%|[34m [0m| 42/50 [03:07<00:34,  4.28s/it]progress:  86%|[34m [0m| 43/50 [03:07<00:30,  4.31s/it]                                                         Episode 44	 reward: -6.80	 makespan: 673.40	 Mean_loss: 0.13462289,  training time: 4.37
progress:  86%|[34m [0m| 43/50 [03:11<00:30,  4.31s/it]progress:  88%|[34m [0m| 44/50 [03:11<00:25,  4.33s/it]                                                         Episode 45	 reward: -6.92	 makespan: 685.25	 Mean_loss: 0.13376591,  training time: 4.21
progress:  88%|[34m [0m| 44/50 [03:15<00:25,  4.33s/it]progress:  90%|[34m [0m| 45/50 [03:15<00:21,  4.29s/it]                                                         Episode 46	 reward: -6.77	 makespan: 670.25	 Mean_loss: 0.13752292,  training time: 4.26
progress:  90%|[34m [0m| 45/50 [03:20<00:21,  4.29s/it]progress:  92%|[34m[0m| 46/50 [03:20<00:17,  4.29s/it]                                                         Episode 47	 reward: -6.90	 makespan: 683.20	 Mean_loss: 0.18494013,  training time: 4.27
progress:  92%|[34m[0m| 46/50 [03:24<00:17,  4.29s/it]progress:  94%|[34m[0m| 47/50 [03:24<00:12,  4.28s/it]                                                         Episode 48	 reward: -6.92	 makespan: 685.55	 Mean_loss: 0.18440525,  training time: 4.38
progress:  94%|[34m[0m| 47/50 [03:28<00:12,  4.28s/it]progress:  96%|[34m[0m| 48/50 [03:28<00:08,  4.32s/it]                                                         Episode 49	 reward: -6.99	 makespan: 691.55	 Mean_loss: 0.18475418,  training time: 4.20
progress:  96%|[34m[0m| 48/50 [03:33<00:08,  4.32s/it]progress:  98%|[34m[0m| 49/50 [03:33<00:04,  4.28s/it]                                                         Episode 50	 reward: -6.93	 makespan: 686.30	 Mean_loss: 0.17701961,  training time: 4.21
progress:  98%|[34m[0m| 49/50 [03:37<00:04,  4.28s/it]progress: 100%|[34m[0m| 50/50 [03:37<00:00,  4.26s/it]progress: 100%|[34m[0m| 50/50 [03:37<00:00,  4.35s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x10_4 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -2.86	 makespan: 282.90	 Mean_loss: 0.02028592,  training time: 2.52
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:03,  2.52s/it]                                                        Episode 2	 reward: -2.96	 makespan: 293.20	 Mean_loss: 0.03128747,  training time: 1.35
progress:   2%|[34m         [0m| 1/50 [00:03<02:03,  2.52s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:28,  1.84s/it]                                                        Episode 3	 reward: -3.01	 makespan: 298.10	 Mean_loss: 0.00913854,  training time: 1.36
progress:   4%|[34m         [0m| 2/50 [00:05<01:28,  1.84s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:16,  1.62s/it]                                                        Episode 4	 reward: -2.90	 makespan: 287.40	 Mean_loss: 0.01217842,  training time: 1.37
progress:   6%|[34m         [0m| 3/50 [00:06<01:16,  1.62s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:10,  1.52s/it]                                                        Episode 5	 reward: -2.95	 makespan: 291.90	 Mean_loss: 0.06735002,  training time: 1.32
progress:   8%|[34m         [0m| 4/50 [00:07<01:10,  1.52s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:05,  1.45s/it]                                                        Episode 6	 reward: -2.91	 makespan: 288.55	 Mean_loss: 0.02982779,  training time: 1.36
progress:  10%|[34m         [0m| 5/50 [00:09<01:05,  1.45s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:02,  1.43s/it]                                                        Episode 7	 reward: -2.78	 makespan: 275.05	 Mean_loss: 0.03179265,  training time: 1.39
progress:  12%|[34m        [0m| 6/50 [00:10<01:02,  1.43s/it]progress:  14%|[34m        [0m| 7/50 [00:10<01:00,  1.42s/it]                                                        Episode 8	 reward: -2.91	 makespan: 287.80	 Mean_loss: 0.02306632,  training time: 1.40
progress:  14%|[34m        [0m| 7/50 [00:12<01:00,  1.42s/it]progress:  16%|[34m        [0m| 8/50 [00:12<00:59,  1.41s/it]                                                        Episode 9	 reward: -2.84	 makespan: 280.80	 Mean_loss: 0.02923793,  training time: 1.30
progress:  16%|[34m        [0m| 8/50 [00:13<00:59,  1.41s/it]progress:  18%|[34m        [0m| 9/50 [00:13<00:56,  1.38s/it]                                                        Episode 10	 reward: -2.90	 makespan: 287.30	 Mean_loss: 0.04439618,  training time: 1.29
progress:  18%|[34m        [0m| 9/50 [00:14<00:56,  1.38s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:54,  1.35s/it]                                                         Episode 11	 reward: -2.88	 makespan: 285.40	 Mean_loss: 0.03472599,  training time: 1.34
progress:  20%|[34m        [0m| 10/50 [00:16<00:54,  1.35s/it]progress:  22%|[34m       [0m| 11/50 [00:16<00:52,  1.35s/it]                                                         Episode 12	 reward: -2.91	 makespan: 287.85	 Mean_loss: 0.04108659,  training time: 1.47
progress:  22%|[34m       [0m| 11/50 [00:17<00:52,  1.35s/it]progress:  24%|[34m       [0m| 12/50 [00:17<00:52,  1.39s/it]                                                         Episode 13	 reward: -2.83	 makespan: 280.35	 Mean_loss: 0.04279396,  training time: 1.39
progress:  24%|[34m       [0m| 12/50 [00:18<00:52,  1.39s/it]progress:  26%|[34m       [0m| 13/50 [00:18<00:51,  1.39s/it]                                                         Episode 14	 reward: -2.79	 makespan: 275.85	 Mean_loss: 0.03138095,  training time: 1.28
progress:  26%|[34m       [0m| 13/50 [00:20<00:51,  1.39s/it]progress:  28%|[34m       [0m| 14/50 [00:20<00:48,  1.36s/it]                                                         Episode 15	 reward: -2.82	 makespan: 279.40	 Mean_loss: 0.03553601,  training time: 1.27
progress:  28%|[34m       [0m| 14/50 [00:21<00:48,  1.36s/it]progress:  30%|[34m       [0m| 15/50 [00:21<00:46,  1.34s/it]                                                         Episode 16	 reward: -2.90	 makespan: 286.70	 Mean_loss: 0.05270766,  training time: 1.30
progress:  30%|[34m       [0m| 15/50 [00:22<00:46,  1.34s/it]progress:  32%|[34m      [0m| 16/50 [00:22<00:45,  1.33s/it]                                                         Episode 17	 reward: -2.96	 makespan: 293.25	 Mean_loss: -0.00049193,  training time: 1.35
progress:  32%|[34m      [0m| 16/50 [00:24<00:45,  1.33s/it]progress:  34%|[34m      [0m| 17/50 [00:24<00:44,  1.33s/it]                                                         Episode 18	 reward: -2.93	 makespan: 290.55	 Mean_loss: 0.02441720,  training time: 1.35
progress:  34%|[34m      [0m| 17/50 [00:25<00:44,  1.33s/it]progress:  36%|[34m      [0m| 18/50 [00:25<00:42,  1.34s/it]                                                         Episode 19	 reward: -2.85	 makespan: 282.45	 Mean_loss: 0.03575000,  training time: 1.46
progress:  36%|[34m      [0m| 18/50 [00:26<00:42,  1.34s/it]progress:  38%|[34m      [0m| 19/50 [00:26<00:42,  1.38s/it]                                                         Episode 20	 reward: -2.92	 makespan: 289.00	 Mean_loss: 0.01577481,  training time: 1.25
progress:  38%|[34m      [0m| 19/50 [00:28<00:42,  1.38s/it]progress:  40%|[34m      [0m| 20/50 [00:28<00:40,  1.34s/it]                                                         Episode 21	 reward: -2.82	 makespan: 279.30	 Mean_loss: 0.02286614,  training time: 1.41
progress:  40%|[34m      [0m| 20/50 [00:29<00:40,  1.34s/it]progress:  42%|[34m     [0m| 21/50 [00:29<00:39,  1.36s/it]                                                         Episode 22	 reward: -2.96	 makespan: 292.60	 Mean_loss: 0.06076703,  training time: 1.27
progress:  42%|[34m     [0m| 21/50 [00:30<00:39,  1.36s/it]progress:  44%|[34m     [0m| 22/50 [00:30<00:37,  1.34s/it]                                                         Episode 23	 reward: -2.88	 makespan: 285.40	 Mean_loss: 0.03978828,  training time: 1.27
progress:  44%|[34m     [0m| 22/50 [00:32<00:37,  1.34s/it]progress:  46%|[34m     [0m| 23/50 [00:32<00:35,  1.32s/it]                                                         Episode 24	 reward: -2.77	 makespan: 274.65	 Mean_loss: 0.00980593,  training time: 1.32
progress:  46%|[34m     [0m| 23/50 [00:33<00:35,  1.32s/it]progress:  48%|[34m     [0m| 24/50 [00:33<00:34,  1.32s/it]                                                         Episode 25	 reward: -2.85	 makespan: 282.60	 Mean_loss: 0.03179071,  training time: 1.39
progress:  48%|[34m     [0m| 24/50 [00:34<00:34,  1.32s/it]progress:  50%|[34m     [0m| 25/50 [00:34<00:33,  1.34s/it]                                                         Episode 26	 reward: -2.91	 makespan: 288.25	 Mean_loss: 0.01416831,  training time: 1.37
progress:  50%|[34m     [0m| 25/50 [00:36<00:33,  1.34s/it]progress:  52%|[34m    [0m| 26/50 [00:36<00:32,  1.35s/it]                                                         Episode 27	 reward: -2.87	 makespan: 284.30	 Mean_loss: 0.03398941,  training time: 1.33
progress:  52%|[34m    [0m| 26/50 [00:37<00:32,  1.35s/it]progress:  54%|[34m    [0m| 27/50 [00:37<00:30,  1.35s/it]                                                         Episode 28	 reward: -2.92	 makespan: 289.40	 Mean_loss: 0.04003467,  training time: 1.31
progress:  54%|[34m    [0m| 27/50 [00:38<00:30,  1.35s/it]progress:  56%|[34m    [0m| 28/50 [00:38<00:29,  1.34s/it]                                                         Episode 29	 reward: -2.88	 makespan: 285.55	 Mean_loss: 0.04536266,  training time: 1.31
progress:  56%|[34m    [0m| 28/50 [00:40<00:29,  1.34s/it]progress:  58%|[34m    [0m| 29/50 [00:40<00:27,  1.33s/it]                                                         Episode 30	 reward: -2.88	 makespan: 284.80	 Mean_loss: 0.02232031,  training time: 1.32
progress:  58%|[34m    [0m| 29/50 [00:41<00:27,  1.33s/it]progress:  60%|[34m    [0m| 30/50 [00:41<00:26,  1.33s/it]                                                         Episode 31	 reward: -2.81	 makespan: 277.90	 Mean_loss: 0.02330141,  training time: 1.27
progress:  60%|[34m    [0m| 30/50 [00:42<00:26,  1.33s/it]progress:  62%|[34m   [0m| 31/50 [00:42<00:24,  1.31s/it]                                                         Episode 32	 reward: -2.83	 makespan: 280.10	 Mean_loss: 0.02172036,  training time: 1.32
progress:  62%|[34m   [0m| 31/50 [00:44<00:24,  1.31s/it]progress:  64%|[34m   [0m| 32/50 [00:44<00:23,  1.32s/it]                                                         Episode 33	 reward: -2.91	 makespan: 288.50	 Mean_loss: 0.02880240,  training time: 1.27
progress:  64%|[34m   [0m| 32/50 [00:45<00:23,  1.32s/it]progress:  66%|[34m   [0m| 33/50 [00:45<00:22,  1.30s/it]                                                         Episode 34	 reward: -2.86	 makespan: 283.25	 Mean_loss: 0.01943432,  training time: 1.32
progress:  66%|[34m   [0m| 33/50 [00:46<00:22,  1.30s/it]progress:  68%|[34m   [0m| 34/50 [00:46<00:20,  1.31s/it]                                                         Episode 35	 reward: -2.93	 makespan: 289.70	 Mean_loss: 0.02303080,  training time: 1.27
progress:  68%|[34m   [0m| 34/50 [00:48<00:20,  1.31s/it]progress:  70%|[34m   [0m| 35/50 [00:48<00:19,  1.30s/it]                                                         Episode 36	 reward: -2.82	 makespan: 279.05	 Mean_loss: 0.02398517,  training time: 1.25
progress:  70%|[34m   [0m| 35/50 [00:49<00:19,  1.30s/it]progress:  72%|[34m  [0m| 36/50 [00:49<00:18,  1.29s/it]                                                         Episode 37	 reward: -2.81	 makespan: 278.65	 Mean_loss: 0.01619761,  training time: 1.32
progress:  72%|[34m  [0m| 36/50 [00:50<00:18,  1.29s/it]progress:  74%|[34m  [0m| 37/50 [00:50<00:16,  1.30s/it]                                                         Episode 38	 reward: -2.85	 makespan: 281.90	 Mean_loss: 0.00016025,  training time: 1.32
progress:  74%|[34m  [0m| 37/50 [00:51<00:16,  1.30s/it]progress:  76%|[34m  [0m| 38/50 [00:51<00:15,  1.31s/it]                                                         Episode 39	 reward: -2.84	 makespan: 281.45	 Mean_loss: 0.03577454,  training time: 1.31
progress:  76%|[34m  [0m| 38/50 [00:53<00:15,  1.31s/it]progress:  78%|[34m  [0m| 39/50 [00:53<00:14,  1.31s/it]                                                         Episode 40	 reward: -2.84	 makespan: 281.55	 Mean_loss: 0.01984118,  training time: 1.26
progress:  78%|[34m  [0m| 39/50 [00:54<00:14,  1.31s/it]progress:  80%|[34m  [0m| 40/50 [00:54<00:12,  1.29s/it]                                                         Episode 41	 reward: -2.86	 makespan: 283.50	 Mean_loss: 0.04491058,  training time: 1.32
progress:  80%|[34m  [0m| 40/50 [00:55<00:12,  1.29s/it]progress:  82%|[34m [0m| 41/50 [00:55<00:11,  1.30s/it]                                                         Episode 42	 reward: -2.76	 makespan: 272.75	 Mean_loss: 0.02790430,  training time: 1.30
progress:  82%|[34m [0m| 41/50 [00:57<00:11,  1.30s/it]progress:  84%|[34m [0m| 42/50 [00:57<00:10,  1.30s/it]                                                         Episode 43	 reward: -2.83	 makespan: 280.25	 Mean_loss: 0.04031278,  training time: 1.27
progress:  84%|[34m [0m| 42/50 [00:58<00:10,  1.30s/it]progress:  86%|[34m [0m| 43/50 [00:58<00:09,  1.29s/it]                                                         Episode 44	 reward: -2.72	 makespan: 269.30	 Mean_loss: 0.02641562,  training time: 1.35
progress:  86%|[34m [0m| 43/50 [00:59<00:09,  1.29s/it]progress:  88%|[34m [0m| 44/50 [00:59<00:07,  1.31s/it]                                                         Episode 45	 reward: -2.81	 makespan: 278.10	 Mean_loss: 0.03309997,  training time: 1.27
progress:  88%|[34m [0m| 44/50 [01:01<00:07,  1.31s/it]progress:  90%|[34m [0m| 45/50 [01:01<00:06,  1.30s/it]                                                         Episode 46	 reward: -2.79	 makespan: 276.60	 Mean_loss: 0.02882718,  training time: 1.35
progress:  90%|[34m [0m| 45/50 [01:02<00:06,  1.30s/it]progress:  92%|[34m[0m| 46/50 [01:02<00:05,  1.32s/it]                                                         Episode 47	 reward: -2.69	 makespan: 266.50	 Mean_loss: 0.03821420,  training time: 1.27
progress:  92%|[34m[0m| 46/50 [01:03<00:05,  1.32s/it]progress:  94%|[34m[0m| 47/50 [01:03<00:03,  1.30s/it]                                                         Episode 48	 reward: -2.77	 makespan: 273.75	 Mean_loss: 0.00844825,  training time: 1.25
progress:  94%|[34m[0m| 47/50 [01:04<00:03,  1.30s/it]progress:  96%|[34m[0m| 48/50 [01:04<00:02,  1.29s/it]                                                         Episode 49	 reward: -2.76	 makespan: 273.45	 Mean_loss: 0.03525538,  training time: 1.26
progress:  96%|[34m[0m| 48/50 [01:06<00:02,  1.29s/it]progress:  98%|[34m[0m| 49/50 [01:06<00:01,  1.28s/it]                                                         Episode 50	 reward: -2.70	 makespan: 267.25	 Mean_loss: 0.05503388,  training time: 1.29
progress:  98%|[34m[0m| 49/50 [01:07<00:01,  1.28s/it]progress: 100%|[34m[0m| 50/50 [01:07<00:00,  1.28s/it]progress: 100%|[34m[0m| 50/50 [01:07<00:00,  1.35s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x10_7 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.85	 makespan: 480.35	 Mean_loss: -0.68129945,  training time: 3.47
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:50,  3.48s/it]                                                        Episode 2	 reward: -4.81	 makespan: 476.50	 Mean_loss: -0.63630193,  training time: 2.41
progress:   2%|[34m         [0m| 1/50 [00:05<02:50,  3.48s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:16,  2.85s/it]                                                        Episode 3	 reward: -4.72	 makespan: 466.90	 Mean_loss: -0.57715750,  training time: 2.38
progress:   4%|[34m         [0m| 2/50 [00:08<02:16,  2.85s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:03,  2.64s/it]                                                        Episode 4	 reward: -4.77	 makespan: 472.60	 Mean_loss: -0.63684267,  training time: 2.29
progress:   6%|[34m         [0m| 3/50 [00:10<02:03,  2.64s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:55,  2.50s/it]                                                        Episode 5	 reward: -4.76	 makespan: 471.70	 Mean_loss: -0.36414677,  training time: 2.31
progress:   8%|[34m         [0m| 4/50 [00:12<01:55,  2.50s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:49,  2.43s/it]                                                        Episode 6	 reward: -4.81	 makespan: 476.25	 Mean_loss: -0.22900005,  training time: 2.29
progress:  10%|[34m         [0m| 5/50 [00:15<01:49,  2.43s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:44,  2.39s/it]                                                        Episode 7	 reward: -4.86	 makespan: 481.10	 Mean_loss: -0.03304577,  training time: 2.30
progress:  12%|[34m        [0m| 6/50 [00:17<01:44,  2.39s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:41,  2.36s/it]                                                        Episode 8	 reward: -4.92	 makespan: 486.60	 Mean_loss: -0.07339611,  training time: 2.40
progress:  14%|[34m        [0m| 7/50 [00:19<01:41,  2.36s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:39,  2.38s/it]                                                        Episode 9	 reward: -4.85	 makespan: 479.80	 Mean_loss: -0.16619171,  training time: 2.29
progress:  16%|[34m        [0m| 8/50 [00:22<01:39,  2.38s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:36,  2.35s/it]                                                        Episode 10	 reward: -4.82	 makespan: 477.50	 Mean_loss: -0.06202298,  training time: 2.28
progress:  18%|[34m        [0m| 9/50 [00:24<01:36,  2.35s/it]progress:  20%|[34m        [0m| 10/50 [00:24<01:33,  2.33s/it]                                                         Episode 11	 reward: -4.94	 makespan: 489.05	 Mean_loss: -0.46959198,  training time: 2.29
progress:  20%|[34m        [0m| 10/50 [00:26<01:33,  2.33s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:30,  2.32s/it]                                                         Episode 12	 reward: -4.82	 makespan: 477.40	 Mean_loss: -0.01447919,  training time: 2.27
progress:  22%|[34m       [0m| 11/50 [00:29<01:30,  2.32s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:27,  2.31s/it]                                                         Episode 13	 reward: -4.83	 makespan: 477.70	 Mean_loss: -0.32603803,  training time: 2.41
progress:  24%|[34m       [0m| 12/50 [00:31<01:27,  2.31s/it]progress:  26%|[34m       [0m| 13/50 [00:31<01:26,  2.34s/it]                                                         Episode 14	 reward: -4.75	 makespan: 470.55	 Mean_loss: 0.52369809,  training time: 2.34
progress:  26%|[34m       [0m| 13/50 [00:33<01:26,  2.34s/it]progress:  28%|[34m       [0m| 14/50 [00:33<01:24,  2.34s/it]                                                         Episode 15	 reward: -4.74	 makespan: 469.25	 Mean_loss: -0.52559882,  training time: 2.35
progress:  28%|[34m       [0m| 14/50 [00:36<01:24,  2.34s/it]progress:  30%|[34m       [0m| 15/50 [00:36<01:22,  2.34s/it]                                                         Episode 16	 reward: -4.83	 makespan: 477.95	 Mean_loss: 0.59640551,  training time: 2.29
progress:  30%|[34m       [0m| 15/50 [00:38<01:22,  2.34s/it]progress:  32%|[34m      [0m| 16/50 [00:38<01:19,  2.33s/it]                                                         Episode 17	 reward: -4.69	 makespan: 464.80	 Mean_loss: -0.39294535,  training time: 2.35
progress:  32%|[34m      [0m| 16/50 [00:40<01:19,  2.33s/it]progress:  34%|[34m      [0m| 17/50 [00:40<01:17,  2.34s/it]                                                         Episode 18	 reward: -4.69	 makespan: 464.70	 Mean_loss: 0.26060176,  training time: 2.32
progress:  34%|[34m      [0m| 17/50 [00:43<01:17,  2.34s/it]progress:  36%|[34m      [0m| 18/50 [00:43<01:14,  2.33s/it]                                                         Episode 19	 reward: -4.68	 makespan: 463.70	 Mean_loss: 0.15111439,  training time: 2.28
progress:  36%|[34m      [0m| 18/50 [00:45<01:14,  2.33s/it]progress:  38%|[34m      [0m| 19/50 [00:45<01:11,  2.32s/it]                                                         Episode 20	 reward: -4.77	 makespan: 472.50	 Mean_loss: -0.20185828,  training time: 2.28
progress:  38%|[34m      [0m| 19/50 [00:47<01:11,  2.32s/it]progress:  40%|[34m      [0m| 20/50 [00:47<01:09,  2.31s/it]                                                         Episode 21	 reward: -4.82	 makespan: 477.65	 Mean_loss: 0.57913786,  training time: 2.30
progress:  40%|[34m      [0m| 20/50 [00:49<01:09,  2.31s/it]progress:  42%|[34m     [0m| 21/50 [00:49<01:06,  2.31s/it]                                                         Episode 22	 reward: -4.66	 makespan: 461.20	 Mean_loss: -0.53655475,  training time: 2.29
progress:  42%|[34m     [0m| 21/50 [00:52<01:06,  2.31s/it]progress:  44%|[34m     [0m| 22/50 [00:52<01:04,  2.31s/it]                                                         Episode 23	 reward: -4.79	 makespan: 474.65	 Mean_loss: 0.35357875,  training time: 2.30
progress:  44%|[34m     [0m| 22/50 [00:54<01:04,  2.31s/it]progress:  46%|[34m     [0m| 23/50 [00:54<01:02,  2.30s/it]                                                         Episode 24	 reward: -4.73	 makespan: 468.50	 Mean_loss: 0.64504045,  training time: 2.32
progress:  46%|[34m     [0m| 23/50 [00:56<01:02,  2.30s/it]progress:  48%|[34m     [0m| 24/50 [00:56<01:00,  2.31s/it]                                                         Episode 25	 reward: -4.63	 makespan: 458.05	 Mean_loss: -0.35257542,  training time: 2.30
progress:  48%|[34m     [0m| 24/50 [00:59<01:00,  2.31s/it]progress:  50%|[34m     [0m| 25/50 [00:59<00:57,  2.31s/it]                                                         Episode 26	 reward: -4.80	 makespan: 474.95	 Mean_loss: 0.31233197,  training time: 2.35
progress:  50%|[34m     [0m| 25/50 [01:01<00:57,  2.31s/it]progress:  52%|[34m    [0m| 26/50 [01:01<00:55,  2.32s/it]                                                         Episode 27	 reward: -4.58	 makespan: 453.20	 Mean_loss: -0.09200549,  training time: 2.45
progress:  52%|[34m    [0m| 26/50 [01:04<00:55,  2.32s/it]progress:  54%|[34m    [0m| 27/50 [01:04<00:54,  2.36s/it]                                                         Episode 28	 reward: -4.80	 makespan: 474.80	 Mean_loss: 0.09915017,  training time: 2.34
progress:  54%|[34m    [0m| 27/50 [01:06<00:54,  2.36s/it]progress:  56%|[34m    [0m| 28/50 [01:06<00:51,  2.36s/it]                                                         Episode 29	 reward: -4.72	 makespan: 467.50	 Mean_loss: -0.06931320,  training time: 2.36
progress:  56%|[34m    [0m| 28/50 [01:08<00:51,  2.36s/it]progress:  58%|[34m    [0m| 29/50 [01:08<00:49,  2.36s/it]                                                         Episode 30	 reward: -4.60	 makespan: 455.40	 Mean_loss: 0.03596063,  training time: 2.36
progress:  58%|[34m    [0m| 29/50 [01:11<00:49,  2.36s/it]progress:  60%|[34m    [0m| 30/50 [01:11<00:47,  2.36s/it]                                                         Episode 31	 reward: -4.72	 makespan: 466.95	 Mean_loss: -0.21536419,  training time: 2.39
progress:  60%|[34m    [0m| 30/50 [01:13<00:47,  2.36s/it]progress:  62%|[34m   [0m| 31/50 [01:13<00:45,  2.37s/it]                                                         Episode 32	 reward: -4.63	 makespan: 458.15	 Mean_loss: 0.40246588,  training time: 2.35
progress:  62%|[34m   [0m| 31/50 [01:15<00:45,  2.37s/it]progress:  64%|[34m   [0m| 32/50 [01:15<00:42,  2.37s/it]                                                         Episode 33	 reward: -4.58	 makespan: 453.75	 Mean_loss: -0.29330474,  training time: 2.27
progress:  64%|[34m   [0m| 32/50 [01:18<00:42,  2.37s/it]progress:  66%|[34m   [0m| 33/50 [01:18<00:39,  2.34s/it]                                                         Episode 34	 reward: -4.68	 makespan: 463.75	 Mean_loss: -0.25099573,  training time: 2.28
progress:  66%|[34m   [0m| 33/50 [01:20<00:39,  2.34s/it]progress:  68%|[34m   [0m| 34/50 [01:20<00:37,  2.32s/it]                                                         Episode 35	 reward: -4.62	 makespan: 457.85	 Mean_loss: 0.33970678,  training time: 2.29
progress:  68%|[34m   [0m| 34/50 [01:22<00:37,  2.32s/it]progress:  70%|[34m   [0m| 35/50 [01:22<00:34,  2.32s/it]                                                         Episode 36	 reward: -4.62	 makespan: 457.65	 Mean_loss: 0.59210372,  training time: 2.35
progress:  70%|[34m   [0m| 35/50 [01:25<00:34,  2.32s/it]progress:  72%|[34m  [0m| 36/50 [01:25<00:32,  2.33s/it]                                                         Episode 37	 reward: -4.63	 makespan: 458.70	 Mean_loss: -0.11967939,  training time: 2.32
progress:  72%|[34m  [0m| 36/50 [01:27<00:32,  2.33s/it]progress:  74%|[34m  [0m| 37/50 [01:27<00:30,  2.33s/it]                                                         Episode 38	 reward: -4.66	 makespan: 460.90	 Mean_loss: 0.34946516,  training time: 2.27
progress:  74%|[34m  [0m| 37/50 [01:29<00:30,  2.33s/it]progress:  76%|[34m  [0m| 38/50 [01:29<00:27,  2.31s/it]                                                         Episode 39	 reward: -4.89	 makespan: 483.65	 Mean_loss: 0.61299086,  training time: 2.28
progress:  76%|[34m  [0m| 38/50 [01:31<00:27,  2.31s/it]progress:  78%|[34m  [0m| 39/50 [01:31<00:25,  2.30s/it]                                                         Episode 40	 reward: -4.74	 makespan: 469.15	 Mean_loss: 0.40294957,  training time: 2.32
progress:  78%|[34m  [0m| 39/50 [01:34<00:25,  2.30s/it]progress:  80%|[34m  [0m| 40/50 [01:34<00:23,  2.31s/it]                                                         Episode 41	 reward: -4.73	 makespan: 468.35	 Mean_loss: 0.48122641,  training time: 2.36
progress:  80%|[34m  [0m| 40/50 [01:36<00:23,  2.31s/it]progress:  82%|[34m [0m| 41/50 [01:36<00:20,  2.33s/it]                                                         Episode 42	 reward: -4.64	 makespan: 459.80	 Mean_loss: 0.59861511,  training time: 2.31
progress:  82%|[34m [0m| 41/50 [01:38<00:20,  2.33s/it]progress:  84%|[34m [0m| 42/50 [01:38<00:18,  2.32s/it]                                                         Episode 43	 reward: -4.64	 makespan: 459.65	 Mean_loss: 0.65741861,  training time: 2.32
progress:  84%|[34m [0m| 42/50 [01:41<00:18,  2.32s/it]progress:  86%|[34m [0m| 43/50 [01:41<00:16,  2.32s/it]                                                         Episode 44	 reward: -4.57	 makespan: 452.30	 Mean_loss: 0.64182556,  training time: 2.34
progress:  86%|[34m [0m| 43/50 [01:43<00:16,  2.32s/it]progress:  88%|[34m [0m| 44/50 [01:43<00:13,  2.33s/it]                                                         Episode 45	 reward: -4.66	 makespan: 461.45	 Mean_loss: -0.16092500,  training time: 2.27
progress:  88%|[34m [0m| 44/50 [01:45<00:13,  2.33s/it]progress:  90%|[34m [0m| 45/50 [01:45<00:11,  2.31s/it]                                                         Episode 46	 reward: -4.82	 makespan: 476.95	 Mean_loss: 0.51742762,  training time: 2.29
progress:  90%|[34m [0m| 45/50 [01:48<00:11,  2.31s/it]progress:  92%|[34m[0m| 46/50 [01:48<00:09,  2.31s/it]                                                         Episode 47	 reward: -4.71	 makespan: 466.70	 Mean_loss: 0.62958586,  training time: 2.31
progress:  92%|[34m[0m| 46/50 [01:50<00:09,  2.31s/it]progress:  94%|[34m[0m| 47/50 [01:50<00:06,  2.31s/it]                                                         Episode 48	 reward: -4.67	 makespan: 462.40	 Mean_loss: 0.53124303,  training time: 2.31
progress:  94%|[34m[0m| 47/50 [01:52<00:06,  2.31s/it]progress:  96%|[34m[0m| 48/50 [01:52<00:04,  2.31s/it]                                                         Episode 49	 reward: -4.46	 makespan: 441.10	 Mean_loss: -0.14551216,  training time: 2.40
progress:  96%|[34m[0m| 48/50 [01:55<00:04,  2.31s/it]progress:  98%|[34m[0m| 49/50 [01:55<00:02,  2.34s/it]                                                         Episode 50	 reward: -4.56	 makespan: 451.35	 Mean_loss: 0.32070342,  training time: 2.29
progress:  98%|[34m[0m| 49/50 [01:57<00:02,  2.34s/it]progress: 100%|[34m[0m| 50/50 [01:57<00:00,  2.33s/it]progress: 100%|[34m[0m| 50/50 [01:57<00:00,  2.35s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x10_10 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.63	 makespan: 656.25	 Mean_loss: 0.33742711,  training time: 4.49
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:40,  4.49s/it]                                                        Episode 2	 reward: -6.63	 makespan: 656.15	 Mean_loss: 0.33909300,  training time: 3.21
progress:   2%|[34m         [0m| 1/50 [00:07<03:40,  4.49s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:59,  3.74s/it]                                                        Episode 3	 reward: -6.66	 makespan: 659.25	 Mean_loss: 0.46403611,  training time: 3.20
progress:   4%|[34m         [0m| 2/50 [00:10<02:59,  3.74s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:44,  3.50s/it]                                                        Episode 4	 reward: -6.72	 makespan: 665.75	 Mean_loss: 0.46446857,  training time: 3.21
progress:   6%|[34m         [0m| 3/50 [00:14<02:44,  3.50s/it]progress:   8%|[34m         [0m| 4/50 [00:14<02:35,  3.38s/it]                                                        Episode 5	 reward: -6.69	 makespan: 662.00	 Mean_loss: 0.40883991,  training time: 3.20
progress:   8%|[34m         [0m| 4/50 [00:17<02:35,  3.38s/it]progress:  10%|[34m         [0m| 5/50 [00:17<02:29,  3.32s/it]                                                        Episode 6	 reward: -6.72	 makespan: 665.15	 Mean_loss: 0.39703712,  training time: 3.42
progress:  10%|[34m         [0m| 5/50 [00:20<02:29,  3.32s/it]progress:  12%|[34m        [0m| 6/50 [00:20<02:27,  3.35s/it]                                                        Episode 7	 reward: -6.60	 makespan: 653.20	 Mean_loss: 0.34027010,  training time: 3.21
progress:  12%|[34m        [0m| 6/50 [00:23<02:27,  3.35s/it]progress:  14%|[34m        [0m| 7/50 [00:23<02:22,  3.31s/it]                                                        Episode 8	 reward: -6.69	 makespan: 662.00	 Mean_loss: 0.33389512,  training time: 3.20
progress:  14%|[34m        [0m| 7/50 [00:27<02:22,  3.31s/it]progress:  16%|[34m        [0m| 8/50 [00:27<02:17,  3.28s/it]                                                        Episode 9	 reward: -6.54	 makespan: 647.80	 Mean_loss: 0.27127776,  training time: 3.19
progress:  16%|[34m        [0m| 8/50 [00:30<02:17,  3.28s/it]progress:  18%|[34m        [0m| 9/50 [00:30<02:13,  3.25s/it]                                                        Episode 10	 reward: -6.56	 makespan: 649.90	 Mean_loss: 0.27559468,  training time: 3.22
progress:  18%|[34m        [0m| 9/50 [00:33<02:13,  3.25s/it]progress:  20%|[34m        [0m| 10/50 [00:33<02:09,  3.24s/it]                                                         Episode 11	 reward: -6.70	 makespan: 663.10	 Mean_loss: 0.20577419,  training time: 3.23
progress:  20%|[34m        [0m| 10/50 [00:36<02:09,  3.24s/it]progress:  22%|[34m       [0m| 11/50 [00:36<02:06,  3.24s/it]                                                         Episode 12	 reward: -6.67	 makespan: 660.30	 Mean_loss: 0.19204971,  training time: 3.21
progress:  22%|[34m       [0m| 11/50 [00:40<02:06,  3.24s/it]progress:  24%|[34m       [0m| 12/50 [00:40<02:02,  3.23s/it]                                                         Episode 13	 reward: -6.49	 makespan: 642.40	 Mean_loss: 0.17367756,  training time: 3.26
progress:  24%|[34m       [0m| 12/50 [00:43<02:02,  3.23s/it]progress:  26%|[34m       [0m| 13/50 [00:43<01:59,  3.24s/it]                                                         Episode 14	 reward: -6.50	 makespan: 643.60	 Mean_loss: 0.16040054,  training time: 3.27
progress:  26%|[34m       [0m| 13/50 [00:46<01:59,  3.24s/it]progress:  28%|[34m       [0m| 14/50 [00:46<01:57,  3.25s/it]                                                         Episode 15	 reward: -6.60	 makespan: 652.95	 Mean_loss: 0.15165645,  training time: 3.23
progress:  28%|[34m       [0m| 14/50 [00:49<01:57,  3.25s/it]progress:  30%|[34m       [0m| 15/50 [00:49<01:53,  3.25s/it]                                                         Episode 16	 reward: -6.42	 makespan: 635.65	 Mean_loss: 0.14397970,  training time: 3.21
progress:  30%|[34m       [0m| 15/50 [00:53<01:53,  3.25s/it]progress:  32%|[34m      [0m| 16/50 [00:53<01:50,  3.24s/it]                                                         Episode 17	 reward: -6.46	 makespan: 639.35	 Mean_loss: 0.15039417,  training time: 3.27
progress:  32%|[34m      [0m| 16/50 [00:56<01:50,  3.24s/it]progress:  34%|[34m      [0m| 17/50 [00:56<01:47,  3.25s/it]                                                         Episode 18	 reward: -6.59	 makespan: 652.25	 Mean_loss: 0.17680305,  training time: 3.22
progress:  34%|[34m      [0m| 17/50 [00:59<01:47,  3.25s/it]progress:  36%|[34m      [0m| 18/50 [00:59<01:43,  3.24s/it]                                                         Episode 19	 reward: -6.59	 makespan: 652.25	 Mean_loss: 0.15472023,  training time: 3.24
progress:  36%|[34m      [0m| 18/50 [01:02<01:43,  3.24s/it]progress:  38%|[34m      [0m| 19/50 [01:02<01:40,  3.24s/it]                                                         Episode 20	 reward: -6.61	 makespan: 654.40	 Mean_loss: 0.15941492,  training time: 3.34
progress:  38%|[34m      [0m| 19/50 [01:06<01:40,  3.24s/it]progress:  40%|[34m      [0m| 20/50 [01:06<01:38,  3.27s/it]                                                         Episode 21	 reward: -6.58	 makespan: 651.75	 Mean_loss: 0.14504561,  training time: 3.33
progress:  40%|[34m      [0m| 20/50 [01:09<01:38,  3.27s/it]progress:  42%|[34m     [0m| 21/50 [01:09<01:35,  3.29s/it]                                                         Episode 22	 reward: -6.43	 makespan: 636.30	 Mean_loss: 0.14671463,  training time: 3.25
progress:  42%|[34m     [0m| 21/50 [01:12<01:35,  3.29s/it]progress:  44%|[34m     [0m| 22/50 [01:12<01:31,  3.28s/it]                                                         Episode 23	 reward: -6.53	 makespan: 646.10	 Mean_loss: 0.16043700,  training time: 3.21
progress:  44%|[34m     [0m| 22/50 [01:15<01:31,  3.28s/it]progress:  46%|[34m     [0m| 23/50 [01:15<01:28,  3.26s/it]                                                         Episode 24	 reward: -6.31	 makespan: 624.35	 Mean_loss: 0.13855189,  training time: 3.21
progress:  46%|[34m     [0m| 23/50 [01:19<01:28,  3.26s/it]progress:  48%|[34m     [0m| 24/50 [01:19<01:24,  3.25s/it]                                                         Episode 25	 reward: -6.42	 makespan: 635.30	 Mean_loss: 0.12734824,  training time: 3.20
progress:  48%|[34m     [0m| 24/50 [01:22<01:24,  3.25s/it]progress:  50%|[34m     [0m| 25/50 [01:22<01:20,  3.23s/it]                                                         Episode 26	 reward: -6.48	 makespan: 641.30	 Mean_loss: 0.12863170,  training time: 3.20
progress:  50%|[34m     [0m| 25/50 [01:25<01:20,  3.23s/it]progress:  52%|[34m    [0m| 26/50 [01:25<01:17,  3.22s/it]                                                         Episode 27	 reward: -6.36	 makespan: 629.20	 Mean_loss: 0.12673980,  training time: 3.18
progress:  52%|[34m    [0m| 26/50 [01:28<01:17,  3.22s/it]progress:  54%|[34m    [0m| 27/50 [01:28<01:13,  3.21s/it]                                                         Episode 28	 reward: -6.37	 makespan: 630.15	 Mean_loss: 0.12429405,  training time: 3.21
progress:  54%|[34m    [0m| 27/50 [01:31<01:13,  3.21s/it]progress:  56%|[34m    [0m| 28/50 [01:31<01:10,  3.21s/it]                                                         Episode 29	 reward: -6.33	 makespan: 627.15	 Mean_loss: 0.13816737,  training time: 3.27
progress:  56%|[34m    [0m| 28/50 [01:35<01:10,  3.21s/it]progress:  58%|[34m    [0m| 29/50 [01:35<01:07,  3.23s/it]                                                         Episode 30	 reward: -6.40	 makespan: 634.05	 Mean_loss: 0.10702328,  training time: 3.19
progress:  58%|[34m    [0m| 29/50 [01:38<01:07,  3.23s/it]progress:  60%|[34m    [0m| 30/50 [01:38<01:04,  3.22s/it]                                                         Episode 31	 reward: -6.27	 makespan: 620.60	 Mean_loss: 0.10156456,  training time: 3.21
progress:  60%|[34m    [0m| 30/50 [01:41<01:04,  3.22s/it]progress:  62%|[34m   [0m| 31/50 [01:41<01:01,  3.22s/it]                                                         Episode 32	 reward: -6.32	 makespan: 625.80	 Mean_loss: 0.10272782,  training time: 3.24
progress:  62%|[34m   [0m| 31/50 [01:44<01:01,  3.22s/it]progress:  64%|[34m   [0m| 32/50 [01:44<00:58,  3.23s/it]                                                         Episode 33	 reward: -6.27	 makespan: 621.10	 Mean_loss: 0.12073058,  training time: 3.33
progress:  64%|[34m   [0m| 32/50 [01:48<00:58,  3.23s/it]progress:  66%|[34m   [0m| 33/50 [01:48<00:55,  3.26s/it]                                                         Episode 34	 reward: -6.36	 makespan: 629.25	 Mean_loss: 0.11452512,  training time: 3.22
progress:  66%|[34m   [0m| 33/50 [01:51<00:55,  3.26s/it]progress:  68%|[34m   [0m| 34/50 [01:51<00:51,  3.25s/it]                                                         Episode 35	 reward: -6.42	 makespan: 635.95	 Mean_loss: 0.10358170,  training time: 3.26
progress:  68%|[34m   [0m| 34/50 [01:54<00:51,  3.25s/it]progress:  70%|[34m   [0m| 35/50 [01:54<00:48,  3.25s/it]                                                         Episode 36	 reward: -6.20	 makespan: 613.90	 Mean_loss: 0.11035766,  training time: 3.25
progress:  70%|[34m   [0m| 35/50 [01:57<00:48,  3.25s/it]progress:  72%|[34m  [0m| 36/50 [01:57<00:45,  3.25s/it]                                                         Episode 37	 reward: -6.32	 makespan: 626.05	 Mean_loss: 0.10002309,  training time: 3.23
progress:  72%|[34m  [0m| 36/50 [02:01<00:45,  3.25s/it]progress:  74%|[34m  [0m| 37/50 [02:01<00:42,  3.25s/it]                                                         Episode 38	 reward: -6.37	 makespan: 630.45	 Mean_loss: 0.11447316,  training time: 3.19
progress:  74%|[34m  [0m| 37/50 [02:04<00:42,  3.25s/it]progress:  76%|[34m  [0m| 38/50 [02:04<00:38,  3.23s/it]                                                         Episode 39	 reward: -6.39	 makespan: 632.75	 Mean_loss: 0.13104899,  training time: 3.24
progress:  76%|[34m  [0m| 38/50 [02:07<00:38,  3.23s/it]progress:  78%|[34m  [0m| 39/50 [02:07<00:35,  3.23s/it]                                                         Episode 40	 reward: -6.40	 makespan: 633.20	 Mean_loss: 0.12637496,  training time: 3.25
progress:  78%|[34m  [0m| 39/50 [02:10<00:35,  3.23s/it]progress:  80%|[34m  [0m| 40/50 [02:10<00:32,  3.24s/it]                                                         Episode 41	 reward: -6.25	 makespan: 618.90	 Mean_loss: 0.09621353,  training time: 3.26
progress:  80%|[34m  [0m| 40/50 [02:14<00:32,  3.24s/it]progress:  82%|[34m [0m| 41/50 [02:14<00:29,  3.25s/it]                                                         Episode 42	 reward: -6.40	 makespan: 633.25	 Mean_loss: 0.11683328,  training time: 3.27
progress:  82%|[34m [0m| 41/50 [02:17<00:29,  3.25s/it]progress:  84%|[34m [0m| 42/50 [02:17<00:26,  3.26s/it]                                                         Episode 43	 reward: -6.34	 makespan: 628.10	 Mean_loss: 0.10415828,  training time: 3.26
progress:  84%|[34m [0m| 42/50 [02:20<00:26,  3.26s/it]progress:  86%|[34m [0m| 43/50 [02:20<00:22,  3.26s/it]                                                         Episode 44	 reward: -6.28	 makespan: 621.50	 Mean_loss: 0.10245584,  training time: 3.52
progress:  86%|[34m [0m| 43/50 [02:24<00:22,  3.26s/it]progress:  88%|[34m [0m| 44/50 [02:24<00:20,  3.34s/it]                                                         Episode 45	 reward: -6.34	 makespan: 627.60	 Mean_loss: 0.11054675,  training time: 3.27
progress:  88%|[34m [0m| 44/50 [02:27<00:20,  3.34s/it]progress:  90%|[34m [0m| 45/50 [02:27<00:16,  3.32s/it]                                                         Episode 46	 reward: -6.13	 makespan: 607.35	 Mean_loss: 0.10753782,  training time: 3.15
progress:  90%|[34m [0m| 45/50 [02:30<00:16,  3.32s/it]progress:  92%|[34m[0m| 46/50 [02:30<00:13,  3.27s/it]                                                         Episode 47	 reward: -6.38	 makespan: 632.10	 Mean_loss: 0.11703209,  training time: 3.21
progress:  92%|[34m[0m| 46/50 [02:33<00:13,  3.27s/it]progress:  94%|[34m[0m| 47/50 [02:33<00:09,  3.25s/it]                                                         Episode 48	 reward: -6.22	 makespan: 615.40	 Mean_loss: 0.10204732,  training time: 3.15
progress:  94%|[34m[0m| 47/50 [02:36<00:09,  3.25s/it]progress:  96%|[34m[0m| 48/50 [02:36<00:06,  3.22s/it]                                                         Episode 49	 reward: -6.36	 makespan: 629.15	 Mean_loss: 0.11880115,  training time: 3.16
progress:  96%|[34m[0m| 48/50 [02:40<00:06,  3.22s/it]progress:  98%|[34m[0m| 49/50 [02:40<00:03,  3.20s/it]                                                         Episode 50	 reward: -6.33	 makespan: 627.10	 Mean_loss: 0.11189847,  training time: 3.20
progress:  98%|[34m[0m| 49/50 [02:43<00:03,  3.20s/it]progress: 100%|[34m[0m| 50/50 [02:43<00:00,  3.20s/it]progress: 100%|[34m[0m| 50/50 [02:43<00:00,  3.27s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x10_12 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.96	 makespan: 788.10	 Mean_loss: 0.54774714,  training time: 5.48
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:28,  5.48s/it]                                                        Episode 2	 reward: -7.99	 makespan: 791.50	 Mean_loss: 0.59175986,  training time: 4.25
progress:   2%|[34m         [0m| 1/50 [00:09<04:28,  5.48s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:48,  4.76s/it]                                                        Episode 3	 reward: -7.92	 makespan: 783.65	 Mean_loss: 0.75447792,  training time: 4.20
progress:   4%|[34m         [0m| 2/50 [00:13<03:48,  4.76s/it]progress:   6%|[34m         [0m| 3/50 [00:13<03:31,  4.51s/it]                                                        Episode 4	 reward: -7.90	 makespan: 781.80	 Mean_loss: 0.75064617,  training time: 4.15
progress:   6%|[34m         [0m| 3/50 [00:18<03:31,  4.51s/it]progress:   8%|[34m         [0m| 4/50 [00:18<03:20,  4.37s/it]                                                        Episode 5	 reward: -7.85	 makespan: 777.40	 Mean_loss: 0.71807736,  training time: 4.38
progress:   8%|[34m         [0m| 4/50 [00:22<03:20,  4.37s/it]progress:  10%|[34m         [0m| 5/50 [00:22<03:16,  4.37s/it]                                                        Episode 6	 reward: -7.96	 makespan: 787.95	 Mean_loss: 0.62827790,  training time: 4.34
progress:  10%|[34m         [0m| 5/50 [00:26<03:16,  4.37s/it]progress:  12%|[34m        [0m| 6/50 [00:26<03:12,  4.36s/it]                                                        Episode 7	 reward: -7.87	 makespan: 779.50	 Mean_loss: 0.62530005,  training time: 4.35
progress:  12%|[34m        [0m| 6/50 [00:31<03:12,  4.36s/it]progress:  14%|[34m        [0m| 7/50 [00:31<03:07,  4.36s/it]                                                        Episode 8	 reward: -7.84	 makespan: 776.60	 Mean_loss: 0.55432212,  training time: 4.28
progress:  14%|[34m        [0m| 7/50 [00:35<03:07,  4.36s/it]progress:  16%|[34m        [0m| 8/50 [00:35<03:02,  4.34s/it]                                                        Episode 9	 reward: -8.07	 makespan: 798.80	 Mean_loss: 0.52095205,  training time: 4.07
progress:  16%|[34m        [0m| 8/50 [00:39<03:02,  4.34s/it]progress:  18%|[34m        [0m| 9/50 [00:39<02:54,  4.25s/it]                                                        Episode 10	 reward: -7.88	 makespan: 780.20	 Mean_loss: 0.42911065,  training time: 4.05
progress:  18%|[34m        [0m| 9/50 [00:43<02:54,  4.25s/it]progress:  20%|[34m        [0m| 10/50 [00:43<02:47,  4.19s/it]                                                         Episode 11	 reward: -7.95	 makespan: 786.75	 Mean_loss: 0.42734429,  training time: 4.09
progress:  20%|[34m        [0m| 10/50 [00:47<02:47,  4.19s/it]progress:  22%|[34m       [0m| 11/50 [00:47<02:42,  4.16s/it]                                                         Episode 12	 reward: -8.03	 makespan: 795.35	 Mean_loss: 0.38676962,  training time: 4.04
progress:  22%|[34m       [0m| 11/50 [00:51<02:42,  4.16s/it]progress:  24%|[34m       [0m| 12/50 [00:51<02:36,  4.13s/it]                                                         Episode 13	 reward: -7.89	 makespan: 781.55	 Mean_loss: 0.29196170,  training time: 4.07
progress:  24%|[34m       [0m| 12/50 [00:55<02:36,  4.13s/it]progress:  26%|[34m       [0m| 13/50 [00:55<02:32,  4.11s/it]                                                         Episode 14	 reward: -7.81	 makespan: 773.45	 Mean_loss: 0.32377264,  training time: 4.06
progress:  26%|[34m       [0m| 13/50 [00:59<02:32,  4.11s/it]progress:  28%|[34m       [0m| 14/50 [00:59<02:27,  4.10s/it]                                                         Episode 15	 reward: -7.84	 makespan: 775.80	 Mean_loss: 0.28903770,  training time: 4.06
progress:  28%|[34m       [0m| 14/50 [01:03<02:27,  4.10s/it]progress:  30%|[34m       [0m| 15/50 [01:03<02:23,  4.09s/it]                                                         Episode 16	 reward: -7.93	 makespan: 785.35	 Mean_loss: 0.34809092,  training time: 4.30
progress:  30%|[34m       [0m| 15/50 [01:08<02:23,  4.09s/it]progress:  32%|[34m      [0m| 16/50 [01:08<02:21,  4.15s/it]                                                         Episode 17	 reward: -7.84	 makespan: 776.00	 Mean_loss: 0.29710406,  training time: 4.23
progress:  32%|[34m      [0m| 16/50 [01:12<02:21,  4.15s/it]progress:  34%|[34m      [0m| 17/50 [01:12<02:17,  4.18s/it]                                                         Episode 18	 reward: -7.97	 makespan: 789.45	 Mean_loss: 0.33398148,  training time: 4.15
progress:  34%|[34m      [0m| 17/50 [01:16<02:17,  4.18s/it]progress:  36%|[34m      [0m| 18/50 [01:16<02:13,  4.17s/it]                                                         Episode 19	 reward: -7.98	 makespan: 789.75	 Mean_loss: 0.25281963,  training time: 4.06
progress:  36%|[34m      [0m| 18/50 [01:20<02:13,  4.17s/it]progress:  38%|[34m      [0m| 19/50 [01:20<02:08,  4.14s/it]                                                         Episode 20	 reward: -7.99	 makespan: 791.50	 Mean_loss: 0.27300781,  training time: 4.20
progress:  38%|[34m      [0m| 19/50 [01:24<02:08,  4.14s/it]progress:  40%|[34m      [0m| 20/50 [01:24<02:04,  4.16s/it]                                                         Episode 21	 reward: -8.04	 makespan: 795.90	 Mean_loss: 0.28124064,  training time: 4.14
progress:  40%|[34m      [0m| 20/50 [01:29<02:04,  4.16s/it]progress:  42%|[34m     [0m| 21/50 [01:29<02:00,  4.16s/it]                                                         Episode 22	 reward: -7.86	 makespan: 777.75	 Mean_loss: 0.22418287,  training time: 4.10
progress:  42%|[34m     [0m| 21/50 [01:33<02:00,  4.16s/it]progress:  44%|[34m     [0m| 22/50 [01:33<01:55,  4.14s/it]                                                         Episode 23	 reward: -7.78	 makespan: 770.15	 Mean_loss: 0.26221773,  training time: 4.31
progress:  44%|[34m     [0m| 22/50 [01:37<01:55,  4.14s/it]progress:  46%|[34m     [0m| 23/50 [01:37<01:53,  4.20s/it]                                                         Episode 24	 reward: -7.85	 makespan: 777.50	 Mean_loss: 0.24636453,  training time: 4.08
progress:  46%|[34m     [0m| 23/50 [01:41<01:53,  4.20s/it]progress:  48%|[34m     [0m| 24/50 [01:41<01:48,  4.16s/it]                                                         Episode 25	 reward: -8.00	 makespan: 792.20	 Mean_loss: 0.25737643,  training time: 4.10
progress:  48%|[34m     [0m| 24/50 [01:45<01:48,  4.16s/it]progress:  50%|[34m     [0m| 25/50 [01:45<01:43,  4.15s/it]                                                         Episode 26	 reward: -7.70	 makespan: 762.35	 Mean_loss: 0.19639656,  training time: 4.28
progress:  50%|[34m     [0m| 25/50 [01:49<01:43,  4.15s/it]progress:  52%|[34m    [0m| 26/50 [01:49<01:40,  4.19s/it]                                                         Episode 27	 reward: -7.66	 makespan: 758.75	 Mean_loss: 0.24257827,  training time: 4.06
progress:  52%|[34m    [0m| 26/50 [01:54<01:40,  4.19s/it]progress:  54%|[34m    [0m| 27/50 [01:54<01:35,  4.15s/it]                                                         Episode 28	 reward: -7.70	 makespan: 762.65	 Mean_loss: 0.22818747,  training time: 4.09
progress:  54%|[34m    [0m| 27/50 [01:58<01:35,  4.15s/it]progress:  56%|[34m    [0m| 28/50 [01:58<01:31,  4.14s/it]                                                         Episode 29	 reward: -7.64	 makespan: 756.75	 Mean_loss: 0.18175648,  training time: 4.16
progress:  56%|[34m    [0m| 28/50 [02:02<01:31,  4.14s/it]progress:  58%|[34m    [0m| 29/50 [02:02<01:27,  4.14s/it]                                                         Episode 30	 reward: -7.66	 makespan: 758.15	 Mean_loss: 0.19387259,  training time: 4.14
progress:  58%|[34m    [0m| 29/50 [02:06<01:27,  4.14s/it]progress:  60%|[34m    [0m| 30/50 [02:06<01:22,  4.15s/it]                                                         Episode 31	 reward: -7.62	 makespan: 754.20	 Mean_loss: 0.20977655,  training time: 4.28
progress:  60%|[34m    [0m| 30/50 [02:10<01:22,  4.15s/it]progress:  62%|[34m   [0m| 31/50 [02:10<01:19,  4.19s/it]                                                         Episode 32	 reward: -7.63	 makespan: 755.10	 Mean_loss: 0.22926208,  training time: 4.33
progress:  62%|[34m   [0m| 31/50 [02:15<01:19,  4.19s/it]progress:  64%|[34m   [0m| 32/50 [02:15<01:16,  4.23s/it]                                                         Episode 33	 reward: -7.68	 makespan: 760.60	 Mean_loss: 0.21552958,  training time: 4.06
progress:  64%|[34m   [0m| 32/50 [02:19<01:16,  4.23s/it]progress:  66%|[34m   [0m| 33/50 [02:19<01:11,  4.18s/it]                                                         Episode 34	 reward: -7.54	 makespan: 746.55	 Mean_loss: 0.15275142,  training time: 4.03
progress:  66%|[34m   [0m| 33/50 [02:23<01:11,  4.18s/it]progress:  68%|[34m   [0m| 34/50 [02:23<01:06,  4.14s/it]                                                         Episode 35	 reward: -7.64	 makespan: 756.60	 Mean_loss: 0.18079373,  training time: 4.05
progress:  68%|[34m   [0m| 34/50 [02:27<01:06,  4.14s/it]progress:  70%|[34m   [0m| 35/50 [02:27<01:01,  4.11s/it]                                                         Episode 36	 reward: -7.71	 makespan: 762.85	 Mean_loss: 0.18613178,  training time: 4.04
progress:  70%|[34m   [0m| 35/50 [02:31<01:01,  4.11s/it]progress:  72%|[34m  [0m| 36/50 [02:31<00:57,  4.09s/it]                                                         Episode 37	 reward: -7.54	 makespan: 746.25	 Mean_loss: 0.18499026,  training time: 4.09
progress:  72%|[34m  [0m| 36/50 [02:35<00:57,  4.09s/it]progress:  74%|[34m  [0m| 37/50 [02:35<00:53,  4.09s/it]                                                         Episode 38	 reward: -7.51	 makespan: 743.40	 Mean_loss: 0.18687302,  training time: 4.04
progress:  74%|[34m  [0m| 37/50 [02:39<00:53,  4.09s/it]progress:  76%|[34m  [0m| 38/50 [02:39<00:48,  4.08s/it]                                                         Episode 39	 reward: -7.57	 makespan: 749.65	 Mean_loss: 0.16468203,  training time: 4.15
progress:  76%|[34m  [0m| 38/50 [02:43<00:48,  4.08s/it]progress:  78%|[34m  [0m| 39/50 [02:43<00:45,  4.10s/it]                                                         Episode 40	 reward: -7.53	 makespan: 745.15	 Mean_loss: 0.18218736,  training time: 4.06
progress:  78%|[34m  [0m| 39/50 [02:47<00:45,  4.10s/it]progress:  80%|[34m  [0m| 40/50 [02:47<00:40,  4.09s/it]                                                         Episode 41	 reward: -7.76	 makespan: 768.65	 Mean_loss: 0.16476640,  training time: 4.10
progress:  80%|[34m  [0m| 40/50 [02:51<00:40,  4.09s/it]progress:  82%|[34m [0m| 41/50 [02:51<00:36,  4.10s/it]                                                         Episode 42	 reward: -7.46	 makespan: 738.65	 Mean_loss: 0.15463535,  training time: 4.16
progress:  82%|[34m [0m| 41/50 [02:55<00:36,  4.10s/it]progress:  84%|[34m [0m| 42/50 [02:55<00:32,  4.11s/it]                                                         Episode 43	 reward: -7.53	 makespan: 745.50	 Mean_loss: 0.18085130,  training time: 4.05
progress:  84%|[34m [0m| 42/50 [02:59<00:32,  4.11s/it]progress:  86%|[34m [0m| 43/50 [02:59<00:28,  4.10s/it]                                                         Episode 44	 reward: -7.49	 makespan: 741.70	 Mean_loss: 0.21194664,  training time: 4.07
progress:  86%|[34m [0m| 43/50 [03:04<00:28,  4.10s/it]progress:  88%|[34m [0m| 44/50 [03:04<00:24,  4.09s/it]                                                         Episode 45	 reward: -7.52	 makespan: 744.70	 Mean_loss: 0.17571269,  training time: 4.28
progress:  88%|[34m [0m| 44/50 [03:08<00:24,  4.09s/it]progress:  90%|[34m [0m| 45/50 [03:08<00:20,  4.15s/it]                                                         Episode 46	 reward: -7.60	 makespan: 752.35	 Mean_loss: 0.15267678,  training time: 4.26
progress:  90%|[34m [0m| 45/50 [03:12<00:20,  4.15s/it]progress:  92%|[34m[0m| 46/50 [03:12<00:16,  4.18s/it]                                                         Episode 47	 reward: -7.55	 makespan: 747.40	 Mean_loss: 0.17702444,  training time: 4.29
progress:  92%|[34m[0m| 46/50 [03:16<00:16,  4.18s/it]progress:  94%|[34m[0m| 47/50 [03:16<00:12,  4.22s/it]                                                         Episode 48	 reward: -7.44	 makespan: 736.35	 Mean_loss: 0.14611359,  training time: 4.05
progress:  94%|[34m[0m| 47/50 [03:20<00:12,  4.22s/it]progress:  96%|[34m[0m| 48/50 [03:20<00:08,  4.17s/it]                                                         Episode 49	 reward: -7.57	 makespan: 749.30	 Mean_loss: 0.15941547,  training time: 4.06
progress:  96%|[34m[0m| 48/50 [03:24<00:08,  4.17s/it]progress:  98%|[34m[0m| 49/50 [03:24<00:04,  4.14s/it]                                                         Episode 50	 reward: -7.34	 makespan: 727.00	 Mean_loss: 0.13787839,  training time: 4.11
progress:  98%|[34m[0m| 49/50 [03:29<00:04,  4.14s/it]progress: 100%|[34m[0m| 50/50 [03:29<00:00,  4.13s/it]progress: 100%|[34m[0m| 50/50 [03:29<00:00,  4.18s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x7_4 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -3.76	 makespan: 372.60	 Mean_loss: 0.04424442,  training time: 2.45
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:00,  2.45s/it]                                                        Episode 2	 reward: -3.65	 makespan: 361.60	 Mean_loss: 0.02066629,  training time: 1.30
progress:   2%|[34m         [0m| 1/50 [00:03<02:00,  2.45s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:25,  1.78s/it]                                                        Episode 3	 reward: -3.65	 makespan: 361.50	 Mean_loss: -0.00329385,  training time: 1.26
progress:   4%|[34m         [0m| 2/50 [00:05<01:25,  1.78s/it]progress:   6%|[34m         [0m| 3/50 [00:05<01:12,  1.55s/it]                                                        Episode 4	 reward: -3.74	 makespan: 370.75	 Mean_loss: 0.01470669,  training time: 1.38
progress:   6%|[34m         [0m| 3/50 [00:06<01:12,  1.55s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:08,  1.48s/it]                                                        Episode 5	 reward: -3.74	 makespan: 370.50	 Mean_loss: 0.02054670,  training time: 1.34
progress:   8%|[34m         [0m| 4/50 [00:07<01:08,  1.48s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:04,  1.43s/it]                                                        Episode 6	 reward: -3.77	 makespan: 373.05	 Mean_loss: 0.03629950,  training time: 1.29
progress:  10%|[34m         [0m| 5/50 [00:09<01:04,  1.43s/it]progress:  12%|[34m        [0m| 6/50 [00:09<01:01,  1.39s/it]                                                        Episode 7	 reward: -3.79	 makespan: 375.15	 Mean_loss: 0.02217154,  training time: 1.28
progress:  12%|[34m        [0m| 6/50 [00:10<01:01,  1.39s/it]progress:  14%|[34m        [0m| 7/50 [00:10<00:58,  1.35s/it]                                                        Episode 8	 reward: -3.72	 makespan: 368.50	 Mean_loss: 0.01758930,  training time: 1.33
progress:  14%|[34m        [0m| 7/50 [00:11<00:58,  1.35s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:56,  1.35s/it]                                                        Episode 9	 reward: -3.71	 makespan: 367.10	 Mean_loss: 0.02226136,  training time: 1.32
progress:  16%|[34m        [0m| 8/50 [00:12<00:56,  1.35s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:54,  1.34s/it]                                                        Episode 10	 reward: -3.68	 makespan: 363.90	 Mean_loss: 0.00660451,  training time: 1.27
progress:  18%|[34m        [0m| 9/50 [00:14<00:54,  1.34s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:52,  1.32s/it]                                                         Episode 11	 reward: -3.74	 makespan: 370.50	 Mean_loss: 0.03903316,  training time: 1.29
progress:  20%|[34m        [0m| 10/50 [00:15<00:52,  1.32s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:51,  1.31s/it]                                                         Episode 12	 reward: -3.68	 makespan: 364.65	 Mean_loss: 0.03778109,  training time: 1.41
progress:  22%|[34m       [0m| 11/50 [00:16<00:51,  1.31s/it]progress:  24%|[34m       [0m| 12/50 [00:16<00:51,  1.34s/it]                                                         Episode 13	 reward: -3.74	 makespan: 370.15	 Mean_loss: 0.02565304,  training time: 1.28
progress:  24%|[34m       [0m| 12/50 [00:18<00:51,  1.34s/it]progress:  26%|[34m       [0m| 13/50 [00:18<00:48,  1.32s/it]                                                         Episode 14	 reward: -3.63	 makespan: 359.15	 Mean_loss: 0.00908575,  training time: 1.30
progress:  26%|[34m       [0m| 13/50 [00:19<00:48,  1.32s/it]progress:  28%|[34m       [0m| 14/50 [00:19<00:47,  1.32s/it]                                                         Episode 15	 reward: -3.75	 makespan: 371.65	 Mean_loss: 0.04270679,  training time: 1.33
progress:  28%|[34m       [0m| 14/50 [00:20<00:47,  1.32s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:46,  1.32s/it]                                                         Episode 16	 reward: -3.65	 makespan: 361.00	 Mean_loss: 0.00898276,  training time: 1.30
progress:  30%|[34m       [0m| 15/50 [00:22<00:46,  1.32s/it]progress:  32%|[34m      [0m| 16/50 [00:22<00:44,  1.32s/it]                                                         Episode 17	 reward: -3.75	 makespan: 371.30	 Mean_loss: 0.02047060,  training time: 1.30
progress:  32%|[34m      [0m| 16/50 [00:23<00:44,  1.32s/it]progress:  34%|[34m      [0m| 17/50 [00:23<00:43,  1.31s/it]                                                         Episode 18	 reward: -3.69	 makespan: 364.90	 Mean_loss: 0.04938583,  training time: 1.29
progress:  34%|[34m      [0m| 17/50 [00:24<00:43,  1.31s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:41,  1.31s/it]                                                         Episode 19	 reward: -3.79	 makespan: 375.45	 Mean_loss: 0.01874615,  training time: 1.26
progress:  36%|[34m      [0m| 18/50 [00:26<00:41,  1.31s/it]progress:  38%|[34m      [0m| 19/50 [00:26<00:40,  1.30s/it]                                                         Episode 20	 reward: -3.73	 makespan: 369.15	 Mean_loss: 0.02767488,  training time: 1.30
progress:  38%|[34m      [0m| 19/50 [00:27<00:40,  1.30s/it]progress:  40%|[34m      [0m| 20/50 [00:27<00:38,  1.30s/it]                                                         Episode 21	 reward: -3.62	 makespan: 358.25	 Mean_loss: 0.02568784,  training time: 1.41
progress:  40%|[34m      [0m| 20/50 [00:28<00:38,  1.30s/it]progress:  42%|[34m     [0m| 21/50 [00:28<00:38,  1.33s/it]                                                         Episode 22	 reward: -3.77	 makespan: 373.00	 Mean_loss: 0.02197118,  training time: 1.28
progress:  42%|[34m     [0m| 21/50 [00:30<00:38,  1.33s/it]progress:  44%|[34m     [0m| 22/50 [00:30<00:36,  1.32s/it]                                                         Episode 23	 reward: -3.72	 makespan: 367.80	 Mean_loss: 0.04226930,  training time: 1.29
progress:  44%|[34m     [0m| 22/50 [00:31<00:36,  1.32s/it]progress:  46%|[34m     [0m| 23/50 [00:31<00:35,  1.31s/it]                                                         Episode 24	 reward: -3.69	 makespan: 364.85	 Mean_loss: 0.03881955,  training time: 1.29
progress:  46%|[34m     [0m| 23/50 [00:32<00:35,  1.31s/it]progress:  48%|[34m     [0m| 24/50 [00:32<00:33,  1.30s/it]                                                         Episode 25	 reward: -3.77	 makespan: 373.05	 Mean_loss: 0.04220361,  training time: 1.40
progress:  48%|[34m     [0m| 24/50 [00:34<00:33,  1.30s/it]progress:  50%|[34m     [0m| 25/50 [00:34<00:33,  1.33s/it]                                                         Episode 26	 reward: -3.67	 makespan: 363.65	 Mean_loss: 0.01738337,  training time: 1.26
progress:  50%|[34m     [0m| 25/50 [00:35<00:33,  1.33s/it]progress:  52%|[34m    [0m| 26/50 [00:35<00:31,  1.31s/it]                                                         Episode 27	 reward: -3.66	 makespan: 362.15	 Mean_loss: 0.01895824,  training time: 1.29
progress:  52%|[34m    [0m| 26/50 [00:36<00:31,  1.31s/it]progress:  54%|[34m    [0m| 27/50 [00:36<00:30,  1.31s/it]                                                         Episode 28	 reward: -3.67	 makespan: 362.85	 Mean_loss: 0.03644058,  training time: 1.23
progress:  54%|[34m    [0m| 27/50 [00:37<00:30,  1.31s/it]progress:  56%|[34m    [0m| 28/50 [00:37<00:28,  1.29s/it]                                                         Episode 29	 reward: -3.68	 makespan: 364.80	 Mean_loss: 0.00383027,  training time: 1.25
progress:  56%|[34m    [0m| 28/50 [00:39<00:28,  1.29s/it]progress:  58%|[34m    [0m| 29/50 [00:39<00:26,  1.28s/it]                                                         Episode 30	 reward: -3.63	 makespan: 359.55	 Mean_loss: 0.02795001,  training time: 1.22
progress:  58%|[34m    [0m| 29/50 [00:40<00:26,  1.28s/it]progress:  60%|[34m    [0m| 30/50 [00:40<00:25,  1.26s/it]                                                         Episode 31	 reward: -3.69	 makespan: 365.45	 Mean_loss: -0.00694654,  training time: 1.23
progress:  60%|[34m    [0m| 30/50 [00:41<00:25,  1.26s/it]progress:  62%|[34m   [0m| 31/50 [00:41<00:23,  1.25s/it]                                                         Episode 32	 reward: -3.64	 makespan: 360.60	 Mean_loss: 0.02723971,  training time: 1.24
progress:  62%|[34m   [0m| 31/50 [00:42<00:23,  1.25s/it]progress:  64%|[34m   [0m| 32/50 [00:42<00:22,  1.25s/it]                                                         Episode 33	 reward: -3.70	 makespan: 366.70	 Mean_loss: 0.02419451,  training time: 1.37
progress:  64%|[34m   [0m| 32/50 [00:44<00:22,  1.25s/it]progress:  66%|[34m   [0m| 33/50 [00:44<00:21,  1.29s/it]                                                         Episode 34	 reward: -3.81	 makespan: 377.10	 Mean_loss: 0.03603170,  training time: 1.23
progress:  66%|[34m   [0m| 33/50 [00:45<00:21,  1.29s/it]progress:  68%|[34m   [0m| 34/50 [00:45<00:20,  1.27s/it]                                                         Episode 35	 reward: -3.74	 makespan: 369.95	 Mean_loss: 0.00285396,  training time: 1.24
progress:  68%|[34m   [0m| 34/50 [00:46<00:20,  1.27s/it]progress:  70%|[34m   [0m| 35/50 [00:46<00:18,  1.26s/it]                                                         Episode 36	 reward: -3.81	 makespan: 377.55	 Mean_loss: 0.04000075,  training time: 1.32
progress:  70%|[34m   [0m| 35/50 [00:47<00:18,  1.26s/it]progress:  72%|[34m  [0m| 36/50 [00:47<00:17,  1.28s/it]                                                         Episode 37	 reward: -3.66	 makespan: 361.95	 Mean_loss: 0.01266739,  training time: 1.35
progress:  72%|[34m  [0m| 36/50 [00:49<00:17,  1.28s/it]progress:  74%|[34m  [0m| 37/50 [00:49<00:16,  1.30s/it]                                                         Episode 38	 reward: -3.80	 makespan: 376.30	 Mean_loss: 0.03997593,  training time: 1.24
progress:  74%|[34m  [0m| 37/50 [00:50<00:16,  1.30s/it]progress:  76%|[34m  [0m| 38/50 [00:50<00:15,  1.28s/it]                                                         Episode 39	 reward: -3.73	 makespan: 369.10	 Mean_loss: 0.01542206,  training time: 1.36
progress:  76%|[34m  [0m| 38/50 [00:51<00:15,  1.28s/it]progress:  78%|[34m  [0m| 39/50 [00:51<00:14,  1.31s/it]                                                         Episode 40	 reward: -3.61	 makespan: 357.00	 Mean_loss: 0.02495669,  training time: 1.29
progress:  78%|[34m  [0m| 39/50 [00:53<00:14,  1.31s/it]progress:  80%|[34m  [0m| 40/50 [00:53<00:13,  1.30s/it]                                                         Episode 41	 reward: -3.80	 makespan: 376.20	 Mean_loss: 0.04119631,  training time: 1.40
progress:  80%|[34m  [0m| 40/50 [00:54<00:13,  1.30s/it]progress:  82%|[34m [0m| 41/50 [00:54<00:12,  1.33s/it]                                                         Episode 42	 reward: -3.68	 makespan: 364.15	 Mean_loss: 0.03185785,  training time: 1.25
progress:  82%|[34m [0m| 41/50 [00:55<00:12,  1.33s/it]progress:  84%|[34m [0m| 42/50 [00:55<00:10,  1.31s/it]                                                         Episode 43	 reward: -3.64	 makespan: 360.10	 Mean_loss: 0.02372371,  training time: 1.35
progress:  84%|[34m [0m| 42/50 [00:57<00:10,  1.31s/it]progress:  86%|[34m [0m| 43/50 [00:57<00:09,  1.32s/it]                                                         Episode 44	 reward: -3.67	 makespan: 363.75	 Mean_loss: 0.01749465,  training time: 1.29
progress:  86%|[34m [0m| 43/50 [00:58<00:09,  1.32s/it]progress:  88%|[34m [0m| 44/50 [00:58<00:07,  1.31s/it]                                                         Episode 45	 reward: -3.71	 makespan: 366.90	 Mean_loss: 0.03915962,  training time: 1.31
progress:  88%|[34m [0m| 44/50 [00:59<00:07,  1.31s/it]progress:  90%|[34m [0m| 45/50 [00:59<00:06,  1.31s/it]                                                         Episode 46	 reward: -3.63	 makespan: 359.20	 Mean_loss: 0.01901653,  training time: 1.30
progress:  90%|[34m [0m| 45/50 [01:01<00:06,  1.31s/it]progress:  92%|[34m[0m| 46/50 [01:01<00:05,  1.31s/it]                                                         Episode 47	 reward: -3.60	 makespan: 356.35	 Mean_loss: 0.02505224,  training time: 1.29
progress:  92%|[34m[0m| 46/50 [01:02<00:05,  1.31s/it]progress:  94%|[34m[0m| 47/50 [01:02<00:03,  1.30s/it]                                                         Episode 48	 reward: -3.58	 makespan: 354.35	 Mean_loss: 0.03713339,  training time: 1.29
progress:  94%|[34m[0m| 47/50 [01:03<00:03,  1.30s/it]progress:  96%|[34m[0m| 48/50 [01:03<00:02,  1.30s/it]                                                         Episode 49	 reward: -3.70	 makespan: 366.20	 Mean_loss: 0.03317238,  training time: 1.29
progress:  96%|[34m[0m| 48/50 [01:05<00:02,  1.30s/it]progress:  98%|[34m[0m| 49/50 [01:05<00:01,  1.30s/it]                                                         Episode 50	 reward: -3.73	 makespan: 369.00	 Mean_loss: 0.03841457,  training time: 1.30
progress:  98%|[34m[0m| 49/50 [01:06<00:01,  1.30s/it]progress: 100%|[34m[0m| 50/50 [01:06<00:00,  1.30s/it]progress: 100%|[34m[0m| 50/50 [01:06<00:00,  1.33s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x7_7 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.90	 makespan: 584.30	 Mean_loss: -0.48402730,  training time: 3.40
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:46,  3.41s/it]                                                        Episode 2	 reward: -5.77	 makespan: 571.70	 Mean_loss: -0.64710033,  training time: 2.16
progress:   2%|[34m         [0m| 1/50 [00:05<02:46,  3.41s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:08,  2.68s/it]                                                        Episode 3	 reward: -5.67	 makespan: 561.20	 Mean_loss: -0.52022707,  training time: 2.20
progress:   4%|[34m         [0m| 2/50 [00:07<02:08,  2.68s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:55,  2.46s/it]                                                        Episode 4	 reward: -5.72	 makespan: 566.60	 Mean_loss: -0.49565390,  training time: 2.35
progress:   6%|[34m         [0m| 3/50 [00:10<01:55,  2.46s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:51,  2.42s/it]                                                        Episode 5	 reward: -5.81	 makespan: 575.65	 Mean_loss: -0.50140208,  training time: 2.24
progress:   8%|[34m         [0m| 4/50 [00:12<01:51,  2.42s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:45,  2.35s/it]                                                        Episode 6	 reward: -5.80	 makespan: 574.15	 Mean_loss: -0.32343411,  training time: 2.32
progress:  10%|[34m         [0m| 5/50 [00:14<01:45,  2.35s/it]progress:  12%|[34m        [0m| 6/50 [00:14<01:43,  2.34s/it]                                                        Episode 7	 reward: -5.74	 makespan: 568.40	 Mean_loss: -0.22632319,  training time: 2.23
progress:  12%|[34m        [0m| 6/50 [00:16<01:43,  2.34s/it]progress:  14%|[34m        [0m| 7/50 [00:16<01:39,  2.31s/it]                                                        Episode 8	 reward: -5.79	 makespan: 573.15	 Mean_loss: -0.14758673,  training time: 2.24
progress:  14%|[34m        [0m| 7/50 [00:19<01:39,  2.31s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:36,  2.29s/it]                                                        Episode 9	 reward: -5.76	 makespan: 570.15	 Mean_loss: 0.04613667,  training time: 2.28
progress:  16%|[34m        [0m| 8/50 [00:21<01:36,  2.29s/it]progress:  18%|[34m        [0m| 9/50 [00:21<01:33,  2.29s/it]                                                        Episode 10	 reward: -5.97	 makespan: 590.75	 Mean_loss: 0.14541189,  training time: 2.29
progress:  18%|[34m        [0m| 9/50 [00:23<01:33,  2.29s/it]progress:  20%|[34m        [0m| 10/50 [00:23<01:31,  2.29s/it]                                                         Episode 11	 reward: -5.73	 makespan: 567.10	 Mean_loss: 0.32769138,  training time: 2.27
progress:  20%|[34m        [0m| 10/50 [00:26<01:31,  2.29s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:29,  2.28s/it]                                                         Episode 12	 reward: -5.72	 makespan: 566.60	 Mean_loss: 0.32520360,  training time: 2.18
progress:  22%|[34m       [0m| 11/50 [00:28<01:29,  2.28s/it]progress:  24%|[34m       [0m| 12/50 [00:28<01:25,  2.25s/it]                                                         Episode 13	 reward: -5.82	 makespan: 576.25	 Mean_loss: 0.63128948,  training time: 2.29
progress:  24%|[34m       [0m| 12/50 [00:30<01:25,  2.25s/it]progress:  26%|[34m       [0m| 13/50 [00:30<01:23,  2.27s/it]                                                         Episode 14	 reward: -5.91	 makespan: 584.80	 Mean_loss: 0.39509702,  training time: 2.24
progress:  26%|[34m       [0m| 13/50 [00:32<01:23,  2.27s/it]progress:  28%|[34m       [0m| 14/50 [00:32<01:21,  2.26s/it]                                                         Episode 15	 reward: -5.78	 makespan: 572.35	 Mean_loss: 0.13301435,  training time: 2.26
progress:  28%|[34m       [0m| 14/50 [00:35<01:21,  2.26s/it]progress:  30%|[34m       [0m| 15/50 [00:35<01:19,  2.26s/it]                                                         Episode 16	 reward: -5.77	 makespan: 571.40	 Mean_loss: -0.16353327,  training time: 2.21
progress:  30%|[34m       [0m| 15/50 [00:37<01:19,  2.26s/it]progress:  32%|[34m      [0m| 16/50 [00:37<01:16,  2.25s/it]                                                         Episode 17	 reward: -5.75	 makespan: 568.90	 Mean_loss: 0.67690694,  training time: 2.21
progress:  32%|[34m      [0m| 16/50 [00:39<01:16,  2.25s/it]progress:  34%|[34m      [0m| 17/50 [00:39<01:13,  2.24s/it]                                                         Episode 18	 reward: -5.70	 makespan: 563.85	 Mean_loss: 0.31908485,  training time: 2.32
progress:  34%|[34m      [0m| 17/50 [00:41<01:13,  2.24s/it]progress:  36%|[34m      [0m| 18/50 [00:41<01:12,  2.26s/it]                                                         Episode 19	 reward: -5.59	 makespan: 553.10	 Mean_loss: 0.77815640,  training time: 2.26
progress:  36%|[34m      [0m| 18/50 [00:44<01:12,  2.26s/it]progress:  38%|[34m      [0m| 19/50 [00:44<01:10,  2.26s/it]                                                         Episode 20	 reward: -5.62	 makespan: 555.90	 Mean_loss: 0.53162009,  training time: 2.26
progress:  38%|[34m      [0m| 19/50 [00:46<01:10,  2.26s/it]progress:  40%|[34m      [0m| 20/50 [00:46<01:07,  2.26s/it]                                                         Episode 21	 reward: -5.72	 makespan: 565.80	 Mean_loss: 0.32703593,  training time: 2.30
progress:  40%|[34m      [0m| 20/50 [00:48<01:07,  2.26s/it]progress:  42%|[34m     [0m| 21/50 [00:48<01:06,  2.28s/it]                                                         Episode 22	 reward: -5.58	 makespan: 552.45	 Mean_loss: 0.57253802,  training time: 2.26
progress:  42%|[34m     [0m| 21/50 [00:50<01:06,  2.28s/it]progress:  44%|[34m     [0m| 22/50 [00:50<01:03,  2.27s/it]                                                         Episode 23	 reward: -5.67	 makespan: 561.50	 Mean_loss: 0.18870401,  training time: 2.23
progress:  44%|[34m     [0m| 22/50 [00:53<01:03,  2.27s/it]progress:  46%|[34m     [0m| 23/50 [00:53<01:01,  2.26s/it]                                                         Episode 24	 reward: -5.66	 makespan: 560.30	 Mean_loss: 0.68740696,  training time: 2.20
progress:  46%|[34m     [0m| 23/50 [00:55<01:01,  2.26s/it]progress:  48%|[34m     [0m| 24/50 [00:55<00:58,  2.25s/it]                                                         Episode 25	 reward: -5.67	 makespan: 561.70	 Mean_loss: 0.59390593,  training time: 2.33
progress:  48%|[34m     [0m| 24/50 [00:57<00:58,  2.25s/it]progress:  50%|[34m     [0m| 25/50 [00:57<00:56,  2.27s/it]                                                         Episode 26	 reward: -5.61	 makespan: 555.55	 Mean_loss: 0.71328735,  training time: 2.22
progress:  50%|[34m     [0m| 25/50 [00:59<00:56,  2.27s/it]progress:  52%|[34m    [0m| 26/50 [00:59<00:54,  2.26s/it]                                                         Episode 27	 reward: -5.73	 makespan: 567.00	 Mean_loss: 0.34591818,  training time: 2.15
progress:  52%|[34m    [0m| 26/50 [01:02<00:54,  2.26s/it]progress:  54%|[34m    [0m| 27/50 [01:02<00:51,  2.23s/it]                                                         Episode 28	 reward: -5.59	 makespan: 553.90	 Mean_loss: 0.76705712,  training time: 2.17
progress:  54%|[34m    [0m| 27/50 [01:04<00:51,  2.23s/it]progress:  56%|[34m    [0m| 28/50 [01:04<00:48,  2.21s/it]                                                         Episode 29	 reward: -5.81	 makespan: 574.85	 Mean_loss: 0.70945823,  training time: 2.14
progress:  56%|[34m    [0m| 28/50 [01:06<00:48,  2.21s/it]progress:  58%|[34m    [0m| 29/50 [01:06<00:46,  2.19s/it]                                                         Episode 30	 reward: -5.65	 makespan: 559.50	 Mean_loss: 0.45872927,  training time: 2.18
progress:  58%|[34m    [0m| 29/50 [01:08<00:46,  2.19s/it]progress:  60%|[34m    [0m| 30/50 [01:08<00:43,  2.19s/it]                                                         Episode 31	 reward: -5.71	 makespan: 565.55	 Mean_loss: 0.04244891,  training time: 2.15
progress:  60%|[34m    [0m| 30/50 [01:10<00:43,  2.19s/it]progress:  62%|[34m   [0m| 31/50 [01:10<00:41,  2.18s/it]                                                         Episode 32	 reward: -5.62	 makespan: 556.30	 Mean_loss: 0.62783635,  training time: 2.18
progress:  62%|[34m   [0m| 31/50 [01:12<00:41,  2.18s/it]progress:  64%|[34m   [0m| 32/50 [01:12<00:39,  2.18s/it]                                                         Episode 33	 reward: -5.72	 makespan: 566.15	 Mean_loss: 0.48522246,  training time: 2.24
progress:  64%|[34m   [0m| 32/50 [01:15<00:39,  2.18s/it]progress:  66%|[34m   [0m| 33/50 [01:15<00:37,  2.20s/it]                                                         Episode 34	 reward: -5.70	 makespan: 564.25	 Mean_loss: -0.39268261,  training time: 2.22
progress:  66%|[34m   [0m| 33/50 [01:17<00:37,  2.20s/it]progress:  68%|[34m   [0m| 34/50 [01:17<00:35,  2.21s/it]                                                         Episode 35	 reward: -5.58	 makespan: 552.75	 Mean_loss: 0.47031564,  training time: 2.23
progress:  68%|[34m   [0m| 34/50 [01:19<00:35,  2.21s/it]progress:  70%|[34m   [0m| 35/50 [01:19<00:33,  2.22s/it]                                                         Episode 36	 reward: -5.58	 makespan: 552.45	 Mean_loss: 0.45783263,  training time: 2.17
progress:  70%|[34m   [0m| 35/50 [01:21<00:33,  2.22s/it]progress:  72%|[34m  [0m| 36/50 [01:21<00:30,  2.21s/it]                                                         Episode 37	 reward: -5.66	 makespan: 560.40	 Mean_loss: 0.85256332,  training time: 2.22
progress:  72%|[34m  [0m| 36/50 [01:23<00:30,  2.21s/it]progress:  74%|[34m  [0m| 37/50 [01:24<00:28,  2.21s/it]                                                         Episode 38	 reward: -5.82	 makespan: 576.35	 Mean_loss: -0.28005818,  training time: 2.21
progress:  74%|[34m  [0m| 37/50 [01:26<00:28,  2.21s/it]progress:  76%|[34m  [0m| 38/50 [01:26<00:26,  2.21s/it]                                                         Episode 39	 reward: -5.79	 makespan: 573.30	 Mean_loss: 0.90779161,  training time: 2.20
progress:  76%|[34m  [0m| 38/50 [01:28<00:26,  2.21s/it]progress:  78%|[34m  [0m| 39/50 [01:28<00:24,  2.21s/it]                                                         Episode 40	 reward: -5.80	 makespan: 574.45	 Mean_loss: 0.55073100,  training time: 2.21
progress:  78%|[34m  [0m| 39/50 [01:30<00:24,  2.21s/it]progress:  80%|[34m  [0m| 40/50 [01:30<00:22,  2.21s/it]                                                         Episode 41	 reward: -5.71	 makespan: 565.25	 Mean_loss: 0.18989673,  training time: 2.22
progress:  80%|[34m  [0m| 40/50 [01:32<00:22,  2.21s/it]progress:  82%|[34m [0m| 41/50 [01:32<00:19,  2.22s/it]                                                         Episode 42	 reward: -5.79	 makespan: 573.65	 Mean_loss: 0.84537053,  training time: 2.24
progress:  82%|[34m [0m| 41/50 [01:35<00:19,  2.22s/it]progress:  84%|[34m [0m| 42/50 [01:35<00:17,  2.22s/it]                                                         Episode 43	 reward: -5.78	 makespan: 571.90	 Mean_loss: -0.34521970,  training time: 2.20
progress:  84%|[34m [0m| 42/50 [01:37<00:17,  2.22s/it]progress:  86%|[34m [0m| 43/50 [01:37<00:15,  2.22s/it]                                                         Episode 44	 reward: -5.83	 makespan: 576.90	 Mean_loss: 0.75356275,  training time: 2.20
progress:  86%|[34m [0m| 43/50 [01:39<00:15,  2.22s/it]progress:  88%|[34m [0m| 44/50 [01:39<00:13,  2.21s/it]                                                         Episode 45	 reward: -5.72	 makespan: 566.30	 Mean_loss: 0.76071936,  training time: 2.19
progress:  88%|[34m [0m| 44/50 [01:41<00:13,  2.21s/it]progress:  90%|[34m [0m| 45/50 [01:41<00:11,  2.21s/it]                                                         Episode 46	 reward: -5.74	 makespan: 568.60	 Mean_loss: 0.45146900,  training time: 2.21
progress:  90%|[34m [0m| 45/50 [01:43<00:11,  2.21s/it]progress:  92%|[34m[0m| 46/50 [01:43<00:08,  2.21s/it]                                                         Episode 47	 reward: -5.85	 makespan: 578.70	 Mean_loss: -0.18947110,  training time: 2.19
progress:  92%|[34m[0m| 46/50 [01:46<00:08,  2.21s/it]progress:  94%|[34m[0m| 47/50 [01:46<00:06,  2.20s/it]                                                         Episode 48	 reward: -5.89	 makespan: 582.65	 Mean_loss: 0.84617567,  training time: 2.21
progress:  94%|[34m[0m| 47/50 [01:48<00:06,  2.20s/it]progress:  96%|[34m[0m| 48/50 [01:48<00:04,  2.21s/it]                                                         Episode 49	 reward: -5.66	 makespan: 559.90	 Mean_loss: 0.52284676,  training time: 2.23
progress:  96%|[34m[0m| 48/50 [01:50<00:04,  2.21s/it]progress:  98%|[34m[0m| 49/50 [01:50<00:02,  2.22s/it]                                                         Episode 50	 reward: -5.92	 makespan: 586.15	 Mean_loss: 0.75110394,  training time: 2.25
progress:  98%|[34m[0m| 49/50 [01:52<00:02,  2.22s/it]progress: 100%|[34m[0m| 50/50 [01:52<00:00,  2.23s/it]progress: 100%|[34m[0m| 50/50 [01:52<00:00,  2.26s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x7_10 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -8.35	 makespan: 826.35	 Mean_loss: 0.83201283,  training time: 4.30
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:31,  4.31s/it]                                                        Episode 2	 reward: -8.21	 makespan: 812.45	 Mean_loss: 0.69024253,  training time: 3.10
progress:   2%|[34m         [0m| 1/50 [00:07<03:31,  4.31s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:52,  3.60s/it]                                                        Episode 3	 reward: -8.27	 makespan: 818.75	 Mean_loss: 0.72160161,  training time: 3.18
progress:   4%|[34m         [0m| 2/50 [00:10<02:52,  3.60s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:40,  3.41s/it]                                                        Episode 4	 reward: -8.32	 makespan: 823.85	 Mean_loss: 0.89024872,  training time: 3.07
progress:   6%|[34m         [0m| 3/50 [00:13<02:40,  3.41s/it]progress:   8%|[34m         [0m| 4/50 [00:13<02:30,  3.28s/it]                                                        Episode 5	 reward: -8.32	 makespan: 823.90	 Mean_loss: 0.96222550,  training time: 3.07
progress:   8%|[34m         [0m| 4/50 [00:16<02:30,  3.28s/it]progress:  10%|[34m         [0m| 5/50 [00:16<02:24,  3.20s/it]                                                        Episode 6	 reward: -8.35	 makespan: 827.00	 Mean_loss: 0.86774135,  training time: 3.29
progress:  10%|[34m         [0m| 5/50 [00:20<02:24,  3.20s/it]progress:  12%|[34m        [0m| 6/50 [00:20<02:22,  3.24s/it]                                                        Episode 7	 reward: -8.27	 makespan: 818.55	 Mean_loss: 0.73650956,  training time: 3.20
progress:  12%|[34m        [0m| 6/50 [00:23<02:22,  3.24s/it]progress:  14%|[34m        [0m| 7/50 [00:23<02:18,  3.23s/it]                                                        Episode 8	 reward: -8.23	 makespan: 814.40	 Mean_loss: 0.64999753,  training time: 3.09
progress:  14%|[34m        [0m| 7/50 [00:26<02:18,  3.23s/it]progress:  16%|[34m        [0m| 8/50 [00:26<02:13,  3.18s/it]                                                        Episode 9	 reward: -8.20	 makespan: 812.10	 Mean_loss: 0.61366975,  training time: 3.14
progress:  16%|[34m        [0m| 8/50 [00:29<02:13,  3.18s/it]progress:  18%|[34m        [0m| 9/50 [00:29<02:10,  3.17s/it]                                                        Episode 10	 reward: -8.22	 makespan: 813.40	 Mean_loss: 0.59536391,  training time: 3.10
progress:  18%|[34m        [0m| 9/50 [00:32<02:10,  3.17s/it]progress:  20%|[34m        [0m| 10/50 [00:32<02:05,  3.15s/it]                                                         Episode 11	 reward: -8.26	 makespan: 817.35	 Mean_loss: 0.55563277,  training time: 3.08
progress:  20%|[34m        [0m| 10/50 [00:35<02:05,  3.15s/it]progress:  22%|[34m       [0m| 11/50 [00:35<02:02,  3.13s/it]                                                         Episode 12	 reward: -8.20	 makespan: 811.95	 Mean_loss: 0.46843070,  training time: 3.06
progress:  22%|[34m       [0m| 11/50 [00:38<02:02,  3.13s/it]progress:  24%|[34m       [0m| 12/50 [00:38<01:58,  3.11s/it]                                                         Episode 13	 reward: -8.24	 makespan: 816.05	 Mean_loss: 0.45654044,  training time: 3.11
progress:  24%|[34m       [0m| 12/50 [00:41<01:58,  3.11s/it]progress:  26%|[34m       [0m| 13/50 [00:41<01:55,  3.11s/it]                                                         Episode 14	 reward: -8.24	 makespan: 815.40	 Mean_loss: 0.37709817,  training time: 3.07
progress:  26%|[34m       [0m| 13/50 [00:44<01:55,  3.11s/it]progress:  28%|[34m       [0m| 14/50 [00:44<01:51,  3.10s/it]                                                         Episode 15	 reward: -8.24	 makespan: 815.80	 Mean_loss: 0.38707834,  training time: 3.08
progress:  28%|[34m       [0m| 14/50 [00:48<01:51,  3.10s/it]progress:  30%|[34m       [0m| 15/50 [00:48<01:48,  3.10s/it]                                                         Episode 16	 reward: -8.16	 makespan: 807.65	 Mean_loss: 0.34015566,  training time: 3.06
progress:  30%|[34m       [0m| 15/50 [00:51<01:48,  3.10s/it]progress:  32%|[34m      [0m| 16/50 [00:51<01:44,  3.09s/it]                                                         Episode 17	 reward: -8.17	 makespan: 809.30	 Mean_loss: 0.28157991,  training time: 3.03
progress:  32%|[34m      [0m| 16/50 [00:54<01:44,  3.09s/it]progress:  34%|[34m      [0m| 17/50 [00:54<01:41,  3.07s/it]                                                         Episode 18	 reward: -8.33	 makespan: 824.35	 Mean_loss: 0.36353704,  training time: 3.09
progress:  34%|[34m      [0m| 17/50 [00:57<01:41,  3.07s/it]progress:  36%|[34m      [0m| 18/50 [00:57<01:38,  3.08s/it]                                                         Episode 19	 reward: -8.05	 makespan: 796.85	 Mean_loss: 0.32240295,  training time: 3.05
progress:  36%|[34m      [0m| 18/50 [01:00<01:38,  3.08s/it]progress:  38%|[34m      [0m| 19/50 [01:00<01:35,  3.07s/it]                                                         Episode 20	 reward: -8.10	 makespan: 802.15	 Mean_loss: 0.34614760,  training time: 3.06
progress:  38%|[34m      [0m| 19/50 [01:03<01:35,  3.07s/it]progress:  40%|[34m      [0m| 20/50 [01:03<01:32,  3.07s/it]                                                         Episode 21	 reward: -8.15	 makespan: 806.80	 Mean_loss: 0.26087508,  training time: 3.03
progress:  40%|[34m      [0m| 20/50 [01:06<01:32,  3.07s/it]progress:  42%|[34m     [0m| 21/50 [01:06<01:28,  3.06s/it]                                                         Episode 22	 reward: -8.16	 makespan: 807.75	 Mean_loss: 0.22944565,  training time: 3.05
progress:  42%|[34m     [0m| 21/50 [01:09<01:28,  3.06s/it]progress:  44%|[34m     [0m| 22/50 [01:09<01:25,  3.06s/it]                                                         Episode 23	 reward: -8.17	 makespan: 808.65	 Mean_loss: 0.22227362,  training time: 3.14
progress:  44%|[34m     [0m| 22/50 [01:12<01:25,  3.06s/it]progress:  46%|[34m     [0m| 23/50 [01:12<01:23,  3.09s/it]                                                         Episode 24	 reward: -8.12	 makespan: 804.05	 Mean_loss: 0.24352676,  training time: 3.05
progress:  46%|[34m     [0m| 23/50 [01:15<01:23,  3.09s/it]progress:  48%|[34m     [0m| 24/50 [01:15<01:19,  3.08s/it]                                                         Episode 25	 reward: -7.99	 makespan: 790.60	 Mean_loss: 0.23492977,  training time: 3.06
progress:  48%|[34m     [0m| 24/50 [01:18<01:19,  3.08s/it]progress:  50%|[34m     [0m| 25/50 [01:18<01:16,  3.07s/it]                                                         Episode 26	 reward: -7.94	 makespan: 785.90	 Mean_loss: 0.20375222,  training time: 3.04
progress:  50%|[34m     [0m| 25/50 [01:21<01:16,  3.07s/it]progress:  52%|[34m    [0m| 26/50 [01:21<01:13,  3.06s/it]                                                         Episode 27	 reward: -8.09	 makespan: 800.50	 Mean_loss: 0.23215860,  training time: 3.06
progress:  52%|[34m    [0m| 26/50 [01:24<01:13,  3.06s/it]progress:  54%|[34m    [0m| 27/50 [01:24<01:10,  3.07s/it]                                                         Episode 28	 reward: -7.85	 makespan: 777.10	 Mean_loss: 0.22587392,  training time: 3.05
progress:  54%|[34m    [0m| 27/50 [01:27<01:10,  3.07s/it]progress:  56%|[34m    [0m| 28/50 [01:27<01:07,  3.06s/it]                                                         Episode 29	 reward: -8.21	 makespan: 812.75	 Mean_loss: 0.23454887,  training time: 3.06
progress:  56%|[34m    [0m| 28/50 [01:30<01:07,  3.06s/it]progress:  58%|[34m    [0m| 29/50 [01:30<01:04,  3.06s/it]                                                         Episode 30	 reward: -7.96	 makespan: 788.20	 Mean_loss: 0.20646034,  training time: 3.09
progress:  58%|[34m    [0m| 29/50 [01:34<01:04,  3.06s/it]progress:  60%|[34m    [0m| 30/50 [01:34<01:01,  3.07s/it]                                                         Episode 31	 reward: -8.03	 makespan: 795.45	 Mean_loss: 0.21541440,  training time: 3.04
progress:  60%|[34m    [0m| 30/50 [01:37<01:01,  3.07s/it]progress:  62%|[34m   [0m| 31/50 [01:37<00:58,  3.06s/it]                                                         Episode 32	 reward: -8.12	 makespan: 803.40	 Mean_loss: 0.15136792,  training time: 3.04
progress:  62%|[34m   [0m| 31/50 [01:40<00:58,  3.06s/it]progress:  64%|[34m   [0m| 32/50 [01:40<00:55,  3.06s/it]                                                         Episode 33	 reward: -8.00	 makespan: 792.00	 Mean_loss: 0.19242047,  training time: 3.03
progress:  64%|[34m   [0m| 32/50 [01:43<00:55,  3.06s/it]progress:  66%|[34m   [0m| 33/50 [01:43<00:51,  3.05s/it]                                                         Episode 34	 reward: -8.10	 makespan: 802.05	 Mean_loss: 0.18931618,  training time: 3.04
progress:  66%|[34m   [0m| 33/50 [01:46<00:51,  3.05s/it]progress:  68%|[34m   [0m| 34/50 [01:46<00:48,  3.05s/it]                                                         Episode 35	 reward: -8.24	 makespan: 815.80	 Mean_loss: 0.23995189,  training time: 3.03
progress:  68%|[34m   [0m| 34/50 [01:49<00:48,  3.05s/it]progress:  70%|[34m   [0m| 35/50 [01:49<00:45,  3.05s/it]                                                         Episode 36	 reward: -8.04	 makespan: 796.40	 Mean_loss: 0.19934806,  training time: 3.05
progress:  70%|[34m   [0m| 35/50 [01:52<00:45,  3.05s/it]progress:  72%|[34m  [0m| 36/50 [01:52<00:42,  3.05s/it]                                                         Episode 37	 reward: -8.07	 makespan: 798.60	 Mean_loss: 0.18984711,  training time: 3.08
progress:  72%|[34m  [0m| 36/50 [01:55<00:42,  3.05s/it]progress:  74%|[34m  [0m| 37/50 [01:55<00:39,  3.06s/it]                                                         Episode 38	 reward: -7.93	 makespan: 785.50	 Mean_loss: 0.19167130,  training time: 3.05
progress:  74%|[34m  [0m| 37/50 [01:58<00:39,  3.06s/it]progress:  76%|[34m  [0m| 38/50 [01:58<00:36,  3.06s/it]                                                         Episode 39	 reward: -7.91	 makespan: 783.45	 Mean_loss: 0.19562569,  training time: 3.05
progress:  76%|[34m  [0m| 38/50 [02:01<00:36,  3.06s/it]progress:  78%|[34m  [0m| 39/50 [02:01<00:33,  3.05s/it]                                                         Episode 40	 reward: -7.97	 makespan: 789.45	 Mean_loss: 0.21566980,  training time: 3.02
progress:  78%|[34m  [0m| 39/50 [02:04<00:33,  3.05s/it]progress:  80%|[34m  [0m| 40/50 [02:04<00:30,  3.05s/it]                                                         Episode 41	 reward: -7.85	 makespan: 777.30	 Mean_loss: 0.16641860,  training time: 3.04
progress:  80%|[34m  [0m| 40/50 [02:07<00:30,  3.05s/it]progress:  82%|[34m [0m| 41/50 [02:07<00:27,  3.05s/it]                                                         Episode 42	 reward: -7.77	 makespan: 769.40	 Mean_loss: 0.14379069,  training time: 3.07
progress:  82%|[34m [0m| 41/50 [02:10<00:27,  3.05s/it]progress:  84%|[34m [0m| 42/50 [02:10<00:24,  3.06s/it]                                                         Episode 43	 reward: -7.97	 makespan: 788.70	 Mean_loss: 0.17738008,  training time: 2.98
progress:  84%|[34m [0m| 42/50 [02:13<00:24,  3.06s/it]progress:  86%|[34m [0m| 43/50 [02:13<00:21,  3.03s/it]                                                         Episode 44	 reward: -7.90	 makespan: 781.65	 Mean_loss: 0.17329431,  training time: 3.00
progress:  86%|[34m [0m| 43/50 [02:16<00:21,  3.03s/it]progress:  88%|[34m [0m| 44/50 [02:16<00:18,  3.02s/it]                                                         Episode 45	 reward: -7.95	 makespan: 787.00	 Mean_loss: 0.15971148,  training time: 3.03
progress:  88%|[34m [0m| 44/50 [02:19<00:18,  3.02s/it]progress:  90%|[34m [0m| 45/50 [02:19<00:15,  3.03s/it]                                                         Episode 46	 reward: -7.89	 makespan: 781.60	 Mean_loss: 0.18809161,  training time: 3.00
progress:  90%|[34m [0m| 45/50 [02:22<00:15,  3.03s/it]progress:  92%|[34m[0m| 46/50 [02:22<00:12,  3.02s/it]                                                         Episode 47	 reward: -7.77	 makespan: 769.45	 Mean_loss: 0.14984000,  training time: 3.02
progress:  92%|[34m[0m| 46/50 [02:25<00:12,  3.02s/it]progress:  94%|[34m[0m| 47/50 [02:25<00:09,  3.02s/it]                                                         Episode 48	 reward: -7.93	 makespan: 784.95	 Mean_loss: 0.13295390,  training time: 2.98
progress:  94%|[34m[0m| 47/50 [02:28<00:09,  3.02s/it]progress:  96%|[34m[0m| 48/50 [02:28<00:06,  3.01s/it]                                                         Episode 49	 reward: -7.84	 makespan: 776.30	 Mean_loss: 0.14687417,  training time: 3.07
progress:  96%|[34m[0m| 48/50 [02:31<00:06,  3.01s/it]progress:  98%|[34m[0m| 49/50 [02:31<00:03,  3.03s/it]                                                         Episode 50	 reward: -7.80	 makespan: 772.35	 Mean_loss: 0.17122589,  training time: 3.03
progress:  98%|[34m[0m| 49/50 [02:34<00:03,  3.03s/it]progress: 100%|[34m[0m| 50/50 [02:34<00:00,  3.03s/it]progress: 100%|[34m[0m| 50/50 [02:34<00:00,  3.10s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x7_12 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -9.97	 makespan: 987.00	 Mean_loss: 1.26282644,  training time: 5.06
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:08,  5.07s/it]                                                        Episode 2	 reward: -9.96	 makespan: 985.65	 Mean_loss: 1.07332790,  training time: 3.88
progress:   2%|[34m         [0m| 1/50 [00:08<04:08,  5.07s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:29,  4.37s/it]                                                        Episode 3	 reward: -9.94	 makespan: 984.05	 Mean_loss: 1.27931869,  training time: 4.08
progress:   4%|[34m         [0m| 2/50 [00:13<03:29,  4.37s/it]progress:   6%|[34m         [0m| 3/50 [00:13<03:19,  4.24s/it]                                                        Episode 4	 reward: -10.13	 makespan: 1002.40	 Mean_loss: 1.59394646,  training time: 3.90
progress:   6%|[34m         [0m| 3/50 [00:16<03:19,  4.24s/it]progress:   8%|[34m         [0m| 4/50 [00:16<03:09,  4.11s/it]                                                        Episode 5	 reward: -9.91	 makespan: 981.30	 Mean_loss: 1.64818704,  training time: 4.02
progress:   8%|[34m         [0m| 4/50 [00:20<03:09,  4.11s/it]progress:  10%|[34m         [0m| 5/50 [00:20<03:03,  4.08s/it]                                                        Episode 6	 reward: -9.97	 makespan: 987.20	 Mean_loss: 1.29640961,  training time: 3.88
progress:  10%|[34m         [0m| 5/50 [00:24<03:03,  4.08s/it]progress:  12%|[34m        [0m| 6/50 [00:24<02:56,  4.01s/it]                                                        Episode 7	 reward: -10.04	 makespan: 993.95	 Mean_loss: 1.21957171,  training time: 3.85
progress:  12%|[34m        [0m| 6/50 [00:28<02:56,  4.01s/it]progress:  14%|[34m        [0m| 7/50 [00:28<02:50,  3.96s/it]                                                        Episode 8	 reward: -9.92	 makespan: 982.40	 Mean_loss: 1.38157284,  training time: 3.91
progress:  14%|[34m        [0m| 7/50 [00:32<02:50,  3.96s/it]progress:  16%|[34m        [0m| 8/50 [00:32<02:45,  3.95s/it]                                                        Episode 9	 reward: -10.07	 makespan: 996.95	 Mean_loss: 1.22121716,  training time: 3.92
progress:  16%|[34m        [0m| 8/50 [00:36<02:45,  3.95s/it]progress:  18%|[34m        [0m| 9/50 [00:36<02:41,  3.94s/it]                                                        Episode 10	 reward: -9.96	 makespan: 985.60	 Mean_loss: 1.00123107,  training time: 3.94
progress:  18%|[34m        [0m| 9/50 [00:40<02:41,  3.94s/it]progress:  20%|[34m        [0m| 10/50 [00:40<02:37,  3.94s/it]                                                         Episode 11	 reward: -9.95	 makespan: 985.40	 Mean_loss: 0.98815668,  training time: 3.93
progress:  20%|[34m        [0m| 10/50 [00:44<02:37,  3.94s/it]progress:  22%|[34m       [0m| 11/50 [00:44<02:33,  3.94s/it]                                                         Episode 12	 reward: -10.02	 makespan: 991.60	 Mean_loss: 0.79094142,  training time: 4.11
progress:  22%|[34m       [0m| 11/50 [00:48<02:33,  3.94s/it]progress:  24%|[34m       [0m| 12/50 [00:48<02:31,  3.99s/it]                                                         Episode 13	 reward: -9.92	 makespan: 982.30	 Mean_loss: 0.79425973,  training time: 3.83
progress:  24%|[34m       [0m| 12/50 [00:52<02:31,  3.99s/it]progress:  26%|[34m       [0m| 13/50 [00:52<02:25,  3.94s/it]                                                         Episode 14	 reward: -9.83	 makespan: 973.00	 Mean_loss: 0.66125345,  training time: 4.16
progress:  26%|[34m       [0m| 13/50 [00:56<02:25,  3.94s/it]progress:  28%|[34m       [0m| 14/50 [00:56<02:24,  4.01s/it]                                                         Episode 15	 reward: -9.91	 makespan: 981.00	 Mean_loss: 0.57954919,  training time: 4.05
progress:  28%|[34m       [0m| 14/50 [01:00<02:24,  4.01s/it]progress:  30%|[34m       [0m| 15/50 [01:00<02:20,  4.03s/it]                                                         Episode 16	 reward: -10.00	 makespan: 989.80	 Mean_loss: 0.54413563,  training time: 3.91
progress:  30%|[34m       [0m| 15/50 [01:04<02:20,  4.03s/it]progress:  32%|[34m      [0m| 16/50 [01:04<02:15,  3.99s/it]                                                         Episode 17	 reward: -10.05	 makespan: 994.70	 Mean_loss: 0.51492262,  training time: 4.03
progress:  32%|[34m      [0m| 16/50 [01:08<02:15,  3.99s/it]progress:  34%|[34m      [0m| 17/50 [01:08<02:12,  4.01s/it]                                                         Episode 18	 reward: -10.04	 makespan: 994.30	 Mean_loss: 0.55127746,  training time: 3.86
progress:  34%|[34m      [0m| 17/50 [01:12<02:12,  4.01s/it]progress:  36%|[34m      [0m| 18/50 [01:12<02:06,  3.96s/it]                                                         Episode 19	 reward: -9.98	 makespan: 988.10	 Mean_loss: 0.54017329,  training time: 3.83
progress:  36%|[34m      [0m| 18/50 [01:16<02:06,  3.96s/it]progress:  38%|[34m      [0m| 19/50 [01:16<02:01,  3.93s/it]                                                         Episode 20	 reward: -9.92	 makespan: 981.65	 Mean_loss: 0.46800146,  training time: 3.84
progress:  38%|[34m      [0m| 19/50 [01:20<02:01,  3.93s/it]progress:  40%|[34m      [0m| 20/50 [01:20<01:57,  3.90s/it]                                                         Episode 21	 reward: -10.13	 makespan: 1002.45	 Mean_loss: 0.46540672,  training time: 3.87
progress:  40%|[34m      [0m| 20/50 [01:23<01:57,  3.90s/it]progress:  42%|[34m     [0m| 21/50 [01:23<01:52,  3.89s/it]                                                         Episode 22	 reward: -10.01	 makespan: 991.25	 Mean_loss: 0.43594211,  training time: 3.90
progress:  42%|[34m     [0m| 21/50 [01:27<01:52,  3.89s/it]progress:  44%|[34m     [0m| 22/50 [01:27<01:49,  3.90s/it]                                                         Episode 23	 reward: -10.07	 makespan: 996.75	 Mean_loss: 0.44979307,  training time: 3.90
progress:  44%|[34m     [0m| 22/50 [01:31<01:49,  3.90s/it]progress:  46%|[34m     [0m| 23/50 [01:31<01:45,  3.90s/it]                                                         Episode 24	 reward: -10.13	 makespan: 1003.35	 Mean_loss: 0.41365772,  training time: 3.88
progress:  46%|[34m     [0m| 23/50 [01:35<01:45,  3.90s/it]progress:  48%|[34m     [0m| 24/50 [01:35<01:41,  3.89s/it]                                                         Episode 25	 reward: -10.05	 makespan: 994.75	 Mean_loss: 0.38619703,  training time: 4.11
progress:  48%|[34m     [0m| 24/50 [01:39<01:41,  3.89s/it]progress:  50%|[34m     [0m| 25/50 [01:39<01:39,  3.96s/it]                                                         Episode 26	 reward: -10.08	 makespan: 998.35	 Mean_loss: 0.44115648,  training time: 3.90
progress:  50%|[34m     [0m| 25/50 [01:43<01:39,  3.96s/it]progress:  52%|[34m    [0m| 26/50 [01:43<01:34,  3.95s/it]                                                         Episode 27	 reward: -9.98	 makespan: 988.05	 Mean_loss: 0.37481877,  training time: 3.81
progress:  52%|[34m    [0m| 26/50 [01:47<01:34,  3.95s/it]progress:  54%|[34m    [0m| 27/50 [01:47<01:29,  3.91s/it]                                                         Episode 28	 reward: -9.89	 makespan: 979.10	 Mean_loss: 0.35913691,  training time: 3.79
progress:  54%|[34m    [0m| 27/50 [01:51<01:29,  3.91s/it]progress:  56%|[34m    [0m| 28/50 [01:51<01:25,  3.87s/it]                                                         Episode 29	 reward: -9.83	 makespan: 973.40	 Mean_loss: 0.29562122,  training time: 3.99
progress:  56%|[34m    [0m| 28/50 [01:55<01:25,  3.87s/it]progress:  58%|[34m    [0m| 29/50 [01:55<01:22,  3.91s/it]                                                         Episode 30	 reward: -9.78	 makespan: 968.55	 Mean_loss: 0.31723490,  training time: 3.89
progress:  58%|[34m    [0m| 29/50 [01:59<01:22,  3.91s/it]progress:  60%|[34m    [0m| 30/50 [01:59<01:18,  3.90s/it]                                                         Episode 31	 reward: -9.76	 makespan: 966.05	 Mean_loss: 0.33862689,  training time: 3.86
progress:  60%|[34m    [0m| 30/50 [02:03<01:18,  3.90s/it]progress:  62%|[34m   [0m| 31/50 [02:03<01:13,  3.89s/it]                                                         Episode 32	 reward: -9.80	 makespan: 969.95	 Mean_loss: 0.31294328,  training time: 3.84
progress:  62%|[34m   [0m| 31/50 [02:06<01:13,  3.89s/it]progress:  64%|[34m   [0m| 32/50 [02:06<01:09,  3.88s/it]                                                         Episode 33	 reward: -9.66	 makespan: 956.45	 Mean_loss: 0.26672673,  training time: 3.84
progress:  64%|[34m   [0m| 32/50 [02:10<01:09,  3.88s/it]progress:  66%|[34m   [0m| 33/50 [02:10<01:05,  3.87s/it]                                                         Episode 34	 reward: -9.64	 makespan: 954.30	 Mean_loss: 0.22360945,  training time: 3.83
progress:  66%|[34m   [0m| 33/50 [02:14<01:05,  3.87s/it]progress:  68%|[34m   [0m| 34/50 [02:14<01:01,  3.86s/it]                                                         Episode 35	 reward: -9.81	 makespan: 970.70	 Mean_loss: 0.25857759,  training time: 3.85
progress:  68%|[34m   [0m| 34/50 [02:18<01:01,  3.86s/it]progress:  70%|[34m   [0m| 35/50 [02:18<00:57,  3.86s/it]                                                         Episode 36	 reward: -9.59	 makespan: 949.40	 Mean_loss: 0.25914830,  training time: 3.88
progress:  70%|[34m   [0m| 35/50 [02:22<00:57,  3.86s/it]progress:  72%|[34m  [0m| 36/50 [02:22<00:54,  3.87s/it]                                                         Episode 37	 reward: -9.48	 makespan: 938.45	 Mean_loss: 0.25593466,  training time: 3.91
progress:  72%|[34m  [0m| 36/50 [02:26<00:54,  3.87s/it]progress:  74%|[34m  [0m| 37/50 [02:26<00:50,  3.88s/it]                                                         Episode 38	 reward: -9.68	 makespan: 958.25	 Mean_loss: 0.24347989,  training time: 3.84
progress:  74%|[34m  [0m| 37/50 [02:30<00:50,  3.88s/it]progress:  76%|[34m  [0m| 38/50 [02:30<00:46,  3.87s/it]                                                         Episode 39	 reward: -9.54	 makespan: 944.35	 Mean_loss: 0.23588268,  training time: 3.88
progress:  76%|[34m  [0m| 38/50 [02:33<00:46,  3.87s/it]progress:  78%|[34m  [0m| 39/50 [02:33<00:42,  3.87s/it]                                                         Episode 40	 reward: -9.46	 makespan: 936.30	 Mean_loss: 0.23961991,  training time: 3.87
progress:  78%|[34m  [0m| 39/50 [02:37<00:42,  3.87s/it]progress:  80%|[34m  [0m| 40/50 [02:37<00:38,  3.87s/it]                                                         Episode 41	 reward: -9.66	 makespan: 956.50	 Mean_loss: 0.19702557,  training time: 4.20
progress:  80%|[34m  [0m| 40/50 [02:42<00:38,  3.87s/it]progress:  82%|[34m [0m| 41/50 [02:42<00:35,  3.97s/it]                                                         Episode 42	 reward: -9.55	 makespan: 945.10	 Mean_loss: 0.20129117,  training time: 4.33
progress:  82%|[34m [0m| 41/50 [02:46<00:35,  3.97s/it]progress:  84%|[34m [0m| 42/50 [02:46<00:32,  4.08s/it]                                                         Episode 43	 reward: -9.67	 makespan: 957.60	 Mean_loss: 0.19379079,  training time: 3.87
progress:  84%|[34m [0m| 42/50 [02:50<00:32,  4.08s/it]progress:  86%|[34m [0m| 43/50 [02:50<00:28,  4.02s/it]                                                         Episode 44	 reward: -9.59	 makespan: 949.90	 Mean_loss: 0.18600306,  training time: 3.84
progress:  86%|[34m [0m| 43/50 [02:54<00:28,  4.02s/it]progress:  88%|[34m [0m| 44/50 [02:54<00:23,  3.97s/it]                                                         Episode 45	 reward: -9.43	 makespan: 933.40	 Mean_loss: 0.16784579,  training time: 4.00
progress:  88%|[34m [0m| 44/50 [02:58<00:23,  3.97s/it]progress:  90%|[34m [0m| 45/50 [02:58<00:19,  3.98s/it]                                                         Episode 46	 reward: -9.48	 makespan: 938.15	 Mean_loss: 0.21372458,  training time: 3.97
progress:  90%|[34m [0m| 45/50 [03:02<00:19,  3.98s/it]progress:  92%|[34m[0m| 46/50 [03:02<00:15,  3.98s/it]                                                         Episode 47	 reward: -9.36	 makespan: 926.15	 Mean_loss: 0.21917176,  training time: 3.82
progress:  92%|[34m[0m| 46/50 [03:05<00:15,  3.98s/it]progress:  94%|[34m[0m| 47/50 [03:05<00:11,  3.93s/it]                                                         Episode 48	 reward: -9.49	 makespan: 939.15	 Mean_loss: 0.22263509,  training time: 3.92
progress:  94%|[34m[0m| 47/50 [03:09<00:11,  3.93s/it]progress:  96%|[34m[0m| 48/50 [03:09<00:07,  3.93s/it]                                                         Episode 49	 reward: -9.28	 makespan: 918.80	 Mean_loss: 0.20145653,  training time: 3.83
progress:  96%|[34m[0m| 48/50 [03:13<00:07,  3.93s/it]progress:  98%|[34m[0m| 49/50 [03:13<00:03,  3.90s/it]                                                         Episode 50	 reward: -9.46	 makespan: 936.45	 Mean_loss: 0.23275155,  training time: 3.79
progress:  98%|[34m[0m| 49/50 [03:17<00:03,  3.90s/it]progress: 100%|[34m[0m| 50/50 [03:17<00:00,  3.87s/it]progress: 100%|[34m[0m| 50/50 [03:17<00:00,  3.95s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x5_4 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.82	 makespan: 476.95	 Mean_loss: 0.59314394,  training time: 2.48
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<02:01,  2.48s/it]                                                        Episode 2	 reward: -4.75	 makespan: 470.40	 Mean_loss: 0.40066296,  training time: 1.22
progress:   2%|[34m         [0m| 1/50 [00:03<02:01,  2.48s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:23,  1.74s/it]                                                        Episode 3	 reward: -4.88	 makespan: 483.40	 Mean_loss: 0.39337569,  training time: 1.22
progress:   4%|[34m         [0m| 2/50 [00:04<01:23,  1.74s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:10,  1.51s/it]                                                        Episode 4	 reward: -4.73	 makespan: 468.10	 Mean_loss: 0.17896195,  training time: 1.34
progress:   6%|[34m         [0m| 3/50 [00:06<01:10,  1.51s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:06,  1.44s/it]                                                        Episode 5	 reward: -4.79	 makespan: 474.35	 Mean_loss: 0.16667977,  training time: 1.25
progress:   8%|[34m         [0m| 4/50 [00:07<01:06,  1.44s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:01,  1.37s/it]                                                        Episode 6	 reward: -4.82	 makespan: 477.35	 Mean_loss: 0.27145463,  training time: 1.29
progress:  10%|[34m         [0m| 5/50 [00:08<01:01,  1.37s/it]progress:  12%|[34m        [0m| 6/50 [00:08<00:59,  1.35s/it]                                                        Episode 7	 reward: -4.77	 makespan: 471.90	 Mean_loss: 0.15944846,  training time: 1.31
progress:  12%|[34m        [0m| 6/50 [00:10<00:59,  1.35s/it]progress:  14%|[34m        [0m| 7/50 [00:10<00:57,  1.34s/it]                                                        Episode 8	 reward: -4.84	 makespan: 478.90	 Mean_loss: 0.11923503,  training time: 1.29
progress:  14%|[34m        [0m| 7/50 [00:11<00:57,  1.34s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:55,  1.32s/it]                                                        Episode 9	 reward: -4.75	 makespan: 470.35	 Mean_loss: 0.08348490,  training time: 1.25
progress:  16%|[34m        [0m| 8/50 [00:12<00:55,  1.32s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:53,  1.30s/it]                                                        Episode 10	 reward: -4.65	 makespan: 460.10	 Mean_loss: 0.09377547,  training time: 1.35
progress:  18%|[34m        [0m| 9/50 [00:14<00:53,  1.30s/it]progress:  20%|[34m        [0m| 10/50 [00:14<00:52,  1.32s/it]                                                         Episode 11	 reward: -4.84	 makespan: 479.20	 Mean_loss: 0.11921824,  training time: 1.29
progress:  20%|[34m        [0m| 10/50 [00:15<00:52,  1.32s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:51,  1.31s/it]                                                         Episode 12	 reward: -4.89	 makespan: 484.25	 Mean_loss: 0.10804553,  training time: 1.36
progress:  22%|[34m       [0m| 11/50 [00:16<00:51,  1.31s/it]progress:  24%|[34m       [0m| 12/50 [00:16<00:50,  1.33s/it]                                                         Episode 13	 reward: -4.89	 makespan: 483.85	 Mean_loss: 0.16635822,  training time: 1.22
progress:  24%|[34m       [0m| 12/50 [00:17<00:50,  1.33s/it]progress:  26%|[34m       [0m| 13/50 [00:17<00:47,  1.30s/it]                                                         Episode 14	 reward: -4.67	 makespan: 462.55	 Mean_loss: 0.16590242,  training time: 1.23
progress:  26%|[34m       [0m| 13/50 [00:19<00:47,  1.30s/it]progress:  28%|[34m       [0m| 14/50 [00:19<00:45,  1.28s/it]                                                         Episode 15	 reward: -4.83	 makespan: 477.85	 Mean_loss: 0.18179366,  training time: 1.38
progress:  28%|[34m       [0m| 14/50 [00:20<00:45,  1.28s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:45,  1.31s/it]                                                         Episode 16	 reward: -4.81	 makespan: 475.90	 Mean_loss: 0.17100099,  training time: 1.35
progress:  30%|[34m       [0m| 15/50 [00:21<00:45,  1.31s/it]progress:  32%|[34m      [0m| 16/50 [00:21<00:44,  1.32s/it]                                                         Episode 17	 reward: -4.91	 makespan: 486.10	 Mean_loss: 0.21397847,  training time: 1.22
progress:  32%|[34m      [0m| 16/50 [00:23<00:44,  1.32s/it]progress:  34%|[34m      [0m| 17/50 [00:23<00:42,  1.29s/it]                                                         Episode 18	 reward: -4.82	 makespan: 477.60	 Mean_loss: 0.25405222,  training time: 1.30
progress:  34%|[34m      [0m| 17/50 [00:24<00:42,  1.29s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:41,  1.30s/it]                                                         Episode 19	 reward: -4.88	 makespan: 482.80	 Mean_loss: 0.13196507,  training time: 1.27
progress:  36%|[34m      [0m| 18/50 [00:25<00:41,  1.30s/it]progress:  38%|[34m      [0m| 19/50 [00:25<00:40,  1.29s/it]                                                         Episode 20	 reward: -4.78	 makespan: 473.10	 Mean_loss: 0.30240488,  training time: 1.32
progress:  38%|[34m      [0m| 19/50 [00:27<00:40,  1.29s/it]progress:  40%|[34m      [0m| 20/50 [00:27<00:39,  1.30s/it]                                                         Episode 21	 reward: -4.73	 makespan: 468.05	 Mean_loss: 0.10491972,  training time: 1.21
progress:  40%|[34m      [0m| 20/50 [00:28<00:39,  1.30s/it]progress:  42%|[34m     [0m| 21/50 [00:28<00:36,  1.28s/it]                                                         Episode 22	 reward: -4.73	 makespan: 468.55	 Mean_loss: 0.13879061,  training time: 1.27
progress:  42%|[34m     [0m| 21/50 [00:29<00:36,  1.28s/it]progress:  44%|[34m     [0m| 22/50 [00:29<00:35,  1.27s/it]                                                         Episode 23	 reward: -4.81	 makespan: 476.25	 Mean_loss: 0.09906907,  training time: 1.28
progress:  44%|[34m     [0m| 22/50 [00:30<00:35,  1.27s/it]progress:  46%|[34m     [0m| 23/50 [00:30<00:34,  1.28s/it]                                                         Episode 24	 reward: -4.73	 makespan: 468.15	 Mean_loss: 0.09724787,  training time: 1.35
progress:  46%|[34m     [0m| 23/50 [00:32<00:34,  1.28s/it]progress:  48%|[34m     [0m| 24/50 [00:32<00:33,  1.30s/it]                                                         Episode 25	 reward: -4.85	 makespan: 479.90	 Mean_loss: 0.14023478,  training time: 1.33
progress:  48%|[34m     [0m| 24/50 [00:33<00:33,  1.30s/it]progress:  50%|[34m     [0m| 25/50 [00:33<00:32,  1.31s/it]                                                         Episode 26	 reward: -4.75	 makespan: 470.25	 Mean_loss: 0.09067400,  training time: 1.27
progress:  50%|[34m     [0m| 25/50 [00:34<00:32,  1.31s/it]progress:  52%|[34m    [0m| 26/50 [00:34<00:31,  1.30s/it]                                                         Episode 27	 reward: -4.77	 makespan: 471.85	 Mean_loss: 0.07695978,  training time: 1.28
progress:  52%|[34m    [0m| 26/50 [00:36<00:31,  1.30s/it]progress:  54%|[34m    [0m| 27/50 [00:36<00:29,  1.30s/it]                                                         Episode 28	 reward: -4.82	 makespan: 477.50	 Mean_loss: 0.21048161,  training time: 1.23
progress:  54%|[34m    [0m| 27/50 [00:37<00:29,  1.30s/it]progress:  56%|[34m    [0m| 28/50 [00:37<00:28,  1.28s/it]                                                         Episode 29	 reward: -4.92	 makespan: 486.60	 Mean_loss: 0.22881812,  training time: 1.26
progress:  56%|[34m    [0m| 28/50 [00:38<00:28,  1.28s/it]progress:  58%|[34m    [0m| 29/50 [00:38<00:26,  1.27s/it]                                                         Episode 30	 reward: -4.81	 makespan: 475.70	 Mean_loss: 0.07608997,  training time: 1.30
progress:  58%|[34m    [0m| 29/50 [00:39<00:26,  1.27s/it]progress:  60%|[34m    [0m| 30/50 [00:39<00:25,  1.28s/it]                                                         Episode 31	 reward: -4.69	 makespan: 464.45	 Mean_loss: 0.14712612,  training time: 1.19
progress:  60%|[34m    [0m| 30/50 [00:41<00:25,  1.28s/it]progress:  62%|[34m   [0m| 31/50 [00:41<00:23,  1.26s/it]                                                         Episode 32	 reward: -4.86	 makespan: 481.40	 Mean_loss: 0.07454222,  training time: 1.30
progress:  62%|[34m   [0m| 31/50 [00:42<00:23,  1.26s/it]progress:  64%|[34m   [0m| 32/50 [00:42<00:22,  1.27s/it]                                                         Episode 33	 reward: -4.79	 makespan: 474.55	 Mean_loss: 0.12693004,  training time: 1.24
progress:  64%|[34m   [0m| 32/50 [00:43<00:22,  1.27s/it]progress:  66%|[34m   [0m| 33/50 [00:43<00:21,  1.26s/it]                                                         Episode 34	 reward: -4.95	 makespan: 489.75	 Mean_loss: 0.11528850,  training time: 1.26
progress:  66%|[34m   [0m| 33/50 [00:44<00:21,  1.26s/it]progress:  68%|[34m   [0m| 34/50 [00:44<00:20,  1.26s/it]                                                         Episode 35	 reward: -4.72	 makespan: 466.90	 Mean_loss: 0.06852485,  training time: 1.20
progress:  68%|[34m   [0m| 34/50 [00:46<00:20,  1.26s/it]progress:  70%|[34m   [0m| 35/50 [00:46<00:18,  1.25s/it]                                                         Episode 36	 reward: -4.79	 makespan: 474.70	 Mean_loss: 0.16348101,  training time: 1.23
progress:  70%|[34m   [0m| 35/50 [00:47<00:18,  1.25s/it]progress:  72%|[34m  [0m| 36/50 [00:47<00:17,  1.24s/it]                                                         Episode 37	 reward: -4.77	 makespan: 472.30	 Mean_loss: 0.06170452,  training time: 1.18
progress:  72%|[34m  [0m| 36/50 [00:48<00:17,  1.24s/it]progress:  74%|[34m  [0m| 37/50 [00:48<00:15,  1.22s/it]                                                         Episode 38	 reward: -4.77	 makespan: 472.45	 Mean_loss: 0.13715887,  training time: 1.20
progress:  74%|[34m  [0m| 37/50 [00:49<00:15,  1.22s/it]progress:  76%|[34m  [0m| 38/50 [00:49<00:14,  1.22s/it]                                                         Episode 39	 reward: -4.73	 makespan: 468.60	 Mean_loss: 0.06875078,  training time: 1.20
progress:  76%|[34m  [0m| 38/50 [00:50<00:14,  1.22s/it]progress:  78%|[34m  [0m| 39/50 [00:50<00:13,  1.21s/it]                                                         Episode 40	 reward: -4.82	 makespan: 477.35	 Mean_loss: 0.09700670,  training time: 1.26
progress:  78%|[34m  [0m| 39/50 [00:52<00:13,  1.21s/it]progress:  80%|[34m  [0m| 40/50 [00:52<00:12,  1.23s/it]                                                         Episode 41	 reward: -4.73	 makespan: 468.65	 Mean_loss: 0.05730576,  training time: 1.20
progress:  80%|[34m  [0m| 40/50 [00:53<00:12,  1.23s/it]progress:  82%|[34m [0m| 41/50 [00:53<00:10,  1.22s/it]                                                         Episode 42	 reward: -4.82	 makespan: 477.45	 Mean_loss: 0.09682463,  training time: 1.29
progress:  82%|[34m [0m| 41/50 [00:54<00:10,  1.22s/it]progress:  84%|[34m [0m| 42/50 [00:54<00:09,  1.24s/it]                                                         Episode 43	 reward: -4.77	 makespan: 471.80	 Mean_loss: 0.11378024,  training time: 1.33
progress:  84%|[34m [0m| 42/50 [00:56<00:09,  1.24s/it]progress:  86%|[34m [0m| 43/50 [00:56<00:08,  1.27s/it]                                                         Episode 44	 reward: -4.76	 makespan: 471.65	 Mean_loss: 0.10927071,  training time: 1.19
progress:  86%|[34m [0m| 43/50 [00:57<00:08,  1.27s/it]progress:  88%|[34m [0m| 44/50 [00:57<00:07,  1.25s/it]                                                         Episode 45	 reward: -4.76	 makespan: 471.20	 Mean_loss: 0.09532247,  training time: 1.18
progress:  88%|[34m [0m| 44/50 [00:58<00:07,  1.25s/it]progress:  90%|[34m [0m| 45/50 [00:58<00:06,  1.23s/it]                                                         Episode 46	 reward: -4.80	 makespan: 474.85	 Mean_loss: 0.13741423,  training time: 1.18
progress:  90%|[34m [0m| 45/50 [00:59<00:06,  1.23s/it]progress:  92%|[34m[0m| 46/50 [00:59<00:04,  1.22s/it]                                                         Episode 47	 reward: -4.70	 makespan: 464.85	 Mean_loss: 0.10551551,  training time: 1.27
progress:  92%|[34m[0m| 46/50 [01:00<00:04,  1.22s/it]progress:  94%|[34m[0m| 47/50 [01:00<00:03,  1.23s/it]                                                         Episode 48	 reward: -4.81	 makespan: 475.85	 Mean_loss: 0.12108501,  training time: 1.23
progress:  94%|[34m[0m| 47/50 [01:02<00:03,  1.23s/it]progress:  96%|[34m[0m| 48/50 [01:02<00:02,  1.23s/it]                                                         Episode 49	 reward: -4.71	 makespan: 466.10	 Mean_loss: 0.07262976,  training time: 1.21
progress:  96%|[34m[0m| 48/50 [01:03<00:02,  1.23s/it]progress:  98%|[34m[0m| 49/50 [01:03<00:01,  1.23s/it]                                                         Episode 50	 reward: -4.75	 makespan: 470.70	 Mean_loss: 0.08123418,  training time: 1.20
progress:  98%|[34m[0m| 49/50 [01:04<00:01,  1.23s/it]progress: 100%|[34m[0m| 50/50 [01:04<00:00,  1.22s/it]progress: 100%|[34m[0m| 50/50 [01:04<00:00,  1.29s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x5_7 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.98	 makespan: 790.40	 Mean_loss: 0.54534519,  training time: 3.42
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:47,  3.42s/it]                                                        Episode 2	 reward: -7.95	 makespan: 787.25	 Mean_loss: 0.05761613,  training time: 2.25
progress:   2%|[34m         [0m| 1/50 [00:05<02:47,  3.42s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:11,  2.73s/it]                                                        Episode 3	 reward: -8.13	 makespan: 804.45	 Mean_loss: 0.02866650,  training time: 2.19
progress:   4%|[34m         [0m| 2/50 [00:07<02:11,  2.73s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:56,  2.49s/it]                                                        Episode 4	 reward: -8.10	 makespan: 801.60	 Mean_loss: -0.02355295,  training time: 2.19
progress:   6%|[34m         [0m| 3/50 [00:10<01:56,  2.49s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:49,  2.37s/it]                                                        Episode 5	 reward: -8.03	 makespan: 794.75	 Mean_loss: 0.10396874,  training time: 2.16
progress:   8%|[34m         [0m| 4/50 [00:12<01:49,  2.37s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:43,  2.30s/it]                                                        Episode 6	 reward: -8.12	 makespan: 803.85	 Mean_loss: -0.10736603,  training time: 2.14
progress:  10%|[34m         [0m| 5/50 [00:14<01:43,  2.30s/it]progress:  12%|[34m        [0m| 6/50 [00:14<01:38,  2.24s/it]                                                        Episode 7	 reward: -8.17	 makespan: 808.40	 Mean_loss: -0.18379672,  training time: 2.17
progress:  12%|[34m        [0m| 6/50 [00:16<01:38,  2.24s/it]progress:  14%|[34m        [0m| 7/50 [00:16<01:35,  2.22s/it]                                                        Episode 8	 reward: -8.26	 makespan: 817.65	 Mean_loss: -0.24195009,  training time: 2.20
progress:  14%|[34m        [0m| 7/50 [00:18<01:35,  2.22s/it]progress:  16%|[34m        [0m| 8/50 [00:18<01:32,  2.21s/it]                                                        Episode 9	 reward: -8.14	 makespan: 805.50	 Mean_loss: -0.31365719,  training time: 2.19
progress:  16%|[34m        [0m| 8/50 [00:20<01:32,  2.21s/it]progress:  18%|[34m        [0m| 9/50 [00:20<01:30,  2.21s/it]                                                        Episode 10	 reward: -8.05	 makespan: 796.60	 Mean_loss: -0.19098955,  training time: 2.20
progress:  18%|[34m        [0m| 9/50 [00:23<01:30,  2.21s/it]progress:  20%|[34m        [0m| 10/50 [00:23<01:28,  2.21s/it]                                                         Episode 11	 reward: -8.20	 makespan: 811.65	 Mean_loss: -0.10140760,  training time: 2.31
progress:  20%|[34m        [0m| 10/50 [00:25<01:28,  2.21s/it]progress:  22%|[34m       [0m| 11/50 [00:25<01:27,  2.24s/it]                                                         Episode 12	 reward: -8.24	 makespan: 815.85	 Mean_loss: -0.37323955,  training time: 2.22
progress:  22%|[34m       [0m| 11/50 [00:27<01:27,  2.24s/it]progress:  24%|[34m       [0m| 12/50 [00:27<01:24,  2.23s/it]                                                         Episode 13	 reward: -8.15	 makespan: 807.20	 Mean_loss: -0.15426581,  training time: 2.36
progress:  24%|[34m       [0m| 12/50 [00:30<01:24,  2.23s/it]progress:  26%|[34m       [0m| 13/50 [00:30<01:24,  2.27s/it]                                                         Episode 14	 reward: -8.10	 makespan: 802.15	 Mean_loss: -0.05341198,  training time: 2.19
progress:  26%|[34m       [0m| 13/50 [00:32<01:24,  2.27s/it]progress:  28%|[34m       [0m| 14/50 [00:32<01:21,  2.25s/it]                                                         Episode 15	 reward: -8.11	 makespan: 802.40	 Mean_loss: -0.05392468,  training time: 2.23
progress:  28%|[34m       [0m| 14/50 [00:34<01:21,  2.25s/it]progress:  30%|[34m       [0m| 15/50 [00:34<01:18,  2.25s/it]                                                         Episode 16	 reward: -8.04	 makespan: 795.70	 Mean_loss: -0.10395447,  training time: 2.19
progress:  30%|[34m       [0m| 15/50 [00:36<01:18,  2.25s/it]progress:  32%|[34m      [0m| 16/50 [00:36<01:15,  2.23s/it]                                                         Episode 17	 reward: -8.12	 makespan: 804.35	 Mean_loss: -0.33150560,  training time: 2.22
progress:  32%|[34m      [0m| 16/50 [00:38<01:15,  2.23s/it]progress:  34%|[34m      [0m| 17/50 [00:38<01:13,  2.23s/it]                                                         Episode 18	 reward: -8.04	 makespan: 795.70	 Mean_loss: -0.12800704,  training time: 2.20
progress:  34%|[34m      [0m| 17/50 [00:41<01:13,  2.23s/it]progress:  36%|[34m      [0m| 18/50 [00:41<01:11,  2.22s/it]                                                         Episode 19	 reward: -8.16	 makespan: 807.90	 Mean_loss: -0.29400766,  training time: 2.22
progress:  36%|[34m      [0m| 18/50 [00:43<01:11,  2.22s/it]progress:  38%|[34m      [0m| 19/50 [00:43<01:08,  2.22s/it]                                                         Episode 20	 reward: -8.12	 makespan: 803.65	 Mean_loss: -0.04255468,  training time: 2.21
progress:  38%|[34m      [0m| 19/50 [00:45<01:08,  2.22s/it]progress:  40%|[34m      [0m| 20/50 [00:45<01:06,  2.22s/it]                                                         Episode 21	 reward: -8.04	 makespan: 795.65	 Mean_loss: -0.16246367,  training time: 2.23
progress:  40%|[34m      [0m| 20/50 [00:47<01:06,  2.22s/it]progress:  42%|[34m     [0m| 21/50 [00:47<01:04,  2.23s/it]                                                         Episode 22	 reward: -8.07	 makespan: 798.50	 Mean_loss: -0.21633153,  training time: 2.27
progress:  42%|[34m     [0m| 21/50 [00:50<01:04,  2.23s/it]progress:  44%|[34m     [0m| 22/50 [00:50<01:02,  2.24s/it]                                                         Episode 23	 reward: -8.19	 makespan: 810.65	 Mean_loss: -0.09527345,  training time: 2.24
progress:  44%|[34m     [0m| 22/50 [00:52<01:02,  2.24s/it]progress:  46%|[34m     [0m| 23/50 [00:52<01:00,  2.24s/it]                                                         Episode 24	 reward: -8.20	 makespan: 811.75	 Mean_loss: -0.26988044,  training time: 2.16
progress:  46%|[34m     [0m| 23/50 [00:54<01:00,  2.24s/it]progress:  48%|[34m     [0m| 24/50 [00:54<00:57,  2.22s/it]                                                         Episode 25	 reward: -8.04	 makespan: 795.75	 Mean_loss: -0.24643986,  training time: 2.16
progress:  48%|[34m     [0m| 24/50 [00:56<00:57,  2.22s/it]progress:  50%|[34m     [0m| 25/50 [00:56<00:55,  2.20s/it]                                                         Episode 26	 reward: -8.01	 makespan: 793.30	 Mean_loss: -0.29879448,  training time: 2.17
progress:  50%|[34m     [0m| 25/50 [00:58<00:55,  2.20s/it]progress:  52%|[34m    [0m| 26/50 [00:58<00:52,  2.19s/it]                                                         Episode 27	 reward: -8.05	 makespan: 797.20	 Mean_loss: -0.18837915,  training time: 2.21
progress:  52%|[34m    [0m| 26/50 [01:00<00:52,  2.19s/it]progress:  54%|[34m    [0m| 27/50 [01:01<00:50,  2.20s/it]                                                         Episode 28	 reward: -7.98	 makespan: 789.70	 Mean_loss: -0.01389063,  training time: 2.23
progress:  54%|[34m    [0m| 27/50 [01:03<00:50,  2.20s/it]progress:  56%|[34m    [0m| 28/50 [01:03<00:48,  2.21s/it]                                                         Episode 29	 reward: -8.05	 makespan: 797.25	 Mean_loss: -0.28017354,  training time: 2.18
progress:  56%|[34m    [0m| 28/50 [01:05<00:48,  2.21s/it]progress:  58%|[34m    [0m| 29/50 [01:05<00:46,  2.20s/it]                                                         Episode 30	 reward: -8.05	 makespan: 797.00	 Mean_loss: -0.21901280,  training time: 2.15
progress:  58%|[34m    [0m| 29/50 [01:07<00:46,  2.20s/it]progress:  60%|[34m    [0m| 30/50 [01:07<00:43,  2.19s/it]                                                         Episode 31	 reward: -7.97	 makespan: 789.35	 Mean_loss: 0.26646143,  training time: 2.18
progress:  60%|[34m    [0m| 30/50 [01:09<00:43,  2.19s/it]progress:  62%|[34m   [0m| 31/50 [01:09<00:41,  2.19s/it]                                                         Episode 32	 reward: -8.24	 makespan: 815.45	 Mean_loss: 0.03445526,  training time: 2.21
progress:  62%|[34m   [0m| 31/50 [01:11<00:41,  2.19s/it]progress:  64%|[34m   [0m| 32/50 [01:11<00:39,  2.20s/it]                                                         Episode 33	 reward: -8.11	 makespan: 803.05	 Mean_loss: -0.05255785,  training time: 2.16
progress:  64%|[34m   [0m| 32/50 [01:14<00:39,  2.20s/it]progress:  66%|[34m   [0m| 33/50 [01:14<00:37,  2.19s/it]                                                         Episode 34	 reward: -8.14	 makespan: 805.40	 Mean_loss: -0.26996595,  training time: 2.26
progress:  66%|[34m   [0m| 33/50 [01:16<00:37,  2.19s/it]progress:  68%|[34m   [0m| 34/50 [01:16<00:35,  2.21s/it]                                                         Episode 35	 reward: -7.96	 makespan: 787.90	 Mean_loss: -0.20371243,  training time: 2.18
progress:  68%|[34m   [0m| 34/50 [01:18<00:35,  2.21s/it]progress:  70%|[34m   [0m| 35/50 [01:18<00:33,  2.20s/it]                                                         Episode 36	 reward: -8.18	 makespan: 809.95	 Mean_loss: 0.41518402,  training time: 2.17
progress:  70%|[34m   [0m| 35/50 [01:20<00:33,  2.20s/it]progress:  72%|[34m  [0m| 36/50 [01:20<00:30,  2.19s/it]                                                         Episode 37	 reward: -8.29	 makespan: 820.75	 Mean_loss: -0.09897498,  training time: 2.16
progress:  72%|[34m  [0m| 36/50 [01:22<00:30,  2.19s/it]progress:  74%|[34m  [0m| 37/50 [01:22<00:28,  2.19s/it]                                                         Episode 38	 reward: -8.15	 makespan: 807.15	 Mean_loss: 0.11972528,  training time: 2.19
progress:  74%|[34m  [0m| 37/50 [01:25<00:28,  2.19s/it]progress:  76%|[34m  [0m| 38/50 [01:25<00:26,  2.19s/it]                                                         Episode 39	 reward: -8.28	 makespan: 820.20	 Mean_loss: 0.15690914,  training time: 2.20
progress:  76%|[34m  [0m| 38/50 [01:27<00:26,  2.19s/it]progress:  78%|[34m  [0m| 39/50 [01:27<00:24,  2.19s/it]                                                         Episode 40	 reward: -8.14	 makespan: 805.90	 Mean_loss: -0.14272588,  training time: 2.23
progress:  78%|[34m  [0m| 39/50 [01:29<00:24,  2.19s/it]progress:  80%|[34m  [0m| 40/50 [01:29<00:22,  2.21s/it]                                                         Episode 41	 reward: -8.05	 makespan: 796.75	 Mean_loss: 0.14292139,  training time: 2.27
progress:  80%|[34m  [0m| 40/50 [01:31<00:22,  2.21s/it]progress:  82%|[34m [0m| 41/50 [01:31<00:20,  2.23s/it]                                                         Episode 42	 reward: -8.03	 makespan: 794.75	 Mean_loss: -0.09806572,  training time: 2.22
progress:  82%|[34m [0m| 41/50 [01:34<00:20,  2.23s/it]progress:  84%|[34m [0m| 42/50 [01:34<00:17,  2.23s/it]                                                         Episode 43	 reward: -8.10	 makespan: 801.45	 Mean_loss: 0.24593773,  training time: 2.19
progress:  84%|[34m [0m| 42/50 [01:36<00:17,  2.23s/it]progress:  86%|[34m [0m| 43/50 [01:36<00:15,  2.22s/it]                                                         Episode 44	 reward: -8.25	 makespan: 816.60	 Mean_loss: 0.33491319,  training time: 2.20
progress:  86%|[34m [0m| 43/50 [01:38<00:15,  2.22s/it]progress:  88%|[34m [0m| 44/50 [01:38<00:13,  2.21s/it]                                                         Episode 45	 reward: -8.13	 makespan: 804.45	 Mean_loss: -0.32369190,  training time: 2.20
progress:  88%|[34m [0m| 44/50 [01:40<00:13,  2.21s/it]progress:  90%|[34m [0m| 45/50 [01:40<00:11,  2.21s/it]                                                         Episode 46	 reward: -8.10	 makespan: 802.30	 Mean_loss: -0.24761413,  training time: 2.21
progress:  90%|[34m [0m| 45/50 [01:42<00:11,  2.21s/it]progress:  92%|[34m[0m| 46/50 [01:42<00:08,  2.21s/it]                                                         Episode 47	 reward: -8.18	 makespan: 809.40	 Mean_loss: -0.41823924,  training time: 2.18
progress:  92%|[34m[0m| 46/50 [01:45<00:08,  2.21s/it]progress:  94%|[34m[0m| 47/50 [01:45<00:06,  2.20s/it]                                                         Episode 48	 reward: -8.06	 makespan: 798.35	 Mean_loss: 0.13765378,  training time: 2.23
progress:  94%|[34m[0m| 47/50 [01:47<00:06,  2.20s/it]progress:  96%|[34m[0m| 48/50 [01:47<00:04,  2.21s/it]                                                         Episode 49	 reward: -8.04	 makespan: 796.15	 Mean_loss: -0.15746966,  training time: 2.25
progress:  96%|[34m[0m| 48/50 [01:49<00:04,  2.21s/it]progress:  98%|[34m[0m| 49/50 [01:49<00:02,  2.23s/it]                                                         Episode 50	 reward: -8.05	 makespan: 797.30	 Mean_loss: -0.04203239,  training time: 2.20
progress:  98%|[34m[0m| 49/50 [01:51<00:02,  2.23s/it]progress: 100%|[34m[0m| 50/50 [01:51<00:00,  2.22s/it]progress: 100%|[34m[0m| 50/50 [01:51<00:00,  2.24s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x5_10 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -11.10	 makespan: 1098.65	 Mean_loss: 2.58251476,  training time: 4.24
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:28,  4.25s/it]                                                        Episode 2	 reward: -11.20	 makespan: 1108.80	 Mean_loss: 2.20414639,  training time: 3.03
progress:   2%|[34m         [0m| 1/50 [00:07<03:28,  4.25s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:49,  3.53s/it]                                                        Episode 3	 reward: -11.37	 makespan: 1125.95	 Mean_loss: 2.11630845,  training time: 3.12
progress:   4%|[34m         [0m| 2/50 [00:10<02:49,  3.53s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:37,  3.34s/it]                                                        Episode 4	 reward: -11.18	 makespan: 1106.90	 Mean_loss: 2.04789400,  training time: 3.04
progress:   6%|[34m         [0m| 3/50 [00:13<02:37,  3.34s/it]progress:   8%|[34m         [0m| 4/50 [00:13<02:28,  3.23s/it]                                                        Episode 5	 reward: -11.13	 makespan: 1102.10	 Mean_loss: 2.20798206,  training time: 3.09
progress:   8%|[34m         [0m| 4/50 [00:16<02:28,  3.23s/it]progress:  10%|[34m         [0m| 5/50 [00:16<02:23,  3.18s/it]                                                        Episode 6	 reward: -11.21	 makespan: 1109.75	 Mean_loss: 2.31848216,  training time: 3.16
progress:  10%|[34m         [0m| 5/50 [00:19<02:23,  3.18s/it]progress:  12%|[34m        [0m| 6/50 [00:19<02:19,  3.17s/it]                                                        Episode 7	 reward: -11.25	 makespan: 1113.30	 Mean_loss: 2.34369826,  training time: 3.09
progress:  12%|[34m        [0m| 6/50 [00:22<02:19,  3.17s/it]progress:  14%|[34m        [0m| 7/50 [00:22<02:15,  3.15s/it]                                                        Episode 8	 reward: -11.02	 makespan: 1090.95	 Mean_loss: 2.00796247,  training time: 2.99
progress:  14%|[34m        [0m| 7/50 [00:25<02:15,  3.15s/it]progress:  16%|[34m        [0m| 8/50 [00:25<02:10,  3.10s/it]                                                        Episode 9	 reward: -11.26	 makespan: 1115.10	 Mean_loss: 1.83213925,  training time: 3.00
progress:  16%|[34m        [0m| 8/50 [00:28<02:10,  3.10s/it]progress:  18%|[34m        [0m| 9/50 [00:28<02:05,  3.07s/it]                                                        Episode 10	 reward: -11.12	 makespan: 1100.55	 Mean_loss: 1.88351762,  training time: 3.01
progress:  18%|[34m        [0m| 9/50 [00:31<02:05,  3.07s/it]progress:  20%|[34m        [0m| 10/50 [00:31<02:02,  3.05s/it]                                                         Episode 11	 reward: -11.23	 makespan: 1111.50	 Mean_loss: 1.58631134,  training time: 3.03
progress:  20%|[34m        [0m| 10/50 [00:34<02:02,  3.05s/it]progress:  22%|[34m       [0m| 11/50 [00:34<01:58,  3.05s/it]                                                         Episode 12	 reward: -11.27	 makespan: 1115.70	 Mean_loss: 1.41907430,  training time: 3.15
progress:  22%|[34m       [0m| 11/50 [00:37<01:58,  3.05s/it]progress:  24%|[34m       [0m| 12/50 [00:38<01:57,  3.08s/it]                                                         Episode 13	 reward: -11.35	 makespan: 1123.55	 Mean_loss: 1.23517001,  training time: 3.11
progress:  24%|[34m       [0m| 12/50 [00:41<01:57,  3.08s/it]progress:  26%|[34m       [0m| 13/50 [00:41<01:54,  3.09s/it]                                                         Episode 14	 reward: -11.26	 makespan: 1114.40	 Mean_loss: 1.36049473,  training time: 3.09
progress:  26%|[34m       [0m| 13/50 [00:44<01:54,  3.09s/it]progress:  28%|[34m       [0m| 14/50 [00:44<01:51,  3.09s/it]                                                         Episode 15	 reward: -11.34	 makespan: 1122.30	 Mean_loss: 1.12407517,  training time: 3.09
progress:  28%|[34m       [0m| 14/50 [00:47<01:51,  3.09s/it]progress:  30%|[34m       [0m| 15/50 [00:47<01:48,  3.09s/it]                                                         Episode 16	 reward: -11.11	 makespan: 1100.20	 Mean_loss: 1.15803802,  training time: 3.14
progress:  30%|[34m       [0m| 15/50 [00:50<01:48,  3.09s/it]progress:  32%|[34m      [0m| 16/50 [00:50<01:45,  3.11s/it]                                                         Episode 17	 reward: -11.34	 makespan: 1122.20	 Mean_loss: 0.99685639,  training time: 2.97
progress:  32%|[34m      [0m| 16/50 [00:53<01:45,  3.11s/it]progress:  34%|[34m      [0m| 17/50 [00:53<01:41,  3.07s/it]                                                         Episode 18	 reward: -11.29	 makespan: 1118.20	 Mean_loss: 0.81228340,  training time: 3.03
progress:  34%|[34m      [0m| 17/50 [00:56<01:41,  3.07s/it]progress:  36%|[34m      [0m| 18/50 [00:56<01:37,  3.06s/it]                                                         Episode 19	 reward: -11.42	 makespan: 1130.85	 Mean_loss: 0.94401759,  training time: 3.02
progress:  36%|[34m      [0m| 18/50 [00:59<01:37,  3.06s/it]progress:  38%|[34m      [0m| 19/50 [00:59<01:34,  3.05s/it]                                                         Episode 20	 reward: -11.51	 makespan: 1139.45	 Mean_loss: 0.73891306,  training time: 3.00
progress:  38%|[34m      [0m| 19/50 [01:02<01:34,  3.05s/it]progress:  40%|[34m      [0m| 20/50 [01:02<01:31,  3.03s/it]                                                         Episode 21	 reward: -11.34	 makespan: 1122.65	 Mean_loss: 0.70174479,  training time: 3.09
progress:  40%|[34m      [0m| 20/50 [01:05<01:31,  3.03s/it]progress:  42%|[34m     [0m| 21/50 [01:05<01:28,  3.05s/it]                                                         Episode 22	 reward: -11.60	 makespan: 1148.65	 Mean_loss: 0.76556665,  training time: 3.03
progress:  42%|[34m     [0m| 21/50 [01:08<01:28,  3.05s/it]progress:  44%|[34m     [0m| 22/50 [01:08<01:25,  3.05s/it]                                                         Episode 23	 reward: -11.57	 makespan: 1145.15	 Mean_loss: 0.70910406,  training time: 3.03
progress:  44%|[34m     [0m| 22/50 [01:11<01:25,  3.05s/it]progress:  46%|[34m     [0m| 23/50 [01:11<01:22,  3.04s/it]                                                         Episode 24	 reward: -11.44	 makespan: 1132.30	 Mean_loss: 0.68474072,  training time: 3.01
progress:  46%|[34m     [0m| 23/50 [01:14<01:22,  3.04s/it]progress:  48%|[34m     [0m| 24/50 [01:14<01:18,  3.03s/it]                                                         Episode 25	 reward: -11.52	 makespan: 1140.55	 Mean_loss: 0.63539153,  training time: 3.08
progress:  48%|[34m     [0m| 24/50 [01:17<01:18,  3.03s/it]progress:  50%|[34m     [0m| 25/50 [01:17<01:16,  3.05s/it]                                                         Episode 26	 reward: -11.70	 makespan: 1158.75	 Mean_loss: 0.65296108,  training time: 3.01
progress:  50%|[34m     [0m| 25/50 [01:20<01:16,  3.05s/it]progress:  52%|[34m    [0m| 26/50 [01:20<01:12,  3.04s/it]                                                         Episode 27	 reward: -11.55	 makespan: 1143.60	 Mean_loss: 0.58360803,  training time: 3.00
progress:  52%|[34m    [0m| 26/50 [01:23<01:12,  3.04s/it]progress:  54%|[34m    [0m| 27/50 [01:23<01:09,  3.03s/it]                                                         Episode 28	 reward: -11.70	 makespan: 1158.60	 Mean_loss: 0.56501806,  training time: 3.03
progress:  54%|[34m    [0m| 27/50 [01:26<01:09,  3.03s/it]progress:  56%|[34m    [0m| 28/50 [01:26<01:06,  3.03s/it]                                                         Episode 29	 reward: -11.69	 makespan: 1156.90	 Mean_loss: 0.61474335,  training time: 3.04
progress:  56%|[34m    [0m| 28/50 [01:29<01:06,  3.03s/it]progress:  58%|[34m    [0m| 29/50 [01:29<01:03,  3.03s/it]                                                         Episode 30	 reward: -11.46	 makespan: 1134.75	 Mean_loss: 0.59594262,  training time: 3.03
progress:  58%|[34m    [0m| 29/50 [01:32<01:03,  3.03s/it]progress:  60%|[34m    [0m| 30/50 [01:32<01:00,  3.03s/it]                                                         Episode 31	 reward: -11.36	 makespan: 1124.40	 Mean_loss: 0.50165308,  training time: 3.05
progress:  60%|[34m    [0m| 30/50 [01:35<01:00,  3.03s/it]progress:  62%|[34m   [0m| 31/50 [01:35<00:57,  3.04s/it]                                                         Episode 32	 reward: -11.46	 makespan: 1134.70	 Mean_loss: 0.47863394,  training time: 3.01
progress:  62%|[34m   [0m| 31/50 [01:38<00:57,  3.04s/it]progress:  64%|[34m   [0m| 32/50 [01:38<00:54,  3.03s/it]                                                         Episode 33	 reward: -11.54	 makespan: 1142.15	 Mean_loss: 0.46081471,  training time: 2.98
progress:  64%|[34m   [0m| 32/50 [01:41<00:54,  3.03s/it]progress:  66%|[34m   [0m| 33/50 [01:41<00:51,  3.02s/it]                                                         Episode 34	 reward: -11.57	 makespan: 1145.15	 Mean_loss: 0.45800245,  training time: 3.07
progress:  66%|[34m   [0m| 33/50 [01:44<00:51,  3.02s/it]progress:  68%|[34m   [0m| 34/50 [01:45<00:48,  3.03s/it]                                                         Episode 35	 reward: -11.42	 makespan: 1130.55	 Mean_loss: 0.44476491,  training time: 3.00
progress:  68%|[34m   [0m| 34/50 [01:48<00:48,  3.03s/it]progress:  70%|[34m   [0m| 35/50 [01:48<00:45,  3.03s/it]                                                         Episode 36	 reward: -11.47	 makespan: 1135.40	 Mean_loss: 0.47177854,  training time: 3.00
progress:  70%|[34m   [0m| 35/50 [01:51<00:45,  3.03s/it]progress:  72%|[34m  [0m| 36/50 [01:51<00:42,  3.02s/it]                                                         Episode 37	 reward: -11.47	 makespan: 1135.45	 Mean_loss: 0.43584573,  training time: 3.02
progress:  72%|[34m  [0m| 36/50 [01:54<00:42,  3.02s/it]progress:  74%|[34m  [0m| 37/50 [01:54<00:39,  3.02s/it]                                                         Episode 38	 reward: -11.34	 makespan: 1122.50	 Mean_loss: 0.41403642,  training time: 3.05
progress:  74%|[34m  [0m| 37/50 [01:57<00:39,  3.02s/it]progress:  76%|[34m  [0m| 38/50 [01:57<00:36,  3.03s/it]                                                         Episode 39	 reward: -11.13	 makespan: 1101.70	 Mean_loss: 0.35889444,  training time: 3.06
progress:  76%|[34m  [0m| 38/50 [02:00<00:36,  3.03s/it]progress:  78%|[34m  [0m| 39/50 [02:00<00:33,  3.04s/it]                                                         Episode 40	 reward: -11.24	 makespan: 1112.80	 Mean_loss: 0.34568819,  training time: 3.14
progress:  78%|[34m  [0m| 39/50 [02:03<00:33,  3.04s/it]progress:  80%|[34m  [0m| 40/50 [02:03<00:30,  3.07s/it]                                                         Episode 41	 reward: -11.47	 makespan: 1135.15	 Mean_loss: 0.49887127,  training time: 2.98
progress:  80%|[34m  [0m| 40/50 [02:06<00:30,  3.07s/it]progress:  82%|[34m [0m| 41/50 [02:06<00:27,  3.05s/it]                                                         Episode 42	 reward: -11.29	 makespan: 1117.65	 Mean_loss: 0.40799749,  training time: 3.08
progress:  82%|[34m [0m| 41/50 [02:09<00:27,  3.05s/it]progress:  84%|[34m [0m| 42/50 [02:09<00:24,  3.06s/it]                                                         Episode 43	 reward: -11.41	 makespan: 1129.25	 Mean_loss: 0.35710448,  training time: 3.00
progress:  84%|[34m [0m| 42/50 [02:12<00:24,  3.06s/it]progress:  86%|[34m [0m| 43/50 [02:12<00:21,  3.04s/it]                                                         Episode 44	 reward: -11.34	 makespan: 1122.45	 Mean_loss: 0.36753583,  training time: 3.00
progress:  86%|[34m [0m| 43/50 [02:15<00:21,  3.04s/it]progress:  88%|[34m [0m| 44/50 [02:15<00:18,  3.03s/it]                                                         Episode 45	 reward: -11.09	 makespan: 1097.60	 Mean_loss: 0.32761994,  training time: 3.02
progress:  88%|[34m [0m| 44/50 [02:18<00:18,  3.03s/it]progress:  90%|[34m [0m| 45/50 [02:18<00:15,  3.03s/it]                                                         Episode 46	 reward: -11.26	 makespan: 1114.65	 Mean_loss: 0.31868166,  training time: 3.02
progress:  90%|[34m [0m| 45/50 [02:21<00:15,  3.03s/it]progress:  92%|[34m[0m| 46/50 [02:21<00:12,  3.03s/it]                                                         Episode 47	 reward: -11.25	 makespan: 1113.75	 Mean_loss: 0.33527291,  training time: 3.00
progress:  92%|[34m[0m| 46/50 [02:24<00:12,  3.03s/it]progress:  94%|[34m[0m| 47/50 [02:24<00:09,  3.02s/it]                                                         Episode 48	 reward: -11.16	 makespan: 1105.05	 Mean_loss: 0.27358115,  training time: 3.09
progress:  94%|[34m[0m| 47/50 [02:27<00:09,  3.02s/it]progress:  96%|[34m[0m| 48/50 [02:27<00:06,  3.04s/it]                                                         Episode 49	 reward: -11.27	 makespan: 1116.20	 Mean_loss: 0.30028805,  training time: 3.08
progress:  96%|[34m[0m| 48/50 [02:30<00:06,  3.04s/it]progress:  98%|[34m[0m| 49/50 [02:30<00:03,  3.06s/it]                                                         Episode 50	 reward: -11.34	 makespan: 1122.95	 Mean_loss: 0.35132465,  training time: 2.97
progress:  98%|[34m[0m| 49/50 [02:33<00:03,  3.06s/it]progress: 100%|[34m[0m| 50/50 [02:33<00:00,  3.03s/it]progress: 100%|[34m[0m| 50/50 [02:33<00:00,  3.07s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x13+mix+SD2_4/15x5_12 --model_suffix free --finetuning_model 15x13+mix+SD2_4 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x13+mix+SD2_4.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x13+mix+SD2_4.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -13.62	 makespan: 1348.85	 Mean_loss: 4.14084387,  training time: 5.28
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:18,  5.28s/it]                                                        Episode 2	 reward: -13.67	 makespan: 1353.00	 Mean_loss: 3.22843862,  training time: 3.87
progress:   2%|[34m         [0m| 1/50 [00:09<04:18,  5.28s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:33,  4.46s/it]                                                        Episode 3	 reward: -13.62	 makespan: 1348.00	 Mean_loss: 3.10801935,  training time: 3.89
progress:   4%|[34m         [0m| 2/50 [00:13<03:33,  4.46s/it]progress:   6%|[34m         [0m| 3/50 [00:13<03:17,  4.20s/it]                                                        Episode 4	 reward: -13.77	 makespan: 1363.00	 Mean_loss: 3.48597765,  training time: 3.96
progress:   6%|[34m         [0m| 3/50 [00:17<03:17,  4.20s/it]progress:   8%|[34m         [0m| 4/50 [00:17<03:09,  4.11s/it]                                                        Episode 5	 reward: -13.83	 makespan: 1368.85	 Mean_loss: 4.23784208,  training time: 4.06
progress:   8%|[34m         [0m| 4/50 [00:21<03:09,  4.11s/it]progress:  10%|[34m         [0m| 5/50 [00:21<03:04,  4.09s/it]                                                        Episode 6	 reward: -13.88	 makespan: 1374.30	 Mean_loss: 4.32031775,  training time: 3.90
progress:  10%|[34m         [0m| 5/50 [00:24<03:04,  4.09s/it]progress:  12%|[34m        [0m| 6/50 [00:25<02:57,  4.03s/it]                                                        Episode 7	 reward: -13.92	 makespan: 1377.60	 Mean_loss: 3.81321335,  training time: 3.88
progress:  12%|[34m        [0m| 6/50 [00:28<02:57,  4.03s/it]progress:  14%|[34m        [0m| 7/50 [00:28<02:51,  3.98s/it]                                                        Episode 8	 reward: -14.09	 makespan: 1394.75	 Mean_loss: 4.27857399,  training time: 3.92
progress:  14%|[34m        [0m| 7/50 [00:32<02:51,  3.98s/it]progress:  16%|[34m        [0m| 8/50 [00:32<02:46,  3.96s/it]                                                        Episode 9	 reward: -13.91	 makespan: 1377.20	 Mean_loss: 3.81651545,  training time: 3.87
progress:  16%|[34m        [0m| 8/50 [00:36<02:46,  3.96s/it]progress:  18%|[34m        [0m| 9/50 [00:36<02:41,  3.94s/it]                                                        Episode 10	 reward: -13.97	 makespan: 1383.10	 Mean_loss: 3.59715056,  training time: 3.95
progress:  18%|[34m        [0m| 9/50 [00:40<02:41,  3.94s/it]progress:  20%|[34m        [0m| 10/50 [00:40<02:37,  3.94s/it]                                                         Episode 11	 reward: -14.10	 makespan: 1396.05	 Mean_loss: 3.03276539,  training time: 3.95
progress:  20%|[34m        [0m| 10/50 [00:44<02:37,  3.94s/it]progress:  22%|[34m       [0m| 11/50 [00:44<02:33,  3.95s/it]                                                         Episode 12	 reward: -14.11	 makespan: 1397.35	 Mean_loss: 3.02160025,  training time: 3.84
progress:  22%|[34m       [0m| 11/50 [00:48<02:33,  3.95s/it]progress:  24%|[34m       [0m| 12/50 [00:48<02:28,  3.91s/it]                                                         Episode 13	 reward: -14.13	 makespan: 1398.40	 Mean_loss: 2.96056986,  training time: 4.09
progress:  24%|[34m       [0m| 12/50 [00:52<02:28,  3.91s/it]progress:  26%|[34m       [0m| 13/50 [00:52<02:26,  3.97s/it]                                                         Episode 14	 reward: -14.33	 makespan: 1418.70	 Mean_loss: 2.65206003,  training time: 3.93
progress:  26%|[34m       [0m| 13/50 [00:56<02:26,  3.97s/it]progress:  28%|[34m       [0m| 14/50 [00:56<02:22,  3.96s/it]                                                         Episode 15	 reward: -14.23	 makespan: 1409.25	 Mean_loss: 2.20664239,  training time: 3.96
progress:  28%|[34m       [0m| 14/50 [01:00<02:22,  3.96s/it]progress:  30%|[34m       [0m| 15/50 [01:00<02:18,  3.96s/it]                                                         Episode 16	 reward: -14.29	 makespan: 1414.90	 Mean_loss: 2.06150508,  training time: 3.97
progress:  30%|[34m       [0m| 15/50 [01:04<02:18,  3.96s/it]progress:  32%|[34m      [0m| 16/50 [01:04<02:14,  3.97s/it]                                                         Episode 17	 reward: -14.24	 makespan: 1410.10	 Mean_loss: 1.74404645,  training time: 3.87
progress:  32%|[34m      [0m| 16/50 [01:08<02:14,  3.97s/it]progress:  34%|[34m      [0m| 17/50 [01:08<02:09,  3.94s/it]                                                         Episode 18	 reward: -14.12	 makespan: 1398.15	 Mean_loss: 1.54223609,  training time: 3.97
progress:  34%|[34m      [0m| 17/50 [01:12<02:09,  3.94s/it]progress:  36%|[34m      [0m| 18/50 [01:12<02:06,  3.95s/it]                                                         Episode 19	 reward: -14.08	 makespan: 1393.45	 Mean_loss: 1.42594969,  training time: 3.83
progress:  36%|[34m      [0m| 18/50 [01:16<02:06,  3.95s/it]progress:  38%|[34m      [0m| 19/50 [01:16<02:01,  3.92s/it]                                                         Episode 20	 reward: -14.30	 makespan: 1415.85	 Mean_loss: 1.33634937,  training time: 3.81
progress:  38%|[34m      [0m| 19/50 [01:19<02:01,  3.92s/it]progress:  40%|[34m      [0m| 20/50 [01:19<01:56,  3.89s/it]                                                         Episode 21	 reward: -14.03	 makespan: 1388.80	 Mean_loss: 1.30771685,  training time: 3.84
progress:  40%|[34m      [0m| 20/50 [01:23<01:56,  3.89s/it]progress:  42%|[34m     [0m| 21/50 [01:23<01:52,  3.88s/it]                                                         Episode 22	 reward: -14.12	 makespan: 1398.35	 Mean_loss: 1.08556831,  training time: 3.83
progress:  42%|[34m     [0m| 21/50 [01:27<01:52,  3.88s/it]progress:  44%|[34m     [0m| 22/50 [01:27<01:48,  3.86s/it]                                                         Episode 23	 reward: -14.08	 makespan: 1394.05	 Mean_loss: 1.19025803,  training time: 4.18
progress:  44%|[34m     [0m| 22/50 [01:31<01:48,  3.86s/it]progress:  46%|[34m     [0m| 23/50 [01:31<01:46,  3.96s/it]                                                         Episode 24	 reward: -14.09	 makespan: 1395.00	 Mean_loss: 0.98806572,  training time: 4.00
progress:  46%|[34m     [0m| 23/50 [01:35<01:46,  3.96s/it]progress:  48%|[34m     [0m| 24/50 [01:35<01:43,  3.97s/it]                                                         Episode 25	 reward: -13.96	 makespan: 1382.25	 Mean_loss: 0.97893679,  training time: 3.82
progress:  48%|[34m     [0m| 24/50 [01:39<01:43,  3.97s/it]progress:  50%|[34m     [0m| 25/50 [01:39<01:38,  3.93s/it]                                                         Episode 26	 reward: -13.92	 makespan: 1378.45	 Mean_loss: 0.93145955,  training time: 3.83
progress:  50%|[34m     [0m| 25/50 [01:43<01:38,  3.93s/it]progress:  52%|[34m    [0m| 26/50 [01:43<01:33,  3.90s/it]                                                         Episode 27	 reward: -13.88	 makespan: 1374.60	 Mean_loss: 0.90947920,  training time: 3.94
progress:  52%|[34m    [0m| 26/50 [01:47<01:33,  3.90s/it]progress:  54%|[34m    [0m| 27/50 [01:47<01:30,  3.91s/it]                                                         Episode 28	 reward: -13.89	 makespan: 1375.00	 Mean_loss: 0.92557502,  training time: 3.89
progress:  54%|[34m    [0m| 27/50 [01:51<01:30,  3.91s/it]progress:  56%|[34m    [0m| 28/50 [01:51<01:26,  3.91s/it]                                                         Episode 29	 reward: -13.92	 makespan: 1378.00	 Mean_loss: 0.81896800,  training time: 3.90
progress:  56%|[34m    [0m| 28/50 [01:55<01:26,  3.91s/it]progress:  58%|[34m    [0m| 29/50 [01:55<01:22,  3.91s/it]                                                         Episode 30	 reward: -13.90	 makespan: 1375.70	 Mean_loss: 0.82265425,  training time: 3.82
progress:  58%|[34m    [0m| 29/50 [01:59<01:22,  3.91s/it]progress:  60%|[34m    [0m| 30/50 [01:59<01:17,  3.88s/it]                                                         Episode 31	 reward: -13.98	 makespan: 1383.65	 Mean_loss: 0.94563830,  training time: 3.82
progress:  60%|[34m    [0m| 30/50 [02:02<01:17,  3.88s/it]progress:  62%|[34m   [0m| 31/50 [02:02<01:13,  3.87s/it]                                                         Episode 32	 reward: -14.01	 makespan: 1387.30	 Mean_loss: 0.79473931,  training time: 3.92
progress:  62%|[34m   [0m| 31/50 [02:06<01:13,  3.87s/it]progress:  64%|[34m   [0m| 32/50 [02:06<01:09,  3.89s/it]                                                         Episode 33	 reward: -13.96	 makespan: 1381.80	 Mean_loss: 0.76947385,  training time: 3.93
progress:  64%|[34m   [0m| 32/50 [02:10<01:09,  3.89s/it]progress:  66%|[34m   [0m| 33/50 [02:10<01:06,  3.90s/it]                                                         Episode 34	 reward: -14.02	 makespan: 1388.45	 Mean_loss: 0.82643294,  training time: 4.02
progress:  66%|[34m   [0m| 33/50 [02:14<01:06,  3.90s/it]progress:  68%|[34m   [0m| 34/50 [02:14<01:02,  3.94s/it]                                                         Episode 35	 reward: -14.18	 makespan: 1404.15	 Mean_loss: 0.81740052,  training time: 3.81
progress:  68%|[34m   [0m| 34/50 [02:18<01:02,  3.94s/it]progress:  70%|[34m   [0m| 35/50 [02:18<00:58,  3.90s/it]                                                         Episode 36	 reward: -13.93	 makespan: 1379.00	 Mean_loss: 0.75244707,  training time: 3.79
progress:  70%|[34m   [0m| 35/50 [02:22<00:58,  3.90s/it]progress:  72%|[34m  [0m| 36/50 [02:22<00:54,  3.87s/it]                                                         Episode 37	 reward: -14.10	 makespan: 1395.90	 Mean_loss: 0.80153936,  training time: 3.90
progress:  72%|[34m  [0m| 36/50 [02:26<00:54,  3.87s/it]progress:  74%|[34m  [0m| 37/50 [02:26<00:50,  3.88s/it]                                                         Episode 38	 reward: -13.96	 makespan: 1381.55	 Mean_loss: 0.72569895,  training time: 4.07
progress:  74%|[34m  [0m| 37/50 [02:30<00:50,  3.88s/it]progress:  76%|[34m  [0m| 38/50 [02:30<00:47,  3.94s/it]                                                         Episode 39	 reward: -13.98	 makespan: 1384.15	 Mean_loss: 0.81566501,  training time: 3.81
progress:  76%|[34m  [0m| 38/50 [02:34<00:47,  3.94s/it]progress:  78%|[34m  [0m| 39/50 [02:34<00:42,  3.90s/it]                                                         Episode 40	 reward: -13.66	 makespan: 1352.30	 Mean_loss: 0.71573120,  training time: 3.79
progress:  78%|[34m  [0m| 39/50 [02:37<00:42,  3.90s/it]progress:  80%|[34m  [0m| 40/50 [02:37<00:38,  3.87s/it]                                                         Episode 41	 reward: -13.70	 makespan: 1356.20	 Mean_loss: 0.72586048,  training time: 3.79
progress:  80%|[34m  [0m| 40/50 [02:41<00:38,  3.87s/it]progress:  82%|[34m [0m| 41/50 [02:41<00:34,  3.85s/it]                                                         Episode 42	 reward: -13.74	 makespan: 1360.75	 Mean_loss: 0.66435879,  training time: 3.80
progress:  82%|[34m [0m| 41/50 [02:45<00:34,  3.85s/it]progress:  84%|[34m [0m| 42/50 [02:45<00:30,  3.83s/it]                                                         Episode 43	 reward: -13.70	 makespan: 1356.00	 Mean_loss: 0.60908973,  training time: 3.79
progress:  84%|[34m [0m| 42/50 [02:49<00:30,  3.83s/it]progress:  86%|[34m [0m| 43/50 [02:49<00:26,  3.82s/it]                                                         Episode 44	 reward: -13.73	 makespan: 1358.85	 Mean_loss: 0.55641496,  training time: 3.82
progress:  86%|[34m [0m| 43/50 [02:53<00:26,  3.82s/it]progress:  88%|[34m [0m| 44/50 [02:53<00:22,  3.82s/it]                                                         Episode 45	 reward: -13.88	 makespan: 1374.50	 Mean_loss: 0.68661517,  training time: 3.78
progress:  88%|[34m [0m| 44/50 [02:56<00:22,  3.82s/it]progress:  90%|[34m [0m| 45/50 [02:56<00:19,  3.81s/it]                                                         Episode 46	 reward: -13.67	 makespan: 1353.35	 Mean_loss: 0.57537925,  training time: 3.79
progress:  90%|[34m [0m| 45/50 [03:00<00:19,  3.81s/it]progress:  92%|[34m[0m| 46/50 [03:00<00:15,  3.81s/it]                                                         Episode 47	 reward: -13.51	 makespan: 1337.70	 Mean_loss: 0.64304060,  training time: 3.83
progress:  92%|[34m[0m| 46/50 [03:04<00:15,  3.81s/it]progress:  94%|[34m[0m| 47/50 [03:04<00:11,  3.81s/it]                                                         Episode 48	 reward: -13.74	 makespan: 1360.65	 Mean_loss: 0.62132668,  training time: 3.78
progress:  94%|[34m[0m| 47/50 [03:08<00:11,  3.81s/it]progress:  96%|[34m[0m| 48/50 [03:08<00:07,  3.81s/it]                                                         Episode 49	 reward: -13.83	 makespan: 1368.80	 Mean_loss: 0.65880793,  training time: 3.78
progress:  96%|[34m[0m| 48/50 [03:12<00:07,  3.81s/it]progress:  98%|[34m[0m| 49/50 [03:12<00:03,  3.80s/it]                                                         Episode 50	 reward: -13.96	 makespan: 1381.80	 Mean_loss: 0.61116892,  training time: 3.81
progress:  98%|[34m[0m| 49/50 [03:15<00:03,  3.80s/it]progress: 100%|[34m[0m| 50/50 [03:15<00:00,  3.80s/it]progress: 100%|[34m[0m| 50/50 [03:15<00:00,  3.92s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127

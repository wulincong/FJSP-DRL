+ source /work/home/lxx_hzau/.bashrc
++ export CUDA_HOME=/usr/local/cuda-11.1/
++ CUDA_HOME=/usr/local/cuda-11.1/
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++ '[' -f /etc/bashrc ']'
++ . /etc/bashrc
+++ '[' '' ']'
+++ shopt -q login_shell
+++ '[' 5235 -gt 199 ']'
++++ /usr/bin/id -gn
++++ /usr/bin/id -un
+++ '[' ac6owqc808 = lxx_hzau ']'
+++ umask 022
+++ SHELL=/bin/bash
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/256term.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/256term.sh
++++ local256=truecolor
++++ '[' -n truecolor ']'
++++ case "$TERM" in
++++ export TERM
++++ '[' -n '' ']'
++++ unset local256
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/abrt-console-notification.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/abrt-console-notification.sh
++++ tty -s
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/bash_completion.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/bash_completion.sh
++++ '[' -z '4.2.46(2)-release' -o -z '' -o -n '' ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/clusconf-env.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/clusconf-env.sh
++++ export CLUSCONF_HOME=/opt/clusconf
++++ CLUSCONF_HOME=/opt/clusconf
++++ export PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ NFSCONF=/opt/clusconf/etc/nfs.cfg
++++ export IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ IPMICONF=/opt/clusconf/etc/ipmi.cfg
++++ export AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ AUTOCLUSCONF=/opt/clusconf/etc/autoconf.cfg
++++ export STARTWAITTIME=300
++++ STARTWAITTIME=300
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorgrep.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorgrep.sh
++++ /usr/libexec/grepconf.sh -c
++++ alias 'grep=grep --color=auto'
++++ alias 'egrep=egrep --color=auto'
++++ alias 'fgrep=fgrep --color=auto'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/colorls.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/colorls.sh
++++ '[' '!' -t 0 ']'
++++ return
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/dawning.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/dawning.sh
++++ export GRIDVIEW_HOME=/opt/gridview
++++ GRIDVIEW_HOME=/opt/gridview
++++ export MUNGE_HOME=/opt/gridview/munge
++++ MUNGE_HOME=/opt/gridview/munge
++++ export PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_HOME=/opt/gridview/slurm
++++ SLURM_HOME=/opt/gridview/slurm
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin/
++++ export LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ LD_LIBRARY_PATH=/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++++ export MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ MANPATH=/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/share/man:/opt/rh/devtoolset-7/root/usr/share/man:/opt/gridview/slurm/share/man:/opt/gridview/munge/share/man:
++++ export C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ C_INCLUDE_PATH=/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/gridview/slurm/include:/opt/gridview/munge/include:/opt/rh/devtoolset-7/root/usr/include/c++/7:/opt/rh/devtoolset-7/root/usr/include/c++/7/x86_64-redhat-linux:/opt/gridview/slurm/include:/opt/gridview/munge/include:
++++ export SLURM_PMIX_DIRECT_CONN=true
++++ SLURM_PMIX_DIRECT_CONN=true
++++ export SLURM_PMIX_DIRECT_CONN_UCX=true
++++ SLURM_PMIX_DIRECT_CONN_UCX=true
++++ export SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ SLURM_PMIX_DIRECT_CONN_EARLY=true
++++ export SLURM_PMIX_TIMEOUT=3000
++++ SLURM_PMIX_TIMEOUT=3000
++++ '[' lxx_hzau '!=' root ']'
++++ export SQUEUE_USERS=lxx_hzau
++++ SQUEUE_USERS=lxx_hzau
++++ export SCONTROL_JOB_USERS=lxx_hzau
++++ SCONTROL_JOB_USERS=lxx_hzau
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/flatpak.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/flatpak.sh
++++ '[' /exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share = /work/home/lxx_hzau/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share ']'
++++ export XDG_DATA_DIRS
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/kde.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/kde.sh
++++ '[' -z /usr ']'
++++ '[' -z '' ']'
++++ grep --color=auto -qs '^PRELINKING=yes' /etc/sysconfig/prelink
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib64/kde4/plugins
++++ for libdir in /usr/lib64 /usr/lib
++++ '[' -n /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins ']'
++++ echo /usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
++++ /bin/grep -q /usr/lib/kde4/plugins
++++ '[' '!' -d /work/home/lxx_hzau/.local/share ']'
++++ unset libdir
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/lang.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/lang.sh
++++ sourced=0
++++ '[' -n en_US.UTF-8 ']'
++++ saved_lang=en_US.UTF-8
++++ '[' -f /work/home/lxx_hzau/.i18n ']'
++++ LANG=en_US.UTF-8
++++ unset saved_lang
++++ '[' 0 = 1 ']'
++++ unset sourced
++++ unset langfile
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/less.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/less.sh
++++ '[' -x /usr/bin/lesspipe.sh ']'
++++ export 'LESSOPEN=||/usr/bin/lesspipe.sh %s'
++++ LESSOPEN='||/usr/bin/lesspipe.sh %s'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/modules.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/modules.sh
++++++ /bin/ps -p 2322 -ocomm=
+++++ /bin/basename slurm_script
++++ shell=slurm_script
++++ '[' -f /usr/share/Modules/init/slurm_script ']'
++++ . /usr/share/Modules/init/sh
+++++ MODULESHOME=/usr/share/Modules
+++++ export MODULESHOME
+++++ '[' compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1 = '' ']'
+++++ '[' /public/software/modules/base:/public/software/modules/apps = '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/mpi-selector.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/mpi-selector.sh
++++ mpi_selector_dir=/var/mpi-selector/data
++++ mpi_selector_homefile=/work/home/lxx_hzau/.mpi-selector
++++ mpi_selector_sysfile=/etc/sysconfig/mpi-selector
++++ mpi_selection=
++++ test -f /work/home/lxx_hzau/.mpi-selector
++++ test -f /etc/sysconfig/mpi-selector
++++ test '' '!=' '' -a -f /var/mpi-selector/data/.sh
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/PackageKit.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/PackageKit.sh
++++ [[ -n '' ]]
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/perl-homedir.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/perl-homedir.sh
++++ PERL_HOMEDIR=1
++++ '[' -f /etc/sysconfig/perl-homedir ']'
++++ '[' -f /work/home/lxx_hzau/.perl-homedir ']'
++++ alias 'perlll=eval `perl -Mlocal::lib`'
++++ '[' x1 = x1 ']'
+++++ perl -Mlocal::lib
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt-graphicssystem.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt-graphicssystem.sh
++++ '[' -z 1 -a -z '' ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/qt.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/qt.sh
++++ '[' -z /usr/lib64/qt-3.3 ']'
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/rocm-gcc-mpi-default.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/rocm-gcc-mpi-default.sh
++++ [[ lxx_hzau =~ root|xhadmin ]]
++++ module use /public/software/modules/apps
+++++ /usr/bin/modulecmd sh use /public/software/modules/apps
++++ eval
++++ module use /public/software/modules/base
+++++ /usr/bin/modulecmd sh use /public/software/modules/base
++++ eval
++++ module unuse /opt/hpc/software/modules
+++++ /usr/bin/modulecmd sh unuse /opt/hpc/software/modules
++++ eval
++++ module load compiler/devtoolset/7.3.1
+++++ /usr/bin/modulecmd sh load compiler/devtoolset/7.3.1
++++ eval
++++ module load mpi/hpcx/gcc-7.3.1
+++++ /usr/bin/modulecmd sh load mpi/hpcx/gcc-7.3.1
++++ eval
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vim.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vim.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' -o -n '' ']'
++++ '[' -x /usr/bin/id ']'
+++++ /usr/bin/id -u
++++ ID=5235
++++ '[' -n 5235 -a 5235 -le 200 ']'
++++ alias vi
++++ alias vi=vim
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/vte.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/vte.sh
++++ '[' -n '4.2.46(2)-release' -o -n '' ']'
++++ [[ hxB == *i* ]]
++++ return 0
+++ for i in '/etc/profile.d/*.sh'
+++ '[' -r /etc/profile.d/which2.sh ']'
+++ '[' '' ']'
+++ . /etc/profile.d/which2.sh
++++ alias 'which=alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
+++ unset i
+++ unset -f pathmunge
+++ /work/home/lxx_hzau/miniconda3/bin/conda shell.bash hook
++ __conda_setup='export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++ '[' 0 -eq 0 ']'
++ eval 'export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+++ '[' -z x ']'
+++ conda activate base
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate base
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1=
++++ __conda_exe shell.posix activate base
++++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate base
+++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
+++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\'''
++++ PS1='(base) '
++++ export PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ PATH=/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export 'CONDA_PROMPT_MODIFIER=(base) '
++++ CONDA_PROMPT_MODIFIER='(base) '
++++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ unset __conda_setup
++ export PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
+ module load nvidia/cuda/11.6
++ /usr/bin/modulecmd sh load nvidia/cuda/11.6
+ eval CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/ ';export' 'CUDA_HOME;CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0' ';export' 'CUDA_ROOT;INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6' ';export' 'LOADEDMODULES;PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin' ';export' 'PATH;_LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6' ';export' '_LMFILES_;'
++ CUDA_HOME=/public/software/compiler/nvidia/cuda/11.6.0:/usr/local/cuda-11.1/
++ export CUDA_HOME
++ CUDA_ROOT=/public/software/compiler/nvidia/cuda/11.6.0
++ export CUDA_ROOT
++ INCLUDE=/public/software/compiler/nvidia/cuda/11.6.0/include:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/include:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/include:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/include:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/public/software/compiler/nvidia/cuda/11.6.0/lib64:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/sharp/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/lib:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/gridview/slurm/lib:/opt/gridview/slurm/lib64:/opt/gridview/munge/lib:
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=compiler/devtoolset/7.3.1:mpi/hpcx/gcc-7.3.1:nvidia/cuda/11.6
++ export LOADEDMODULES
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export PATH
++ _LMFILES_=/public/software/modules/base/compiler/devtoolset/7.3.1:/public/software/modules/base/mpi/hpcx/gcc-7.3.1:/public/software/modules/base/nvidia/cuda/11.6
++ export _LMFILES_
+ conda activate RL-torch
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate RL-torch
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate RL-torch
++ /work/home/lxx_hzau/miniconda3/bin/conda shell.posix activate RL-torch
+ ask_conda='PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
+ eval 'PS1='\''(RL-torch) '\''
export PATH='\''/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin'\''
export CONDA_PREFIX='\''/work/home/lxx_hzau/miniconda3/envs/RL-torch'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''RL-torch'\''
export CONDA_PROMPT_MODIFIER='\''(RL-torch) '\''
export PYTHONPATH='\''/work/home/lxx_hzau/project/FJSP-DRL-main'\''
export CONDA_PREFIX_1='\''/work/home/lxx_hzau/miniconda3'\''
export CONDA_EXE='\''/work/home/lxx_hzau/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/home/lxx_hzau/miniconda3/bin/python'\'''
++ PS1='(RL-torch) '
++ export PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ PATH=/public/software/compiler/nvidia/cuda/11.6.0/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/home/lxx_hzau/local/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/work/home/lxx_hzau/local/bin:/work/home/lxx_hzau/miniconda3/envs/RL-torch/bin:/work/home/lxx_hzau/miniconda3/condabin:/opt/hpc/software/mpi/hpcx/v2.11.0/gcc-7.3.1/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/hcoll/bin:/opt/hpc/software/mpi/hpcx/v2.11.0/ucx_without_rocm/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/lib64/qt-3.3/bin:/work/home/lxx_hzau/perl5/bin:/opt/gridview/slurm/bin:/opt/gridview/slurm/sbin:/opt/gridview/munge/bin:/opt/gridview/munge/sbin:/opt/clusconf/sbin:/opt/clusconf/bin:/usr/local/bin:/usr/bin:/usr/local/cuda-11.1/bin:/usr/local/sbin:/usr/sbin:/usr/local/cuda-11.1/bin:/work/home/lxx_hzau/.local/bin:/work/home/lxx_hzau/bin:/usr/local/cuda-11.1/bin:/usr/local/cuda-11.1/bin
++ export CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ CONDA_PREFIX=/work/home/lxx_hzau/miniconda3/envs/RL-torch
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=RL-torch
++ CONDA_DEFAULT_ENV=RL-torch
++ export 'CONDA_PROMPT_MODIFIER=(RL-torch) '
++ CONDA_PROMPT_MODIFIER='(RL-torch) '
++ export PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ PYTHONPATH=/work/home/lxx_hzau/project/FJSP-DRL-main
++ export CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ CONDA_PREFIX_1=/work/home/lxx_hzau/miniconda3
++ export CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ CONDA_EXE=/work/home/lxx_hzau/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/work/home/lxx_hzau/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ t=train
+ exp=exp17_1
+ echo exp17_1
exp17_1
+ cat

->  op_per_job ->
+ n_j_options='15 15 15 15'
+ n_m_options='13 10 7 5'
+ op_per_job_options='4 7 10 12'
+ logdir=./runs/exp17_1
+ hidden_dim_actor=512
+ hidden_dim_critic=512
+ num_mlp_layers_actor=3
+ num_mlp_layers_critic=3
+ num_envs=4
+ meta_iterations=200
+ max_updates_maml=500
+ num_tasks=4
+ max_updates_finetune=50
+ lr=0.003
+ data='13,4 10,7 7,10 5,12'
+ logdir_dan=./runs/exp17_1/DAN
+ python train/DAN.py --n_j 15 --n_m 5 --op_per_job 12 --data_source SD2 --model_suffix SD2_12 --logdir ./runs/exp17_1/DAN/train_model/15x5x12 --max_updates 300
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+SD2_12
-------------------------Training Setting-------------------------
source : SD2
model name :15x5+mix+SD2_12
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/300 [00:00<?, ?it/s]                                                 Episode 1	 reward: -20.43	 makespan: 2022.80	 Mean_loss: 22.64959717,  training time: 7.01
progress:   0%|[34m          [0m| 0/300 [00:07<?, ?it/s]progress:   0%|[34m          [0m| 1/300 [00:07<34:56,  7.01s/it]                                                         Episode 2	 reward: -19.52	 makespan: 1932.20	 Mean_loss: 18.76117897,  training time: 3.77
progress:   0%|[34m          [0m| 1/300 [00:10<34:56,  7.01s/it]progress:   1%|[34m          [0m| 2/300 [00:10<25:22,  5.11s/it]                                                         Episode 3	 reward: -19.07	 makespan: 1887.65	 Mean_loss: 15.47761917,  training time: 3.83
progress:   1%|[34m          [0m| 2/300 [00:14<25:22,  5.11s/it]progress:   1%|[34m          [0m| 3/300 [00:14<22:23,  4.52s/it]                                                         Episode 4	 reward: -18.78	 makespan: 1858.95	 Mean_loss: 11.35195351,  training time: 3.74
progress:   1%|[34m          [0m| 3/300 [00:18<22:23,  4.52s/it]progress:   1%|[34m         [0m| 4/300 [00:18<20:47,  4.21s/it]                                                         Episode 5	 reward: -19.17	 makespan: 1897.80	 Mean_loss: 10.63013554,  training time: 3.93
progress:   1%|[34m         [0m| 4/300 [00:22<20:47,  4.21s/it]progress:   2%|[34m         [0m| 5/300 [00:22<20:13,  4.11s/it]                                                         Episode 6	 reward: -20.00	 makespan: 1980.15	 Mean_loss: 12.30818462,  training time: 3.93
progress:   2%|[34m         [0m| 5/300 [00:26<20:13,  4.11s/it]progress:   2%|[34m         [0m| 6/300 [00:26<19:50,  4.05s/it]                                                         Episode 7	 reward: -19.46	 makespan: 1926.85	 Mean_loss: 14.01500511,  training time: 4.01
progress:   2%|[34m         [0m| 6/300 [00:30<19:50,  4.05s/it]progress:   2%|[34m         [0m| 7/300 [00:30<19:43,  4.04s/it]                                                         Episode 8	 reward: -19.45	 makespan: 1925.50	 Mean_loss: 14.72734642,  training time: 3.99
progress:   2%|[34m         [0m| 7/300 [00:34<19:43,  4.04s/it]progress:   3%|[34m         [0m| 8/300 [00:34<19:34,  4.02s/it]                                                         Episode 9	 reward: -20.14	 makespan: 1993.65	 Mean_loss: 15.80562878,  training time: 3.93
progress:   3%|[34m         [0m| 8/300 [00:38<19:34,  4.02s/it]progress:   3%|[34m         [0m| 9/300 [00:38<19:22,  3.99s/it]                                                         Episode 10	 reward: -20.25	 makespan: 2004.90	 Mean_loss: 16.86549377,  training time: 3.83
progress:   3%|[34m         [0m| 9/300 [00:41<19:22,  3.99s/it]progress:   3%|[34m         [0m| 10/300 [00:41<19:03,  3.94s/it]                                                          Episode 11	 reward: -19.97	 makespan: 1976.55	 Mean_loss: 17.59708023,  training time: 3.90
progress:   3%|[34m         [0m| 10/300 [00:45<19:03,  3.94s/it]progress:   4%|[34m         [0m| 11/300 [00:45<18:55,  3.93s/it]                                                          Episode 12	 reward: -20.10	 makespan: 1989.70	 Mean_loss: 17.98911858,  training time: 3.78
progress:   4%|[34m         [0m| 11/300 [00:49<18:55,  3.93s/it]progress:   4%|[34m         [0m| 12/300 [00:49<18:38,  3.88s/it]                                                          Episode 13	 reward: -20.55	 makespan: 2034.85	 Mean_loss: 17.08071518,  training time: 3.88
progress:   4%|[34m         [0m| 12/300 [00:53<18:38,  3.88s/it]progress:   4%|[34m         [0m| 13/300 [00:53<18:34,  3.88s/it]                                                          Episode 14	 reward: -19.92	 makespan: 1972.50	 Mean_loss: 14.38840008,  training time: 3.73
progress:   4%|[34m         [0m| 13/300 [00:57<18:34,  3.88s/it]progress:   5%|[34m         [0m| 14/300 [00:57<18:17,  3.84s/it]                                                          Episode 15	 reward: -20.33	 makespan: 2012.60	 Mean_loss: 13.88965702,  training time: 3.93
progress:   5%|[34m         [0m| 14/300 [01:01<18:17,  3.84s/it]progress:   5%|[34m         [0m| 15/300 [01:01<18:21,  3.87s/it]                                                          Episode 16	 reward: -20.38	 makespan: 2017.55	 Mean_loss: 14.04613113,  training time: 3.85
progress:   5%|[34m         [0m| 15/300 [01:05<18:21,  3.87s/it]progress:   5%|[34m         [0m| 16/300 [01:05<18:16,  3.86s/it]                                                          Episode 17	 reward: -20.38	 makespan: 2017.70	 Mean_loss: 14.73794270,  training time: 3.79
progress:   5%|[34m         [0m| 16/300 [01:08<18:16,  3.86s/it]progress:   6%|[34m         [0m| 17/300 [01:08<18:06,  3.84s/it]                                                          Episode 18	 reward: -19.95	 makespan: 1975.10	 Mean_loss: 12.93645954,  training time: 3.84
progress:   6%|[34m         [0m| 17/300 [01:12<18:06,  3.84s/it]progress:   6%|[34m         [0m| 18/300 [01:12<18:02,  3.84s/it]                                                          Episode 19	 reward: -20.07	 makespan: 1987.25	 Mean_loss: 12.98776627,  training time: 3.86
progress:   6%|[34m         [0m| 18/300 [01:16<18:02,  3.84s/it]progress:   6%|[34m         [0m| 19/300 [01:16<18:00,  3.85s/it]                                                          Episode 20	 reward: -19.84	 makespan: 1964.55	 Mean_loss: 12.62973022,  training time: 3.82
progress:   6%|[34m         [0m| 19/300 [01:20<18:00,  3.85s/it]progress:   7%|[34m         [0m| 20/300 [01:20<17:54,  3.84s/it]                                                          Episode 21	 reward: -19.57	 makespan: 1937.55	 Mean_loss: 10.60758686,  training time: 3.96
progress:   7%|[34m         [0m| 20/300 [01:24<17:54,  3.84s/it]progress:   7%|[34m         [0m| 21/300 [01:24<18:00,  3.87s/it]                                                          Episode 22	 reward: -19.21	 makespan: 1901.30	 Mean_loss: 10.43036652,  training time: 3.78
progress:   7%|[34m         [0m| 21/300 [01:28<18:00,  3.87s/it]progress:   7%|[34m         [0m| 22/300 [01:28<17:49,  3.85s/it]                                                          Episode 23	 reward: -19.08	 makespan: 1888.85	 Mean_loss: 10.00355911,  training time: 3.88
progress:   7%|[34m         [0m| 22/300 [01:31<17:49,  3.85s/it]progress:   8%|[34m         [0m| 23/300 [01:31<17:48,  3.86s/it]                                                          Episode 24	 reward: -18.78	 makespan: 1858.95	 Mean_loss: 9.40468693,  training time: 3.77
progress:   8%|[34m         [0m| 23/300 [01:35<17:48,  3.86s/it]progress:   8%|[34m         [0m| 24/300 [01:35<17:37,  3.83s/it]                                                          Episode 25	 reward: -19.20	 makespan: 1901.20	 Mean_loss: 7.76292372,  training time: 3.75
progress:   8%|[34m         [0m| 24/300 [01:39<17:37,  3.83s/it]progress:   8%|[34m         [0m| 25/300 [01:39<17:26,  3.81s/it]                                                          Episode 26	 reward: -18.65	 makespan: 1845.90	 Mean_loss: 7.43652058,  training time: 3.76
progress:   8%|[34m         [0m| 25/300 [01:43<17:26,  3.81s/it]progress:   9%|[34m         [0m| 26/300 [01:43<17:18,  3.79s/it]                                                          Episode 27	 reward: -18.99	 makespan: 1879.70	 Mean_loss: 6.66188955,  training time: 3.77
progress:   9%|[34m         [0m| 26/300 [01:47<17:18,  3.79s/it]progress:   9%|[34m         [0m| 27/300 [01:47<17:13,  3.79s/it]                                                          Episode 28	 reward: -18.31	 makespan: 1812.90	 Mean_loss: 7.71219683,  training time: 3.83
progress:   9%|[34m         [0m| 27/300 [01:50<17:13,  3.79s/it]progress:   9%|[34m         [0m| 28/300 [01:50<17:13,  3.80s/it]                                                          Episode 29	 reward: -17.82	 makespan: 1763.90	 Mean_loss: 6.52364063,  training time: 3.76
progress:   9%|[34m         [0m| 28/300 [01:54<17:13,  3.80s/it]progress:  10%|[34m         [0m| 29/300 [01:54<17:06,  3.79s/it]                                                          Episode 30	 reward: -18.22	 makespan: 1804.25	 Mean_loss: 5.68852711,  training time: 3.75
progress:  10%|[34m         [0m| 29/300 [01:58<17:06,  3.79s/it]progress:  10%|[34m         [0m| 30/300 [01:58<17:00,  3.78s/it]                                                          Episode 31	 reward: -18.46	 makespan: 1827.50	 Mean_loss: 6.05961752,  training time: 3.80
progress:  10%|[34m         [0m| 30/300 [02:02<17:00,  3.78s/it]progress:  10%|[34m         [0m| 31/300 [02:02<16:58,  3.79s/it]                                                          Episode 32	 reward: -18.18	 makespan: 1799.65	 Mean_loss: 5.68772030,  training time: 3.84
progress:  10%|[34m         [0m| 31/300 [02:06<16:58,  3.79s/it]progress:  11%|[34m         [0m| 32/300 [02:06<16:59,  3.80s/it]                                                          Episode 33	 reward: -17.56	 makespan: 1738.40	 Mean_loss: 4.66762829,  training time: 3.74
progress:  11%|[34m         [0m| 32/300 [02:09<16:59,  3.80s/it]progress:  11%|[34m         [0m| 33/300 [02:09<16:50,  3.79s/it]                                                          Episode 34	 reward: -17.52	 makespan: 1734.90	 Mean_loss: 4.43782902,  training time: 3.94
progress:  11%|[34m         [0m| 33/300 [02:13<16:50,  3.79s/it]progress:  11%|[34m        [0m| 34/300 [02:13<16:59,  3.83s/it]                                                          Episode 35	 reward: -17.45	 makespan: 1727.55	 Mean_loss: 4.23502254,  training time: 3.88
progress:  11%|[34m        [0m| 34/300 [02:17<16:59,  3.83s/it]progress:  12%|[34m        [0m| 35/300 [02:17<16:59,  3.85s/it]                                                          Episode 36	 reward: -17.17	 makespan: 1700.15	 Mean_loss: 3.54858923,  training time: 3.79
progress:  12%|[34m        [0m| 35/300 [02:21<16:59,  3.85s/it]progress:  12%|[34m        [0m| 36/300 [02:21<16:51,  3.83s/it]                                                          Episode 37	 reward: -16.93	 makespan: 1676.05	 Mean_loss: 3.57624149,  training time: 3.89
progress:  12%|[34m        [0m| 36/300 [02:25<16:51,  3.83s/it]progress:  12%|[34m        [0m| 37/300 [02:25<16:51,  3.85s/it]                                                          Episode 38	 reward: -16.52	 makespan: 1635.50	 Mean_loss: 3.08301544,  training time: 3.78
progress:  12%|[34m        [0m| 37/300 [02:29<16:51,  3.85s/it]progress:  13%|[34m        [0m| 38/300 [02:29<16:42,  3.83s/it]                                                          Episode 39	 reward: -16.65	 makespan: 1647.95	 Mean_loss: 2.89313984,  training time: 3.75
progress:  13%|[34m        [0m| 38/300 [02:32<16:42,  3.83s/it]progress:  13%|[34m        [0m| 39/300 [02:32<16:33,  3.81s/it]                                                          Episode 40	 reward: -16.63	 makespan: 1646.50	 Mean_loss: 2.83532262,  training time: 3.82
progress:  13%|[34m        [0m| 39/300 [02:36<16:33,  3.81s/it]progress:  13%|[34m        [0m| 40/300 [02:36<16:30,  3.81s/it]                                                          Episode 41	 reward: -16.23	 makespan: 1607.25	 Mean_loss: 2.45438671,  training time: 3.82
progress:  13%|[34m        [0m| 40/300 [02:40<16:30,  3.81s/it]progress:  14%|[34m        [0m| 41/300 [02:40<16:27,  3.81s/it]                                                          Episode 42	 reward: -15.73	 makespan: 1557.35	 Mean_loss: 2.38245082,  training time: 3.77
progress:  14%|[34m        [0m| 41/300 [02:44<16:27,  3.81s/it]progress:  14%|[34m        [0m| 42/300 [02:44<16:20,  3.80s/it]                                                          Episode 43	 reward: -15.82	 makespan: 1566.55	 Mean_loss: 2.04183602,  training time: 3.84
progress:  14%|[34m        [0m| 42/300 [02:48<16:20,  3.80s/it]progress:  14%|[34m        [0m| 43/300 [02:48<16:19,  3.81s/it]                                                          Episode 44	 reward: -15.44	 makespan: 1528.45	 Mean_loss: 1.78653288,  training time: 3.80
progress:  14%|[34m        [0m| 43/300 [02:51<16:19,  3.81s/it]progress:  15%|[34m        [0m| 44/300 [02:51<16:15,  3.81s/it]                                                          Episode 45	 reward: -14.94	 makespan: 1479.10	 Mean_loss: 1.59957480,  training time: 3.81
progress:  15%|[34m        [0m| 44/300 [02:55<16:15,  3.81s/it]progress:  15%|[34m        [0m| 45/300 [02:55<16:11,  3.81s/it]                                                          Episode 46	 reward: -15.24	 makespan: 1509.15	 Mean_loss: 1.50843740,  training time: 3.87
progress:  15%|[34m        [0m| 45/300 [02:59<16:11,  3.81s/it]progress:  15%|[34m        [0m| 46/300 [02:59<16:12,  3.83s/it]                                                          Episode 47	 reward: -15.11	 makespan: 1496.25	 Mean_loss: 1.40774202,  training time: 3.93
progress:  15%|[34m        [0m| 46/300 [03:03<16:12,  3.83s/it]progress:  16%|[34m        [0m| 47/300 [03:03<16:16,  3.86s/it]                                                          Episode 48	 reward: -14.98	 makespan: 1483.35	 Mean_loss: 1.41385412,  training time: 3.91
progress:  16%|[34m        [0m| 47/300 [03:07<16:16,  3.86s/it]progress:  16%|[34m        [0m| 48/300 [03:07<16:16,  3.87s/it]                                                          Episode 49	 reward: -14.68	 makespan: 1453.75	 Mean_loss: 1.23452830,  training time: 3.75
progress:  16%|[34m        [0m| 48/300 [03:11<16:16,  3.87s/it]progress:  16%|[34m        [0m| 49/300 [03:11<16:03,  3.84s/it]                                                          Episode 50	 reward: -14.66	 makespan: 1451.75	 Mean_loss: 1.15756798,  training time: 3.75
progress:  16%|[34m        [0m| 49/300 [03:14<16:03,  3.84s/it]progress:  17%|[34m        [0m| 50/300 [03:14<15:52,  3.81s/it]                                                          Episode 51	 reward: -14.63	 makespan: 1447.95	 Mean_loss: 1.05170989,  training time: 3.72
progress:  17%|[34m        [0m| 50/300 [03:18<15:52,  3.81s/it]progress:  17%|[34m        [0m| 51/300 [03:18<15:41,  3.78s/it]                                                          Episode 52	 reward: -14.23	 makespan: 1408.85	 Mean_loss: 0.85944444,  training time: 3.74
progress:  17%|[34m        [0m| 51/300 [03:22<15:41,  3.78s/it]progress:  17%|[34m        [0m| 52/300 [03:22<15:34,  3.77s/it]                                                          Episode 53	 reward: -14.39	 makespan: 1424.65	 Mean_loss: 0.94120717,  training time: 3.84
progress:  17%|[34m        [0m| 52/300 [03:26<15:34,  3.77s/it]progress:  18%|[34m        [0m| 53/300 [03:26<15:36,  3.79s/it]                                                          Episode 54	 reward: -14.19	 makespan: 1405.30	 Mean_loss: 0.74456245,  training time: 3.74
progress:  18%|[34m        [0m| 53/300 [03:29<15:36,  3.79s/it]progress:  18%|[34m        [0m| 54/300 [03:29<15:28,  3.77s/it]                                                          Episode 55	 reward: -14.00	 makespan: 1385.60	 Mean_loss: 0.77107179,  training time: 3.72
progress:  18%|[34m        [0m| 54/300 [03:33<15:28,  3.77s/it]progress:  18%|[34m        [0m| 55/300 [03:33<15:20,  3.76s/it]                                                          Episode 56	 reward: -14.17	 makespan: 1402.90	 Mean_loss: 0.76449621,  training time: 3.78
progress:  18%|[34m        [0m| 55/300 [03:37<15:20,  3.76s/it]progress:  19%|[34m        [0m| 56/300 [03:37<15:18,  3.76s/it]                                                          Episode 57	 reward: -14.11	 makespan: 1396.40	 Mean_loss: 0.73814732,  training time: 3.75
progress:  19%|[34m        [0m| 56/300 [03:41<15:18,  3.76s/it]progress:  19%|[34m        [0m| 57/300 [03:41<15:13,  3.76s/it]                                                          Episode 58	 reward: -13.96	 makespan: 1382.15	 Mean_loss: 0.65851790,  training time: 3.73
progress:  19%|[34m        [0m| 57/300 [03:44<15:13,  3.76s/it]progress:  19%|[34m        [0m| 58/300 [03:44<15:07,  3.75s/it]                                                          Episode 59	 reward: -13.88	 makespan: 1374.00	 Mean_loss: 0.59995264,  training time: 3.72
progress:  19%|[34m        [0m| 58/300 [03:48<15:07,  3.75s/it]progress:  20%|[34m        [0m| 59/300 [03:48<15:01,  3.74s/it]                                                          Episode 60	 reward: -13.97	 makespan: 1382.95	 Mean_loss: 0.78221744,  training time: 3.73
progress:  20%|[34m        [0m| 59/300 [03:52<15:01,  3.74s/it]progress:  20%|[34m        [0m| 60/300 [03:52<14:57,  3.74s/it]                                                          Episode 61	 reward: -14.12	 makespan: 1397.70	 Mean_loss: 0.65311533,  training time: 3.79
progress:  20%|[34m        [0m| 60/300 [03:56<14:57,  3.74s/it]progress:  20%|[34m        [0m| 61/300 [03:56<14:57,  3.76s/it]                                                          Episode 62	 reward: -14.06	 makespan: 1391.55	 Mean_loss: 0.68459922,  training time: 3.77
progress:  20%|[34m        [0m| 61/300 [03:59<14:57,  3.76s/it]progress:  21%|[34m        [0m| 62/300 [03:59<14:55,  3.76s/it]                                                          Episode 63	 reward: -14.14	 makespan: 1400.30	 Mean_loss: 0.68176848,  training time: 3.73
progress:  21%|[34m        [0m| 62/300 [04:03<14:55,  3.76s/it]progress:  21%|[34m        [0m| 63/300 [04:03<14:57,  3.79s/it]                                                          Episode 64	 reward: -14.02	 makespan: 1388.45	 Mean_loss: 0.54957223,  training time: 3.83
progress:  21%|[34m        [0m| 63/300 [04:07<14:57,  3.79s/it]progress:  21%|[34m       [0m| 64/300 [04:07<14:57,  3.80s/it]                                                          Episode 65	 reward: -13.96	 makespan: 1382.05	 Mean_loss: 0.60218662,  training time: 3.72
progress:  21%|[34m       [0m| 64/300 [04:11<14:57,  3.80s/it]progress:  22%|[34m       [0m| 65/300 [04:11<14:47,  3.78s/it]                                                          Episode 66	 reward: -13.89	 makespan: 1375.55	 Mean_loss: 0.57564461,  training time: 3.72
progress:  22%|[34m       [0m| 65/300 [04:15<14:47,  3.78s/it]progress:  22%|[34m       [0m| 66/300 [04:15<14:39,  3.76s/it]                                                          Episode 67	 reward: -13.92	 makespan: 1377.60	 Mean_loss: 0.53404468,  training time: 3.78
progress:  22%|[34m       [0m| 66/300 [04:18<14:39,  3.76s/it]progress:  22%|[34m       [0m| 67/300 [04:18<14:37,  3.76s/it]                                                          Episode 68	 reward: -13.61	 makespan: 1347.75	 Mean_loss: 0.55634201,  training time: 3.81
progress:  22%|[34m       [0m| 67/300 [04:22<14:37,  3.76s/it]progress:  23%|[34m       [0m| 68/300 [04:22<14:38,  3.79s/it]                                                          Episode 69	 reward: -13.78	 makespan: 1363.85	 Mean_loss: 0.51011044,  training time: 3.74
progress:  23%|[34m       [0m| 68/300 [04:26<14:38,  3.79s/it]progress:  23%|[34m       [0m| 69/300 [04:26<14:31,  3.77s/it]                                                          Episode 70	 reward: -13.84	 makespan: 1369.80	 Mean_loss: 0.57024574,  training time: 3.84
progress:  23%|[34m       [0m| 69/300 [04:30<14:31,  3.77s/it]progress:  23%|[34m       [0m| 70/300 [04:30<14:32,  3.79s/it]                                                          Episode 71	 reward: -13.79	 makespan: 1365.05	 Mean_loss: 0.49967003,  training time: 3.79
progress:  23%|[34m       [0m| 70/300 [04:34<14:32,  3.79s/it]progress:  24%|[34m       [0m| 71/300 [04:34<14:28,  3.79s/it]                                                          Episode 72	 reward: -13.65	 makespan: 1351.45	 Mean_loss: 0.52749765,  training time: 3.80
progress:  24%|[34m       [0m| 71/300 [04:37<14:28,  3.79s/it]progress:  24%|[34m       [0m| 72/300 [04:37<14:25,  3.79s/it]                                                          Episode 73	 reward: -13.90	 makespan: 1375.90	 Mean_loss: 0.44582883,  training time: 3.80
progress:  24%|[34m       [0m| 72/300 [04:41<14:25,  3.79s/it]progress:  24%|[34m       [0m| 73/300 [04:41<14:21,  3.80s/it]                                                          Episode 74	 reward: -13.72	 makespan: 1357.80	 Mean_loss: 0.49543908,  training time: 3.87
progress:  24%|[34m       [0m| 73/300 [04:45<14:21,  3.80s/it]progress:  25%|[34m       [0m| 74/300 [04:45<14:23,  3.82s/it]                                                          Episode 75	 reward: -13.81	 makespan: 1366.75	 Mean_loss: 0.48073649,  training time: 3.81
progress:  25%|[34m       [0m| 74/300 [04:49<14:23,  3.82s/it]progress:  25%|[34m       [0m| 75/300 [04:49<14:18,  3.82s/it]                                                          Episode 76	 reward: -13.72	 makespan: 1358.15	 Mean_loss: 0.48532462,  training time: 3.74
progress:  25%|[34m       [0m| 75/300 [04:53<14:18,  3.82s/it]progress:  25%|[34m       [0m| 76/300 [04:53<14:10,  3.80s/it]                                                          Episode 77	 reward: -13.65	 makespan: 1350.95	 Mean_loss: 0.46739596,  training time: 3.89
progress:  25%|[34m       [0m| 76/300 [04:56<14:10,  3.80s/it]progress:  26%|[34m       [0m| 77/300 [04:56<14:12,  3.82s/it]                                                          Episode 78	 reward: -13.69	 makespan: 1355.35	 Mean_loss: 0.45523313,  training time: 3.82
progress:  26%|[34m       [0m| 77/300 [05:00<14:12,  3.82s/it]progress:  26%|[34m       [0m| 78/300 [05:00<14:08,  3.82s/it]                                                          Episode 79	 reward: -13.70	 makespan: 1356.15	 Mean_loss: 0.38308305,  training time: 3.81
progress:  26%|[34m       [0m| 78/300 [05:04<14:08,  3.82s/it]progress:  26%|[34m       [0m| 79/300 [05:04<14:03,  3.82s/it]                                                          Episode 80	 reward: -13.78	 makespan: 1364.70	 Mean_loss: 0.43109146,  training time: 3.79
progress:  26%|[34m       [0m| 79/300 [05:08<14:03,  3.82s/it]progress:  27%|[34m       [0m| 80/300 [05:08<13:58,  3.81s/it]                                                          Episode 81	 reward: -13.26	 makespan: 1313.10	 Mean_loss: 0.50027698,  training time: 3.91
progress:  27%|[34m       [0m| 80/300 [05:12<13:58,  3.81s/it]progress:  27%|[34m       [0m| 81/300 [05:12<14:01,  3.84s/it]                                                          Episode 82	 reward: -13.21	 makespan: 1308.10	 Mean_loss: 0.44097504,  training time: 3.76
progress:  27%|[34m       [0m| 81/300 [05:16<14:01,  3.84s/it]progress:  27%|[34m       [0m| 82/300 [05:16<13:52,  3.82s/it]                                                          Episode 83	 reward: -13.46	 makespan: 1332.45	 Mean_loss: 0.42619407,  training time: 3.76
progress:  27%|[34m       [0m| 82/300 [05:19<13:52,  3.82s/it]progress:  28%|[34m       [0m| 83/300 [05:19<13:44,  3.80s/it]                                                          Episode 84	 reward: -13.26	 makespan: 1312.90	 Mean_loss: 0.47000897,  training time: 3.75
progress:  28%|[34m       [0m| 83/300 [05:23<13:44,  3.80s/it]progress:  28%|[34m       [0m| 84/300 [05:23<13:37,  3.78s/it]                                                          Episode 85	 reward: -13.22	 makespan: 1309.20	 Mean_loss: 0.37426040,  training time: 3.82
progress:  28%|[34m       [0m| 84/300 [05:27<13:37,  3.78s/it]progress:  28%|[34m       [0m| 85/300 [05:27<13:36,  3.80s/it]                                                          Episode 86	 reward: -13.32	 makespan: 1318.90	 Mean_loss: 0.37879580,  training time: 3.74
progress:  28%|[34m       [0m| 85/300 [05:31<13:36,  3.80s/it]progress:  29%|[34m       [0m| 86/300 [05:31<13:29,  3.78s/it]                                                          Episode 87	 reward: -13.37	 makespan: 1323.25	 Mean_loss: 0.49004146,  training time: 3.82
progress:  29%|[34m       [0m| 86/300 [05:34<13:29,  3.78s/it]progress:  29%|[34m       [0m| 87/300 [05:34<13:27,  3.79s/it]                                                          Episode 88	 reward: -13.21	 makespan: 1307.95	 Mean_loss: 0.33939421,  training time: 3.86
progress:  29%|[34m       [0m| 87/300 [05:38<13:27,  3.79s/it]progress:  29%|[34m       [0m| 88/300 [05:38<13:28,  3.81s/it]                                                          Episode 89	 reward: -13.32	 makespan: 1318.30	 Mean_loss: 0.36987609,  training time: 3.91
progress:  29%|[34m       [0m| 88/300 [05:42<13:28,  3.81s/it]progress:  30%|[34m       [0m| 89/300 [05:42<13:31,  3.84s/it]                                                          Episode 90	 reward: -13.26	 makespan: 1312.95	 Mean_loss: 0.41089872,  training time: 3.81
progress:  30%|[34m       [0m| 89/300 [05:46<13:31,  3.84s/it]progress:  30%|[34m       [0m| 90/300 [05:46<13:25,  3.83s/it]                                                          Episode 91	 reward: -13.23	 makespan: 1310.00	 Mean_loss: 0.40840623,  training time: 3.82
progress:  30%|[34m       [0m| 90/300 [05:50<13:25,  3.83s/it]progress:  30%|[34m       [0m| 91/300 [05:50<13:20,  3.83s/it]                                                          Episode 92	 reward: -13.33	 makespan: 1319.95	 Mean_loss: 0.40562516,  training time: 3.79
progress:  30%|[34m       [0m| 91/300 [05:54<13:20,  3.83s/it]progress:  31%|[34m       [0m| 92/300 [05:54<13:14,  3.82s/it]                                                          Episode 93	 reward: -13.29	 makespan: 1315.45	 Mean_loss: 0.38456923,  training time: 3.81
progress:  31%|[34m       [0m| 92/300 [05:57<13:14,  3.82s/it]progress:  31%|[34m       [0m| 93/300 [05:57<13:10,  3.82s/it]                                                          Episode 94	 reward: -13.20	 makespan: 1306.60	 Mean_loss: 0.39450189,  training time: 3.78
progress:  31%|[34m       [0m| 93/300 [06:01<13:10,  3.82s/it]progress:  31%|[34m      [0m| 94/300 [06:01<13:04,  3.81s/it]                                                          Episode 95	 reward: -13.36	 makespan: 1322.65	 Mean_loss: 0.32278425,  training time: 3.81
progress:  31%|[34m      [0m| 94/300 [06:05<13:04,  3.81s/it]progress:  32%|[34m      [0m| 95/300 [06:05<13:00,  3.81s/it]                                                          Episode 96	 reward: -13.33	 makespan: 1319.20	 Mean_loss: 0.35902116,  training time: 3.84
progress:  32%|[34m      [0m| 95/300 [06:09<13:00,  3.81s/it]progress:  32%|[34m      [0m| 96/300 [06:09<12:59,  3.82s/it]                                                          Episode 97	 reward: -13.02	 makespan: 1288.70	 Mean_loss: 0.28815120,  training time: 4.01
progress:  32%|[34m      [0m| 96/300 [06:13<12:59,  3.82s/it]progress:  32%|[34m      [0m| 97/300 [06:13<13:06,  3.88s/it]                                                          Episode 98	 reward: -13.43	 makespan: 1329.25	 Mean_loss: 0.37972853,  training time: 4.13
progress:  32%|[34m      [0m| 97/300 [06:17<13:06,  3.88s/it]progress:  33%|[34m      [0m| 98/300 [06:17<13:18,  3.95s/it]                                                          Episode 99	 reward: -13.32	 makespan: 1318.40	 Mean_loss: 0.32885835,  training time: 3.79
progress:  33%|[34m      [0m| 98/300 [06:21<13:18,  3.95s/it]progress:  33%|[34m      [0m| 99/300 [06:21<13:04,  3.90s/it]                                                          Episode 100	 reward: -13.48	 makespan: 1334.90	 Mean_loss: 0.34762219,  training time: 3.75
progress:  33%|[34m      [0m| 99/300 [06:25<13:04,  3.90s/it]progress:  33%|[34m      [0m| 100/300 [06:25<12:51,  3.86s/it]                                                           Episode 101	 reward: -13.53	 makespan: 1339.65	 Mean_loss: 0.38693419,  training time: 3.83
progress:  33%|[34m      [0m| 100/300 [06:28<12:51,  3.86s/it]progress:  34%|[34m      [0m| 101/300 [06:28<12:46,  3.85s/it]                                                           Episode 102	 reward: -13.40	 makespan: 1326.75	 Mean_loss: 0.42707583,  training time: 3.73
progress:  34%|[34m      [0m| 101/300 [06:32<12:46,  3.85s/it]progress:  34%|[34m      [0m| 102/300 [06:32<12:35,  3.81s/it]                                                           Episode 103	 reward: -13.38	 makespan: 1325.00	 Mean_loss: 0.42738879,  training time: 3.74
progress:  34%|[34m      [0m| 102/300 [06:36<12:35,  3.81s/it]progress:  34%|[34m      [0m| 103/300 [06:36<12:27,  3.79s/it]                                                           Episode 104	 reward: -13.45	 makespan: 1331.70	 Mean_loss: 0.37201470,  training time: 3.91
progress:  34%|[34m      [0m| 103/300 [06:40<12:27,  3.79s/it]progress:  35%|[34m      [0m| 104/300 [06:40<12:30,  3.83s/it]                                                           Episode 105	 reward: -13.47	 makespan: 1333.60	 Mean_loss: 0.37295705,  training time: 3.74
progress:  35%|[34m      [0m| 104/300 [06:44<12:30,  3.83s/it]progress:  35%|[34m      [0m| 105/300 [06:44<12:21,  3.80s/it]                                                           Episode 106	 reward: -13.30	 makespan: 1316.70	 Mean_loss: 0.27733856,  training time: 3.82
progress:  35%|[34m      [0m| 105/300 [06:47<12:21,  3.80s/it]progress:  35%|[34m      [0m| 106/300 [06:47<12:18,  3.81s/it]                                                           Episode 107	 reward: -13.30	 makespan: 1316.40	 Mean_loss: 0.37203920,  training time: 3.89
progress:  35%|[34m      [0m| 106/300 [06:51<12:18,  3.81s/it]progress:  36%|[34m      [0m| 107/300 [06:51<12:19,  3.83s/it]                                                           Episode 108	 reward: -13.26	 makespan: 1312.35	 Mean_loss: 0.35799873,  training time: 3.91
progress:  36%|[34m      [0m| 107/300 [06:55<12:19,  3.83s/it]progress:  36%|[34m      [0m| 108/300 [06:55<12:20,  3.86s/it]                                                           Episode 109	 reward: -13.30	 makespan: 1316.45	 Mean_loss: 0.35244328,  training time: 3.73
progress:  36%|[34m      [0m| 108/300 [06:59<12:20,  3.86s/it]progress:  36%|[34m      [0m| 109/300 [06:59<12:09,  3.82s/it]                                                           Episode 110	 reward: -13.26	 makespan: 1312.75	 Mean_loss: 0.30510095,  training time: 3.73
progress:  36%|[34m      [0m| 109/300 [07:03<12:09,  3.82s/it]progress:  37%|[34m      [0m| 110/300 [07:03<12:00,  3.79s/it]                                                           Episode 111	 reward: -13.34	 makespan: 1320.60	 Mean_loss: 0.29409257,  training time: 3.73
progress:  37%|[34m      [0m| 110/300 [07:06<12:00,  3.79s/it]progress:  37%|[34m      [0m| 111/300 [07:06<11:53,  3.78s/it]                                                           Episode 112	 reward: -13.18	 makespan: 1304.40	 Mean_loss: 0.33453178,  training time: 3.85
progress:  37%|[34m      [0m| 111/300 [07:10<11:53,  3.78s/it]progress:  37%|[34m      [0m| 112/300 [07:10<11:54,  3.80s/it]                                                           Episode 113	 reward: -13.41	 makespan: 1327.70	 Mean_loss: 0.36171401,  training time: 3.90
progress:  37%|[34m      [0m| 112/300 [07:14<11:54,  3.80s/it]progress:  38%|[34m      [0m| 113/300 [07:14<11:55,  3.83s/it]                                                           Episode 114	 reward: -13.34	 makespan: 1320.85	 Mean_loss: 0.44226331,  training time: 3.76
progress:  38%|[34m      [0m| 113/300 [07:18<11:55,  3.83s/it]progress:  38%|[34m      [0m| 114/300 [07:18<11:48,  3.81s/it]                                                           Episode 115	 reward: -13.27	 makespan: 1313.50	 Mean_loss: 0.28301147,  training time: 3.73
progress:  38%|[34m      [0m| 114/300 [07:22<11:48,  3.81s/it]progress:  38%|[34m      [0m| 115/300 [07:22<11:40,  3.79s/it]                                                           Episode 116	 reward: -13.33	 makespan: 1319.35	 Mean_loss: 0.30848220,  training time: 3.97
progress:  38%|[34m      [0m| 115/300 [07:26<11:40,  3.79s/it]progress:  39%|[34m      [0m| 116/300 [07:26<11:48,  3.85s/it]                                                           Episode 117	 reward: -13.43	 makespan: 1329.30	 Mean_loss: 0.38725901,  training time: 3.91
progress:  39%|[34m      [0m| 116/300 [07:30<11:48,  3.85s/it]progress:  39%|[34m      [0m| 117/300 [07:30<11:47,  3.87s/it]                                                           Episode 118	 reward: -13.23	 makespan: 1310.20	 Mean_loss: 0.33190578,  training time: 4.65
progress:  39%|[34m      [0m| 117/300 [07:34<11:47,  3.87s/it]progress:  39%|[34m      [0m| 118/300 [07:34<12:31,  4.13s/it]                                                           Episode 119	 reward: -13.35	 makespan: 1321.95	 Mean_loss: 0.35909575,  training time: 3.74
progress:  39%|[34m      [0m| 118/300 [07:38<12:31,  4.13s/it]progress:  40%|[34m      [0m| 119/300 [07:38<12:06,  4.01s/it]                                                           Episode 120	 reward: -13.54	 makespan: 1340.15	 Mean_loss: 0.32003248,  training time: 3.85
progress:  40%|[34m      [0m| 119/300 [07:42<12:06,  4.01s/it]progress:  40%|[34m      [0m| 120/300 [07:42<11:53,  3.96s/it]                                                           Episode 121	 reward: -13.56	 makespan: 1342.05	 Mean_loss: 0.31342193,  training time: 3.98
progress:  40%|[34m      [0m| 120/300 [07:46<11:53,  3.96s/it]progress:  40%|[34m      [0m| 121/300 [07:46<11:51,  3.97s/it]                                                           Episode 122	 reward: -13.60	 makespan: 1346.55	 Mean_loss: 0.33658302,  training time: 3.71
progress:  40%|[34m      [0m| 121/300 [07:50<11:51,  3.97s/it]progress:  41%|[34m      [0m| 122/300 [07:50<11:33,  3.89s/it]                                                           Episode 123	 reward: -13.40	 makespan: 1326.55	 Mean_loss: 0.29036126,  training time: 3.87
progress:  41%|[34m      [0m| 122/300 [07:53<11:33,  3.89s/it]progress:  41%|[34m      [0m| 123/300 [07:53<11:27,  3.89s/it]                                                           Episode 124	 reward: -13.37	 makespan: 1324.10	 Mean_loss: 0.27417925,  training time: 3.88
progress:  41%|[34m      [0m| 123/300 [07:57<11:27,  3.89s/it]progress:  41%|[34m     [0m| 124/300 [07:57<11:23,  3.89s/it]                                                           Episode 125	 reward: -13.56	 makespan: 1342.25	 Mean_loss: 0.34618810,  training time: 3.86
progress:  41%|[34m     [0m| 124/300 [08:01<11:23,  3.89s/it]progress:  42%|[34m     [0m| 125/300 [08:01<11:18,  3.88s/it]                                                           Episode 126	 reward: -13.46	 makespan: 1332.30	 Mean_loss: 0.33108875,  training time: 3.84
progress:  42%|[34m     [0m| 125/300 [08:05<11:18,  3.88s/it]progress:  42%|[34m     [0m| 126/300 [08:05<11:12,  3.87s/it]                                                           Episode 127	 reward: -13.54	 makespan: 1340.15	 Mean_loss: 0.27515215,  training time: 6.22
progress:  42%|[34m     [0m| 126/300 [08:11<11:12,  3.87s/it]progress:  42%|[34m     [0m| 127/300 [08:11<13:11,  4.57s/it]                                                           Episode 128	 reward: -13.52	 makespan: 1338.50	 Mean_loss: 0.29982817,  training time: 3.77
progress:  42%|[34m     [0m| 127/300 [08:15<13:11,  4.57s/it]progress:  43%|[34m     [0m| 128/300 [08:15<12:25,  4.33s/it]                                                           Episode 129	 reward: -13.48	 makespan: 1334.70	 Mean_loss: 0.34773791,  training time: 3.79
progress:  43%|[34m     [0m| 128/300 [08:19<12:25,  4.33s/it]progress:  43%|[34m     [0m| 129/300 [08:19<11:52,  4.17s/it]                                                           Episode 130	 reward: -13.41	 makespan: 1327.15	 Mean_loss: 0.26314431,  training time: 3.77
progress:  43%|[34m     [0m| 129/300 [08:23<11:52,  4.17s/it]progress:  43%|[34m     [0m| 130/300 [08:23<11:28,  4.05s/it]                                                           Episode 131	 reward: -13.48	 makespan: 1334.90	 Mean_loss: 0.26457801,  training time: 3.86
progress:  43%|[34m     [0m| 130/300 [08:26<11:28,  4.05s/it]progress:  44%|[34m     [0m| 131/300 [08:26<11:14,  3.99s/it]                                                           Episode 132	 reward: -13.46	 makespan: 1332.90	 Mean_loss: 0.28658599,  training time: 3.87
progress:  44%|[34m     [0m| 131/300 [08:30<11:14,  3.99s/it]progress:  44%|[34m     [0m| 132/300 [08:30<11:04,  3.96s/it]                                                           Episode 133	 reward: -13.52	 makespan: 1338.45	 Mean_loss: 0.28807816,  training time: 3.70
progress:  44%|[34m     [0m| 132/300 [08:34<11:04,  3.96s/it]progress:  44%|[34m     [0m| 133/300 [08:34<10:47,  3.88s/it]                                                           Episode 134	 reward: -13.45	 makespan: 1331.50	 Mean_loss: 0.26665118,  training time: 3.71
progress:  44%|[34m     [0m| 133/300 [08:38<10:47,  3.88s/it]progress:  45%|[34m     [0m| 134/300 [08:38<10:35,  3.83s/it]                                                           Episode 135	 reward: -13.60	 makespan: 1346.00	 Mean_loss: 0.34797767,  training time: 3.72
progress:  45%|[34m     [0m| 134/300 [08:41<10:35,  3.83s/it]progress:  45%|[34m     [0m| 135/300 [08:41<10:26,  3.80s/it]                                                           Episode 136	 reward: -13.37	 makespan: 1323.90	 Mean_loss: 0.26317433,  training time: 3.73
progress:  45%|[34m     [0m| 135/300 [08:45<10:26,  3.80s/it]progress:  45%|[34m     [0m| 136/300 [08:45<10:19,  3.78s/it]                                                           Episode 137	 reward: -13.47	 makespan: 1333.10	 Mean_loss: 0.28038126,  training time: 3.75
progress:  45%|[34m     [0m| 136/300 [08:49<10:19,  3.78s/it]progress:  46%|[34m     [0m| 137/300 [08:49<10:14,  3.77s/it]                                                           Episode 138	 reward: -13.58	 makespan: 1344.15	 Mean_loss: 0.29789963,  training time: 3.77
progress:  46%|[34m     [0m| 137/300 [08:53<10:14,  3.77s/it]progress:  46%|[34m     [0m| 138/300 [08:53<10:10,  3.77s/it]                                                           Episode 139	 reward: -13.52	 makespan: 1338.05	 Mean_loss: 0.26158518,  training time: 3.94
progress:  46%|[34m     [0m| 138/300 [08:57<10:10,  3.77s/it]progress:  46%|[34m     [0m| 139/300 [08:57<10:15,  3.82s/it]                                                           Episode 140	 reward: -13.39	 makespan: 1325.95	 Mean_loss: 0.27389762,  training time: 3.82
progress:  46%|[34m     [0m| 139/300 [09:00<10:15,  3.82s/it]progress:  47%|[34m     [0m| 140/300 [09:00<10:11,  3.82s/it]                                                           Episode 141	 reward: -13.04	 makespan: 1291.45	 Mean_loss: 0.23760472,  training time: 3.84
progress:  47%|[34m     [0m| 140/300 [09:04<10:11,  3.82s/it]progress:  47%|[34m     [0m| 141/300 [09:04<10:08,  3.83s/it]                                                           Episode 142	 reward: -13.03	 makespan: 1290.30	 Mean_loss: 0.24754913,  training time: 3.77
progress:  47%|[34m     [0m| 141/300 [09:08<10:08,  3.83s/it]progress:  47%|[34m     [0m| 142/300 [09:08<10:02,  3.81s/it]                                                           Episode 143	 reward: -12.84	 makespan: 1270.85	 Mean_loss: 0.24613814,  training time: 3.92
progress:  47%|[34m     [0m| 142/300 [09:12<10:02,  3.81s/it]progress:  48%|[34m     [0m| 143/300 [09:12<10:03,  3.84s/it]                                                           Episode 144	 reward: -13.05	 makespan: 1292.10	 Mean_loss: 0.24940914,  training time: 3.85
progress:  48%|[34m     [0m| 143/300 [09:16<10:03,  3.84s/it]progress:  48%|[34m     [0m| 144/300 [09:16<10:00,  3.85s/it]                                                           Episode 145	 reward: -12.98	 makespan: 1285.40	 Mean_loss: 0.25703424,  training time: 3.74
progress:  48%|[34m     [0m| 144/300 [09:20<10:00,  3.85s/it]progress:  48%|[34m     [0m| 145/300 [09:20<09:51,  3.82s/it]                                                           Episode 146	 reward: -12.94	 makespan: 1281.30	 Mean_loss: 0.24060220,  training time: 3.75
progress:  48%|[34m     [0m| 145/300 [09:23<09:51,  3.82s/it]progress:  49%|[34m     [0m| 146/300 [09:23<09:44,  3.80s/it]                                                           Episode 147	 reward: -13.11	 makespan: 1297.85	 Mean_loss: 0.21505360,  training time: 4.05
progress:  49%|[34m     [0m| 146/300 [09:27<09:44,  3.80s/it]progress:  49%|[34m     [0m| 147/300 [09:27<09:52,  3.87s/it]                                                           Episode 148	 reward: -12.98	 makespan: 1284.75	 Mean_loss: 0.21393387,  training time: 3.73
progress:  49%|[34m     [0m| 147/300 [09:31<09:52,  3.87s/it]progress:  49%|[34m     [0m| 148/300 [09:31<09:42,  3.83s/it]                                                           Episode 149	 reward: -13.16	 makespan: 1302.95	 Mean_loss: 0.26019901,  training time: 3.80
progress:  49%|[34m     [0m| 148/300 [09:35<09:42,  3.83s/it]progress:  50%|[34m     [0m| 149/300 [09:35<09:36,  3.82s/it]                                                           Episode 150	 reward: -12.82	 makespan: 1269.30	 Mean_loss: 0.25073603,  training time: 3.80
progress:  50%|[34m     [0m| 149/300 [09:39<09:36,  3.82s/it]progress:  50%|[34m     [0m| 150/300 [09:39<09:32,  3.82s/it]                                                           Episode 151	 reward: -12.88	 makespan: 1274.65	 Mean_loss: 0.22945687,  training time: 3.78
progress:  50%|[34m     [0m| 150/300 [09:42<09:32,  3.82s/it]progress:  50%|[34m     [0m| 151/300 [09:42<09:26,  3.80s/it]                                                           Episode 152	 reward: -12.86	 makespan: 1273.55	 Mean_loss: 0.22746789,  training time: 3.74
progress:  50%|[34m     [0m| 151/300 [09:46<09:26,  3.80s/it]progress:  51%|[34m     [0m| 152/300 [09:46<09:20,  3.78s/it]                                                           Episode 153	 reward: -12.82	 makespan: 1269.05	 Mean_loss: 0.22606160,  training time: 3.76
progress:  51%|[34m     [0m| 152/300 [09:50<09:20,  3.78s/it]progress:  51%|[34m     [0m| 153/300 [09:50<09:15,  3.78s/it]                                                           Episode 154	 reward: -12.87	 makespan: 1274.20	 Mean_loss: 0.27193227,  training time: 3.74
progress:  51%|[34m     [0m| 153/300 [09:54<09:15,  3.78s/it]progress:  51%|[34m    [0m| 154/300 [09:54<09:09,  3.77s/it]                                                           Episode 155	 reward: -12.83	 makespan: 1269.75	 Mean_loss: 0.20724240,  training time: 3.74
progress:  51%|[34m    [0m| 154/300 [09:57<09:09,  3.77s/it]progress:  52%|[34m    [0m| 155/300 [09:57<09:04,  3.76s/it]                                                           Episode 156	 reward: -12.92	 makespan: 1278.75	 Mean_loss: 0.27596626,  training time: 3.75
progress:  52%|[34m    [0m| 155/300 [10:01<09:04,  3.76s/it]progress:  52%|[34m    [0m| 156/300 [10:01<09:00,  3.75s/it]                                                           Episode 157	 reward: -12.80	 makespan: 1266.85	 Mean_loss: 0.23829383,  training time: 3.75
progress:  52%|[34m    [0m| 156/300 [10:05<09:00,  3.75s/it]progress:  52%|[34m    [0m| 157/300 [10:05<08:56,  3.75s/it]                                                           Episode 158	 reward: -12.89	 makespan: 1276.45	 Mean_loss: 0.20697102,  training time: 3.72
progress:  52%|[34m    [0m| 157/300 [10:09<08:56,  3.75s/it]progress:  53%|[34m    [0m| 158/300 [10:09<08:51,  3.74s/it]                                                           Episode 159	 reward: -12.80	 makespan: 1267.10	 Mean_loss: 0.19545639,  training time: 3.73
progress:  53%|[34m    [0m| 158/300 [10:12<08:51,  3.74s/it]progress:  53%|[34m    [0m| 159/300 [10:12<08:47,  3.74s/it]                                                           Episode 160	 reward: -12.86	 makespan: 1272.80	 Mean_loss: 0.20004500,  training time: 3.81
progress:  53%|[34m    [0m| 159/300 [10:16<08:47,  3.74s/it]progress:  53%|[34m    [0m| 160/300 [10:16<08:46,  3.76s/it]                                                           Episode 161	 reward: -12.92	 makespan: 1278.80	 Mean_loss: 0.26259133,  training time: 3.83
progress:  53%|[34m    [0m| 160/300 [10:20<08:46,  3.76s/it]progress:  54%|[34m    [0m| 161/300 [10:20<08:45,  3.78s/it]                                                           Episode 162	 reward: -12.98	 makespan: 1284.90	 Mean_loss: 0.37331694,  training time: 3.77
progress:  54%|[34m    [0m| 161/300 [10:24<08:45,  3.78s/it]progress:  54%|[34m    [0m| 162/300 [10:24<08:41,  3.78s/it]                                                           Episode 163	 reward: -12.93	 makespan: 1280.35	 Mean_loss: 0.30871713,  training time: 3.77
progress:  54%|[34m    [0m| 162/300 [10:28<08:41,  3.78s/it]progress:  54%|[34m    [0m| 163/300 [10:28<08:37,  3.77s/it]                                                           Episode 164	 reward: -12.90	 makespan: 1277.10	 Mean_loss: 0.27800223,  training time: 3.78
progress:  54%|[34m    [0m| 163/300 [10:31<08:37,  3.77s/it]progress:  55%|[34m    [0m| 164/300 [10:31<08:33,  3.78s/it]                                                           Episode 165	 reward: -12.88	 makespan: 1274.90	 Mean_loss: 0.25734428,  training time: 3.71
progress:  55%|[34m    [0m| 164/300 [10:35<08:33,  3.78s/it]progress:  55%|[34m    [0m| 165/300 [10:35<08:27,  3.76s/it]                                                           Episode 166	 reward: -13.00	 makespan: 1287.40	 Mean_loss: 0.32294276,  training time: 3.84
progress:  55%|[34m    [0m| 165/300 [10:39<08:27,  3.76s/it]progress:  55%|[34m    [0m| 166/300 [10:39<08:26,  3.78s/it]                                                           Episode 167	 reward: -13.12	 makespan: 1298.40	 Mean_loss: 0.28224584,  training time: 3.72
progress:  55%|[34m    [0m| 166/300 [10:43<08:26,  3.78s/it]progress:  56%|[34m    [0m| 167/300 [10:43<08:20,  3.76s/it]                                                           Episode 168	 reward: -12.99	 makespan: 1286.45	 Mean_loss: 0.34275848,  training time: 3.82
progress:  56%|[34m    [0m| 167/300 [10:46<08:20,  3.76s/it]progress:  56%|[34m    [0m| 168/300 [10:46<08:19,  3.78s/it]                                                           Episode 169	 reward: -12.97	 makespan: 1284.35	 Mean_loss: 0.27661893,  training time: 3.70
progress:  56%|[34m    [0m| 168/300 [10:50<08:19,  3.78s/it]progress:  56%|[34m    [0m| 169/300 [10:50<08:13,  3.77s/it]                                                           Episode 170	 reward: -13.03	 makespan: 1289.85	 Mean_loss: 0.30811346,  training time: 3.71
progress:  56%|[34m    [0m| 169/300 [10:54<08:13,  3.77s/it]progress:  57%|[34m    [0m| 170/300 [10:54<08:07,  3.75s/it]                                                           Episode 171	 reward: -12.84	 makespan: 1270.75	 Mean_loss: 0.28224853,  training time: 3.72
progress:  57%|[34m    [0m| 170/300 [10:58<08:07,  3.75s/it]progress:  57%|[34m    [0m| 171/300 [10:58<08:02,  3.74s/it]                                                           Episode 172	 reward: -12.93	 makespan: 1280.05	 Mean_loss: 0.30282152,  training time: 3.85
progress:  57%|[34m    [0m| 171/300 [11:01<08:02,  3.74s/it]progress:  57%|[34m    [0m| 172/300 [11:01<08:03,  3.77s/it]                                                           Episode 173	 reward: -13.02	 makespan: 1289.00	 Mean_loss: 0.32861713,  training time: 3.75
progress:  57%|[34m    [0m| 172/300 [11:05<08:03,  3.77s/it]progress:  58%|[34m    [0m| 173/300 [11:05<07:58,  3.77s/it]                                                           Episode 174	 reward: -13.06	 makespan: 1293.20	 Mean_loss: 0.34816074,  training time: 3.90
progress:  58%|[34m    [0m| 173/300 [11:09<07:58,  3.77s/it]progress:  58%|[34m    [0m| 174/300 [11:09<07:59,  3.81s/it]                                                           Episode 175	 reward: -12.83	 makespan: 1270.60	 Mean_loss: 0.26057941,  training time: 3.96
progress:  58%|[34m    [0m| 174/300 [11:13<07:59,  3.81s/it]progress:  58%|[34m    [0m| 175/300 [11:13<08:01,  3.85s/it]                                                           Episode 176	 reward: -12.93	 makespan: 1279.70	 Mean_loss: 0.23975046,  training time: 3.96
progress:  58%|[34m    [0m| 175/300 [11:17<08:01,  3.85s/it]progress:  59%|[34m    [0m| 176/300 [11:17<08:02,  3.89s/it]                                                           Episode 177	 reward: -12.89	 makespan: 1276.35	 Mean_loss: 0.28380233,  training time: 3.90
progress:  59%|[34m    [0m| 176/300 [11:21<08:02,  3.89s/it]progress:  59%|[34m    [0m| 177/300 [11:21<07:58,  3.89s/it]                                                           Episode 178	 reward: -13.03	 makespan: 1290.15	 Mean_loss: 0.25735101,  training time: 3.80
progress:  59%|[34m    [0m| 177/300 [11:25<07:58,  3.89s/it]progress:  59%|[34m    [0m| 178/300 [11:25<07:51,  3.86s/it]                                                           Episode 179	 reward: -13.02	 makespan: 1288.65	 Mean_loss: 0.30233619,  training time: 3.86
progress:  59%|[34m    [0m| 178/300 [11:29<07:51,  3.86s/it]progress:  60%|[34m    [0m| 179/300 [11:29<07:47,  3.86s/it]                                                           Episode 180	 reward: -13.08	 makespan: 1295.30	 Mean_loss: 0.26860657,  training time: 3.76
progress:  60%|[34m    [0m| 179/300 [11:32<07:47,  3.86s/it]progress:  60%|[34m    [0m| 180/300 [11:32<07:39,  3.83s/it]                                                           Episode 181	 reward: -13.29	 makespan: 1315.45	 Mean_loss: 0.23143224,  training time: 3.82
progress:  60%|[34m    [0m| 180/300 [11:36<07:39,  3.83s/it]progress:  60%|[34m    [0m| 181/300 [11:36<07:35,  3.83s/it]                                                           Episode 182	 reward: -13.36	 makespan: 1322.90	 Mean_loss: 0.26878968,  training time: 3.72
progress:  60%|[34m    [0m| 181/300 [11:40<07:35,  3.83s/it]progress:  61%|[34m    [0m| 182/300 [11:40<07:28,  3.80s/it]                                                           Episode 183	 reward: -13.31	 makespan: 1317.70	 Mean_loss: 0.24833298,  training time: 3.98
progress:  61%|[34m    [0m| 182/300 [11:44<07:28,  3.80s/it]progress:  61%|[34m    [0m| 183/300 [11:44<07:30,  3.85s/it]                                                           Episode 184	 reward: -13.21	 makespan: 1307.90	 Mean_loss: 0.26317421,  training time: 3.70
progress:  61%|[34m    [0m| 183/300 [11:48<07:30,  3.85s/it]progress:  61%|[34m   [0m| 184/300 [11:48<07:21,  3.81s/it]                                                           Episode 185	 reward: -13.13	 makespan: 1299.65	 Mean_loss: 0.23088184,  training time: 3.81
progress:  61%|[34m   [0m| 184/300 [11:51<07:21,  3.81s/it]progress:  62%|[34m   [0m| 185/300 [11:51<07:17,  3.81s/it]                                                           Episode 186	 reward: -13.12	 makespan: 1299.20	 Mean_loss: 0.20878147,  training time: 3.70
progress:  62%|[34m   [0m| 185/300 [11:55<07:17,  3.81s/it]progress:  62%|[34m   [0m| 186/300 [11:55<07:10,  3.78s/it]                                                           Episode 187	 reward: -13.17	 makespan: 1303.65	 Mean_loss: 0.26934594,  training time: 3.77
progress:  62%|[34m   [0m| 186/300 [11:59<07:10,  3.78s/it]progress:  62%|[34m   [0m| 187/300 [11:59<07:06,  3.78s/it]                                                           Episode 188	 reward: -13.24	 makespan: 1311.05	 Mean_loss: 0.22527751,  training time: 4.05
progress:  62%|[34m   [0m| 187/300 [12:03<07:06,  3.78s/it]progress:  63%|[34m   [0m| 188/300 [12:03<07:12,  3.86s/it]                                                           Episode 189	 reward: -13.17	 makespan: 1303.70	 Mean_loss: 0.21614172,  training time: 3.71
progress:  63%|[34m   [0m| 188/300 [12:07<07:12,  3.86s/it]progress:  63%|[34m   [0m| 189/300 [12:07<07:03,  3.81s/it]                                                           Episode 190	 reward: -13.17	 makespan: 1303.55	 Mean_loss: 0.19880262,  training time: 3.71
progress:  63%|[34m   [0m| 189/300 [12:10<07:03,  3.81s/it]progress:  63%|[34m   [0m| 190/300 [12:10<06:56,  3.78s/it]                                                           Episode 191	 reward: -13.25	 makespan: 1311.60	 Mean_loss: 0.22467181,  training time: 3.78
progress:  63%|[34m   [0m| 190/300 [12:14<06:56,  3.78s/it]progress:  64%|[34m   [0m| 191/300 [12:14<06:52,  3.78s/it]                                                           Episode 192	 reward: -13.34	 makespan: 1320.55	 Mean_loss: 0.21027875,  training time: 3.81
progress:  64%|[34m   [0m| 191/300 [12:18<06:52,  3.78s/it]progress:  64%|[34m   [0m| 192/300 [12:18<06:49,  3.79s/it]                                                           Episode 193	 reward: -13.20	 makespan: 1306.45	 Mean_loss: 0.19010232,  training time: 3.82
progress:  64%|[34m   [0m| 192/300 [12:22<06:49,  3.79s/it]progress:  64%|[34m   [0m| 193/300 [12:22<06:46,  3.80s/it]                                                           Episode 194	 reward: -13.17	 makespan: 1303.80	 Mean_loss: 0.21257815,  training time: 3.87
progress:  64%|[34m   [0m| 193/300 [12:26<06:46,  3.80s/it]progress:  65%|[34m   [0m| 194/300 [12:26<06:44,  3.82s/it]                                                           Episode 195	 reward: -13.14	 makespan: 1300.80	 Mean_loss: 0.18687165,  training time: 3.99
progress:  65%|[34m   [0m| 194/300 [12:30<06:44,  3.82s/it]progress:  65%|[34m   [0m| 195/300 [12:30<06:46,  3.87s/it]                                                           Episode 196	 reward: -13.14	 makespan: 1300.60	 Mean_loss: 0.16079357,  training time: 3.88
progress:  65%|[34m   [0m| 195/300 [12:34<06:46,  3.87s/it]progress:  65%|[34m   [0m| 196/300 [12:34<06:42,  3.87s/it]                                                           Episode 197	 reward: -13.19	 makespan: 1305.75	 Mean_loss: 0.22787696,  training time: 3.89
progress:  65%|[34m   [0m| 196/300 [12:37<06:42,  3.87s/it]progress:  66%|[34m   [0m| 197/300 [12:37<06:39,  3.88s/it]                                                           Episode 198	 reward: -13.27	 makespan: 1313.55	 Mean_loss: 0.21240729,  training time: 3.73
progress:  66%|[34m   [0m| 197/300 [12:41<06:39,  3.88s/it]progress:  66%|[34m   [0m| 198/300 [12:41<06:31,  3.83s/it]                                                           Episode 199	 reward: -13.11	 makespan: 1297.90	 Mean_loss: 0.23989217,  training time: 3.79
progress:  66%|[34m   [0m| 198/300 [12:45<06:31,  3.83s/it]progress:  66%|[34m   [0m| 199/300 [12:45<06:25,  3.82s/it]                                                           Episode 200	 reward: -13.21	 makespan: 1308.00	 Mean_loss: 0.22497605,  training time: 3.74
progress:  66%|[34m   [0m| 199/300 [12:49<06:25,  3.82s/it]progress:  67%|[34m   [0m| 200/300 [12:49<06:19,  3.80s/it]                                                           Episode 201	 reward: -12.86	 makespan: 1273.30	 Mean_loss: 0.19962686,  training time: 3.93
progress:  67%|[34m   [0m| 200/300 [12:53<06:19,  3.80s/it]progress:  67%|[34m   [0m| 201/300 [12:53<06:19,  3.84s/it]                                                           Episode 202	 reward: -12.71	 makespan: 1258.70	 Mean_loss: 0.18967120,  training time: 4.04
progress:  67%|[34m   [0m| 201/300 [12:57<06:19,  3.84s/it]progress:  67%|[34m   [0m| 202/300 [12:57<06:21,  3.90s/it]                                                           Episode 203	 reward: -12.91	 makespan: 1277.95	 Mean_loss: 0.20062336,  training time: 3.79
progress:  67%|[34m   [0m| 202/300 [13:00<06:21,  3.90s/it]progress:  68%|[34m   [0m| 203/300 [13:00<06:14,  3.87s/it]                                                           Episode 204	 reward: -12.81	 makespan: 1267.90	 Mean_loss: 0.17138502,  training time: 3.77
progress:  68%|[34m   [0m| 203/300 [13:04<06:14,  3.87s/it]progress:  68%|[34m   [0m| 204/300 [13:04<06:08,  3.84s/it]                                                           Episode 205	 reward: -12.80	 makespan: 1267.50	 Mean_loss: 0.19495519,  training time: 3.72
progress:  68%|[34m   [0m| 204/300 [13:08<06:08,  3.84s/it]progress:  68%|[34m   [0m| 205/300 [13:08<06:01,  3.80s/it]                                                           Episode 206	 reward: -12.84	 makespan: 1270.80	 Mean_loss: 0.17037719,  training time: 3.72
progress:  68%|[34m   [0m| 205/300 [13:12<06:01,  3.80s/it]progress:  69%|[34m   [0m| 206/300 [13:12<05:55,  3.78s/it]                                                           Episode 207	 reward: -12.92	 makespan: 1278.90	 Mean_loss: 0.16657518,  training time: 3.70
progress:  69%|[34m   [0m| 206/300 [13:15<05:55,  3.78s/it]progress:  69%|[34m   [0m| 207/300 [13:15<05:49,  3.75s/it]                                                           Episode 208	 reward: -12.93	 makespan: 1280.25	 Mean_loss: 0.19629927,  training time: 3.71
progress:  69%|[34m   [0m| 207/300 [13:19<05:49,  3.75s/it]progress:  69%|[34m   [0m| 208/300 [13:19<05:44,  3.74s/it]                                                           Episode 209	 reward: -12.76	 makespan: 1263.35	 Mean_loss: 0.17261192,  training time: 3.73
progress:  69%|[34m   [0m| 208/300 [13:23<05:44,  3.74s/it]progress:  70%|[34m   [0m| 209/300 [13:23<05:40,  3.74s/it]                                                           Episode 210	 reward: -12.85	 makespan: 1271.95	 Mean_loss: 0.18127808,  training time: 3.76
progress:  70%|[34m   [0m| 209/300 [13:27<05:40,  3.74s/it]progress:  70%|[34m   [0m| 210/300 [13:27<05:37,  3.75s/it]                                                           Episode 211	 reward: -12.86	 makespan: 1272.80	 Mean_loss: 0.21450229,  training time: 3.69
progress:  70%|[34m   [0m| 210/300 [13:30<05:37,  3.75s/it]progress:  70%|[34m   [0m| 211/300 [13:30<05:31,  3.73s/it]                                                           Episode 212	 reward: -12.66	 makespan: 1253.35	 Mean_loss: 0.18136965,  training time: 3.75
progress:  70%|[34m   [0m| 211/300 [13:34<05:31,  3.73s/it]progress:  71%|[34m   [0m| 212/300 [13:34<05:28,  3.74s/it]                                                           Episode 213	 reward: -12.81	 makespan: 1268.55	 Mean_loss: 0.24057965,  training time: 3.71
progress:  71%|[34m   [0m| 212/300 [13:38<05:28,  3.74s/it]progress:  71%|[34m   [0m| 213/300 [13:38<05:24,  3.73s/it]                                                           Episode 214	 reward: -12.82	 makespan: 1269.00	 Mean_loss: 0.13546243,  training time: 3.85
progress:  71%|[34m   [0m| 213/300 [13:42<05:24,  3.73s/it]progress:  71%|[34m  [0m| 214/300 [13:42<05:23,  3.77s/it]                                                           Episode 215	 reward: -12.83	 makespan: 1269.95	 Mean_loss: 0.17981389,  training time: 3.85
progress:  71%|[34m  [0m| 214/300 [13:45<05:23,  3.77s/it]progress:  72%|[34m  [0m| 215/300 [13:45<05:22,  3.79s/it]                                                           Episode 216	 reward: -12.80	 makespan: 1267.65	 Mean_loss: 0.14983177,  training time: 3.74
progress:  72%|[34m  [0m| 215/300 [13:49<05:22,  3.79s/it]progress:  72%|[34m  [0m| 216/300 [13:49<05:17,  3.78s/it]                                                           Episode 217	 reward: -12.85	 makespan: 1271.80	 Mean_loss: 0.18690969,  training time: 3.75
progress:  72%|[34m  [0m| 216/300 [13:53<05:17,  3.78s/it]progress:  72%|[34m  [0m| 217/300 [13:53<05:12,  3.77s/it]                                                           Episode 218	 reward: -12.97	 makespan: 1283.70	 Mean_loss: 0.18484214,  training time: 3.73
progress:  72%|[34m  [0m| 217/300 [13:57<05:12,  3.77s/it]progress:  73%|[34m  [0m| 218/300 [13:57<05:08,  3.76s/it]                                                           Episode 219	 reward: -12.84	 makespan: 1271.55	 Mean_loss: 0.19469310,  training time: 3.72
progress:  73%|[34m  [0m| 218/300 [14:00<05:08,  3.76s/it]progress:  73%|[34m  [0m| 219/300 [14:00<05:03,  3.75s/it]                                                           Episode 220	 reward: -13.01	 makespan: 1288.45	 Mean_loss: 0.20633091,  training time: 3.72
progress:  73%|[34m  [0m| 219/300 [14:04<05:03,  3.75s/it]progress:  73%|[34m  [0m| 220/300 [14:04<04:59,  3.74s/it]                                                           Episode 221	 reward: -12.95	 makespan: 1281.80	 Mean_loss: 0.18612444,  training time: 3.83
progress:  73%|[34m  [0m| 220/300 [14:08<04:59,  3.74s/it]progress:  74%|[34m  [0m| 221/300 [14:08<04:57,  3.77s/it]                                                           Episode 222	 reward: -12.99	 makespan: 1286.30	 Mean_loss: 0.20328586,  training time: 3.73
progress:  74%|[34m  [0m| 221/300 [14:12<04:57,  3.77s/it]progress:  74%|[34m  [0m| 222/300 [14:12<04:52,  3.76s/it]                                                           Episode 223	 reward: -12.86	 makespan: 1273.15	 Mean_loss: 0.16110539,  training time: 3.74
progress:  74%|[34m  [0m| 222/300 [14:15<04:52,  3.76s/it]progress:  74%|[34m  [0m| 223/300 [14:15<04:48,  3.75s/it]                                                           Episode 224	 reward: -12.90	 makespan: 1277.35	 Mean_loss: 0.21838482,  training time: 3.99
progress:  74%|[34m  [0m| 223/300 [14:19<04:48,  3.75s/it]progress:  75%|[34m  [0m| 224/300 [14:19<04:50,  3.83s/it]                                                           Episode 225	 reward: -12.78	 makespan: 1265.10	 Mean_loss: 0.15581460,  training time: 3.85
progress:  75%|[34m  [0m| 224/300 [14:23<04:50,  3.83s/it]progress:  75%|[34m  [0m| 225/300 [14:23<04:47,  3.83s/it]                                                           Episode 226	 reward: -12.70	 makespan: 1257.55	 Mean_loss: 0.18314770,  training time: 3.72
progress:  75%|[34m  [0m| 225/300 [14:27<04:47,  3.83s/it]progress:  75%|[34m  [0m| 226/300 [14:27<04:41,  3.80s/it]                                                           Episode 227	 reward: -12.74	 makespan: 1260.85	 Mean_loss: 0.16000107,  training time: 3.93
progress:  75%|[34m  [0m| 226/300 [14:31<04:41,  3.80s/it]progress:  76%|[34m  [0m| 227/300 [14:31<04:40,  3.84s/it]                                                           Episode 228	 reward: -12.73	 makespan: 1260.45	 Mean_loss: 0.16078557,  training time: 3.73
progress:  76%|[34m  [0m| 227/300 [14:35<04:40,  3.84s/it]progress:  76%|[34m  [0m| 228/300 [14:35<04:34,  3.81s/it]                                                           Episode 229	 reward: -12.82	 makespan: 1269.65	 Mean_loss: 0.15759134,  training time: 3.82
progress:  76%|[34m  [0m| 228/300 [14:38<04:34,  3.81s/it]progress:  76%|[34m  [0m| 229/300 [14:38<04:30,  3.81s/it]                                                           Episode 230	 reward: -12.78	 makespan: 1265.05	 Mean_loss: 0.16384636,  training time: 3.99
progress:  76%|[34m  [0m| 229/300 [14:42<04:30,  3.81s/it]progress:  77%|[34m  [0m| 230/300 [14:42<04:30,  3.86s/it]                                                           Episode 231	 reward: -12.87	 makespan: 1274.20	 Mean_loss: 0.15476982,  training time: 3.91
progress:  77%|[34m  [0m| 230/300 [14:46<04:30,  3.86s/it]progress:  77%|[34m  [0m| 231/300 [14:46<04:27,  3.88s/it]                                                           Episode 232	 reward: -12.67	 makespan: 1254.80	 Mean_loss: 0.14404222,  training time: 3.96
progress:  77%|[34m  [0m| 231/300 [14:50<04:27,  3.88s/it]progress:  77%|[34m  [0m| 232/300 [14:50<04:25,  3.90s/it]                                                           Episode 233	 reward: -12.79	 makespan: 1266.55	 Mean_loss: 0.17656773,  training time: 3.92
progress:  77%|[34m  [0m| 232/300 [14:54<04:25,  3.90s/it]progress:  78%|[34m  [0m| 233/300 [14:54<04:21,  3.91s/it]                                                           Episode 234	 reward: -12.75	 makespan: 1262.65	 Mean_loss: 0.17453045,  training time: 3.78
progress:  78%|[34m  [0m| 233/300 [14:58<04:21,  3.91s/it]progress:  78%|[34m  [0m| 234/300 [14:58<04:15,  3.87s/it]                                                           Episode 235	 reward: -12.79	 makespan: 1266.65	 Mean_loss: 0.20814379,  training time: 3.84
progress:  78%|[34m  [0m| 234/300 [15:02<04:15,  3.87s/it]progress:  78%|[34m  [0m| 235/300 [15:02<04:11,  3.86s/it]                                                           Episode 236	 reward: -12.75	 makespan: 1261.80	 Mean_loss: 0.14880162,  training time: 3.94
progress:  78%|[34m  [0m| 235/300 [15:06<04:11,  3.86s/it]progress:  79%|[34m  [0m| 236/300 [15:06<04:09,  3.90s/it]                                                           Episode 237	 reward: -12.77	 makespan: 1264.10	 Mean_loss: 0.17873371,  training time: 4.33
progress:  79%|[34m  [0m| 236/300 [15:10<04:09,  3.90s/it]progress:  79%|[34m  [0m| 237/300 [15:10<04:14,  4.04s/it]                                                           Episode 238	 reward: -12.81	 makespan: 1268.10	 Mean_loss: 0.16633482,  training time: 3.80
progress:  79%|[34m  [0m| 237/300 [15:14<04:14,  4.04s/it]progress:  79%|[34m  [0m| 238/300 [15:14<04:05,  3.96s/it]                                                           Episode 239	 reward: -12.79	 makespan: 1266.55	 Mean_loss: 0.15759808,  training time: 3.76
progress:  79%|[34m  [0m| 238/300 [15:18<04:05,  3.96s/it]progress:  80%|[34m  [0m| 239/300 [15:18<03:58,  3.90s/it]                                                           Episode 240	 reward: -12.72	 makespan: 1259.25	 Mean_loss: 0.12692004,  training time: 3.87
progress:  80%|[34m  [0m| 239/300 [15:22<03:58,  3.90s/it]progress:  80%|[34m  [0m| 240/300 [15:22<03:53,  3.90s/it]                                                           Episode 241	 reward: -12.60	 makespan: 1246.95	 Mean_loss: 0.15775326,  training time: 3.99
progress:  80%|[34m  [0m| 240/300 [15:26<03:53,  3.90s/it]progress:  80%|[34m  [0m| 241/300 [15:26<03:51,  3.92s/it]                                                           Episode 242	 reward: -12.69	 makespan: 1256.45	 Mean_loss: 0.16131049,  training time: 3.79
progress:  80%|[34m  [0m| 241/300 [15:29<03:51,  3.92s/it]progress:  81%|[34m  [0m| 242/300 [15:29<03:45,  3.88s/it]                                                           Episode 243	 reward: -12.60	 makespan: 1247.50	 Mean_loss: 0.14672644,  training time: 3.82
progress:  81%|[34m  [0m| 242/300 [15:33<03:45,  3.88s/it]progress:  81%|[34m  [0m| 243/300 [15:33<03:40,  3.86s/it]                                                           Episode 244	 reward: -12.53	 makespan: 1240.35	 Mean_loss: 0.16207448,  training time: 3.74
progress:  81%|[34m  [0m| 243/300 [15:37<03:40,  3.86s/it]progress:  81%|[34m [0m| 244/300 [15:37<03:34,  3.83s/it]                                                           Episode 245	 reward: -12.43	 makespan: 1230.30	 Mean_loss: 0.13558851,  training time: 3.72
progress:  81%|[34m [0m| 244/300 [15:41<03:34,  3.83s/it]progress:  82%|[34m [0m| 245/300 [15:41<03:28,  3.80s/it]                                                           Episode 246	 reward: -12.59	 makespan: 1246.70	 Mean_loss: 0.13198200,  training time: 3.73
progress:  82%|[34m [0m| 245/300 [15:44<03:28,  3.80s/it]progress:  82%|[34m [0m| 246/300 [15:44<03:24,  3.78s/it]                                                           Episode 247	 reward: -12.58	 makespan: 1245.20	 Mean_loss: 0.16795594,  training time: 3.83
progress:  82%|[34m [0m| 246/300 [15:48<03:24,  3.78s/it]progress:  82%|[34m [0m| 247/300 [15:48<03:21,  3.79s/it]                                                           Episode 248	 reward: -12.43	 makespan: 1230.95	 Mean_loss: 0.13754924,  training time: 4.28
progress:  82%|[34m [0m| 247/300 [15:53<03:21,  3.79s/it]progress:  83%|[34m [0m| 248/300 [15:53<03:24,  3.94s/it]                                                           Episode 249	 reward: -12.46	 makespan: 1233.70	 Mean_loss: 0.12266532,  training time: 3.87
progress:  83%|[34m [0m| 248/300 [15:56<03:24,  3.94s/it]progress:  83%|[34m [0m| 249/300 [15:56<03:19,  3.92s/it]                                                           Episode 250	 reward: -12.59	 makespan: 1246.90	 Mean_loss: 0.11983967,  training time: 3.74
progress:  83%|[34m [0m| 249/300 [16:00<03:19,  3.92s/it]progress:  83%|[34m [0m| 250/300 [16:00<03:13,  3.87s/it]                                                           Episode 251	 reward: -12.49	 makespan: 1236.70	 Mean_loss: 0.12755555,  training time: 3.70
progress:  83%|[34m [0m| 250/300 [16:04<03:13,  3.87s/it]progress:  84%|[34m [0m| 251/300 [16:04<03:06,  3.82s/it]                                                           Episode 252	 reward: -12.68	 makespan: 1254.85	 Mean_loss: 0.13714206,  training time: 5.14
progress:  84%|[34m [0m| 251/300 [16:09<03:06,  3.82s/it]progress:  84%|[34m [0m| 252/300 [16:09<03:22,  4.21s/it]                                                           Episode 253	 reward: -12.59	 makespan: 1246.05	 Mean_loss: 0.12680750,  training time: 3.82
progress:  84%|[34m [0m| 252/300 [16:13<03:22,  4.21s/it]progress:  84%|[34m [0m| 253/300 [16:13<03:12,  4.10s/it]                                                           Episode 254	 reward: -12.44	 makespan: 1231.80	 Mean_loss: 0.19295239,  training time: 3.73
progress:  84%|[34m [0m| 253/300 [16:17<03:12,  4.10s/it]progress:  85%|[34m [0m| 254/300 [16:17<03:03,  3.99s/it]                                                           Episode 255	 reward: -12.23	 makespan: 1210.50	 Mean_loss: 0.13292821,  training time: 3.78
progress:  85%|[34m [0m| 254/300 [16:20<03:03,  3.99s/it]progress:  85%|[34m [0m| 255/300 [16:20<02:56,  3.93s/it]                                                           Episode 256	 reward: -12.53	 makespan: 1240.85	 Mean_loss: 0.17356358,  training time: 4.15
progress:  85%|[34m [0m| 255/300 [16:24<02:56,  3.93s/it]progress:  85%|[34m [0m| 256/300 [16:24<02:55,  3.99s/it]                                                           Episode 257	 reward: -12.51	 makespan: 1238.25	 Mean_loss: 0.13168471,  training time: 3.71
progress:  85%|[34m [0m| 256/300 [16:28<02:55,  3.99s/it]progress:  86%|[34m [0m| 257/300 [16:28<02:48,  3.91s/it]                                                           Episode 258	 reward: -12.48	 makespan: 1235.25	 Mean_loss: 0.13637693,  training time: 3.81
progress:  86%|[34m [0m| 257/300 [16:32<02:48,  3.91s/it]progress:  86%|[34m [0m| 258/300 [16:32<02:42,  3.88s/it]                                                           Episode 259	 reward: -12.41	 makespan: 1229.00	 Mean_loss: 0.11700483,  training time: 3.82
progress:  86%|[34m [0m| 258/300 [16:36<02:42,  3.88s/it]progress:  86%|[34m [0m| 259/300 [16:36<02:38,  3.86s/it]                                                           Episode 260	 reward: -12.55	 makespan: 1242.35	 Mean_loss: 0.12184738,  training time: 3.80
progress:  86%|[34m [0m| 259/300 [16:40<02:38,  3.86s/it]progress:  87%|[34m [0m| 260/300 [16:40<02:33,  3.84s/it]                                                           Episode 261	 reward: -12.82	 makespan: 1269.00	 Mean_loss: 0.27195859,  training time: 3.84
progress:  87%|[34m [0m| 260/300 [16:43<02:33,  3.84s/it]progress:  87%|[34m [0m| 261/300 [16:43<02:29,  3.84s/it]                                                           Episode 262	 reward: -12.79	 makespan: 1266.65	 Mean_loss: 0.23945245,  training time: 3.95
progress:  87%|[34m [0m| 261/300 [16:47<02:29,  3.84s/it]progress:  87%|[34m [0m| 262/300 [16:47<02:27,  3.87s/it]                                                           Episode 263	 reward: -12.69	 makespan: 1256.30	 Mean_loss: 0.19281459,  training time: 3.75
progress:  87%|[34m [0m| 262/300 [16:51<02:27,  3.87s/it]progress:  88%|[34m [0m| 263/300 [16:51<02:22,  3.84s/it]                                                           Episode 264	 reward: -12.71	 makespan: 1258.05	 Mean_loss: 0.18542811,  training time: 3.75
progress:  88%|[34m [0m| 263/300 [16:55<02:22,  3.84s/it]progress:  88%|[34m [0m| 264/300 [16:55<02:17,  3.81s/it]                                                           Episode 265	 reward: -12.93	 makespan: 1280.40	 Mean_loss: 0.26434103,  training time: 3.85
progress:  88%|[34m [0m| 264/300 [16:59<02:17,  3.81s/it]progress:  88%|[34m [0m| 265/300 [16:59<02:13,  3.82s/it]                                                           Episode 266	 reward: -12.99	 makespan: 1285.90	 Mean_loss: 0.28857100,  training time: 3.74
progress:  88%|[34m [0m| 265/300 [17:02<02:13,  3.82s/it]progress:  89%|[34m [0m| 266/300 [17:02<02:09,  3.80s/it]                                                           Episode 267	 reward: -12.72	 makespan: 1259.40	 Mean_loss: 0.21096633,  training time: 3.76
progress:  89%|[34m [0m| 266/300 [17:06<02:09,  3.80s/it]progress:  89%|[34m [0m| 267/300 [17:06<02:05,  3.79s/it]                                                           Episode 268	 reward: -12.73	 makespan: 1260.55	 Mean_loss: 0.25910231,  training time: 3.77
progress:  89%|[34m [0m| 267/300 [17:10<02:05,  3.79s/it]progress:  89%|[34m [0m| 268/300 [17:10<02:01,  3.78s/it]                                                           Episode 269	 reward: -12.69	 makespan: 1256.05	 Mean_loss: 0.20229682,  training time: 3.74
progress:  89%|[34m [0m| 268/300 [17:14<02:01,  3.78s/it]progress:  90%|[34m [0m| 269/300 [17:14<01:56,  3.77s/it]                                                           Episode 270	 reward: -12.85	 makespan: 1272.40	 Mean_loss: 0.21619757,  training time: 3.71
progress:  90%|[34m [0m| 269/300 [17:17<01:56,  3.77s/it]progress:  90%|[34m [0m| 270/300 [17:17<01:52,  3.75s/it]                                                           Episode 271	 reward: -12.77	 makespan: 1264.65	 Mean_loss: 0.19049077,  training time: 3.72
progress:  90%|[34m [0m| 270/300 [17:21<01:52,  3.75s/it]progress:  90%|[34m [0m| 271/300 [17:21<01:48,  3.75s/it]                                                           Episode 272	 reward: -12.76	 makespan: 1263.50	 Mean_loss: 0.20871046,  training time: 3.73
progress:  90%|[34m [0m| 271/300 [17:25<01:48,  3.75s/it]progress:  91%|[34m [0m| 272/300 [17:25<01:44,  3.74s/it]                                                           Episode 273	 reward: -12.88	 makespan: 1275.45	 Mean_loss: 0.22618248,  training time: 3.74
progress:  91%|[34m [0m| 272/300 [17:29<01:44,  3.74s/it]progress:  91%|[34m [0m| 273/300 [17:29<01:40,  3.74s/it]                                                           Episode 274	 reward: -12.67	 makespan: 1254.70	 Mean_loss: 0.18449277,  training time: 3.78
progress:  91%|[34m [0m| 273/300 [17:32<01:40,  3.74s/it]progress:  91%|[34m[0m| 274/300 [17:32<01:37,  3.75s/it]                                                           Episode 275	 reward: -12.79	 makespan: 1265.95	 Mean_loss: 0.22861756,  training time: 3.97
progress:  91%|[34m[0m| 274/300 [17:36<01:37,  3.75s/it]progress:  92%|[34m[0m| 275/300 [17:36<01:35,  3.82s/it]                                                           Episode 276	 reward: -12.77	 makespan: 1264.05	 Mean_loss: 0.23389620,  training time: 3.91
progress:  92%|[34m[0m| 275/300 [17:40<01:35,  3.82s/it]progress:  92%|[34m[0m| 276/300 [17:40<01:32,  3.85s/it]                                                           Episode 277	 reward: -12.87	 makespan: 1274.60	 Mean_loss: 0.20551945,  training time: 3.81
progress:  92%|[34m[0m| 276/300 [17:44<01:32,  3.85s/it]progress:  92%|[34m[0m| 277/300 [17:44<01:28,  3.84s/it]                                                           Episode 278	 reward: -12.91	 makespan: 1277.80	 Mean_loss: 0.18182464,  training time: 3.94
progress:  92%|[34m[0m| 277/300 [17:48<01:28,  3.84s/it]progress:  93%|[34m[0m| 278/300 [17:48<01:25,  3.87s/it]                                                           Episode 279	 reward: -12.77	 makespan: 1264.20	 Mean_loss: 0.21636531,  training time: 3.74
progress:  93%|[34m[0m| 278/300 [17:52<01:25,  3.87s/it]progress:  93%|[34m[0m| 279/300 [17:52<01:20,  3.83s/it]                                                           Episode 280	 reward: -12.92	 makespan: 1279.20	 Mean_loss: 0.19961108,  training time: 3.77
progress:  93%|[34m[0m| 279/300 [17:56<01:20,  3.83s/it]progress:  93%|[34m[0m| 280/300 [17:56<01:16,  3.81s/it]                                                           Episode 281	 reward: -12.69	 makespan: 1255.90	 Mean_loss: 0.20984966,  training time: 3.87
progress:  93%|[34m[0m| 280/300 [17:59<01:16,  3.81s/it]progress:  94%|[34m[0m| 281/300 [17:59<01:12,  3.83s/it]                                                           Episode 282	 reward: -12.64	 makespan: 1251.85	 Mean_loss: 0.17968270,  training time: 3.75
progress:  94%|[34m[0m| 281/300 [18:03<01:12,  3.83s/it]progress:  94%|[34m[0m| 282/300 [18:03<01:08,  3.80s/it]                                                           Episode 283	 reward: -12.60	 makespan: 1247.15	 Mean_loss: 0.17826620,  training time: 3.73
progress:  94%|[34m[0m| 282/300 [18:07<01:08,  3.80s/it]progress:  94%|[34m[0m| 283/300 [18:07<01:04,  3.78s/it]                                                           Episode 284	 reward: -12.58	 makespan: 1245.75	 Mean_loss: 0.18741512,  training time: 3.72
progress:  94%|[34m[0m| 283/300 [18:11<01:04,  3.78s/it]progress:  95%|[34m[0m| 284/300 [18:11<01:00,  3.76s/it]                                                           Episode 285	 reward: -12.56	 makespan: 1243.75	 Mean_loss: 0.19983876,  training time: 3.71
progress:  95%|[34m[0m| 284/300 [18:14<01:00,  3.76s/it]progress:  95%|[34m[0m| 285/300 [18:14<00:56,  3.75s/it]                                                           Episode 286	 reward: -12.65	 makespan: 1252.35	 Mean_loss: 0.17877530,  training time: 3.77
progress:  95%|[34m[0m| 285/300 [18:18<00:56,  3.75s/it]progress:  95%|[34m[0m| 286/300 [18:18<00:52,  3.75s/it]                                                           Episode 287	 reward: -12.59	 makespan: 1246.75	 Mean_loss: 0.17672798,  training time: 3.72
progress:  95%|[34m[0m| 286/300 [18:22<00:52,  3.75s/it]progress:  96%|[34m[0m| 287/300 [18:22<00:48,  3.74s/it]                                                           Episode 288	 reward: -12.58	 makespan: 1245.85	 Mean_loss: 0.16283348,  training time: 3.74
progress:  96%|[34m[0m| 287/300 [18:26<00:48,  3.74s/it]progress:  96%|[34m[0m| 288/300 [18:26<00:44,  3.74s/it]                                                           Episode 289	 reward: -12.51	 makespan: 1238.55	 Mean_loss: 0.18048203,  training time: 3.74
progress:  96%|[34m[0m| 288/300 [18:29<00:44,  3.74s/it]progress:  96%|[34m[0m| 289/300 [18:29<00:41,  3.74s/it]                                                           Episode 290	 reward: -12.52	 makespan: 1239.70	 Mean_loss: 0.16817267,  training time: 3.76
progress:  96%|[34m[0m| 289/300 [18:33<00:41,  3.74s/it]progress:  97%|[34m[0m| 290/300 [18:33<00:37,  3.75s/it]                                                           Episode 291	 reward: -12.53	 makespan: 1240.10	 Mean_loss: 0.16823560,  training time: 3.83
progress:  97%|[34m[0m| 290/300 [18:37<00:37,  3.75s/it]progress:  97%|[34m[0m| 291/300 [18:37<00:33,  3.77s/it]                                                           Episode 292	 reward: -12.58	 makespan: 1245.55	 Mean_loss: 0.14159800,  training time: 3.78
progress:  97%|[34m[0m| 291/300 [18:41<00:33,  3.77s/it]progress:  97%|[34m[0m| 292/300 [18:41<00:30,  3.77s/it]                                                           Episode 293	 reward: -12.54	 makespan: 1241.80	 Mean_loss: 0.16192120,  training time: 3.71
progress:  97%|[34m[0m| 292/300 [18:44<00:30,  3.77s/it]progress:  98%|[34m[0m| 293/300 [18:44<00:26,  3.76s/it]                                                           Episode 294	 reward: -12.72	 makespan: 1259.45	 Mean_loss: 0.18839742,  training time: 3.74
progress:  98%|[34m[0m| 293/300 [18:48<00:26,  3.76s/it]progress:  98%|[34m[0m| 294/300 [18:48<00:22,  3.75s/it]                                                           Episode 295	 reward: -12.53	 makespan: 1240.50	 Mean_loss: 0.14841811,  training time: 3.82
progress:  98%|[34m[0m| 294/300 [18:52<00:22,  3.75s/it]progress:  98%|[34m[0m| 295/300 [18:52<00:18,  3.77s/it]                                                           Episode 296	 reward: -12.43	 makespan: 1231.05	 Mean_loss: 0.16459425,  training time: 3.76
progress:  98%|[34m[0m| 295/300 [18:56<00:18,  3.77s/it]progress:  99%|[34m[0m| 296/300 [18:56<00:15,  3.77s/it]                                                           Episode 297	 reward: -12.58	 makespan: 1245.90	 Mean_loss: 0.18865158,  training time: 3.82
progress:  99%|[34m[0m| 296/300 [19:00<00:15,  3.77s/it]progress:  99%|[34m[0m| 297/300 [19:00<00:11,  3.78s/it]                                                           Episode 298	 reward: -12.45	 makespan: 1232.85	 Mean_loss: 0.17642514,  training time: 3.76
progress:  99%|[34m[0m| 297/300 [19:03<00:11,  3.78s/it]progress:  99%|[34m[0m| 298/300 [19:03<00:07,  3.78s/it]                                                           Episode 299	 reward: -12.53	 makespan: 1240.05	 Mean_loss: 0.15867890,  training time: 3.76
progress:  99%|[34m[0m| 298/300 [19:07<00:07,  3.78s/it]progress: 100%|[34m[0m| 299/300 [19:07<00:03,  3.77s/it]                                                           Episode 300	 reward: -12.54	 makespan: 1241.10	 Mean_loss: 0.19978401,  training time: 3.74
progress: 100%|[34m[0m| 299/300 [19:11<00:03,  3.77s/it]progress: 100%|[34m[0m| 300/300 [19:11<00:00,  3.76s/it]progress: 100%|[34m[0m| 300/300 [19:11<00:00,  3.84s/it]
+ n_j=15
+ for model in 15x5+mix+SD2_12
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x13_4 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -2.47	 makespan: 244.20	 Mean_loss: 0.52190757,  training time: 4.13
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:23,  4.14s/it]                                                        Episode 2	 reward: -2.57	 makespan: 254.55	 Mean_loss: 0.34147248,  training time: 1.32
progress:   2%|[34m         [0m| 1/50 [00:05<03:23,  4.14s/it]progress:   4%|[34m         [0m| 2/50 [00:05<01:59,  2.48s/it]                                                        Episode 3	 reward: -2.43	 makespan: 240.45	 Mean_loss: 0.18338968,  training time: 1.36
progress:   4%|[34m         [0m| 2/50 [00:06<01:59,  2.48s/it]progress:   6%|[34m         [0m| 3/50 [00:06<01:32,  1.97s/it]                                                        Episode 4	 reward: -2.58	 makespan: 255.75	 Mean_loss: 0.11467571,  training time: 1.31
progress:   6%|[34m         [0m| 3/50 [00:08<01:32,  1.97s/it]progress:   8%|[34m         [0m| 4/50 [00:08<01:18,  1.71s/it]                                                        Episode 5	 reward: -2.55	 makespan: 252.55	 Mean_loss: 0.05300396,  training time: 1.35
progress:   8%|[34m         [0m| 4/50 [00:09<01:18,  1.71s/it]progress:  10%|[34m         [0m| 5/50 [00:09<01:11,  1.58s/it]                                                        Episode 6	 reward: -2.64	 makespan: 261.20	 Mean_loss: 0.05681305,  training time: 1.34
progress:  10%|[34m         [0m| 5/50 [00:10<01:11,  1.58s/it]progress:  12%|[34m        [0m| 6/50 [00:10<01:06,  1.50s/it]                                                        Episode 7	 reward: -2.66	 makespan: 263.40	 Mean_loss: 0.05262978,  training time: 1.42
progress:  12%|[34m        [0m| 6/50 [00:12<01:06,  1.50s/it]progress:  14%|[34m        [0m| 7/50 [00:12<01:03,  1.48s/it]                                                        Episode 8	 reward: -2.61	 makespan: 257.95	 Mean_loss: 0.02727022,  training time: 1.31
progress:  14%|[34m        [0m| 7/50 [00:13<01:03,  1.48s/it]progress:  16%|[34m        [0m| 8/50 [00:13<00:59,  1.42s/it]                                                        Episode 9	 reward: -2.52	 makespan: 249.35	 Mean_loss: 0.04815166,  training time: 1.28
progress:  16%|[34m        [0m| 8/50 [00:14<00:59,  1.42s/it]progress:  18%|[34m        [0m| 9/50 [00:14<00:56,  1.38s/it]                                                        Episode 10	 reward: -2.56	 makespan: 253.60	 Mean_loss: 0.07573058,  training time: 1.32
progress:  18%|[34m        [0m| 9/50 [00:16<00:56,  1.38s/it]progress:  20%|[34m        [0m| 10/50 [00:16<00:54,  1.36s/it]                                                         Episode 11	 reward: -2.58	 makespan: 255.75	 Mean_loss: 0.04110546,  training time: 1.29
progress:  20%|[34m        [0m| 10/50 [00:17<00:54,  1.36s/it]progress:  22%|[34m       [0m| 11/50 [00:17<00:52,  1.34s/it]                                                         Episode 12	 reward: -2.66	 makespan: 263.15	 Mean_loss: 0.03276303,  training time: 1.45
progress:  22%|[34m       [0m| 11/50 [00:18<00:52,  1.34s/it]progress:  24%|[34m       [0m| 12/50 [00:18<00:52,  1.38s/it]                                                         Episode 13	 reward: -2.59	 makespan: 256.45	 Mean_loss: 0.03433557,  training time: 1.38
progress:  24%|[34m       [0m| 12/50 [00:20<00:52,  1.38s/it]progress:  26%|[34m       [0m| 13/50 [00:20<00:50,  1.38s/it]                                                         Episode 14	 reward: -2.47	 makespan: 244.60	 Mean_loss: 0.03327239,  training time: 1.36
progress:  26%|[34m       [0m| 13/50 [00:21<00:50,  1.38s/it]progress:  28%|[34m       [0m| 14/50 [00:21<00:49,  1.37s/it]                                                         Episode 15	 reward: -2.59	 makespan: 256.00	 Mean_loss: 0.04983554,  training time: 1.34
progress:  28%|[34m       [0m| 14/50 [00:23<00:49,  1.37s/it]progress:  30%|[34m       [0m| 15/50 [00:23<00:47,  1.36s/it]                                                         Episode 16	 reward: -2.65	 makespan: 262.75	 Mean_loss: 0.03882095,  training time: 1.35
progress:  30%|[34m       [0m| 15/50 [00:24<00:47,  1.36s/it]progress:  32%|[34m      [0m| 16/50 [00:24<00:46,  1.36s/it]                                                         Episode 17	 reward: -2.50	 makespan: 247.65	 Mean_loss: 0.02683224,  training time: 1.36
progress:  32%|[34m      [0m| 16/50 [00:25<00:46,  1.36s/it]progress:  34%|[34m      [0m| 17/50 [00:25<00:44,  1.36s/it]                                                         Episode 18	 reward: -2.63	 makespan: 260.85	 Mean_loss: 0.05086985,  training time: 1.34
progress:  34%|[34m      [0m| 17/50 [00:27<00:44,  1.36s/it]progress:  36%|[34m      [0m| 18/50 [00:27<00:43,  1.36s/it]                                                         Episode 19	 reward: -2.61	 makespan: 258.55	 Mean_loss: 0.02797702,  training time: 1.34
progress:  36%|[34m      [0m| 18/50 [00:28<00:43,  1.36s/it]progress:  38%|[34m      [0m| 19/50 [00:28<00:41,  1.35s/it]                                                         Episode 20	 reward: -2.62	 makespan: 259.25	 Mean_loss: 0.05315888,  training time: 1.30
progress:  38%|[34m      [0m| 19/50 [00:29<00:41,  1.35s/it]progress:  40%|[34m      [0m| 20/50 [00:29<00:40,  1.34s/it]                                                         Episode 21	 reward: -2.66	 makespan: 263.75	 Mean_loss: 0.05118334,  training time: 1.28
progress:  40%|[34m      [0m| 20/50 [00:31<00:40,  1.34s/it]progress:  42%|[34m     [0m| 21/50 [00:31<00:38,  1.32s/it]                                                         Episode 22	 reward: -2.59	 makespan: 256.90	 Mean_loss: 0.04283416,  training time: 1.29
progress:  42%|[34m     [0m| 21/50 [00:32<00:38,  1.32s/it]progress:  44%|[34m     [0m| 22/50 [00:32<00:36,  1.31s/it]                                                         Episode 23	 reward: -2.56	 makespan: 253.45	 Mean_loss: 0.03499810,  training time: 1.34
progress:  44%|[34m     [0m| 22/50 [00:33<00:36,  1.31s/it]progress:  46%|[34m     [0m| 23/50 [00:33<00:35,  1.32s/it]                                                         Episode 24	 reward: -2.54	 makespan: 251.00	 Mean_loss: 0.02598398,  training time: 1.34
progress:  46%|[34m     [0m| 23/50 [00:34<00:35,  1.32s/it]progress:  48%|[34m     [0m| 24/50 [00:34<00:34,  1.33s/it]                                                         Episode 25	 reward: -2.44	 makespan: 241.40	 Mean_loss: 0.01188236,  training time: 1.29
progress:  48%|[34m     [0m| 24/50 [00:36<00:34,  1.33s/it]progress:  50%|[34m     [0m| 25/50 [00:36<00:32,  1.32s/it]                                                         Episode 26	 reward: -2.65	 makespan: 262.25	 Mean_loss: 0.05819157,  training time: 1.31
progress:  50%|[34m     [0m| 25/50 [00:37<00:32,  1.32s/it]progress:  52%|[34m    [0m| 26/50 [00:37<00:31,  1.32s/it]                                                         Episode 27	 reward: -2.49	 makespan: 246.20	 Mean_loss: 0.01206894,  training time: 1.28
progress:  52%|[34m    [0m| 26/50 [00:38<00:31,  1.32s/it]progress:  54%|[34m    [0m| 27/50 [00:38<00:30,  1.31s/it]                                                         Episode 28	 reward: -2.61	 makespan: 258.05	 Mean_loss: 0.05439426,  training time: 1.36
progress:  54%|[34m    [0m| 27/50 [00:40<00:30,  1.31s/it]progress:  56%|[34m    [0m| 28/50 [00:40<00:29,  1.32s/it]                                                         Episode 29	 reward: -2.60	 makespan: 256.95	 Mean_loss: 0.01661848,  training time: 1.29
progress:  56%|[34m    [0m| 28/50 [00:41<00:29,  1.32s/it]progress:  58%|[34m    [0m| 29/50 [00:41<00:27,  1.31s/it]                                                         Episode 30	 reward: -2.46	 makespan: 243.20	 Mean_loss: 0.02969480,  training time: 1.37
progress:  58%|[34m    [0m| 29/50 [00:42<00:27,  1.31s/it]progress:  60%|[34m    [0m| 30/50 [00:42<00:26,  1.33s/it]                                                         Episode 31	 reward: -2.51	 makespan: 248.20	 Mean_loss: 0.05404890,  training time: 1.31
progress:  60%|[34m    [0m| 30/50 [00:44<00:26,  1.33s/it]progress:  62%|[34m   [0m| 31/50 [00:44<00:25,  1.33s/it]                                                         Episode 32	 reward: -2.53	 makespan: 250.80	 Mean_loss: 0.01786616,  training time: 1.28
progress:  62%|[34m   [0m| 31/50 [00:45<00:25,  1.33s/it]progress:  64%|[34m   [0m| 32/50 [00:45<00:23,  1.31s/it]                                                         Episode 33	 reward: -2.63	 makespan: 259.90	 Mean_loss: 0.02018685,  training time: 1.28
progress:  64%|[34m   [0m| 32/50 [00:46<00:23,  1.31s/it]progress:  66%|[34m   [0m| 33/50 [00:46<00:22,  1.30s/it]                                                         Episode 34	 reward: -2.56	 makespan: 253.60	 Mean_loss: 0.02471964,  training time: 1.33
progress:  66%|[34m   [0m| 33/50 [00:48<00:22,  1.30s/it]progress:  68%|[34m   [0m| 34/50 [00:48<00:20,  1.31s/it]                                                         Episode 35	 reward: -2.49	 makespan: 246.30	 Mean_loss: 0.02702667,  training time: 1.27
progress:  68%|[34m   [0m| 34/50 [00:49<00:20,  1.31s/it]progress:  70%|[34m   [0m| 35/50 [00:49<00:19,  1.30s/it]                                                         Episode 36	 reward: -2.61	 makespan: 258.20	 Mean_loss: 0.02056830,  training time: 1.36
progress:  70%|[34m   [0m| 35/50 [00:50<00:19,  1.30s/it]progress:  72%|[34m  [0m| 36/50 [00:50<00:18,  1.32s/it]                                                         Episode 37	 reward: -2.56	 makespan: 253.40	 Mean_loss: 0.02245006,  training time: 1.29
progress:  72%|[34m  [0m| 36/50 [00:52<00:18,  1.32s/it]progress:  74%|[34m  [0m| 37/50 [00:52<00:17,  1.31s/it]                                                         Episode 38	 reward: -2.55	 makespan: 252.30	 Mean_loss: 0.03043960,  training time: 1.34
progress:  74%|[34m  [0m| 37/50 [00:53<00:17,  1.31s/it]progress:  76%|[34m  [0m| 38/50 [00:53<00:15,  1.32s/it]                                                         Episode 39	 reward: -2.51	 makespan: 248.50	 Mean_loss: 0.03888787,  training time: 1.31
progress:  76%|[34m  [0m| 38/50 [00:54<00:15,  1.32s/it]progress:  78%|[34m  [0m| 39/50 [00:54<00:14,  1.32s/it]                                                         Episode 40	 reward: -2.56	 makespan: 253.40	 Mean_loss: 0.02096367,  training time: 1.31
progress:  78%|[34m  [0m| 39/50 [00:56<00:14,  1.32s/it]progress:  80%|[34m  [0m| 40/50 [00:56<00:13,  1.32s/it]                                                         Episode 41	 reward: -2.52	 makespan: 249.60	 Mean_loss: 0.03350849,  training time: 1.31
progress:  80%|[34m  [0m| 40/50 [00:57<00:13,  1.32s/it]progress:  82%|[34m [0m| 41/50 [00:57<00:11,  1.32s/it]                                                         Episode 42	 reward: -2.49	 makespan: 246.55	 Mean_loss: 0.01071588,  training time: 1.33
progress:  82%|[34m [0m| 41/50 [00:58<00:11,  1.32s/it]progress:  84%|[34m [0m| 42/50 [00:58<00:10,  1.32s/it]                                                         Episode 43	 reward: -2.49	 makespan: 246.35	 Mean_loss: 0.03733440,  training time: 1.27
progress:  84%|[34m [0m| 42/50 [00:59<00:10,  1.32s/it]progress:  86%|[34m [0m| 43/50 [00:59<00:09,  1.31s/it]                                                         Episode 44	 reward: -2.52	 makespan: 249.30	 Mean_loss: 0.04298828,  training time: 1.36
progress:  86%|[34m [0m| 43/50 [01:01<00:09,  1.31s/it]progress:  88%|[34m [0m| 44/50 [01:01<00:07,  1.32s/it]                                                         Episode 45	 reward: -2.56	 makespan: 253.20	 Mean_loss: 0.07103694,  training time: 1.32
progress:  88%|[34m [0m| 44/50 [01:02<00:07,  1.32s/it]progress:  90%|[34m [0m| 45/50 [01:02<00:06,  1.33s/it]                                                         Episode 46	 reward: -2.50	 makespan: 247.70	 Mean_loss: 0.04818975,  training time: 1.28
progress:  90%|[34m [0m| 45/50 [01:03<00:06,  1.33s/it]progress:  92%|[34m[0m| 46/50 [01:03<00:05,  1.31s/it]                                                         Episode 47	 reward: -2.55	 makespan: 252.45	 Mean_loss: 0.02995128,  training time: 1.37
progress:  92%|[34m[0m| 46/50 [01:05<00:05,  1.31s/it]progress:  94%|[34m[0m| 47/50 [01:05<00:03,  1.33s/it]                                                         Episode 48	 reward: -2.45	 makespan: 242.20	 Mean_loss: 0.03071982,  training time: 1.30
progress:  94%|[34m[0m| 47/50 [01:06<00:03,  1.33s/it]progress:  96%|[34m[0m| 48/50 [01:06<00:02,  1.32s/it]                                                         Episode 49	 reward: -2.43	 makespan: 240.55	 Mean_loss: 0.03095437,  training time: 1.27
progress:  96%|[34m[0m| 48/50 [01:07<00:02,  1.32s/it]progress:  98%|[34m[0m| 49/50 [01:07<00:01,  1.31s/it]                                                         Episode 50	 reward: -2.53	 makespan: 250.40	 Mean_loss: 0.02349569,  training time: 1.27
progress:  98%|[34m[0m| 49/50 [01:09<00:01,  1.31s/it]progress: 100%|[34m[0m| 50/50 [01:09<00:00,  1.30s/it]progress: 100%|[34m[0m| 50/50 [01:09<00:00,  1.38s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x13_7 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.31	 makespan: 426.65	 Mean_loss: 0.37963399,  training time: 3.59
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:56,  3.60s/it]                                                        Episode 2	 reward: -4.21	 makespan: 416.55	 Mean_loss: 0.28610271,  training time: 2.36
progress:   2%|[34m         [0m| 1/50 [00:05<02:56,  3.60s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:17,  2.87s/it]                                                        Episode 3	 reward: -4.31	 makespan: 426.65	 Mean_loss: 0.00798137,  training time: 2.38
progress:   4%|[34m         [0m| 2/50 [00:08<02:17,  2.87s/it]progress:   6%|[34m         [0m| 3/50 [00:08<02:04,  2.65s/it]                                                        Episode 4	 reward: -4.46	 makespan: 441.75	 Mean_loss: -0.03093702,  training time: 2.36
progress:   6%|[34m         [0m| 3/50 [00:10<02:04,  2.65s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:56,  2.54s/it]                                                        Episode 5	 reward: -4.41	 makespan: 437.05	 Mean_loss: -0.41004989,  training time: 2.36
progress:   8%|[34m         [0m| 4/50 [00:13<01:56,  2.54s/it]progress:  10%|[34m         [0m| 5/50 [00:13<01:51,  2.48s/it]                                                        Episode 6	 reward: -4.36	 makespan: 431.15	 Mean_loss: -0.22017387,  training time: 2.40
progress:  10%|[34m         [0m| 5/50 [00:15<01:51,  2.48s/it]progress:  12%|[34m        [0m| 6/50 [00:15<01:47,  2.45s/it]                                                        Episode 7	 reward: -4.50	 makespan: 445.70	 Mean_loss: 0.00416397,  training time: 2.36
progress:  12%|[34m        [0m| 6/50 [00:17<01:47,  2.45s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:44,  2.42s/it]                                                        Episode 8	 reward: -4.37	 makespan: 433.00	 Mean_loss: -0.23185012,  training time: 2.40
progress:  14%|[34m        [0m| 7/50 [00:20<01:44,  2.42s/it]progress:  16%|[34m        [0m| 8/50 [00:20<01:41,  2.42s/it]                                                        Episode 9	 reward: -4.36	 makespan: 431.60	 Mean_loss: -0.11397077,  training time: 2.38
progress:  16%|[34m        [0m| 8/50 [00:22<01:41,  2.42s/it]progress:  18%|[34m        [0m| 9/50 [00:22<01:38,  2.41s/it]                                                        Episode 10	 reward: -4.40	 makespan: 435.45	 Mean_loss: -0.19146931,  training time: 2.37
progress:  18%|[34m        [0m| 9/50 [00:25<01:38,  2.41s/it]progress:  20%|[34m        [0m| 10/50 [00:25<01:35,  2.40s/it]                                                         Episode 11	 reward: -4.30	 makespan: 426.10	 Mean_loss: 0.21294053,  training time: 2.43
progress:  20%|[34m        [0m| 10/50 [00:27<01:35,  2.40s/it]progress:  22%|[34m       [0m| 11/50 [00:27<01:33,  2.41s/it]                                                         Episode 12	 reward: -4.33	 makespan: 428.20	 Mean_loss: -0.19234434,  training time: 2.34
progress:  22%|[34m       [0m| 11/50 [00:29<01:33,  2.41s/it]progress:  24%|[34m       [0m| 12/50 [00:29<01:30,  2.39s/it]                                                         Episode 13	 reward: -4.40	 makespan: 436.05	 Mean_loss: -0.28839904,  training time: 2.60
progress:  24%|[34m       [0m| 12/50 [00:32<01:30,  2.39s/it]progress:  26%|[34m       [0m| 13/50 [00:32<01:30,  2.46s/it]                                                         Episode 14	 reward: -4.20	 makespan: 415.45	 Mean_loss: 0.18565491,  training time: 2.38
progress:  26%|[34m       [0m| 13/50 [00:34<01:30,  2.46s/it]progress:  28%|[34m       [0m| 14/50 [00:34<01:27,  2.43s/it]                                                         Episode 15	 reward: -4.34	 makespan: 429.60	 Mean_loss: 0.00012001,  training time: 2.43
progress:  28%|[34m       [0m| 14/50 [00:37<01:27,  2.43s/it]progress:  30%|[34m       [0m| 15/50 [00:37<01:25,  2.43s/it]                                                         Episode 16	 reward: -4.32	 makespan: 427.65	 Mean_loss: 0.26036128,  training time: 2.37
progress:  30%|[34m       [0m| 15/50 [00:39<01:25,  2.43s/it]progress:  32%|[34m      [0m| 16/50 [00:39<01:22,  2.41s/it]                                                         Episode 17	 reward: -4.31	 makespan: 426.30	 Mean_loss: -0.48149067,  training time: 2.38
progress:  32%|[34m      [0m| 16/50 [00:41<01:22,  2.41s/it]progress:  34%|[34m      [0m| 17/50 [00:41<01:19,  2.40s/it]                                                         Episode 18	 reward: -4.27	 makespan: 423.20	 Mean_loss: -0.37501046,  training time: 2.37
progress:  34%|[34m      [0m| 17/50 [00:44<01:19,  2.40s/it]progress:  36%|[34m      [0m| 18/50 [00:44<01:16,  2.40s/it]                                                         Episode 19	 reward: -4.26	 makespan: 421.65	 Mean_loss: 0.28531048,  training time: 2.38
progress:  36%|[34m      [0m| 18/50 [00:46<01:16,  2.40s/it]progress:  38%|[34m      [0m| 19/50 [00:46<01:14,  2.39s/it]                                                         Episode 20	 reward: -4.33	 makespan: 429.00	 Mean_loss: -0.52070320,  training time: 2.36
progress:  38%|[34m      [0m| 19/50 [00:49<01:14,  2.39s/it]progress:  40%|[34m      [0m| 20/50 [00:49<01:11,  2.38s/it]                                                         Episode 21	 reward: -4.34	 makespan: 429.50	 Mean_loss: -0.65972620,  training time: 2.40
progress:  40%|[34m      [0m| 20/50 [00:51<01:11,  2.38s/it]progress:  42%|[34m     [0m| 21/50 [00:51<01:09,  2.39s/it]                                                         Episode 22	 reward: -4.37	 makespan: 432.35	 Mean_loss: -0.48288086,  training time: 2.35
progress:  42%|[34m     [0m| 21/50 [00:53<01:09,  2.39s/it]progress:  44%|[34m     [0m| 22/50 [00:53<01:06,  2.38s/it]                                                         Episode 23	 reward: -4.22	 makespan: 417.45	 Mean_loss: -0.06293444,  training time: 2.40
progress:  44%|[34m     [0m| 22/50 [00:56<01:06,  2.38s/it]progress:  46%|[34m     [0m| 23/50 [00:56<01:04,  2.39s/it]                                                         Episode 24	 reward: -4.30	 makespan: 425.95	 Mean_loss: -0.15627334,  training time: 2.40
progress:  46%|[34m     [0m| 23/50 [00:58<01:04,  2.39s/it]progress:  48%|[34m     [0m| 24/50 [00:58<01:02,  2.39s/it]                                                         Episode 25	 reward: -4.28	 makespan: 423.70	 Mean_loss: 0.20206782,  training time: 2.36
progress:  48%|[34m     [0m| 24/50 [01:01<01:02,  2.39s/it]progress:  50%|[34m     [0m| 25/50 [01:01<00:59,  2.38s/it]                                                         Episode 26	 reward: -4.27	 makespan: 422.65	 Mean_loss: -0.28520542,  training time: 2.39
progress:  50%|[34m     [0m| 25/50 [01:03<00:59,  2.38s/it]progress:  52%|[34m    [0m| 26/50 [01:03<00:57,  2.39s/it]                                                         Episode 27	 reward: -4.35	 makespan: 430.25	 Mean_loss: -0.28848714,  training time: 2.36
progress:  52%|[34m    [0m| 26/50 [01:05<00:57,  2.39s/it]progress:  54%|[34m    [0m| 27/50 [01:05<00:54,  2.38s/it]                                                         Episode 28	 reward: -4.27	 makespan: 422.90	 Mean_loss: -0.29773375,  training time: 2.46
progress:  54%|[34m    [0m| 27/50 [01:08<00:54,  2.38s/it]progress:  56%|[34m    [0m| 28/50 [01:08<00:52,  2.40s/it]                                                         Episode 29	 reward: -4.23	 makespan: 419.05	 Mean_loss: -0.38337412,  training time: 2.39
progress:  56%|[34m    [0m| 28/50 [01:10<00:52,  2.40s/it]progress:  58%|[34m    [0m| 29/50 [01:10<00:50,  2.40s/it]                                                         Episode 30	 reward: -4.21	 makespan: 416.80	 Mean_loss: 0.54122156,  training time: 2.35
progress:  58%|[34m    [0m| 29/50 [01:12<00:50,  2.40s/it]progress:  60%|[34m    [0m| 30/50 [01:12<00:47,  2.39s/it]                                                         Episode 31	 reward: -4.44	 makespan: 439.10	 Mean_loss: -0.60800380,  training time: 2.39
progress:  60%|[34m    [0m| 30/50 [01:15<00:47,  2.39s/it]progress:  62%|[34m   [0m| 31/50 [01:15<00:45,  2.39s/it]                                                         Episode 32	 reward: -4.34	 makespan: 429.75	 Mean_loss: -0.44490230,  training time: 2.37
progress:  62%|[34m   [0m| 31/50 [01:17<00:45,  2.39s/it]progress:  64%|[34m   [0m| 32/50 [01:17<00:42,  2.38s/it]                                                         Episode 33	 reward: -4.32	 makespan: 427.40	 Mean_loss: -0.19122082,  training time: 2.31
progress:  64%|[34m   [0m| 32/50 [01:20<00:42,  2.38s/it]progress:  66%|[34m   [0m| 33/50 [01:20<00:40,  2.36s/it]                                                         Episode 34	 reward: -4.37	 makespan: 432.70	 Mean_loss: -0.31609643,  training time: 2.33
progress:  66%|[34m   [0m| 33/50 [01:22<00:40,  2.36s/it]progress:  68%|[34m   [0m| 34/50 [01:22<00:37,  2.35s/it]                                                         Episode 35	 reward: -4.29	 makespan: 425.00	 Mean_loss: -0.02678545,  training time: 2.35
progress:  68%|[34m   [0m| 34/50 [01:24<00:37,  2.35s/it]progress:  70%|[34m   [0m| 35/50 [01:24<00:35,  2.36s/it]                                                         Episode 36	 reward: -4.32	 makespan: 428.00	 Mean_loss: 0.52266258,  training time: 2.36
progress:  70%|[34m   [0m| 35/50 [01:27<00:35,  2.36s/it]progress:  72%|[34m  [0m| 36/50 [01:27<00:33,  2.36s/it]                                                         Episode 37	 reward: -4.37	 makespan: 432.45	 Mean_loss: -0.05774590,  training time: 2.37
progress:  72%|[34m  [0m| 36/50 [01:29<00:33,  2.36s/it]progress:  74%|[34m  [0m| 37/50 [01:29<00:30,  2.36s/it]                                                         Episode 38	 reward: -4.24	 makespan: 419.70	 Mean_loss: -0.21655142,  training time: 2.45
progress:  74%|[34m  [0m| 37/50 [01:31<00:30,  2.36s/it]progress:  76%|[34m  [0m| 38/50 [01:31<00:28,  2.39s/it]                                                         Episode 39	 reward: -4.48	 makespan: 443.70	 Mean_loss: -0.32307428,  training time: 2.32
progress:  76%|[34m  [0m| 38/50 [01:34<00:28,  2.39s/it]progress:  78%|[34m  [0m| 39/50 [01:34<00:26,  2.37s/it]                                                         Episode 40	 reward: -4.42	 makespan: 437.40	 Mean_loss: -0.07376911,  training time: 2.32
progress:  78%|[34m  [0m| 39/50 [01:36<00:26,  2.37s/it]progress:  80%|[34m  [0m| 40/50 [01:36<00:23,  2.36s/it]                                                         Episode 41	 reward: -4.38	 makespan: 433.25	 Mean_loss: -0.30642581,  training time: 2.36
progress:  80%|[34m  [0m| 40/50 [01:38<00:23,  2.36s/it]progress:  82%|[34m [0m| 41/50 [01:38<00:21,  2.36s/it]                                                         Episode 42	 reward: -4.27	 makespan: 423.15	 Mean_loss: -0.03478894,  training time: 2.46
progress:  82%|[34m [0m| 41/50 [01:41<00:21,  2.36s/it]progress:  84%|[34m [0m| 42/50 [01:41<00:19,  2.39s/it]                                                         Episode 43	 reward: -4.38	 makespan: 434.00	 Mean_loss: -0.07337695,  training time: 2.35
progress:  84%|[34m [0m| 42/50 [01:43<00:19,  2.39s/it]progress:  86%|[34m [0m| 43/50 [01:43<00:16,  2.38s/it]                                                         Episode 44	 reward: -4.21	 makespan: 416.55	 Mean_loss: -0.05709030,  training time: 2.37
progress:  86%|[34m [0m| 43/50 [01:46<00:16,  2.38s/it]progress:  88%|[34m [0m| 44/50 [01:46<00:14,  2.38s/it]                                                         Episode 45	 reward: -4.26	 makespan: 421.35	 Mean_loss: -0.14726274,  training time: 2.30
progress:  88%|[34m [0m| 44/50 [01:48<00:14,  2.38s/it]progress:  90%|[34m [0m| 45/50 [01:48<00:11,  2.36s/it]                                                         Episode 46	 reward: -4.34	 makespan: 429.80	 Mean_loss: -0.07326563,  training time: 2.32
progress:  90%|[34m [0m| 45/50 [01:50<00:11,  2.36s/it]progress:  92%|[34m[0m| 46/50 [01:50<00:09,  2.35s/it]                                                         Episode 47	 reward: -4.39	 makespan: 434.15	 Mean_loss: -0.13076690,  training time: 2.31
progress:  92%|[34m[0m| 46/50 [01:53<00:09,  2.35s/it]progress:  94%|[34m[0m| 47/50 [01:53<00:07,  2.34s/it]                                                         Episode 48	 reward: -4.47	 makespan: 442.30	 Mean_loss: 0.07573549,  training time: 2.32
progress:  94%|[34m[0m| 47/50 [01:55<00:07,  2.34s/it]progress:  96%|[34m[0m| 48/50 [01:55<00:04,  2.33s/it]                                                         Episode 49	 reward: -4.36	 makespan: 431.75	 Mean_loss: -0.21802495,  training time: 2.33
progress:  96%|[34m[0m| 48/50 [01:57<00:04,  2.33s/it]progress:  98%|[34m[0m| 49/50 [01:57<00:02,  2.33s/it]                                                         Episode 50	 reward: -4.50	 makespan: 445.15	 Mean_loss: 0.53639948,  training time: 2.31
progress:  98%|[34m[0m| 49/50 [02:00<00:02,  2.33s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.33s/it]progress: 100%|[34m[0m| 50/50 [02:00<00:00,  2.40s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x13_10 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.04	 makespan: 598.10	 Mean_loss: 0.28550810,  training time: 4.61
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:46,  4.62s/it]                                                        Episode 2	 reward: -5.98	 makespan: 592.05	 Mean_loss: 0.22273652,  training time: 3.39
progress:   2%|[34m         [0m| 1/50 [00:08<03:46,  4.62s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:07,  3.90s/it]                                                        Episode 3	 reward: -5.93	 makespan: 587.00	 Mean_loss: 0.16504414,  training time: 3.37
progress:   4%|[34m         [0m| 2/50 [00:11<03:07,  3.90s/it]progress:   6%|[34m         [0m| 3/50 [00:11<02:51,  3.66s/it]                                                        Episode 4	 reward: -5.89	 makespan: 582.80	 Mean_loss: 0.11353718,  training time: 3.36
progress:   6%|[34m         [0m| 3/50 [00:14<02:51,  3.66s/it]progress:   8%|[34m         [0m| 4/50 [00:14<02:42,  3.54s/it]                                                        Episode 5	 reward: -5.91	 makespan: 584.95	 Mean_loss: 0.11705931,  training time: 3.37
progress:   8%|[34m         [0m| 4/50 [00:18<02:42,  3.54s/it]progress:  10%|[34m         [0m| 5/50 [00:18<02:36,  3.48s/it]                                                        Episode 6	 reward: -5.97	 makespan: 590.65	 Mean_loss: 0.10392669,  training time: 3.50
progress:  10%|[34m         [0m| 5/50 [00:21<02:36,  3.48s/it]progress:  12%|[34m        [0m| 6/50 [00:21<02:33,  3.49s/it]                                                        Episode 7	 reward: -6.09	 makespan: 602.90	 Mean_loss: 0.09537379,  training time: 3.37
progress:  12%|[34m        [0m| 6/50 [00:24<02:33,  3.49s/it]progress:  14%|[34m        [0m| 7/50 [00:24<02:28,  3.45s/it]                                                        Episode 8	 reward: -5.91	 makespan: 585.50	 Mean_loss: 0.08199222,  training time: 3.36
progress:  14%|[34m        [0m| 7/50 [00:28<02:28,  3.45s/it]progress:  16%|[34m        [0m| 8/50 [00:28<02:23,  3.42s/it]                                                        Episode 9	 reward: -5.92	 makespan: 585.80	 Mean_loss: 0.09334955,  training time: 3.35
progress:  16%|[34m        [0m| 8/50 [00:31<02:23,  3.42s/it]progress:  18%|[34m        [0m| 9/50 [00:31<02:19,  3.40s/it]                                                        Episode 10	 reward: -6.02	 makespan: 596.30	 Mean_loss: 0.08913609,  training time: 3.35
progress:  18%|[34m        [0m| 9/50 [00:35<02:19,  3.40s/it]progress:  20%|[34m        [0m| 10/50 [00:35<02:15,  3.39s/it]                                                         Episode 11	 reward: -5.72	 makespan: 565.85	 Mean_loss: 0.07561859,  training time: 3.42
progress:  20%|[34m        [0m| 10/50 [00:38<02:15,  3.39s/it]progress:  22%|[34m       [0m| 11/50 [00:38<02:12,  3.40s/it]                                                         Episode 12	 reward: -5.92	 makespan: 586.30	 Mean_loss: 0.06583256,  training time: 3.39
progress:  22%|[34m       [0m| 11/50 [00:41<02:12,  3.40s/it]progress:  24%|[34m       [0m| 12/50 [00:41<02:09,  3.40s/it]                                                         Episode 13	 reward: -5.95	 makespan: 588.90	 Mean_loss: 0.06533960,  training time: 3.35
progress:  24%|[34m       [0m| 12/50 [00:45<02:09,  3.40s/it]progress:  26%|[34m       [0m| 13/50 [00:45<02:05,  3.38s/it]                                                         Episode 14	 reward: -5.92	 makespan: 585.90	 Mean_loss: 0.08787338,  training time: 3.33
progress:  26%|[34m       [0m| 13/50 [00:48<02:05,  3.38s/it]progress:  28%|[34m       [0m| 14/50 [00:48<02:01,  3.37s/it]                                                         Episode 15	 reward: -5.93	 makespan: 586.85	 Mean_loss: 0.06357546,  training time: 3.28
progress:  28%|[34m       [0m| 14/50 [00:51<02:01,  3.37s/it]progress:  30%|[34m       [0m| 15/50 [00:51<01:57,  3.34s/it]                                                         Episode 16	 reward: -5.94	 makespan: 587.75	 Mean_loss: 0.06718232,  training time: 3.29
progress:  30%|[34m       [0m| 15/50 [00:55<01:57,  3.34s/it]progress:  32%|[34m      [0m| 16/50 [00:55<01:53,  3.33s/it]                                                         Episode 17	 reward: -5.93	 makespan: 587.20	 Mean_loss: 0.06704067,  training time: 3.31
progress:  32%|[34m      [0m| 16/50 [00:58<01:53,  3.33s/it]progress:  34%|[34m      [0m| 17/50 [00:58<01:49,  3.33s/it]                                                         Episode 18	 reward: -6.08	 makespan: 602.25	 Mean_loss: 0.08754817,  training time: 3.33
progress:  34%|[34m      [0m| 17/50 [01:01<01:49,  3.33s/it]progress:  36%|[34m      [0m| 18/50 [01:01<01:46,  3.33s/it]                                                         Episode 19	 reward: -5.88	 makespan: 582.55	 Mean_loss: 0.08490504,  training time: 3.33
progress:  36%|[34m      [0m| 18/50 [01:05<01:46,  3.33s/it]progress:  38%|[34m      [0m| 19/50 [01:05<01:43,  3.33s/it]                                                         Episode 20	 reward: -5.95	 makespan: 589.05	 Mean_loss: 0.06398711,  training time: 3.33
progress:  38%|[34m      [0m| 19/50 [01:08<01:43,  3.33s/it]progress:  40%|[34m      [0m| 20/50 [01:08<01:40,  3.33s/it]                                                         Episode 21	 reward: -5.79	 makespan: 573.00	 Mean_loss: 0.07342257,  training time: 3.34
progress:  40%|[34m      [0m| 20/50 [01:11<01:40,  3.33s/it]progress:  42%|[34m     [0m| 21/50 [01:11<01:36,  3.34s/it]                                                         Episode 22	 reward: -5.93	 makespan: 587.15	 Mean_loss: 0.08818968,  training time: 3.36
progress:  42%|[34m     [0m| 21/50 [01:15<01:36,  3.34s/it]progress:  44%|[34m     [0m| 22/50 [01:15<01:33,  3.35s/it]                                                         Episode 23	 reward: -5.88	 makespan: 582.15	 Mean_loss: 0.06232997,  training time: 3.52
progress:  44%|[34m     [0m| 22/50 [01:18<01:33,  3.35s/it]progress:  46%|[34m     [0m| 23/50 [01:18<01:31,  3.40s/it]                                                         Episode 24	 reward: -5.91	 makespan: 585.15	 Mean_loss: 0.06025785,  training time: 3.35
progress:  46%|[34m     [0m| 23/50 [01:22<01:31,  3.40s/it]progress:  48%|[34m     [0m| 24/50 [01:22<01:28,  3.39s/it]                                                         Episode 25	 reward: -5.78	 makespan: 572.55	 Mean_loss: 0.04935176,  training time: 3.32
progress:  48%|[34m     [0m| 24/50 [01:25<01:28,  3.39s/it]progress:  50%|[34m     [0m| 25/50 [01:25<01:24,  3.37s/it]                                                         Episode 26	 reward: -5.91	 makespan: 584.60	 Mean_loss: 0.06949938,  training time: 3.33
progress:  50%|[34m     [0m| 25/50 [01:28<01:24,  3.37s/it]progress:  52%|[34m    [0m| 26/50 [01:28<01:20,  3.36s/it]                                                         Episode 27	 reward: -5.84	 makespan: 578.40	 Mean_loss: 0.05617917,  training time: 3.40
progress:  52%|[34m    [0m| 26/50 [01:32<01:20,  3.36s/it]progress:  54%|[34m    [0m| 27/50 [01:32<01:17,  3.37s/it]                                                         Episode 28	 reward: -5.89	 makespan: 583.50	 Mean_loss: 0.06297380,  training time: 3.46
progress:  54%|[34m    [0m| 27/50 [01:35<01:17,  3.37s/it]progress:  56%|[34m    [0m| 28/50 [01:35<01:14,  3.40s/it]                                                         Episode 29	 reward: -5.92	 makespan: 586.15	 Mean_loss: 0.05635436,  training time: 3.41
progress:  56%|[34m    [0m| 28/50 [01:39<01:14,  3.40s/it]progress:  58%|[34m    [0m| 29/50 [01:39<01:11,  3.40s/it]                                                         Episode 30	 reward: -5.97	 makespan: 590.75	 Mean_loss: 0.05831316,  training time: 3.40
progress:  58%|[34m    [0m| 29/50 [01:42<01:11,  3.40s/it]progress:  60%|[34m    [0m| 30/50 [01:42<01:08,  3.40s/it]                                                         Episode 31	 reward: -5.83	 makespan: 577.40	 Mean_loss: 0.07467830,  training time: 3.37
progress:  60%|[34m    [0m| 30/50 [01:45<01:08,  3.40s/it]progress:  62%|[34m   [0m| 31/50 [01:45<01:04,  3.39s/it]                                                         Episode 32	 reward: -5.87	 makespan: 580.95	 Mean_loss: 0.07719231,  training time: 3.37
progress:  62%|[34m   [0m| 31/50 [01:49<01:04,  3.39s/it]progress:  64%|[34m   [0m| 32/50 [01:49<01:00,  3.39s/it]                                                         Episode 33	 reward: -6.04	 makespan: 598.30	 Mean_loss: 0.06679986,  training time: 3.34
progress:  64%|[34m   [0m| 32/50 [01:52<01:00,  3.39s/it]progress:  66%|[34m   [0m| 33/50 [01:52<00:57,  3.38s/it]                                                         Episode 34	 reward: -5.82	 makespan: 575.90	 Mean_loss: 0.06271201,  training time: 3.29
progress:  66%|[34m   [0m| 33/50 [01:55<00:57,  3.38s/it]progress:  68%|[34m   [0m| 34/50 [01:55<00:53,  3.35s/it]                                                         Episode 35	 reward: -5.87	 makespan: 581.55	 Mean_loss: 0.05578565,  training time: 3.33
progress:  68%|[34m   [0m| 34/50 [01:59<00:53,  3.35s/it]progress:  70%|[34m   [0m| 35/50 [01:59<00:50,  3.35s/it]                                                         Episode 36	 reward: -5.73	 makespan: 567.50	 Mean_loss: 0.06474923,  training time: 3.37
progress:  70%|[34m   [0m| 35/50 [02:02<00:50,  3.35s/it]progress:  72%|[34m  [0m| 36/50 [02:02<00:46,  3.36s/it]                                                         Episode 37	 reward: -6.00	 makespan: 594.10	 Mean_loss: 0.06471523,  training time: 3.33
progress:  72%|[34m  [0m| 36/50 [02:05<00:46,  3.36s/it]progress:  74%|[34m  [0m| 37/50 [02:05<00:43,  3.35s/it]                                                         Episode 38	 reward: -5.79	 makespan: 572.85	 Mean_loss: 0.05290248,  training time: 3.30
progress:  74%|[34m  [0m| 37/50 [02:09<00:43,  3.35s/it]progress:  76%|[34m  [0m| 38/50 [02:09<00:40,  3.33s/it]                                                         Episode 39	 reward: -5.79	 makespan: 573.30	 Mean_loss: 0.06968399,  training time: 3.36
progress:  76%|[34m  [0m| 38/50 [02:12<00:40,  3.33s/it]progress:  78%|[34m  [0m| 39/50 [02:12<00:36,  3.34s/it]                                                         Episode 40	 reward: -6.03	 makespan: 597.05	 Mean_loss: 0.06780887,  training time: 3.40
progress:  78%|[34m  [0m| 39/50 [02:15<00:36,  3.34s/it]progress:  80%|[34m  [0m| 40/50 [02:15<00:33,  3.36s/it]                                                         Episode 41	 reward: -5.90	 makespan: 583.90	 Mean_loss: 0.05982244,  training time: 3.27
progress:  80%|[34m  [0m| 40/50 [02:19<00:33,  3.36s/it]progress:  82%|[34m [0m| 41/50 [02:19<00:30,  3.33s/it]                                                         Episode 42	 reward: -5.84	 makespan: 577.95	 Mean_loss: 0.04246243,  training time: 3.34
progress:  82%|[34m [0m| 41/50 [02:22<00:30,  3.33s/it]progress:  84%|[34m [0m| 42/50 [02:22<00:26,  3.34s/it]                                                         Episode 43	 reward: -5.86	 makespan: 579.65	 Mean_loss: 0.06671371,  training time: 3.28
progress:  84%|[34m [0m| 42/50 [02:25<00:26,  3.34s/it]progress:  86%|[34m [0m| 43/50 [02:25<00:23,  3.32s/it]                                                         Episode 44	 reward: -5.93	 makespan: 586.90	 Mean_loss: 0.07101110,  training time: 3.31
progress:  86%|[34m [0m| 43/50 [02:29<00:23,  3.32s/it]progress:  88%|[34m [0m| 44/50 [02:29<00:19,  3.32s/it]                                                         Episode 45	 reward: -5.78	 makespan: 572.70	 Mean_loss: 0.05387137,  training time: 3.32
progress:  88%|[34m [0m| 44/50 [02:32<00:19,  3.32s/it]progress:  90%|[34m [0m| 45/50 [02:32<00:16,  3.32s/it]                                                         Episode 46	 reward: -5.83	 makespan: 577.00	 Mean_loss: 0.03783451,  training time: 3.29
progress:  90%|[34m [0m| 45/50 [02:35<00:16,  3.32s/it]progress:  92%|[34m[0m| 46/50 [02:35<00:13,  3.31s/it]                                                         Episode 47	 reward: -5.89	 makespan: 583.55	 Mean_loss: 0.06087910,  training time: 3.33
progress:  92%|[34m[0m| 46/50 [02:39<00:13,  3.31s/it]progress:  94%|[34m[0m| 47/50 [02:39<00:09,  3.32s/it]                                                         Episode 48	 reward: -5.84	 makespan: 577.95	 Mean_loss: 0.05913478,  training time: 3.29
progress:  94%|[34m[0m| 47/50 [02:42<00:09,  3.32s/it]progress:  96%|[34m[0m| 48/50 [02:42<00:06,  3.31s/it]                                                         Episode 49	 reward: -5.85	 makespan: 579.50	 Mean_loss: 0.07310995,  training time: 3.36
progress:  96%|[34m[0m| 48/50 [02:45<00:06,  3.31s/it]progress:  98%|[34m[0m| 49/50 [02:45<00:03,  3.33s/it]                                                         Episode 50	 reward: -5.75	 makespan: 569.30	 Mean_loss: 0.05906513,  training time: 3.34
progress:  98%|[34m[0m| 49/50 [02:49<00:03,  3.33s/it]progress: 100%|[34m[0m| 50/50 [02:49<00:00,  3.33s/it]progress: 100%|[34m[0m| 50/50 [02:49<00:00,  3.38s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x13_12 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 13 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x13+mix
save model name:  15x13+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x13+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.89	 makespan: 682.05	 Mean_loss: 0.36153385,  training time: 5.38
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:23,  5.38s/it]                                                        Episode 2	 reward: -6.86	 makespan: 679.35	 Mean_loss: 0.26111382,  training time: 4.23
progress:   2%|[34m         [0m| 1/50 [00:09<04:23,  5.38s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:45,  4.70s/it]                                                        Episode 3	 reward: -7.08	 makespan: 701.15	 Mean_loss: 0.23226726,  training time: 4.39
progress:   4%|[34m         [0m| 2/50 [00:13<03:45,  4.70s/it]progress:   6%|[34m         [0m| 3/50 [00:13<03:34,  4.56s/it]                                                        Episode 4	 reward: -6.89	 makespan: 682.30	 Mean_loss: 0.15817621,  training time: 4.32
progress:   6%|[34m         [0m| 3/50 [00:18<03:34,  4.56s/it]progress:   8%|[34m         [0m| 4/50 [00:18<03:25,  4.47s/it]                                                        Episode 5	 reward: -7.08	 makespan: 700.95	 Mean_loss: 0.15001342,  training time: 4.38
progress:   8%|[34m         [0m| 4/50 [00:22<03:25,  4.47s/it]progress:  10%|[34m         [0m| 5/50 [00:22<03:19,  4.44s/it]                                                        Episode 6	 reward: -6.92	 makespan: 685.20	 Mean_loss: 0.13902946,  training time: 4.20
progress:  10%|[34m         [0m| 5/50 [00:26<03:19,  4.44s/it]progress:  12%|[34m        [0m| 6/50 [00:26<03:11,  4.36s/it]                                                        Episode 7	 reward: -6.76	 makespan: 669.20	 Mean_loss: 0.13651477,  training time: 4.21
progress:  12%|[34m        [0m| 6/50 [00:31<03:11,  4.36s/it]progress:  14%|[34m        [0m| 7/50 [00:31<03:05,  4.31s/it]                                                        Episode 8	 reward: -6.93	 makespan: 685.70	 Mean_loss: 0.14257917,  training time: 4.33
progress:  14%|[34m        [0m| 7/50 [00:35<03:05,  4.31s/it]progress:  16%|[34m        [0m| 8/50 [00:35<03:01,  4.32s/it]                                                        Episode 9	 reward: -6.80	 makespan: 673.10	 Mean_loss: 0.14827459,  training time: 4.28
progress:  16%|[34m        [0m| 8/50 [00:39<03:01,  4.32s/it]progress:  18%|[34m        [0m| 9/50 [00:39<02:56,  4.31s/it]                                                        Episode 10	 reward: -6.98	 makespan: 690.55	 Mean_loss: 0.13505617,  training time: 4.26
progress:  18%|[34m        [0m| 9/50 [00:44<02:56,  4.31s/it]progress:  20%|[34m        [0m| 10/50 [00:44<02:51,  4.30s/it]                                                         Episode 11	 reward: -6.73	 makespan: 666.25	 Mean_loss: 0.11955814,  training time: 4.27
progress:  20%|[34m        [0m| 10/50 [00:48<02:51,  4.30s/it]progress:  22%|[34m       [0m| 11/50 [00:48<02:47,  4.29s/it]                                                         Episode 12	 reward: -7.00	 makespan: 692.60	 Mean_loss: 0.13693574,  training time: 4.19
progress:  22%|[34m       [0m| 11/50 [00:52<02:47,  4.29s/it]progress:  24%|[34m       [0m| 12/50 [00:52<02:42,  4.26s/it]                                                         Episode 13	 reward: -6.83	 makespan: 676.35	 Mean_loss: 0.13246237,  training time: 4.22
progress:  24%|[34m       [0m| 12/50 [00:56<02:42,  4.26s/it]progress:  26%|[34m       [0m| 13/50 [00:56<02:37,  4.25s/it]                                                         Episode 14	 reward: -7.00	 makespan: 692.60	 Mean_loss: 0.11971334,  training time: 4.18
progress:  26%|[34m       [0m| 13/50 [01:00<02:37,  4.25s/it]progress:  28%|[34m       [0m| 14/50 [01:00<02:32,  4.23s/it]                                                         Episode 15	 reward: -6.87	 makespan: 679.70	 Mean_loss: 0.11004008,  training time: 4.29
progress:  28%|[34m       [0m| 14/50 [01:05<02:32,  4.23s/it]progress:  30%|[34m       [0m| 15/50 [01:05<02:28,  4.25s/it]                                                         Episode 16	 reward: -6.95	 makespan: 687.95	 Mean_loss: 0.11420496,  training time: 4.27
progress:  30%|[34m       [0m| 15/50 [01:09<02:28,  4.25s/it]progress:  32%|[34m      [0m| 16/50 [01:09<02:24,  4.26s/it]                                                         Episode 17	 reward: -6.88	 makespan: 681.55	 Mean_loss: 0.11599258,  training time: 4.24
progress:  32%|[34m      [0m| 16/50 [01:13<02:24,  4.26s/it]progress:  34%|[34m      [0m| 17/50 [01:13<02:20,  4.26s/it]                                                         Episode 18	 reward: -6.77	 makespan: 669.85	 Mean_loss: 0.13595299,  training time: 4.45
progress:  34%|[34m      [0m| 17/50 [01:18<02:20,  4.26s/it]progress:  36%|[34m      [0m| 18/50 [01:18<02:18,  4.32s/it]                                                         Episode 19	 reward: -6.94	 makespan: 687.15	 Mean_loss: 0.09839414,  training time: 4.42
progress:  36%|[34m      [0m| 18/50 [01:22<02:18,  4.32s/it]progress:  38%|[34m      [0m| 19/50 [01:22<02:14,  4.35s/it]                                                         Episode 20	 reward: -6.85	 makespan: 678.10	 Mean_loss: 0.10984704,  training time: 4.26
progress:  38%|[34m      [0m| 19/50 [01:26<02:14,  4.35s/it]progress:  40%|[34m      [0m| 20/50 [01:26<02:09,  4.33s/it]                                                         Episode 21	 reward: -6.91	 makespan: 684.50	 Mean_loss: 0.09010299,  training time: 4.23
progress:  40%|[34m      [0m| 20/50 [01:31<02:09,  4.33s/it]progress:  42%|[34m     [0m| 21/50 [01:31<02:04,  4.30s/it]                                                         Episode 22	 reward: -6.84	 makespan: 677.35	 Mean_loss: 0.09859911,  training time: 4.22
progress:  42%|[34m     [0m| 21/50 [01:35<02:04,  4.30s/it]progress:  44%|[34m     [0m| 22/50 [01:35<01:59,  4.28s/it]                                                         Episode 23	 reward: -6.83	 makespan: 675.75	 Mean_loss: 0.10154455,  training time: 4.22
progress:  44%|[34m     [0m| 22/50 [01:39<01:59,  4.28s/it]progress:  46%|[34m     [0m| 23/50 [01:39<01:55,  4.26s/it]                                                         Episode 24	 reward: -6.90	 makespan: 682.70	 Mean_loss: 0.09052720,  training time: 4.19
progress:  46%|[34m     [0m| 23/50 [01:43<01:55,  4.26s/it]progress:  48%|[34m     [0m| 24/50 [01:43<01:50,  4.24s/it]                                                         Episode 25	 reward: -6.86	 makespan: 679.50	 Mean_loss: 0.10233372,  training time: 4.20
progress:  48%|[34m     [0m| 24/50 [01:48<01:50,  4.24s/it]progress:  50%|[34m     [0m| 25/50 [01:48<01:45,  4.23s/it]                                                         Episode 26	 reward: -6.83	 makespan: 675.70	 Mean_loss: 0.08119651,  training time: 4.21
progress:  50%|[34m     [0m| 25/50 [01:52<01:45,  4.23s/it]progress:  52%|[34m    [0m| 26/50 [01:52<01:41,  4.23s/it]                                                         Episode 27	 reward: -6.91	 makespan: 683.70	 Mean_loss: 0.08310623,  training time: 4.27
progress:  52%|[34m    [0m| 26/50 [01:56<01:41,  4.23s/it]progress:  54%|[34m    [0m| 27/50 [01:56<01:37,  4.25s/it]                                                         Episode 28	 reward: -6.71	 makespan: 664.60	 Mean_loss: 0.08980297,  training time: 4.17
progress:  54%|[34m    [0m| 27/50 [02:00<01:37,  4.25s/it]progress:  56%|[34m    [0m| 28/50 [02:00<01:32,  4.22s/it]                                                         Episode 29	 reward: -6.84	 makespan: 677.05	 Mean_loss: 0.09368107,  training time: 4.22
progress:  56%|[34m    [0m| 28/50 [02:04<01:32,  4.22s/it]progress:  58%|[34m    [0m| 29/50 [02:04<01:28,  4.23s/it]                                                         Episode 30	 reward: -6.86	 makespan: 679.15	 Mean_loss: 0.10139032,  training time: 4.29
progress:  58%|[34m    [0m| 29/50 [02:09<01:28,  4.23s/it]progress:  60%|[34m    [0m| 30/50 [02:09<01:24,  4.25s/it]                                                         Episode 31	 reward: -7.02	 makespan: 695.25	 Mean_loss: 0.08884809,  training time: 4.28
progress:  60%|[34m    [0m| 30/50 [02:13<01:24,  4.25s/it]progress:  62%|[34m   [0m| 31/50 [02:13<01:20,  4.26s/it]                                                         Episode 32	 reward: -7.08	 makespan: 700.95	 Mean_loss: 0.09944132,  training time: 4.23
progress:  62%|[34m   [0m| 31/50 [02:17<01:20,  4.26s/it]progress:  64%|[34m   [0m| 32/50 [02:17<01:16,  4.25s/it]                                                         Episode 33	 reward: -6.96	 makespan: 689.15	 Mean_loss: 0.09918914,  training time: 4.19
progress:  64%|[34m   [0m| 32/50 [02:21<01:16,  4.25s/it]progress:  66%|[34m   [0m| 33/50 [02:21<01:12,  4.24s/it]                                                         Episode 34	 reward: -6.85	 makespan: 678.30	 Mean_loss: 0.07943124,  training time: 4.20
progress:  66%|[34m   [0m| 33/50 [02:26<01:12,  4.24s/it]progress:  68%|[34m   [0m| 34/50 [02:26<01:07,  4.23s/it]                                                         Episode 35	 reward: -6.82	 makespan: 675.40	 Mean_loss: 0.08290076,  training time: 4.22
progress:  68%|[34m   [0m| 34/50 [02:30<01:07,  4.23s/it]progress:  70%|[34m   [0m| 35/50 [02:30<01:03,  4.23s/it]                                                         Episode 36	 reward: -6.80	 makespan: 673.60	 Mean_loss: 0.09726754,  training time: 4.21
progress:  70%|[34m   [0m| 35/50 [02:34<01:03,  4.23s/it]progress:  72%|[34m  [0m| 36/50 [02:34<00:59,  4.23s/it]                                                         Episode 37	 reward: -6.87	 makespan: 679.90	 Mean_loss: 0.09871158,  training time: 4.21
progress:  72%|[34m  [0m| 36/50 [02:38<00:59,  4.23s/it]progress:  74%|[34m  [0m| 37/50 [02:38<00:54,  4.22s/it]                                                         Episode 38	 reward: -6.91	 makespan: 683.85	 Mean_loss: 0.07762848,  training time: 4.20
progress:  74%|[34m  [0m| 37/50 [02:43<00:54,  4.22s/it]progress:  76%|[34m  [0m| 38/50 [02:43<00:50,  4.22s/it]                                                         Episode 39	 reward: -7.11	 makespan: 703.40	 Mean_loss: 0.09331964,  training time: 4.22
progress:  76%|[34m  [0m| 38/50 [02:47<00:50,  4.22s/it]progress:  78%|[34m  [0m| 39/50 [02:47<00:46,  4.23s/it]                                                         Episode 40	 reward: -6.82	 makespan: 674.75	 Mean_loss: 0.09563246,  training time: 4.32
progress:  78%|[34m  [0m| 39/50 [02:51<00:46,  4.23s/it]progress:  80%|[34m  [0m| 40/50 [02:51<00:42,  4.26s/it]                                                         Episode 41	 reward: -6.94	 makespan: 687.15	 Mean_loss: 0.06817960,  training time: 4.22
progress:  80%|[34m  [0m| 40/50 [02:55<00:42,  4.26s/it]progress:  82%|[34m [0m| 41/50 [02:55<00:38,  4.25s/it]                                                         Episode 42	 reward: -6.85	 makespan: 678.25	 Mean_loss: 0.07814682,  training time: 4.25
progress:  82%|[34m [0m| 41/50 [03:00<00:38,  4.25s/it]progress:  84%|[34m [0m| 42/50 [03:00<00:34,  4.25s/it]                                                         Episode 43	 reward: -6.91	 makespan: 684.25	 Mean_loss: 0.08782142,  training time: 4.20
progress:  84%|[34m [0m| 42/50 [03:04<00:34,  4.25s/it]progress:  86%|[34m [0m| 43/50 [03:04<00:29,  4.24s/it]                                                         Episode 44	 reward: -6.90	 makespan: 682.90	 Mean_loss: 0.08832902,  training time: 4.44
progress:  86%|[34m [0m| 43/50 [03:08<00:29,  4.24s/it]progress:  88%|[34m [0m| 44/50 [03:08<00:25,  4.30s/it]                                                         Episode 45	 reward: -6.66	 makespan: 659.35	 Mean_loss: 0.06495485,  training time: 4.21
progress:  88%|[34m [0m| 44/50 [03:12<00:25,  4.30s/it]progress:  90%|[34m [0m| 45/50 [03:12<00:21,  4.28s/it]                                                         Episode 46	 reward: -7.00	 makespan: 693.05	 Mean_loss: 0.10869238,  training time: 4.24
progress:  90%|[34m [0m| 45/50 [03:17<00:21,  4.28s/it]progress:  92%|[34m[0m| 46/50 [03:17<00:17,  4.27s/it]                                                         Episode 47	 reward: -6.84	 makespan: 677.00	 Mean_loss: 0.10507944,  training time: 4.20
progress:  92%|[34m[0m| 46/50 [03:21<00:17,  4.27s/it]progress:  94%|[34m[0m| 47/50 [03:21<00:12,  4.25s/it]                                                         Episode 48	 reward: -6.77	 makespan: 670.25	 Mean_loss: 0.10202558,  training time: 4.23
progress:  94%|[34m[0m| 47/50 [03:25<00:12,  4.25s/it]progress:  96%|[34m[0m| 48/50 [03:25<00:08,  4.25s/it]                                                         Episode 49	 reward: -6.90	 makespan: 682.80	 Mean_loss: 0.07856980,  training time: 4.43
progress:  96%|[34m[0m| 48/50 [03:30<00:08,  4.25s/it]progress:  98%|[34m[0m| 49/50 [03:30<00:04,  4.30s/it]                                                         Episode 50	 reward: -6.83	 makespan: 676.30	 Mean_loss: 0.08010494,  training time: 4.20
progress:  98%|[34m[0m| 49/50 [03:34<00:04,  4.30s/it]progress: 100%|[34m[0m| 50/50 [03:34<00:00,  4.27s/it]progress: 100%|[34m[0m| 50/50 [03:34<00:00,  4.29s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x10_4 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -2.70	 makespan: 267.15	 Mean_loss: 0.50742257,  training time: 2.38
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:56,  2.39s/it]                                                        Episode 2	 reward: -2.82	 makespan: 279.20	 Mean_loss: 0.32537085,  training time: 1.22
progress:   2%|[34m         [0m| 1/50 [00:03<01:56,  2.39s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:21,  1.71s/it]                                                        Episode 3	 reward: -2.86	 makespan: 283.20	 Mean_loss: 0.18422204,  training time: 1.28
progress:   4%|[34m         [0m| 2/50 [00:04<01:21,  1.71s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:11,  1.52s/it]                                                        Episode 4	 reward: -2.83	 makespan: 280.50	 Mean_loss: 0.14500825,  training time: 1.30
progress:   6%|[34m         [0m| 3/50 [00:06<01:11,  1.52s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:05,  1.43s/it]                                                        Episode 5	 reward: -2.76	 makespan: 272.80	 Mean_loss: 0.07275914,  training time: 1.22
progress:   8%|[34m         [0m| 4/50 [00:07<01:05,  1.43s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:01,  1.36s/it]                                                        Episode 6	 reward: -2.88	 makespan: 284.75	 Mean_loss: 0.06805512,  training time: 1.22
progress:  10%|[34m         [0m| 5/50 [00:08<01:01,  1.36s/it]progress:  12%|[34m        [0m| 6/50 [00:08<00:57,  1.31s/it]                                                        Episode 7	 reward: -2.83	 makespan: 280.25	 Mean_loss: 0.03296884,  training time: 1.24
progress:  12%|[34m        [0m| 6/50 [00:09<00:57,  1.31s/it]progress:  14%|[34m        [0m| 7/50 [00:09<00:55,  1.29s/it]                                                        Episode 8	 reward: -2.97	 makespan: 294.40	 Mean_loss: 0.04633325,  training time: 1.37
progress:  14%|[34m        [0m| 7/50 [00:11<00:55,  1.29s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:55,  1.32s/it]                                                        Episode 9	 reward: -2.77	 makespan: 274.55	 Mean_loss: 0.03816334,  training time: 1.23
progress:  16%|[34m        [0m| 8/50 [00:12<00:55,  1.32s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:52,  1.29s/it]                                                        Episode 10	 reward: -2.81	 makespan: 278.45	 Mean_loss: 0.04687472,  training time: 1.28
progress:  18%|[34m        [0m| 9/50 [00:13<00:52,  1.29s/it]progress:  20%|[34m        [0m| 10/50 [00:13<00:51,  1.29s/it]                                                         Episode 11	 reward: -2.76	 makespan: 273.30	 Mean_loss: 0.02288498,  training time: 1.28
progress:  20%|[34m        [0m| 10/50 [00:15<00:51,  1.29s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:50,  1.29s/it]                                                         Episode 12	 reward: -2.80	 makespan: 277.25	 Mean_loss: 0.06786811,  training time: 1.33
progress:  22%|[34m       [0m| 11/50 [00:16<00:50,  1.29s/it]progress:  24%|[34m       [0m| 12/50 [00:16<00:49,  1.30s/it]                                                         Episode 13	 reward: -2.89	 makespan: 286.05	 Mean_loss: 0.04360302,  training time: 1.22
progress:  24%|[34m       [0m| 12/50 [00:17<00:49,  1.30s/it]progress:  26%|[34m       [0m| 13/50 [00:17<00:47,  1.28s/it]                                                         Episode 14	 reward: -2.87	 makespan: 284.50	 Mean_loss: 0.02994397,  training time: 1.31
progress:  26%|[34m       [0m| 13/50 [00:18<00:47,  1.28s/it]progress:  28%|[34m       [0m| 14/50 [00:18<00:46,  1.29s/it]                                                         Episode 15	 reward: -2.92	 makespan: 289.50	 Mean_loss: 0.04082770,  training time: 1.29
progress:  28%|[34m       [0m| 14/50 [00:20<00:46,  1.29s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:45,  1.29s/it]                                                         Episode 16	 reward: -2.81	 makespan: 277.85	 Mean_loss: 0.02637754,  training time: 1.30
progress:  30%|[34m       [0m| 15/50 [00:21<00:45,  1.29s/it]progress:  32%|[34m      [0m| 16/50 [00:21<00:44,  1.30s/it]                                                         Episode 17	 reward: -2.87	 makespan: 283.65	 Mean_loss: 0.05451185,  training time: 1.25
progress:  32%|[34m      [0m| 16/50 [00:22<00:44,  1.30s/it]progress:  34%|[34m      [0m| 17/50 [00:22<00:42,  1.28s/it]                                                         Episode 18	 reward: -2.64	 makespan: 261.20	 Mean_loss: 0.01288996,  training time: 1.41
progress:  34%|[34m      [0m| 17/50 [00:24<00:42,  1.28s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:42,  1.33s/it]                                                         Episode 19	 reward: -2.77	 makespan: 273.85	 Mean_loss: 0.03636694,  training time: 1.31
progress:  36%|[34m      [0m| 18/50 [00:25<00:42,  1.33s/it]progress:  38%|[34m      [0m| 19/50 [00:25<00:41,  1.32s/it]                                                         Episode 20	 reward: -2.79	 makespan: 276.55	 Mean_loss: 0.04743277,  training time: 1.29
progress:  38%|[34m      [0m| 19/50 [00:26<00:41,  1.32s/it]progress:  40%|[34m      [0m| 20/50 [00:26<00:39,  1.32s/it]                                                         Episode 21	 reward: -2.80	 makespan: 277.00	 Mean_loss: 0.04864072,  training time: 1.26
progress:  40%|[34m      [0m| 20/50 [00:28<00:39,  1.32s/it]progress:  42%|[34m     [0m| 21/50 [00:28<00:37,  1.30s/it]                                                         Episode 22	 reward: -2.79	 makespan: 275.95	 Mean_loss: 0.01119995,  training time: 1.28
progress:  42%|[34m     [0m| 21/50 [00:29<00:37,  1.30s/it]progress:  44%|[34m     [0m| 22/50 [00:29<00:36,  1.29s/it]                                                         Episode 23	 reward: -2.76	 makespan: 273.00	 Mean_loss: 0.01935117,  training time: 1.36
progress:  44%|[34m     [0m| 22/50 [00:30<00:36,  1.29s/it]progress:  46%|[34m     [0m| 23/50 [00:30<00:35,  1.32s/it]                                                         Episode 24	 reward: -2.83	 makespan: 279.75	 Mean_loss: 0.03758460,  training time: 1.32
progress:  46%|[34m     [0m| 23/50 [00:32<00:35,  1.32s/it]progress:  48%|[34m     [0m| 24/50 [00:32<00:34,  1.32s/it]                                                         Episode 25	 reward: -2.77	 makespan: 274.05	 Mean_loss: 0.04520311,  training time: 1.22
progress:  48%|[34m     [0m| 24/50 [00:33<00:34,  1.32s/it]progress:  50%|[34m     [0m| 25/50 [00:33<00:32,  1.29s/it]                                                         Episode 26	 reward: -2.85	 makespan: 281.70	 Mean_loss: 0.01832272,  training time: 1.21
progress:  50%|[34m     [0m| 25/50 [00:34<00:32,  1.29s/it]progress:  52%|[34m    [0m| 26/50 [00:34<00:30,  1.27s/it]                                                         Episode 27	 reward: -2.83	 makespan: 280.60	 Mean_loss: 0.04248293,  training time: 1.25
progress:  52%|[34m    [0m| 26/50 [00:35<00:30,  1.27s/it]progress:  54%|[34m    [0m| 27/50 [00:35<00:29,  1.26s/it]                                                         Episode 28	 reward: -2.83	 makespan: 280.45	 Mean_loss: 0.02722189,  training time: 1.26
progress:  54%|[34m    [0m| 27/50 [00:37<00:29,  1.26s/it]progress:  56%|[34m    [0m| 28/50 [00:37<00:27,  1.26s/it]                                                         Episode 29	 reward: -2.79	 makespan: 275.75	 Mean_loss: 0.01774756,  training time: 1.27
progress:  56%|[34m    [0m| 28/50 [00:38<00:27,  1.26s/it]progress:  58%|[34m    [0m| 29/50 [00:38<00:26,  1.27s/it]                                                         Episode 30	 reward: -2.81	 makespan: 278.55	 Mean_loss: 0.02475891,  training time: 1.30
progress:  58%|[34m    [0m| 29/50 [00:39<00:26,  1.27s/it]progress:  60%|[34m    [0m| 30/50 [00:39<00:25,  1.28s/it]                                                         Episode 31	 reward: -2.84	 makespan: 280.95	 Mean_loss: 0.04655165,  training time: 1.27
progress:  60%|[34m    [0m| 30/50 [00:40<00:25,  1.28s/it]progress:  62%|[34m   [0m| 31/50 [00:40<00:24,  1.28s/it]                                                         Episode 32	 reward: -2.81	 makespan: 278.60	 Mean_loss: 0.03532946,  training time: 1.24
progress:  62%|[34m   [0m| 31/50 [00:42<00:24,  1.28s/it]progress:  64%|[34m   [0m| 32/50 [00:42<00:22,  1.27s/it]                                                         Episode 33	 reward: -2.72	 makespan: 269.35	 Mean_loss: 0.00728271,  training time: 1.30
progress:  64%|[34m   [0m| 32/50 [00:43<00:22,  1.27s/it]progress:  66%|[34m   [0m| 33/50 [00:43<00:21,  1.28s/it]                                                         Episode 34	 reward: -2.78	 makespan: 274.75	 Mean_loss: 0.02039989,  training time: 1.26
progress:  66%|[34m   [0m| 33/50 [00:44<00:21,  1.28s/it]progress:  68%|[34m   [0m| 34/50 [00:44<00:20,  1.28s/it]                                                         Episode 35	 reward: -2.81	 makespan: 277.80	 Mean_loss: 0.03662688,  training time: 1.24
progress:  68%|[34m   [0m| 34/50 [00:45<00:20,  1.28s/it]progress:  70%|[34m   [0m| 35/50 [00:45<00:18,  1.26s/it]                                                         Episode 36	 reward: -2.75	 makespan: 272.05	 Mean_loss: 0.01051587,  training time: 1.23
progress:  70%|[34m   [0m| 35/50 [00:47<00:18,  1.26s/it]progress:  72%|[34m  [0m| 36/50 [00:47<00:17,  1.26s/it]                                                         Episode 37	 reward: -2.84	 makespan: 280.80	 Mean_loss: 0.05580954,  training time: 1.21
progress:  72%|[34m  [0m| 36/50 [00:48<00:17,  1.26s/it]progress:  74%|[34m  [0m| 37/50 [00:48<00:16,  1.24s/it]                                                         Episode 38	 reward: -2.76	 makespan: 273.15	 Mean_loss: 0.01548794,  training time: 1.21
progress:  74%|[34m  [0m| 37/50 [00:49<00:16,  1.24s/it]progress:  76%|[34m  [0m| 38/50 [00:49<00:14,  1.23s/it]                                                         Episode 39	 reward: -2.79	 makespan: 276.30	 Mean_loss: 0.04685497,  training time: 1.23
progress:  76%|[34m  [0m| 38/50 [00:50<00:14,  1.23s/it]progress:  78%|[34m  [0m| 39/50 [00:50<00:13,  1.23s/it]                                                         Episode 40	 reward: -2.80	 makespan: 277.40	 Mean_loss: 0.04818387,  training time: 1.22
progress:  78%|[34m  [0m| 39/50 [00:52<00:13,  1.23s/it]progress:  80%|[34m  [0m| 40/50 [00:52<00:12,  1.23s/it]                                                         Episode 41	 reward: -2.73	 makespan: 270.25	 Mean_loss: 0.01727441,  training time: 1.29
progress:  80%|[34m  [0m| 40/50 [00:53<00:12,  1.23s/it]progress:  82%|[34m [0m| 41/50 [00:53<00:11,  1.25s/it]                                                         Episode 42	 reward: -2.82	 makespan: 279.65	 Mean_loss: 0.04843721,  training time: 1.23
progress:  82%|[34m [0m| 41/50 [00:54<00:11,  1.25s/it]progress:  84%|[34m [0m| 42/50 [00:54<00:09,  1.24s/it]                                                         Episode 43	 reward: -2.83	 makespan: 279.95	 Mean_loss: 0.03003582,  training time: 1.22
progress:  84%|[34m [0m| 42/50 [00:55<00:09,  1.24s/it]progress:  86%|[34m [0m| 43/50 [00:55<00:08,  1.24s/it]                                                         Episode 44	 reward: -2.77	 makespan: 273.80	 Mean_loss: 0.05622937,  training time: 1.23
progress:  86%|[34m [0m| 43/50 [00:57<00:08,  1.24s/it]progress:  88%|[34m [0m| 44/50 [00:57<00:07,  1.24s/it]                                                         Episode 45	 reward: -2.83	 makespan: 280.00	 Mean_loss: 0.04273653,  training time: 1.21
progress:  88%|[34m [0m| 44/50 [00:58<00:07,  1.24s/it]progress:  90%|[34m [0m| 45/50 [00:58<00:06,  1.23s/it]                                                         Episode 46	 reward: -2.72	 makespan: 269.15	 Mean_loss: 0.02248847,  training time: 1.40
progress:  90%|[34m [0m| 45/50 [00:59<00:06,  1.23s/it]progress:  92%|[34m[0m| 46/50 [00:59<00:05,  1.29s/it]                                                         Episode 47	 reward: -2.83	 makespan: 280.05	 Mean_loss: 0.02225602,  training time: 1.33
progress:  92%|[34m[0m| 46/50 [01:01<00:05,  1.29s/it]progress:  94%|[34m[0m| 47/50 [01:01<00:03,  1.30s/it]                                                         Episode 48	 reward: -2.80	 makespan: 276.95	 Mean_loss: 0.00280288,  training time: 1.22
progress:  94%|[34m[0m| 47/50 [01:02<00:03,  1.30s/it]progress:  96%|[34m[0m| 48/50 [01:02<00:02,  1.28s/it]                                                         Episode 49	 reward: -2.77	 makespan: 274.10	 Mean_loss: 0.00980200,  training time: 1.24
progress:  96%|[34m[0m| 48/50 [01:03<00:02,  1.28s/it]progress:  98%|[34m[0m| 49/50 [01:03<00:01,  1.27s/it]                                                         Episode 50	 reward: -2.80	 makespan: 276.80	 Mean_loss: 0.03613135,  training time: 1.21
progress:  98%|[34m[0m| 49/50 [01:04<00:01,  1.27s/it]progress: 100%|[34m[0m| 50/50 [01:04<00:00,  1.25s/it]progress: 100%|[34m[0m| 50/50 [01:04<00:00,  1.29s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x10_7 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.72	 makespan: 467.15	 Mean_loss: 0.61880112,  training time: 3.46
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:49,  3.47s/it]                                                        Episode 2	 reward: -4.63	 makespan: 458.75	 Mean_loss: 0.10502510,  training time: 2.31
progress:   2%|[34m         [0m| 1/50 [00:05<02:49,  3.47s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:13,  2.79s/it]                                                        Episode 3	 reward: -4.69	 makespan: 464.05	 Mean_loss: 0.43819556,  training time: 2.18
progress:   4%|[34m         [0m| 2/50 [00:07<02:13,  2.79s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:58,  2.51s/it]                                                        Episode 4	 reward: -4.72	 makespan: 467.35	 Mean_loss: 0.05604519,  training time: 2.39
progress:   6%|[34m         [0m| 3/50 [00:10<01:58,  2.51s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:53,  2.47s/it]                                                        Episode 5	 reward: -4.59	 makespan: 454.40	 Mean_loss: -0.43559062,  training time: 2.32
progress:   8%|[34m         [0m| 4/50 [00:12<01:53,  2.47s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:48,  2.42s/it]                                                        Episode 6	 reward: -4.64	 makespan: 459.45	 Mean_loss: -0.33149043,  training time: 2.26
progress:  10%|[34m         [0m| 5/50 [00:14<01:48,  2.42s/it]progress:  12%|[34m        [0m| 6/50 [00:14<01:44,  2.37s/it]                                                        Episode 7	 reward: -4.62	 makespan: 457.05	 Mean_loss: -0.36971852,  training time: 2.29
progress:  12%|[34m        [0m| 6/50 [00:17<01:44,  2.37s/it]progress:  14%|[34m        [0m| 7/50 [00:17<01:40,  2.34s/it]                                                        Episode 8	 reward: -4.56	 makespan: 451.55	 Mean_loss: 0.35732305,  training time: 2.16
progress:  14%|[34m        [0m| 7/50 [00:19<01:40,  2.34s/it]progress:  16%|[34m        [0m| 8/50 [00:19<01:36,  2.29s/it]                                                        Episode 9	 reward: -4.60	 makespan: 455.35	 Mean_loss: -0.54954100,  training time: 2.16
progress:  16%|[34m        [0m| 8/50 [00:21<01:36,  2.29s/it]progress:  18%|[34m        [0m| 9/50 [00:21<01:32,  2.25s/it]                                                        Episode 10	 reward: -4.77	 makespan: 471.80	 Mean_loss: 0.63898706,  training time: 2.26
progress:  18%|[34m        [0m| 9/50 [00:23<01:32,  2.25s/it]progress:  20%|[34m        [0m| 10/50 [00:23<01:30,  2.26s/it]                                                         Episode 11	 reward: -4.63	 makespan: 458.50	 Mean_loss: -0.31804165,  training time: 2.35
progress:  20%|[34m        [0m| 10/50 [00:26<01:30,  2.26s/it]progress:  22%|[34m       [0m| 11/50 [00:26<01:29,  2.29s/it]                                                         Episode 12	 reward: -4.68	 makespan: 463.55	 Mean_loss: 0.22764310,  training time: 2.28
progress:  22%|[34m       [0m| 11/50 [00:28<01:29,  2.29s/it]progress:  24%|[34m       [0m| 12/50 [00:28<01:26,  2.29s/it]                                                         Episode 13	 reward: -4.62	 makespan: 457.85	 Mean_loss: -0.53210133,  training time: 2.30
progress:  24%|[34m       [0m| 12/50 [00:30<01:26,  2.29s/it]progress:  26%|[34m       [0m| 13/50 [00:30<01:24,  2.29s/it]                                                         Episode 14	 reward: -4.70	 makespan: 465.75	 Mean_loss: 0.52465510,  training time: 2.28
progress:  26%|[34m       [0m| 13/50 [00:33<01:24,  2.29s/it]progress:  28%|[34m       [0m| 14/50 [00:33<01:22,  2.29s/it]                                                         Episode 15	 reward: -4.65	 makespan: 460.45	 Mean_loss: 0.21056557,  training time: 2.23
progress:  28%|[34m       [0m| 14/50 [00:35<01:22,  2.29s/it]progress:  30%|[34m       [0m| 15/50 [00:35<01:19,  2.28s/it]                                                         Episode 16	 reward: -4.83	 makespan: 477.85	 Mean_loss: 0.86967313,  training time: 2.26
progress:  30%|[34m       [0m| 15/50 [00:37<01:19,  2.28s/it]progress:  32%|[34m      [0m| 16/50 [00:37<01:17,  2.27s/it]                                                         Episode 17	 reward: -4.66	 makespan: 460.90	 Mean_loss: -0.22499597,  training time: 2.29
progress:  32%|[34m      [0m| 16/50 [00:39<01:17,  2.27s/it]progress:  34%|[34m      [0m| 17/50 [00:39<01:15,  2.28s/it]                                                         Episode 18	 reward: -4.69	 makespan: 464.35	 Mean_loss: 0.58182186,  training time: 2.17
progress:  34%|[34m      [0m| 17/50 [00:42<01:15,  2.28s/it]progress:  36%|[34m      [0m| 18/50 [00:42<01:11,  2.25s/it]                                                         Episode 19	 reward: -4.54	 makespan: 449.75	 Mean_loss: 0.23023906,  training time: 2.20
progress:  36%|[34m      [0m| 18/50 [00:44<01:11,  2.25s/it]progress:  38%|[34m      [0m| 19/50 [00:44<01:09,  2.23s/it]                                                         Episode 20	 reward: -4.51	 makespan: 446.45	 Mean_loss: 0.39201325,  training time: 2.24
progress:  38%|[34m      [0m| 19/50 [00:46<01:09,  2.23s/it]progress:  40%|[34m      [0m| 20/50 [00:46<01:07,  2.24s/it]                                                         Episode 21	 reward: -4.64	 makespan: 459.70	 Mean_loss: -0.20305711,  training time: 2.17
progress:  40%|[34m      [0m| 20/50 [00:48<01:07,  2.24s/it]progress:  42%|[34m     [0m| 21/50 [00:48<01:04,  2.22s/it]                                                         Episode 22	 reward: -4.53	 makespan: 448.10	 Mean_loss: 0.54089111,  training time: 2.17
progress:  42%|[34m     [0m| 21/50 [00:50<01:04,  2.22s/it]progress:  44%|[34m     [0m| 22/50 [00:50<01:01,  2.21s/it]                                                         Episode 23	 reward: -4.56	 makespan: 451.55	 Mean_loss: 0.45306167,  training time: 2.17
progress:  44%|[34m     [0m| 22/50 [00:53<01:01,  2.21s/it]progress:  46%|[34m     [0m| 23/50 [00:53<00:59,  2.20s/it]                                                         Episode 24	 reward: -4.72	 makespan: 466.95	 Mean_loss: -0.03918891,  training time: 2.30
progress:  46%|[34m     [0m| 23/50 [00:55<00:59,  2.20s/it]progress:  48%|[34m     [0m| 24/50 [00:55<00:58,  2.23s/it]                                                         Episode 25	 reward: -4.77	 makespan: 472.65	 Mean_loss: 0.27782720,  training time: 2.20
progress:  48%|[34m     [0m| 24/50 [00:57<00:58,  2.23s/it]progress:  50%|[34m     [0m| 25/50 [00:57<00:55,  2.22s/it]                                                         Episode 26	 reward: -4.69	 makespan: 464.35	 Mean_loss: -0.19979939,  training time: 2.25
progress:  50%|[34m     [0m| 25/50 [00:59<00:55,  2.22s/it]progress:  52%|[34m    [0m| 26/50 [00:59<00:53,  2.23s/it]                                                         Episode 27	 reward: -4.46	 makespan: 441.35	 Mean_loss: -0.02234807,  training time: 2.20
progress:  52%|[34m    [0m| 26/50 [01:02<00:53,  2.23s/it]progress:  54%|[34m    [0m| 27/50 [01:02<00:51,  2.22s/it]                                                         Episode 28	 reward: -4.66	 makespan: 461.00	 Mean_loss: -0.11906889,  training time: 2.26
progress:  54%|[34m    [0m| 27/50 [01:04<00:51,  2.22s/it]progress:  56%|[34m    [0m| 28/50 [01:04<00:49,  2.24s/it]                                                         Episode 29	 reward: -4.52	 makespan: 447.80	 Mean_loss: 0.68120074,  training time: 2.23
progress:  56%|[34m    [0m| 28/50 [01:06<00:49,  2.24s/it]progress:  58%|[34m    [0m| 29/50 [01:06<00:46,  2.24s/it]                                                         Episode 30	 reward: -4.56	 makespan: 451.40	 Mean_loss: 0.64380878,  training time: 2.27
progress:  58%|[34m    [0m| 29/50 [01:08<00:46,  2.24s/it]progress:  60%|[34m    [0m| 30/50 [01:08<00:44,  2.25s/it]                                                         Episode 31	 reward: -4.55	 makespan: 450.65	 Mean_loss: 0.03434493,  training time: 2.23
progress:  60%|[34m    [0m| 30/50 [01:11<00:44,  2.25s/it]progress:  62%|[34m   [0m| 31/50 [01:11<00:42,  2.24s/it]                                                         Episode 32	 reward: -4.76	 makespan: 470.75	 Mean_loss: 0.24391228,  training time: 2.26
progress:  62%|[34m   [0m| 31/50 [01:13<00:42,  2.24s/it]progress:  64%|[34m   [0m| 32/50 [01:13<00:40,  2.25s/it]                                                         Episode 33	 reward: -4.67	 makespan: 462.15	 Mean_loss: 0.23129749,  training time: 2.21
progress:  64%|[34m   [0m| 32/50 [01:15<00:40,  2.25s/it]progress:  66%|[34m   [0m| 33/50 [01:15<00:38,  2.24s/it]                                                         Episode 34	 reward: -4.49	 makespan: 444.45	 Mean_loss: -0.22533979,  training time: 2.33
progress:  66%|[34m   [0m| 33/50 [01:17<00:38,  2.24s/it]progress:  68%|[34m   [0m| 34/50 [01:17<00:36,  2.27s/it]                                                         Episode 35	 reward: -4.62	 makespan: 456.90	 Mean_loss: -0.21540028,  training time: 2.37
progress:  68%|[34m   [0m| 34/50 [01:20<00:36,  2.27s/it]progress:  70%|[34m   [0m| 35/50 [01:20<00:34,  2.30s/it]                                                         Episode 36	 reward: -4.72	 makespan: 467.55	 Mean_loss: -0.00557612,  training time: 2.39
progress:  70%|[34m   [0m| 35/50 [01:22<00:34,  2.30s/it]progress:  72%|[34m  [0m| 36/50 [01:22<00:32,  2.33s/it]                                                         Episode 37	 reward: -4.51	 makespan: 446.75	 Mean_loss: -0.49378282,  training time: 2.29
progress:  72%|[34m  [0m| 36/50 [01:24<00:32,  2.33s/it]progress:  74%|[34m  [0m| 37/50 [01:24<00:30,  2.32s/it]                                                         Episode 38	 reward: -4.55	 makespan: 450.90	 Mean_loss: 0.25146696,  training time: 2.27
progress:  74%|[34m  [0m| 37/50 [01:27<00:30,  2.32s/it]progress:  76%|[34m  [0m| 38/50 [01:27<00:27,  2.31s/it]                                                         Episode 39	 reward: -4.57	 makespan: 452.65	 Mean_loss: 0.46616560,  training time: 2.32
progress:  76%|[34m  [0m| 38/50 [01:29<00:27,  2.31s/it]progress:  78%|[34m  [0m| 39/50 [01:29<00:25,  2.31s/it]                                                         Episode 40	 reward: -4.62	 makespan: 457.25	 Mean_loss: 0.34364510,  training time: 2.19
progress:  78%|[34m  [0m| 39/50 [01:31<00:25,  2.31s/it]progress:  80%|[34m  [0m| 40/50 [01:31<00:22,  2.28s/it]                                                         Episode 41	 reward: -4.63	 makespan: 458.75	 Mean_loss: 0.40028805,  training time: 2.25
progress:  80%|[34m  [0m| 40/50 [01:34<00:22,  2.28s/it]progress:  82%|[34m [0m| 41/50 [01:34<00:20,  2.27s/it]                                                         Episode 42	 reward: -4.54	 makespan: 449.75	 Mean_loss: 0.28653660,  training time: 2.20
progress:  82%|[34m [0m| 41/50 [01:36<00:20,  2.27s/it]progress:  84%|[34m [0m| 42/50 [01:36<00:18,  2.25s/it]                                                         Episode 43	 reward: -4.67	 makespan: 462.75	 Mean_loss: -0.01985340,  training time: 2.17
progress:  84%|[34m [0m| 42/50 [01:38<00:18,  2.25s/it]progress:  86%|[34m [0m| 43/50 [01:38<00:15,  2.23s/it]                                                         Episode 44	 reward: -4.61	 makespan: 456.40	 Mean_loss: 0.58551168,  training time: 2.19
progress:  86%|[34m [0m| 43/50 [01:40<00:15,  2.23s/it]progress:  88%|[34m [0m| 44/50 [01:40<00:13,  2.22s/it]                                                         Episode 45	 reward: -4.66	 makespan: 461.45	 Mean_loss: 0.10545141,  training time: 2.25
progress:  88%|[34m [0m| 44/50 [01:42<00:13,  2.22s/it]progress:  90%|[34m [0m| 45/50 [01:42<00:11,  2.23s/it]                                                         Episode 46	 reward: -4.64	 makespan: 459.65	 Mean_loss: 0.43276891,  training time: 2.19
progress:  90%|[34m [0m| 45/50 [01:45<00:11,  2.23s/it]progress:  92%|[34m[0m| 46/50 [01:45<00:08,  2.22s/it]                                                         Episode 47	 reward: -4.59	 makespan: 454.30	 Mean_loss: -0.12167252,  training time: 2.31
progress:  92%|[34m[0m| 46/50 [01:47<00:08,  2.22s/it]progress:  94%|[34m[0m| 47/50 [01:47<00:06,  2.25s/it]                                                         Episode 48	 reward: -4.58	 makespan: 453.55	 Mean_loss: -0.19704494,  training time: 2.29
progress:  94%|[34m[0m| 47/50 [01:49<00:06,  2.25s/it]progress:  96%|[34m[0m| 48/50 [01:49<00:04,  2.26s/it]                                                         Episode 49	 reward: -4.65	 makespan: 459.90	 Mean_loss: -0.43610567,  training time: 2.31
progress:  96%|[34m[0m| 48/50 [01:51<00:04,  2.26s/it]progress:  98%|[34m[0m| 49/50 [01:51<00:02,  2.28s/it]                                                         Episode 50	 reward: -4.77	 makespan: 472.40	 Mean_loss: -0.12082427,  training time: 2.38
progress:  98%|[34m[0m| 49/50 [01:54<00:02,  2.28s/it]progress: 100%|[34m[0m| 50/50 [01:54<00:00,  2.31s/it]progress: 100%|[34m[0m| 50/50 [01:54<00:00,  2.29s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x10_10 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -6.29	 makespan: 622.70	 Mean_loss: 0.35851765,  training time: 4.36
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:34,  4.37s/it]                                                        Episode 2	 reward: -6.49	 makespan: 642.60	 Mean_loss: 0.24610268,  training time: 3.20
progress:   2%|[34m         [0m| 1/50 [00:07<03:34,  4.37s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:57,  3.69s/it]                                                        Episode 3	 reward: -6.43	 makespan: 636.90	 Mean_loss: 0.24124137,  training time: 3.17
progress:   4%|[34m         [0m| 2/50 [00:10<02:57,  3.69s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:42,  3.46s/it]                                                        Episode 4	 reward: -6.44	 makespan: 637.80	 Mean_loss: 0.16555265,  training time: 3.11
progress:   6%|[34m         [0m| 3/50 [00:13<02:42,  3.46s/it]progress:   8%|[34m         [0m| 4/50 [00:13<02:32,  3.32s/it]                                                        Episode 5	 reward: -6.32	 makespan: 625.85	 Mean_loss: 0.12391184,  training time: 3.11
progress:   8%|[34m         [0m| 4/50 [00:17<02:32,  3.32s/it]progress:  10%|[34m         [0m| 5/50 [00:17<02:26,  3.25s/it]                                                        Episode 6	 reward: -6.27	 makespan: 620.85	 Mean_loss: 0.10301525,  training time: 3.19
progress:  10%|[34m         [0m| 5/50 [00:20<02:26,  3.25s/it]progress:  12%|[34m        [0m| 6/50 [00:20<02:22,  3.23s/it]                                                        Episode 7	 reward: -6.33	 makespan: 626.80	 Mean_loss: 0.10117758,  training time: 3.10
progress:  12%|[34m        [0m| 6/50 [00:23<02:22,  3.23s/it]progress:  14%|[34m        [0m| 7/50 [00:23<02:17,  3.19s/it]                                                        Episode 8	 reward: -6.29	 makespan: 623.00	 Mean_loss: 0.09700620,  training time: 3.11
progress:  14%|[34m        [0m| 7/50 [00:26<02:17,  3.19s/it]progress:  16%|[34m        [0m| 8/50 [00:26<02:13,  3.17s/it]                                                        Episode 9	 reward: -6.48	 makespan: 641.25	 Mean_loss: 0.08481760,  training time: 3.10
progress:  16%|[34m        [0m| 8/50 [00:29<02:13,  3.17s/it]progress:  18%|[34m        [0m| 9/50 [00:29<02:09,  3.15s/it]                                                        Episode 10	 reward: -6.33	 makespan: 626.50	 Mean_loss: 0.08458344,  training time: 3.11
progress:  18%|[34m        [0m| 9/50 [00:32<02:09,  3.15s/it]progress:  20%|[34m        [0m| 10/50 [00:32<02:05,  3.14s/it]                                                         Episode 11	 reward: -6.38	 makespan: 631.70	 Mean_loss: 0.08203402,  training time: 3.18
progress:  20%|[34m        [0m| 10/50 [00:35<02:05,  3.14s/it]progress:  22%|[34m       [0m| 11/50 [00:35<02:03,  3.16s/it]                                                         Episode 12	 reward: -6.29	 makespan: 622.55	 Mean_loss: 0.08456443,  training time: 3.17
progress:  22%|[34m       [0m| 11/50 [00:39<02:03,  3.16s/it]progress:  24%|[34m       [0m| 12/50 [00:39<02:00,  3.16s/it]                                                         Episode 13	 reward: -6.36	 makespan: 629.45	 Mean_loss: 0.07978047,  training time: 3.14
progress:  24%|[34m       [0m| 12/50 [00:42<02:00,  3.16s/it]progress:  26%|[34m       [0m| 13/50 [00:42<01:56,  3.16s/it]                                                         Episode 14	 reward: -6.43	 makespan: 637.05	 Mean_loss: 0.07321629,  training time: 3.22
progress:  26%|[34m       [0m| 13/50 [00:45<01:56,  3.16s/it]progress:  28%|[34m       [0m| 14/50 [00:45<01:54,  3.18s/it]                                                         Episode 15	 reward: -6.41	 makespan: 634.40	 Mean_loss: 0.08325408,  training time: 3.17
progress:  28%|[34m       [0m| 14/50 [00:48<01:54,  3.18s/it]progress:  30%|[34m       [0m| 15/50 [00:48<01:51,  3.18s/it]                                                         Episode 16	 reward: -6.44	 makespan: 637.75	 Mean_loss: 0.07820453,  training time: 3.14
progress:  30%|[34m       [0m| 15/50 [00:51<01:51,  3.18s/it]progress:  32%|[34m      [0m| 16/50 [00:51<01:47,  3.17s/it]                                                         Episode 17	 reward: -6.41	 makespan: 634.70	 Mean_loss: 0.08258715,  training time: 3.12
progress:  32%|[34m      [0m| 16/50 [00:54<01:47,  3.17s/it]progress:  34%|[34m      [0m| 17/50 [00:54<01:44,  3.16s/it]                                                         Episode 18	 reward: -6.49	 makespan: 642.75	 Mean_loss: 0.07134680,  training time: 3.23
progress:  34%|[34m      [0m| 17/50 [00:58<01:44,  3.16s/it]progress:  36%|[34m      [0m| 18/50 [00:58<01:41,  3.18s/it]                                                         Episode 19	 reward: -6.43	 makespan: 636.55	 Mean_loss: 0.10751015,  training time: 3.27
progress:  36%|[34m      [0m| 18/50 [01:01<01:41,  3.18s/it]progress:  38%|[34m      [0m| 19/50 [01:01<01:39,  3.21s/it]                                                         Episode 20	 reward: -6.48	 makespan: 641.05	 Mean_loss: 0.08846735,  training time: 3.20
progress:  38%|[34m      [0m| 19/50 [01:04<01:39,  3.21s/it]progress:  40%|[34m      [0m| 20/50 [01:04<01:36,  3.21s/it]                                                         Episode 21	 reward: -6.40	 makespan: 634.00	 Mean_loss: 0.08883826,  training time: 3.08
progress:  40%|[34m      [0m| 20/50 [01:07<01:36,  3.21s/it]progress:  42%|[34m     [0m| 21/50 [01:07<01:32,  3.17s/it]                                                         Episode 22	 reward: -6.21	 makespan: 615.20	 Mean_loss: 0.08056246,  training time: 3.09
progress:  42%|[34m     [0m| 21/50 [01:10<01:32,  3.17s/it]progress:  44%|[34m     [0m| 22/50 [01:10<01:28,  3.15s/it]                                                         Episode 23	 reward: -6.45	 makespan: 638.70	 Mean_loss: 0.08669691,  training time: 3.08
progress:  44%|[34m     [0m| 22/50 [01:13<01:28,  3.15s/it]progress:  46%|[34m     [0m| 23/50 [01:13<01:24,  3.13s/it]                                                         Episode 24	 reward: -6.43	 makespan: 636.65	 Mean_loss: 0.08912671,  training time: 3.08
progress:  46%|[34m     [0m| 23/50 [01:16<01:24,  3.13s/it]progress:  48%|[34m     [0m| 24/50 [01:16<01:21,  3.12s/it]                                                         Episode 25	 reward: -6.42	 makespan: 635.30	 Mean_loss: 0.06210934,  training time: 3.10
progress:  48%|[34m     [0m| 24/50 [01:20<01:21,  3.12s/it]progress:  50%|[34m     [0m| 25/50 [01:20<01:17,  3.12s/it]                                                         Episode 26	 reward: -6.35	 makespan: 628.45	 Mean_loss: 0.09238759,  training time: 3.14
progress:  50%|[34m     [0m| 25/50 [01:23<01:17,  3.12s/it]progress:  52%|[34m    [0m| 26/50 [01:23<01:15,  3.13s/it]                                                         Episode 27	 reward: -6.27	 makespan: 620.25	 Mean_loss: 0.06568231,  training time: 3.15
progress:  52%|[34m    [0m| 26/50 [01:26<01:15,  3.13s/it]progress:  54%|[34m    [0m| 27/50 [01:26<01:12,  3.14s/it]                                                         Episode 28	 reward: -6.30	 makespan: 623.80	 Mean_loss: 0.07083026,  training time: 3.17
progress:  54%|[34m    [0m| 27/50 [01:29<01:12,  3.14s/it]progress:  56%|[34m    [0m| 28/50 [01:29<01:09,  3.15s/it]                                                         Episode 29	 reward: -6.20	 makespan: 613.65	 Mean_loss: 0.07076664,  training time: 3.10
progress:  56%|[34m    [0m| 28/50 [01:32<01:09,  3.15s/it]progress:  58%|[34m    [0m| 29/50 [01:32<01:05,  3.14s/it]                                                         Episode 30	 reward: -6.32	 makespan: 626.00	 Mean_loss: 0.07156794,  training time: 3.13
progress:  58%|[34m    [0m| 29/50 [01:35<01:05,  3.14s/it]progress:  60%|[34m    [0m| 30/50 [01:35<01:02,  3.14s/it]                                                         Episode 31	 reward: -6.34	 makespan: 627.95	 Mean_loss: 0.07662252,  training time: 3.07
progress:  60%|[34m    [0m| 30/50 [01:38<01:02,  3.14s/it]progress:  62%|[34m   [0m| 31/50 [01:38<00:59,  3.12s/it]                                                         Episode 32	 reward: -6.20	 makespan: 613.95	 Mean_loss: 0.07864942,  training time: 3.10
progress:  62%|[34m   [0m| 31/50 [01:41<00:59,  3.12s/it]progress:  64%|[34m   [0m| 32/50 [01:42<00:56,  3.12s/it]                                                         Episode 33	 reward: -6.35	 makespan: 628.50	 Mean_loss: 0.07348726,  training time: 3.11
progress:  64%|[34m   [0m| 32/50 [01:45<00:56,  3.12s/it]progress:  66%|[34m   [0m| 33/50 [01:45<00:52,  3.12s/it]                                                         Episode 34	 reward: -6.26	 makespan: 619.25	 Mean_loss: 0.05787044,  training time: 3.15
progress:  66%|[34m   [0m| 33/50 [01:48<00:52,  3.12s/it]progress:  68%|[34m   [0m| 34/50 [01:48<00:50,  3.13s/it]                                                         Episode 35	 reward: -6.38	 makespan: 631.65	 Mean_loss: 0.05295930,  training time: 3.08
progress:  68%|[34m   [0m| 34/50 [01:51<00:50,  3.13s/it]progress:  70%|[34m   [0m| 35/50 [01:51<00:46,  3.12s/it]                                                         Episode 36	 reward: -6.21	 makespan: 615.05	 Mean_loss: 0.05216711,  training time: 3.16
progress:  70%|[34m   [0m| 35/50 [01:54<00:46,  3.12s/it]progress:  72%|[34m  [0m| 36/50 [01:54<00:43,  3.13s/it]                                                         Episode 37	 reward: -6.15	 makespan: 609.15	 Mean_loss: 0.06662002,  training time: 3.10
progress:  72%|[34m  [0m| 36/50 [01:57<00:43,  3.13s/it]progress:  74%|[34m  [0m| 37/50 [01:57<00:40,  3.12s/it]                                                         Episode 38	 reward: -6.24	 makespan: 617.55	 Mean_loss: 0.06842391,  training time: 3.09
progress:  74%|[34m  [0m| 37/50 [02:00<00:40,  3.12s/it]progress:  76%|[34m  [0m| 38/50 [02:00<00:37,  3.12s/it]                                                         Episode 39	 reward: -6.15	 makespan: 608.90	 Mean_loss: 0.06404281,  training time: 3.11
progress:  76%|[34m  [0m| 38/50 [02:03<00:37,  3.12s/it]progress:  78%|[34m  [0m| 39/50 [02:03<00:34,  3.12s/it]                                                         Episode 40	 reward: -6.19	 makespan: 612.40	 Mean_loss: 0.05857334,  training time: 3.14
progress:  78%|[34m  [0m| 39/50 [02:06<00:34,  3.12s/it]progress:  80%|[34m  [0m| 40/50 [02:06<00:31,  3.12s/it]                                                         Episode 41	 reward: -6.23	 makespan: 616.95	 Mean_loss: 0.05675112,  training time: 3.08
progress:  80%|[34m  [0m| 40/50 [02:10<00:31,  3.12s/it]progress:  82%|[34m [0m| 41/50 [02:10<00:28,  3.11s/it]                                                         Episode 42	 reward: -6.26	 makespan: 619.55	 Mean_loss: 0.05701452,  training time: 3.15
progress:  82%|[34m [0m| 41/50 [02:13<00:28,  3.11s/it]progress:  84%|[34m [0m| 42/50 [02:13<00:25,  3.13s/it]                                                         Episode 43	 reward: -6.26	 makespan: 619.90	 Mean_loss: 0.06505607,  training time: 3.14
progress:  84%|[34m [0m| 42/50 [02:16<00:25,  3.13s/it]progress:  86%|[34m [0m| 43/50 [02:16<00:21,  3.13s/it]                                                         Episode 44	 reward: -6.24	 makespan: 617.75	 Mean_loss: 0.06762681,  training time: 3.08
progress:  86%|[34m [0m| 43/50 [02:19<00:21,  3.13s/it]progress:  88%|[34m [0m| 44/50 [02:19<00:18,  3.12s/it]                                                         Episode 45	 reward: -6.23	 makespan: 616.40	 Mean_loss: 0.06869245,  training time: 3.15
progress:  88%|[34m [0m| 44/50 [02:22<00:18,  3.12s/it]progress:  90%|[34m [0m| 45/50 [02:22<00:15,  3.13s/it]                                                         Episode 46	 reward: -6.22	 makespan: 615.85	 Mean_loss: 0.05863534,  training time: 3.18
progress:  90%|[34m [0m| 45/50 [02:25<00:15,  3.13s/it]progress:  92%|[34m[0m| 46/50 [02:25<00:12,  3.15s/it]                                                         Episode 47	 reward: -6.28	 makespan: 622.05	 Mean_loss: 0.08924095,  training time: 3.15
progress:  92%|[34m[0m| 46/50 [02:28<00:12,  3.15s/it]progress:  94%|[34m[0m| 47/50 [02:28<00:09,  3.15s/it]                                                         Episode 48	 reward: -6.18	 makespan: 611.95	 Mean_loss: 0.06741000,  training time: 3.17
progress:  94%|[34m[0m| 47/50 [02:32<00:09,  3.15s/it]progress:  96%|[34m[0m| 48/50 [02:32<00:06,  3.16s/it]                                                         Episode 49	 reward: -6.34	 makespan: 627.45	 Mean_loss: 0.06609339,  training time: 3.11
progress:  96%|[34m[0m| 48/50 [02:35<00:06,  3.16s/it]progress:  98%|[34m[0m| 49/50 [02:35<00:03,  3.15s/it]                                                         Episode 50	 reward: -6.21	 makespan: 614.50	 Mean_loss: 0.08972041,  training time: 3.17
progress:  98%|[34m[0m| 49/50 [02:38<00:03,  3.15s/it]progress: 100%|[34m[0m| 50/50 [02:38<00:00,  3.16s/it]progress: 100%|[34m[0m| 50/50 [02:38<00:00,  3.17s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x10_12 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 10 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x10+mix
save model name:  15x10+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x10+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.78	 makespan: 769.85	 Mean_loss: 0.39545327,  training time: 5.21
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:15,  5.21s/it]                                                        Episode 2	 reward: -7.70	 makespan: 762.55	 Mean_loss: 0.21761513,  training time: 3.97
progress:   2%|[34m         [0m| 1/50 [00:09<04:15,  5.21s/it]progress:   4%|[34m         [0m| 2/50 [00:09<03:35,  4.49s/it]                                                        Episode 3	 reward: -7.72	 makespan: 764.40	 Mean_loss: 0.18027139,  training time: 4.05
progress:   4%|[34m         [0m| 2/50 [00:13<03:35,  4.49s/it]progress:   6%|[34m         [0m| 3/50 [00:13<03:21,  4.29s/it]                                                        Episode 4	 reward: -7.73	 makespan: 764.80	 Mean_loss: 0.19075602,  training time: 4.05
progress:   6%|[34m         [0m| 3/50 [00:17<03:21,  4.29s/it]progress:   8%|[34m         [0m| 4/50 [00:17<03:13,  4.20s/it]                                                        Episode 5	 reward: -7.64	 makespan: 756.40	 Mean_loss: 0.15365128,  training time: 4.18
progress:   8%|[34m         [0m| 4/50 [00:21<03:13,  4.20s/it]progress:  10%|[34m         [0m| 5/50 [00:21<03:08,  4.19s/it]                                                        Episode 6	 reward: -7.70	 makespan: 762.15	 Mean_loss: 0.14720023,  training time: 4.08
progress:  10%|[34m         [0m| 5/50 [00:25<03:08,  4.19s/it]progress:  12%|[34m        [0m| 6/50 [00:25<03:02,  4.16s/it]                                                        Episode 7	 reward: -7.71	 makespan: 763.05	 Mean_loss: 0.13640268,  training time: 3.98
progress:  12%|[34m        [0m| 6/50 [00:29<03:02,  4.16s/it]progress:  14%|[34m        [0m| 7/50 [00:29<02:56,  4.10s/it]                                                        Episode 8	 reward: -7.78	 makespan: 769.85	 Mean_loss: 0.12876248,  training time: 4.20
progress:  14%|[34m        [0m| 7/50 [00:33<02:56,  4.10s/it]progress:  16%|[34m        [0m| 8/50 [00:33<02:53,  4.14s/it]                                                        Episode 9	 reward: -7.61	 makespan: 753.25	 Mean_loss: 0.08041436,  training time: 3.98
progress:  16%|[34m        [0m| 8/50 [00:37<02:53,  4.14s/it]progress:  18%|[34m        [0m| 9/50 [00:37<02:47,  4.09s/it]                                                        Episode 10	 reward: -7.68	 makespan: 759.85	 Mean_loss: 0.13292047,  training time: 4.17
progress:  18%|[34m        [0m| 9/50 [00:41<02:47,  4.09s/it]progress:  20%|[34m        [0m| 10/50 [00:41<02:44,  4.12s/it]                                                         Episode 11	 reward: -7.55	 makespan: 747.65	 Mean_loss: 0.10332204,  training time: 3.99
progress:  20%|[34m        [0m| 10/50 [00:45<02:44,  4.12s/it]progress:  22%|[34m       [0m| 11/50 [00:45<02:39,  4.08s/it]                                                         Episode 12	 reward: -7.65	 makespan: 757.30	 Mean_loss: 0.10794529,  training time: 3.98
progress:  22%|[34m       [0m| 11/50 [00:49<02:39,  4.08s/it]progress:  24%|[34m       [0m| 12/50 [00:49<02:34,  4.06s/it]                                                         Episode 13	 reward: -7.79	 makespan: 770.95	 Mean_loss: 0.14068440,  training time: 3.95
progress:  24%|[34m       [0m| 12/50 [00:53<02:34,  4.06s/it]progress:  26%|[34m       [0m| 13/50 [00:53<02:29,  4.03s/it]                                                         Episode 14	 reward: -7.60	 makespan: 752.50	 Mean_loss: 0.11163768,  training time: 3.95
progress:  26%|[34m       [0m| 13/50 [00:57<02:29,  4.03s/it]progress:  28%|[34m       [0m| 14/50 [00:57<02:24,  4.01s/it]                                                         Episode 15	 reward: -7.55	 makespan: 747.75	 Mean_loss: 0.12023350,  training time: 4.02
progress:  28%|[34m       [0m| 14/50 [01:01<02:24,  4.01s/it]progress:  30%|[34m       [0m| 15/50 [01:01<02:20,  4.01s/it]                                                         Episode 16	 reward: -7.55	 makespan: 747.65	 Mean_loss: 0.08969085,  training time: 4.01
progress:  30%|[34m       [0m| 15/50 [01:05<02:20,  4.01s/it]progress:  32%|[34m      [0m| 16/50 [01:05<02:16,  4.01s/it]                                                         Episode 17	 reward: -7.56	 makespan: 748.15	 Mean_loss: 0.09428818,  training time: 3.98
progress:  32%|[34m      [0m| 16/50 [01:09<02:16,  4.01s/it]progress:  34%|[34m      [0m| 17/50 [01:09<02:12,  4.01s/it]                                                         Episode 18	 reward: -7.57	 makespan: 749.65	 Mean_loss: 0.09422833,  training time: 3.95
progress:  34%|[34m      [0m| 17/50 [01:13<02:12,  4.01s/it]progress:  36%|[34m      [0m| 18/50 [01:13<02:07,  3.99s/it]                                                         Episode 19	 reward: -7.56	 makespan: 748.30	 Mean_loss: 0.09748895,  training time: 4.02
progress:  36%|[34m      [0m| 18/50 [01:17<02:07,  3.99s/it]progress:  38%|[34m      [0m| 19/50 [01:17<02:04,  4.00s/it]                                                         Episode 20	 reward: -7.60	 makespan: 752.20	 Mean_loss: 0.10311366,  training time: 3.95
progress:  38%|[34m      [0m| 19/50 [01:21<02:04,  4.00s/it]progress:  40%|[34m      [0m| 20/50 [01:21<01:59,  3.99s/it]                                                         Episode 21	 reward: -7.48	 makespan: 740.95	 Mean_loss: 0.08619540,  training time: 4.00
progress:  40%|[34m      [0m| 20/50 [01:25<01:59,  3.99s/it]progress:  42%|[34m     [0m| 21/50 [01:25<01:55,  3.99s/it]                                                         Episode 22	 reward: -7.54	 makespan: 746.05	 Mean_loss: 0.08200756,  training time: 3.96
progress:  42%|[34m     [0m| 21/50 [01:29<01:55,  3.99s/it]progress:  44%|[34m     [0m| 22/50 [01:29<01:51,  3.99s/it]                                                         Episode 23	 reward: -7.65	 makespan: 757.20	 Mean_loss: 0.11284269,  training time: 4.05
progress:  44%|[34m     [0m| 22/50 [01:33<01:51,  3.99s/it]progress:  46%|[34m     [0m| 23/50 [01:33<01:48,  4.01s/it]                                                         Episode 24	 reward: -7.65	 makespan: 756.95	 Mean_loss: 0.11444283,  training time: 4.04
progress:  46%|[34m     [0m| 23/50 [01:37<01:48,  4.01s/it]progress:  48%|[34m     [0m| 24/50 [01:37<01:44,  4.02s/it]                                                         Episode 25	 reward: -7.64	 makespan: 756.15	 Mean_loss: 0.09629080,  training time: 3.96
progress:  48%|[34m     [0m| 24/50 [01:41<01:44,  4.02s/it]progress:  50%|[34m     [0m| 25/50 [01:41<01:40,  4.00s/it]                                                         Episode 26	 reward: -7.69	 makespan: 761.05	 Mean_loss: 0.09593759,  training time: 3.98
progress:  50%|[34m     [0m| 25/50 [01:45<01:40,  4.00s/it]progress:  52%|[34m    [0m| 26/50 [01:45<01:35,  4.00s/it]                                                         Episode 27	 reward: -7.54	 makespan: 746.25	 Mean_loss: 0.11133614,  training time: 3.94
progress:  52%|[34m    [0m| 26/50 [01:49<01:35,  4.00s/it]progress:  54%|[34m    [0m| 27/50 [01:49<01:31,  3.98s/it]                                                         Episode 28	 reward: -7.62	 makespan: 754.40	 Mean_loss: 0.09136828,  training time: 3.99
progress:  54%|[34m    [0m| 27/50 [01:53<01:31,  3.98s/it]progress:  56%|[34m    [0m| 28/50 [01:53<01:27,  3.99s/it]                                                         Episode 29	 reward: -7.63	 makespan: 755.15	 Mean_loss: 0.12132603,  training time: 3.97
progress:  56%|[34m    [0m| 28/50 [01:57<01:27,  3.99s/it]progress:  58%|[34m    [0m| 29/50 [01:57<01:23,  3.99s/it]                                                         Episode 30	 reward: -7.58	 makespan: 750.65	 Mean_loss: 0.08006673,  training time: 4.01
progress:  58%|[34m    [0m| 29/50 [02:01<01:23,  3.99s/it]progress:  60%|[34m    [0m| 30/50 [02:01<01:19,  4.00s/it]                                                         Episode 31	 reward: -7.59	 makespan: 751.20	 Mean_loss: 0.08074690,  training time: 3.99
progress:  60%|[34m    [0m| 30/50 [02:05<01:19,  4.00s/it]progress:  62%|[34m   [0m| 31/50 [02:05<01:15,  4.00s/it]                                                         Episode 32	 reward: -7.57	 makespan: 749.45	 Mean_loss: 0.07601205,  training time: 4.05
progress:  62%|[34m   [0m| 31/50 [02:09<01:15,  4.00s/it]progress:  64%|[34m   [0m| 32/50 [02:09<01:12,  4.02s/it]                                                         Episode 33	 reward: -7.52	 makespan: 744.20	 Mean_loss: 0.08470632,  training time: 3.98
progress:  64%|[34m   [0m| 32/50 [02:13<01:12,  4.02s/it]progress:  66%|[34m   [0m| 33/50 [02:13<01:08,  4.01s/it]                                                         Episode 34	 reward: -7.47	 makespan: 739.55	 Mean_loss: 0.08975885,  training time: 4.11
progress:  66%|[34m   [0m| 33/50 [02:17<01:08,  4.01s/it]progress:  68%|[34m   [0m| 34/50 [02:17<01:04,  4.04s/it]                                                         Episode 35	 reward: -7.52	 makespan: 744.00	 Mean_loss: 0.08174709,  training time: 3.93
progress:  68%|[34m   [0m| 34/50 [02:21<01:04,  4.04s/it]progress:  70%|[34m   [0m| 35/50 [02:21<01:00,  4.01s/it]                                                         Episode 36	 reward: -7.62	 makespan: 754.65	 Mean_loss: 0.08661376,  training time: 4.02
progress:  70%|[34m   [0m| 35/50 [02:25<01:00,  4.01s/it]progress:  72%|[34m  [0m| 36/50 [02:25<00:56,  4.02s/it]                                                         Episode 37	 reward: -7.58	 makespan: 750.65	 Mean_loss: 0.07398193,  training time: 3.96
progress:  72%|[34m  [0m| 36/50 [02:29<00:56,  4.02s/it]progress:  74%|[34m  [0m| 37/50 [02:29<00:52,  4.00s/it]                                                         Episode 38	 reward: -7.56	 makespan: 748.55	 Mean_loss: 0.08721951,  training time: 3.98
progress:  74%|[34m  [0m| 37/50 [02:33<00:52,  4.00s/it]progress:  76%|[34m  [0m| 38/50 [02:33<00:47,  4.00s/it]                                                         Episode 39	 reward: -7.34	 makespan: 727.00	 Mean_loss: 0.07762554,  training time: 4.10
progress:  76%|[34m  [0m| 38/50 [02:38<00:47,  4.00s/it]progress:  78%|[34m  [0m| 39/50 [02:38<00:44,  4.03s/it]                                                         Episode 40	 reward: -7.62	 makespan: 754.10	 Mean_loss: 0.10108012,  training time: 3.93
progress:  78%|[34m  [0m| 39/50 [02:41<00:44,  4.03s/it]progress:  80%|[34m  [0m| 40/50 [02:41<00:40,  4.00s/it]                                                         Episode 41	 reward: -7.47	 makespan: 739.50	 Mean_loss: 0.07647762,  training time: 3.96
progress:  80%|[34m  [0m| 40/50 [02:45<00:40,  4.00s/it]progress:  82%|[34m [0m| 41/50 [02:45<00:35,  3.99s/it]                                                         Episode 42	 reward: -7.53	 makespan: 745.50	 Mean_loss: 0.06674301,  training time: 3.95
progress:  82%|[34m [0m| 41/50 [02:49<00:35,  3.99s/it]progress:  84%|[34m [0m| 42/50 [02:49<00:31,  3.99s/it]                                                         Episode 43	 reward: -7.45	 makespan: 737.10	 Mean_loss: 0.07980023,  training time: 3.97
progress:  84%|[34m [0m| 42/50 [02:53<00:31,  3.99s/it]progress:  86%|[34m [0m| 43/50 [02:53<00:27,  3.98s/it]                                                         Episode 44	 reward: -7.46	 makespan: 738.45	 Mean_loss: 0.06362575,  training time: 3.93
progress:  86%|[34m [0m| 43/50 [02:57<00:27,  3.98s/it]progress:  88%|[34m [0m| 44/50 [02:57<00:23,  3.97s/it]                                                         Episode 45	 reward: -7.38	 makespan: 730.45	 Mean_loss: 0.06640783,  training time: 3.96
progress:  88%|[34m [0m| 44/50 [03:01<00:23,  3.97s/it]progress:  90%|[34m [0m| 45/50 [03:01<00:19,  3.97s/it]                                                         Episode 46	 reward: -7.37	 makespan: 729.95	 Mean_loss: 0.08127856,  training time: 4.02
progress:  90%|[34m [0m| 45/50 [03:05<00:19,  3.97s/it]progress:  92%|[34m[0m| 46/50 [03:05<00:15,  3.99s/it]                                                         Episode 47	 reward: -7.41	 makespan: 733.90	 Mean_loss: 0.07952009,  training time: 3.96
progress:  92%|[34m[0m| 46/50 [03:09<00:15,  3.99s/it]progress:  94%|[34m[0m| 47/50 [03:09<00:11,  3.98s/it]                                                         Episode 48	 reward: -7.38	 makespan: 730.65	 Mean_loss: 0.05605115,  training time: 4.09
progress:  94%|[34m[0m| 47/50 [03:13<00:11,  3.98s/it]progress:  96%|[34m[0m| 48/50 [03:13<00:08,  4.02s/it]                                                         Episode 49	 reward: -7.56	 makespan: 748.00	 Mean_loss: 0.09305885,  training time: 4.05
progress:  96%|[34m[0m| 48/50 [03:17<00:08,  4.02s/it]progress:  98%|[34m[0m| 49/50 [03:17<00:04,  4.03s/it]                                                         Episode 50	 reward: -7.42	 makespan: 734.80	 Mean_loss: 0.07504319,  training time: 4.11
progress:  98%|[34m[0m| 49/50 [03:22<00:04,  4.03s/it]progress: 100%|[34m[0m| 50/50 [03:22<00:00,  4.06s/it]progress: 100%|[34m[0m| 50/50 [03:22<00:00,  4.04s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x7_4 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -3.55	 makespan: 351.15	 Mean_loss: 0.49830094,  training time: 2.35
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:55,  2.36s/it]                                                        Episode 2	 reward: -3.55	 makespan: 351.85	 Mean_loss: 0.31254840,  training time: 1.20
progress:   2%|[34m         [0m| 1/50 [00:03<01:55,  2.36s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:20,  1.68s/it]                                                        Episode 3	 reward: -3.64	 makespan: 360.75	 Mean_loss: 0.20062591,  training time: 1.19
progress:   4%|[34m         [0m| 2/50 [00:04<01:20,  1.68s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:08,  1.46s/it]                                                        Episode 4	 reward: -3.49	 makespan: 345.75	 Mean_loss: 0.12238185,  training time: 1.21
progress:   6%|[34m         [0m| 3/50 [00:05<01:08,  1.46s/it]progress:   8%|[34m         [0m| 4/50 [00:05<01:02,  1.36s/it]                                                        Episode 5	 reward: -3.57	 makespan: 353.40	 Mean_loss: 0.09268104,  training time: 1.20
progress:   8%|[34m         [0m| 4/50 [00:07<01:02,  1.36s/it]progress:  10%|[34m         [0m| 5/50 [00:07<00:58,  1.31s/it]                                                        Episode 6	 reward: -3.56	 makespan: 352.80	 Mean_loss: 0.10238817,  training time: 1.22
progress:  10%|[34m         [0m| 5/50 [00:08<00:58,  1.31s/it]progress:  12%|[34m        [0m| 6/50 [00:08<00:56,  1.28s/it]                                                        Episode 7	 reward: -3.51	 makespan: 347.20	 Mean_loss: 0.08402326,  training time: 1.24
progress:  12%|[34m        [0m| 6/50 [00:09<00:56,  1.28s/it]progress:  14%|[34m        [0m| 7/50 [00:09<00:54,  1.27s/it]                                                        Episode 8	 reward: -3.55	 makespan: 351.40	 Mean_loss: 0.09131075,  training time: 1.25
progress:  14%|[34m        [0m| 7/50 [00:10<00:54,  1.27s/it]progress:  16%|[34m        [0m| 8/50 [00:10<00:53,  1.26s/it]                                                        Episode 9	 reward: -3.51	 makespan: 347.50	 Mean_loss: 0.08104557,  training time: 1.23
progress:  16%|[34m        [0m| 8/50 [00:12<00:53,  1.26s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:51,  1.26s/it]                                                        Episode 10	 reward: -3.56	 makespan: 352.20	 Mean_loss: 0.07822904,  training time: 1.19
progress:  18%|[34m        [0m| 9/50 [00:13<00:51,  1.26s/it]progress:  20%|[34m        [0m| 10/50 [00:13<00:49,  1.24s/it]                                                         Episode 11	 reward: -3.60	 makespan: 356.55	 Mean_loss: 0.08184031,  training time: 1.20
progress:  20%|[34m        [0m| 10/50 [00:14<00:49,  1.24s/it]progress:  22%|[34m       [0m| 11/50 [00:14<00:47,  1.23s/it]                                                         Episode 12	 reward: -3.54	 makespan: 350.90	 Mean_loss: 0.08786874,  training time: 1.29
progress:  22%|[34m       [0m| 11/50 [00:15<00:47,  1.23s/it]progress:  24%|[34m       [0m| 12/50 [00:15<00:47,  1.25s/it]                                                         Episode 13	 reward: -3.55	 makespan: 351.50	 Mean_loss: 0.09135258,  training time: 1.21
progress:  24%|[34m       [0m| 12/50 [00:17<00:47,  1.25s/it]progress:  26%|[34m       [0m| 13/50 [00:17<00:45,  1.24s/it]                                                         Episode 14	 reward: -3.57	 makespan: 353.85	 Mean_loss: 0.07831041,  training time: 1.20
progress:  26%|[34m       [0m| 13/50 [00:18<00:45,  1.24s/it]progress:  28%|[34m       [0m| 14/50 [00:18<00:44,  1.23s/it]                                                         Episode 15	 reward: -3.64	 makespan: 360.20	 Mean_loss: 0.09880345,  training time: 1.24
progress:  28%|[34m       [0m| 14/50 [00:19<00:44,  1.23s/it]progress:  30%|[34m       [0m| 15/50 [00:19<00:43,  1.24s/it]                                                         Episode 16	 reward: -3.45	 makespan: 341.90	 Mean_loss: 0.07372335,  training time: 1.27
progress:  30%|[34m       [0m| 15/50 [00:20<00:43,  1.24s/it]progress:  32%|[34m      [0m| 16/50 [00:20<00:42,  1.25s/it]                                                         Episode 17	 reward: -3.55	 makespan: 351.00	 Mean_loss: 0.07619940,  training time: 1.25
progress:  32%|[34m      [0m| 16/50 [00:22<00:42,  1.25s/it]progress:  34%|[34m      [0m| 17/50 [00:22<00:41,  1.25s/it]                                                         Episode 18	 reward: -3.54	 makespan: 350.50	 Mean_loss: 0.07057052,  training time: 1.28
progress:  34%|[34m      [0m| 17/50 [00:23<00:41,  1.25s/it]progress:  36%|[34m      [0m| 18/50 [00:23<00:40,  1.26s/it]                                                         Episode 19	 reward: -3.54	 makespan: 350.30	 Mean_loss: 0.06590745,  training time: 1.19
progress:  36%|[34m      [0m| 18/50 [00:24<00:40,  1.26s/it]progress:  38%|[34m      [0m| 19/50 [00:24<00:38,  1.24s/it]                                                         Episode 20	 reward: -3.46	 makespan: 342.60	 Mean_loss: 0.07560611,  training time: 1.21
progress:  38%|[34m      [0m| 19/50 [00:25<00:38,  1.24s/it]progress:  40%|[34m      [0m| 20/50 [00:25<00:36,  1.23s/it]                                                         Episode 21	 reward: -3.55	 makespan: 351.15	 Mean_loss: 0.08291628,  training time: 1.21
progress:  40%|[34m      [0m| 20/50 [00:26<00:36,  1.23s/it]progress:  42%|[34m     [0m| 21/50 [00:26<00:35,  1.23s/it]                                                         Episode 22	 reward: -3.53	 makespan: 349.85	 Mean_loss: 0.09940089,  training time: 1.19
progress:  42%|[34m     [0m| 21/50 [00:28<00:35,  1.23s/it]progress:  44%|[34m     [0m| 22/50 [00:28<00:34,  1.22s/it]                                                         Episode 23	 reward: -3.57	 makespan: 353.30	 Mean_loss: 0.08495058,  training time: 1.26
progress:  44%|[34m     [0m| 22/50 [00:29<00:34,  1.22s/it]progress:  46%|[34m     [0m| 23/50 [00:29<00:33,  1.23s/it]                                                         Episode 24	 reward: -3.58	 makespan: 354.25	 Mean_loss: 0.06735269,  training time: 1.19
progress:  46%|[34m     [0m| 23/50 [00:30<00:33,  1.23s/it]progress:  48%|[34m     [0m| 24/50 [00:30<00:31,  1.22s/it]                                                         Episode 25	 reward: -3.61	 makespan: 357.70	 Mean_loss: 0.04760348,  training time: 1.28
progress:  48%|[34m     [0m| 24/50 [00:31<00:31,  1.22s/it]progress:  50%|[34m     [0m| 25/50 [00:31<00:30,  1.24s/it]                                                         Episode 26	 reward: -3.59	 makespan: 355.85	 Mean_loss: 0.06235941,  training time: 1.23
progress:  50%|[34m     [0m| 25/50 [00:33<00:30,  1.24s/it]progress:  52%|[34m    [0m| 26/50 [00:33<00:29,  1.24s/it]                                                         Episode 27	 reward: -3.61	 makespan: 357.10	 Mean_loss: 0.11074138,  training time: 1.22
progress:  52%|[34m    [0m| 26/50 [00:34<00:29,  1.24s/it]progress:  54%|[34m    [0m| 27/50 [00:34<00:28,  1.23s/it]                                                         Episode 28	 reward: -3.56	 makespan: 352.65	 Mean_loss: 0.07512575,  training time: 1.19
progress:  54%|[34m    [0m| 27/50 [00:35<00:28,  1.23s/it]progress:  56%|[34m    [0m| 28/50 [00:35<00:26,  1.22s/it]                                                         Episode 29	 reward: -3.52	 makespan: 348.05	 Mean_loss: 0.08962913,  training time: 1.23
progress:  56%|[34m    [0m| 28/50 [00:36<00:26,  1.22s/it]progress:  58%|[34m    [0m| 29/50 [00:36<00:25,  1.23s/it]                                                         Episode 30	 reward: -3.53	 makespan: 349.90	 Mean_loss: 0.06181238,  training time: 1.32
progress:  58%|[34m    [0m| 29/50 [00:38<00:25,  1.23s/it]progress:  60%|[34m    [0m| 30/50 [00:38<00:25,  1.26s/it]                                                         Episode 31	 reward: -3.54	 makespan: 350.40	 Mean_loss: 0.07402223,  training time: 1.22
progress:  60%|[34m    [0m| 30/50 [00:39<00:25,  1.26s/it]progress:  62%|[34m   [0m| 31/50 [00:39<00:23,  1.25s/it]                                                         Episode 32	 reward: -3.51	 makespan: 347.55	 Mean_loss: 0.08890401,  training time: 1.21
progress:  62%|[34m   [0m| 31/50 [00:40<00:23,  1.25s/it]progress:  64%|[34m   [0m| 32/50 [00:40<00:22,  1.24s/it]                                                         Episode 33	 reward: -3.47	 makespan: 343.10	 Mean_loss: 0.09282815,  training time: 1.19
progress:  64%|[34m   [0m| 32/50 [00:41<00:22,  1.24s/it]progress:  66%|[34m   [0m| 33/50 [00:41<00:20,  1.22s/it]                                                         Episode 34	 reward: -3.54	 makespan: 350.45	 Mean_loss: 0.09305474,  training time: 1.17
progress:  66%|[34m   [0m| 33/50 [00:42<00:20,  1.22s/it]progress:  68%|[34m   [0m| 34/50 [00:42<00:19,  1.21s/it]                                                         Episode 35	 reward: -3.52	 makespan: 348.25	 Mean_loss: 0.08028664,  training time: 1.20
progress:  68%|[34m   [0m| 34/50 [00:44<00:19,  1.21s/it]progress:  70%|[34m   [0m| 35/50 [00:44<00:18,  1.21s/it]                                                         Episode 36	 reward: -3.57	 makespan: 353.90	 Mean_loss: 0.06459427,  training time: 1.19
progress:  70%|[34m   [0m| 35/50 [00:45<00:18,  1.21s/it]progress:  72%|[34m  [0m| 36/50 [00:45<00:16,  1.20s/it]                                                         Episode 37	 reward: -3.54	 makespan: 350.45	 Mean_loss: 0.06067216,  training time: 1.27
progress:  72%|[34m  [0m| 36/50 [00:46<00:16,  1.20s/it]progress:  74%|[34m  [0m| 37/50 [00:46<00:15,  1.23s/it]                                                         Episode 38	 reward: -3.51	 makespan: 347.20	 Mean_loss: 0.06792583,  training time: 1.21
progress:  74%|[34m  [0m| 37/50 [00:47<00:15,  1.23s/it]progress:  76%|[34m  [0m| 38/50 [00:47<00:14,  1.22s/it]                                                         Episode 39	 reward: -3.48	 makespan: 344.70	 Mean_loss: 0.06675428,  training time: 1.21
progress:  76%|[34m  [0m| 38/50 [00:49<00:14,  1.22s/it]progress:  78%|[34m  [0m| 39/50 [00:49<00:13,  1.22s/it]                                                         Episode 40	 reward: -3.59	 makespan: 355.25	 Mean_loss: 0.08330759,  training time: 1.22
progress:  78%|[34m  [0m| 39/50 [00:50<00:13,  1.22s/it]progress:  80%|[34m  [0m| 40/50 [00:50<00:12,  1.23s/it]                                                         Episode 41	 reward: -3.57	 makespan: 353.75	 Mean_loss: 0.07363598,  training time: 1.34
progress:  80%|[34m  [0m| 40/50 [00:51<00:12,  1.23s/it]progress:  82%|[34m [0m| 41/50 [00:51<00:11,  1.26s/it]                                                         Episode 42	 reward: -3.45	 makespan: 341.60	 Mean_loss: 0.06690621,  training time: 1.33
progress:  82%|[34m [0m| 41/50 [00:52<00:11,  1.26s/it]progress:  84%|[34m [0m| 42/50 [00:52<00:10,  1.28s/it]                                                         Episode 43	 reward: -3.51	 makespan: 347.50	 Mean_loss: 0.03696444,  training time: 1.20
progress:  84%|[34m [0m| 42/50 [00:54<00:10,  1.28s/it]progress:  86%|[34m [0m| 43/50 [00:54<00:08,  1.26s/it]                                                         Episode 44	 reward: -3.46	 makespan: 342.70	 Mean_loss: 0.03703362,  training time: 1.19
progress:  86%|[34m [0m| 43/50 [00:55<00:08,  1.26s/it]progress:  88%|[34m [0m| 44/50 [00:55<00:07,  1.24s/it]                                                         Episode 45	 reward: -3.48	 makespan: 344.50	 Mean_loss: 0.07926273,  training time: 1.27
progress:  88%|[34m [0m| 44/50 [00:56<00:07,  1.24s/it]progress:  90%|[34m [0m| 45/50 [00:56<00:06,  1.25s/it]                                                         Episode 46	 reward: -3.54	 makespan: 350.40	 Mean_loss: 0.03774420,  training time: 1.21
progress:  90%|[34m [0m| 45/50 [00:57<00:06,  1.25s/it]progress:  92%|[34m[0m| 46/50 [00:57<00:04,  1.24s/it]                                                         Episode 47	 reward: -3.57	 makespan: 353.30	 Mean_loss: 0.07707786,  training time: 1.25
progress:  92%|[34m[0m| 46/50 [00:59<00:04,  1.24s/it]progress:  94%|[34m[0m| 47/50 [00:59<00:03,  1.25s/it]                                                         Episode 48	 reward: -3.50	 makespan: 346.75	 Mean_loss: 0.05683941,  training time: 1.27
progress:  94%|[34m[0m| 47/50 [01:00<00:03,  1.25s/it]progress:  96%|[34m[0m| 48/50 [01:00<00:02,  1.26s/it]                                                         Episode 49	 reward: -3.56	 makespan: 352.15	 Mean_loss: 0.06670254,  training time: 1.28
progress:  96%|[34m[0m| 48/50 [01:01<00:02,  1.26s/it]progress:  98%|[34m[0m| 49/50 [01:01<00:01,  1.26s/it]                                                         Episode 50	 reward: -3.57	 makespan: 353.05	 Mean_loss: 0.07701464,  training time: 1.20
progress:  98%|[34m[0m| 49/50 [01:02<00:01,  1.26s/it]progress: 100%|[34m[0m| 50/50 [01:02<00:00,  1.25s/it]progress: 100%|[34m[0m| 50/50 [01:02<00:00,  1.26s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x7_7 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -5.52	 makespan: 546.90	 Mean_loss: 0.86241400,  training time: 3.36
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:45,  3.37s/it]                                                        Episode 2	 reward: -5.58	 makespan: 551.95	 Mean_loss: 0.67268807,  training time: 2.28
progress:   2%|[34m         [0m| 1/50 [00:05<02:45,  3.37s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:11,  2.73s/it]                                                        Episode 3	 reward: -5.59	 makespan: 553.40	 Mean_loss: 0.39676696,  training time: 2.21
progress:   4%|[34m         [0m| 2/50 [00:07<02:11,  2.73s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:57,  2.50s/it]                                                        Episode 4	 reward: -5.58	 makespan: 552.50	 Mean_loss: 0.54433823,  training time: 2.17
progress:   6%|[34m         [0m| 3/50 [00:10<01:57,  2.50s/it]progress:   8%|[34m         [0m| 4/50 [00:10<01:49,  2.37s/it]                                                        Episode 5	 reward: -5.62	 makespan: 556.40	 Mean_loss: 0.10365768,  training time: 2.19
progress:   8%|[34m         [0m| 4/50 [00:12<01:49,  2.37s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:43,  2.31s/it]                                                        Episode 6	 reward: -5.63	 makespan: 557.35	 Mean_loss: -0.00393963,  training time: 2.17
progress:  10%|[34m         [0m| 5/50 [00:14<01:43,  2.31s/it]progress:  12%|[34m        [0m| 6/50 [00:14<01:39,  2.27s/it]                                                        Episode 7	 reward: -5.66	 makespan: 560.20	 Mean_loss: 0.28033358,  training time: 2.25
progress:  12%|[34m        [0m| 6/50 [00:16<01:39,  2.27s/it]progress:  14%|[34m        [0m| 7/50 [00:16<01:37,  2.26s/it]                                                        Episode 8	 reward: -5.70	 makespan: 564.00	 Mean_loss: 0.61225414,  training time: 2.17
progress:  14%|[34m        [0m| 7/50 [00:18<01:37,  2.26s/it]progress:  16%|[34m        [0m| 8/50 [00:18<01:33,  2.24s/it]                                                        Episode 9	 reward: -5.70	 makespan: 563.85	 Mean_loss: 0.05674573,  training time: 2.18
progress:  16%|[34m        [0m| 8/50 [00:21<01:33,  2.24s/it]progress:  18%|[34m        [0m| 9/50 [00:21<01:31,  2.22s/it]                                                        Episode 10	 reward: -5.68	 makespan: 562.25	 Mean_loss: 0.09764410,  training time: 2.16
progress:  18%|[34m        [0m| 9/50 [00:23<01:31,  2.22s/it]progress:  20%|[34m        [0m| 10/50 [00:23<01:28,  2.21s/it]                                                         Episode 11	 reward: -5.67	 makespan: 561.45	 Mean_loss: 0.28846431,  training time: 2.24
progress:  20%|[34m        [0m| 10/50 [00:25<01:28,  2.21s/it]progress:  22%|[34m       [0m| 11/50 [00:25<01:26,  2.22s/it]                                                         Episode 12	 reward: -5.64	 makespan: 558.85	 Mean_loss: 0.67683738,  training time: 2.17
progress:  22%|[34m       [0m| 11/50 [00:27<01:26,  2.22s/it]progress:  24%|[34m       [0m| 12/50 [00:27<01:23,  2.21s/it]                                                         Episode 13	 reward: -5.60	 makespan: 553.95	 Mean_loss: 0.37848613,  training time: 2.27
progress:  24%|[34m       [0m| 12/50 [00:29<01:23,  2.21s/it]progress:  26%|[34m       [0m| 13/50 [00:29<01:22,  2.23s/it]                                                         Episode 14	 reward: -5.65	 makespan: 559.00	 Mean_loss: 0.15089537,  training time: 2.20
progress:  26%|[34m       [0m| 13/50 [00:32<01:22,  2.23s/it]progress:  28%|[34m       [0m| 14/50 [00:32<01:19,  2.22s/it]                                                         Episode 15	 reward: -5.65	 makespan: 559.70	 Mean_loss: 0.34821540,  training time: 2.18
progress:  28%|[34m       [0m| 14/50 [00:34<01:19,  2.22s/it]progress:  30%|[34m       [0m| 15/50 [00:34<01:17,  2.21s/it]                                                         Episode 16	 reward: -5.75	 makespan: 569.20	 Mean_loss: 0.41027752,  training time: 2.24
progress:  30%|[34m       [0m| 15/50 [00:36<01:17,  2.21s/it]progress:  32%|[34m      [0m| 16/50 [00:36<01:15,  2.22s/it]                                                         Episode 17	 reward: -5.66	 makespan: 559.95	 Mean_loss: 0.60415030,  training time: 2.18
progress:  32%|[34m      [0m| 16/50 [00:38<01:15,  2.22s/it]progress:  34%|[34m      [0m| 17/50 [00:38<01:12,  2.21s/it]                                                         Episode 18	 reward: -5.61	 makespan: 555.85	 Mean_loss: 0.21050505,  training time: 2.18
progress:  34%|[34m      [0m| 17/50 [00:40<01:12,  2.21s/it]progress:  36%|[34m      [0m| 18/50 [00:40<01:10,  2.20s/it]                                                         Episode 19	 reward: -5.55	 makespan: 549.80	 Mean_loss: -0.26156598,  training time: 2.17
progress:  36%|[34m      [0m| 18/50 [00:43<01:10,  2.20s/it]progress:  38%|[34m      [0m| 19/50 [00:43<01:08,  2.19s/it]                                                         Episode 20	 reward: -5.68	 makespan: 561.95	 Mean_loss: -0.09707078,  training time: 2.22
progress:  38%|[34m      [0m| 19/50 [00:45<01:08,  2.19s/it]progress:  40%|[34m      [0m| 20/50 [00:45<01:06,  2.20s/it]                                                         Episode 21	 reward: -5.75	 makespan: 569.15	 Mean_loss: -0.47971389,  training time: 2.33
progress:  40%|[34m      [0m| 20/50 [00:47<01:06,  2.20s/it]progress:  42%|[34m     [0m| 21/50 [00:47<01:05,  2.24s/it]                                                         Episode 22	 reward: -5.81	 makespan: 575.25	 Mean_loss: 0.69755113,  training time: 2.21
progress:  42%|[34m     [0m| 21/50 [00:49<01:05,  2.24s/it]progress:  44%|[34m     [0m| 22/50 [00:49<01:02,  2.24s/it]                                                         Episode 23	 reward: -5.65	 makespan: 558.90	 Mean_loss: 0.55770195,  training time: 2.23
progress:  44%|[34m     [0m| 22/50 [00:52<01:02,  2.24s/it]progress:  46%|[34m     [0m| 23/50 [00:52<01:00,  2.24s/it]                                                         Episode 24	 reward: -5.59	 makespan: 553.00	 Mean_loss: 0.05006648,  training time: 2.17
progress:  46%|[34m     [0m| 23/50 [00:54<01:00,  2.24s/it]progress:  48%|[34m     [0m| 24/50 [00:54<00:57,  2.22s/it]                                                         Episode 25	 reward: -5.72	 makespan: 566.65	 Mean_loss: 0.65099204,  training time: 2.21
progress:  48%|[34m     [0m| 24/50 [00:56<00:57,  2.22s/it]progress:  50%|[34m     [0m| 25/50 [00:56<00:55,  2.22s/it]                                                         Episode 26	 reward: -5.82	 makespan: 576.55	 Mean_loss: 0.48102754,  training time: 2.19
progress:  50%|[34m     [0m| 25/50 [00:58<00:55,  2.22s/it]progress:  52%|[34m    [0m| 26/50 [00:58<00:53,  2.21s/it]                                                         Episode 27	 reward: -5.77	 makespan: 571.25	 Mean_loss: -0.13016866,  training time: 2.17
progress:  52%|[34m    [0m| 26/50 [01:00<00:53,  2.21s/it]progress:  54%|[34m    [0m| 27/50 [01:00<00:50,  2.20s/it]                                                         Episode 28	 reward: -5.79	 makespan: 572.75	 Mean_loss: 0.22009778,  training time: 2.25
progress:  54%|[34m    [0m| 27/50 [01:03<00:50,  2.20s/it]progress:  56%|[34m    [0m| 28/50 [01:03<00:48,  2.22s/it]                                                         Episode 29	 reward: -5.78	 makespan: 572.00	 Mean_loss: -0.19703048,  training time: 2.21
progress:  56%|[34m    [0m| 28/50 [01:05<00:48,  2.22s/it]progress:  58%|[34m    [0m| 29/50 [01:05<00:46,  2.22s/it]                                                         Episode 30	 reward: -5.82	 makespan: 576.20	 Mean_loss: 0.22036779,  training time: 2.25
progress:  58%|[34m    [0m| 29/50 [01:07<00:46,  2.22s/it]progress:  60%|[34m    [0m| 30/50 [01:07<00:44,  2.23s/it]                                                         Episode 31	 reward: -5.80	 makespan: 574.50	 Mean_loss: 0.71257079,  training time: 2.34
progress:  60%|[34m    [0m| 30/50 [01:09<00:44,  2.23s/it]progress:  62%|[34m   [0m| 31/50 [01:09<00:43,  2.27s/it]                                                         Episode 32	 reward: -5.62	 makespan: 556.80	 Mean_loss: 0.10458540,  training time: 2.19
progress:  62%|[34m   [0m| 31/50 [01:12<00:43,  2.27s/it]progress:  64%|[34m   [0m| 32/50 [01:12<00:40,  2.25s/it]                                                         Episode 33	 reward: -5.79	 makespan: 573.50	 Mean_loss: 0.39746207,  training time: 2.24
progress:  64%|[34m   [0m| 32/50 [01:14<00:40,  2.25s/it]progress:  66%|[34m   [0m| 33/50 [01:14<00:38,  2.25s/it]                                                         Episode 34	 reward: -5.60	 makespan: 554.10	 Mean_loss: -0.02586874,  training time: 2.18
progress:  66%|[34m   [0m| 33/50 [01:16<00:38,  2.25s/it]progress:  68%|[34m   [0m| 34/50 [01:16<00:35,  2.23s/it]                                                         Episode 35	 reward: -5.66	 makespan: 560.80	 Mean_loss: 0.16495062,  training time: 2.19
progress:  68%|[34m   [0m| 34/50 [01:18<00:35,  2.23s/it]progress:  70%|[34m   [0m| 35/50 [01:18<00:33,  2.22s/it]                                                         Episode 36	 reward: -5.67	 makespan: 561.55	 Mean_loss: 0.13688621,  training time: 2.20
progress:  70%|[34m   [0m| 35/50 [01:21<00:33,  2.22s/it]progress:  72%|[34m  [0m| 36/50 [01:21<00:31,  2.21s/it]                                                         Episode 37	 reward: -5.56	 makespan: 550.05	 Mean_loss: 0.42646182,  training time: 2.18
progress:  72%|[34m  [0m| 36/50 [01:23<00:31,  2.21s/it]progress:  74%|[34m  [0m| 37/50 [01:23<00:28,  2.20s/it]                                                         Episode 38	 reward: -5.73	 makespan: 567.15	 Mean_loss: 0.34570569,  training time: 2.18
progress:  74%|[34m  [0m| 37/50 [01:25<00:28,  2.20s/it]progress:  76%|[34m  [0m| 38/50 [01:25<00:26,  2.20s/it]                                                         Episode 39	 reward: -5.68	 makespan: 561.95	 Mean_loss: 0.54243410,  training time: 2.19
progress:  76%|[34m  [0m| 38/50 [01:27<00:26,  2.20s/it]progress:  78%|[34m  [0m| 39/50 [01:27<00:24,  2.20s/it]                                                         Episode 40	 reward: -5.78	 makespan: 572.05	 Mean_loss: 0.24873157,  training time: 2.20
progress:  78%|[34m  [0m| 39/50 [01:29<00:24,  2.20s/it]progress:  80%|[34m  [0m| 40/50 [01:29<00:22,  2.20s/it]                                                         Episode 41	 reward: -5.63	 makespan: 557.20	 Mean_loss: -0.34067267,  training time: 2.17
progress:  80%|[34m  [0m| 40/50 [01:31<00:22,  2.20s/it]progress:  82%|[34m [0m| 41/50 [01:31<00:19,  2.19s/it]                                                         Episode 42	 reward: -5.63	 makespan: 557.25	 Mean_loss: 0.44726253,  training time: 2.28
progress:  82%|[34m [0m| 41/50 [01:34<00:19,  2.19s/it]progress:  84%|[34m [0m| 42/50 [01:34<00:17,  2.22s/it]                                                         Episode 43	 reward: -5.63	 makespan: 557.80	 Mean_loss: 0.09294575,  training time: 2.25
progress:  84%|[34m [0m| 42/50 [01:36<00:17,  2.22s/it]progress:  86%|[34m [0m| 43/50 [01:36<00:15,  2.23s/it]                                                         Episode 44	 reward: -5.57	 makespan: 551.65	 Mean_loss: -0.45329493,  training time: 2.19
progress:  86%|[34m [0m| 43/50 [01:38<00:15,  2.23s/it]progress:  88%|[34m [0m| 44/50 [01:38<00:13,  2.22s/it]                                                         Episode 45	 reward: -5.58	 makespan: 552.00	 Mean_loss: -0.45836681,  training time: 2.17
progress:  88%|[34m [0m| 44/50 [01:40<00:13,  2.22s/it]progress:  90%|[34m [0m| 45/50 [01:40<00:11,  2.21s/it]                                                         Episode 46	 reward: -5.67	 makespan: 561.40	 Mean_loss: 0.62902606,  training time: 2.17
progress:  90%|[34m [0m| 45/50 [01:43<00:11,  2.21s/it]progress:  92%|[34m[0m| 46/50 [01:43<00:08,  2.20s/it]                                                         Episode 47	 reward: -5.82	 makespan: 575.90	 Mean_loss: 0.64667875,  training time: 2.25
progress:  92%|[34m[0m| 46/50 [01:45<00:08,  2.20s/it]progress:  94%|[34m[0m| 47/50 [01:45<00:06,  2.22s/it]                                                         Episode 48	 reward: -5.55	 makespan: 549.25	 Mean_loss: 0.18066403,  training time: 2.18
progress:  94%|[34m[0m| 47/50 [01:47<00:06,  2.22s/it]progress:  96%|[34m[0m| 48/50 [01:47<00:04,  2.21s/it]                                                         Episode 49	 reward: -5.63	 makespan: 557.10	 Mean_loss: 0.12525445,  training time: 2.20
progress:  96%|[34m[0m| 48/50 [01:49<00:04,  2.21s/it]progress:  98%|[34m[0m| 49/50 [01:49<00:02,  2.21s/it]                                                         Episode 50	 reward: -5.58	 makespan: 552.35	 Mean_loss: 0.45505235,  training time: 2.18
progress:  98%|[34m[0m| 49/50 [01:51<00:02,  2.21s/it]progress: 100%|[34m[0m| 50/50 [01:51<00:00,  2.20s/it]progress: 100%|[34m[0m| 50/50 [01:51<00:00,  2.24s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x7_10 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.86	 makespan: 777.95	 Mean_loss: 0.27368683,  training time: 4.16
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:24,  4.17s/it]                                                        Episode 2	 reward: -7.62	 makespan: 754.40	 Mean_loss: 0.22273605,  training time: 3.00
progress:   2%|[34m         [0m| 1/50 [00:07<03:24,  4.17s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:47,  3.49s/it]                                                        Episode 3	 reward: -7.73	 makespan: 764.90	 Mean_loss: 0.16371973,  training time: 3.06
progress:   4%|[34m         [0m| 2/50 [00:10<02:47,  3.49s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:34,  3.29s/it]                                                        Episode 4	 reward: -7.77	 makespan: 768.85	 Mean_loss: 0.15726568,  training time: 3.05
progress:   6%|[34m         [0m| 3/50 [00:13<02:34,  3.29s/it]progress:   8%|[34m         [0m| 4/50 [00:13<02:27,  3.20s/it]                                                        Episode 5	 reward: -7.66	 makespan: 758.80	 Mean_loss: 0.11584204,  training time: 3.04
progress:   8%|[34m         [0m| 4/50 [00:16<02:27,  3.20s/it]progress:  10%|[34m         [0m| 5/50 [00:16<02:21,  3.15s/it]                                                        Episode 6	 reward: -7.83	 makespan: 775.00	 Mean_loss: 0.11278100,  training time: 3.15
progress:  10%|[34m         [0m| 5/50 [00:19<02:21,  3.15s/it]progress:  12%|[34m        [0m| 6/50 [00:19<02:18,  3.15s/it]                                                        Episode 7	 reward: -7.72	 makespan: 764.10	 Mean_loss: 0.10277748,  training time: 3.16
progress:  12%|[34m        [0m| 6/50 [00:22<02:18,  3.15s/it]progress:  14%|[34m        [0m| 7/50 [00:22<02:15,  3.16s/it]                                                        Episode 8	 reward: -7.73	 makespan: 764.85	 Mean_loss: 0.09618038,  training time: 3.14
progress:  14%|[34m        [0m| 7/50 [00:25<02:15,  3.16s/it]progress:  16%|[34m        [0m| 8/50 [00:25<02:12,  3.15s/it]                                                        Episode 9	 reward: -7.78	 makespan: 770.00	 Mean_loss: 0.11277216,  training time: 3.12
progress:  16%|[34m        [0m| 8/50 [00:28<02:12,  3.15s/it]progress:  18%|[34m        [0m| 9/50 [00:28<02:09,  3.15s/it]                                                        Episode 10	 reward: -7.74	 makespan: 766.55	 Mean_loss: 0.09839999,  training time: 3.05
progress:  18%|[34m        [0m| 9/50 [00:32<02:09,  3.15s/it]progress:  20%|[34m        [0m| 10/50 [00:32<02:04,  3.12s/it]                                                         Episode 11	 reward: -7.77	 makespan: 768.75	 Mean_loss: 0.07588997,  training time: 3.05
progress:  20%|[34m        [0m| 10/50 [00:35<02:04,  3.12s/it]progress:  22%|[34m       [0m| 11/50 [00:35<02:00,  3.10s/it]                                                         Episode 12	 reward: -7.72	 makespan: 764.40	 Mean_loss: 0.07586858,  training time: 3.04
progress:  22%|[34m       [0m| 11/50 [00:38<02:00,  3.10s/it]progress:  24%|[34m       [0m| 12/50 [00:38<01:57,  3.08s/it]                                                         Episode 13	 reward: -7.73	 makespan: 765.45	 Mean_loss: 0.09261843,  training time: 3.03
progress:  24%|[34m       [0m| 12/50 [00:41<01:57,  3.08s/it]progress:  26%|[34m       [0m| 13/50 [00:41<01:53,  3.07s/it]                                                         Episode 14	 reward: -7.83	 makespan: 774.75	 Mean_loss: 0.08169090,  training time: 3.12
progress:  26%|[34m       [0m| 13/50 [00:44<01:53,  3.07s/it]progress:  28%|[34m       [0m| 14/50 [00:44<01:51,  3.09s/it]                                                         Episode 15	 reward: -7.60	 makespan: 752.45	 Mean_loss: 0.06243128,  training time: 3.01
progress:  28%|[34m       [0m| 14/50 [00:47<01:51,  3.09s/it]progress:  30%|[34m       [0m| 15/50 [00:47<01:47,  3.07s/it]                                                         Episode 16	 reward: -7.59	 makespan: 751.10	 Mean_loss: 0.06903127,  training time: 2.99
progress:  30%|[34m       [0m| 15/50 [00:50<01:47,  3.07s/it]progress:  32%|[34m      [0m| 16/50 [00:50<01:43,  3.05s/it]                                                         Episode 17	 reward: -7.77	 makespan: 769.10	 Mean_loss: 0.09021761,  training time: 3.00
progress:  32%|[34m      [0m| 16/50 [00:53<01:43,  3.05s/it]progress:  34%|[34m      [0m| 17/50 [00:53<01:40,  3.04s/it]                                                         Episode 18	 reward: -7.83	 makespan: 774.90	 Mean_loss: 0.08660031,  training time: 2.99
progress:  34%|[34m      [0m| 17/50 [00:56<01:40,  3.04s/it]progress:  36%|[34m      [0m| 18/50 [00:56<01:36,  3.02s/it]                                                         Episode 19	 reward: -7.73	 makespan: 765.10	 Mean_loss: 0.07796284,  training time: 3.01
progress:  36%|[34m      [0m| 18/50 [00:59<01:36,  3.02s/it]progress:  38%|[34m      [0m| 19/50 [00:59<01:33,  3.02s/it]                                                         Episode 20	 reward: -7.62	 makespan: 754.65	 Mean_loss: 0.06596032,  training time: 3.03
progress:  38%|[34m      [0m| 19/50 [01:02<01:33,  3.02s/it]progress:  40%|[34m      [0m| 20/50 [01:02<01:30,  3.03s/it]                                                         Episode 21	 reward: -7.63	 makespan: 755.20	 Mean_loss: 0.09015088,  training time: 3.04
progress:  40%|[34m      [0m| 20/50 [01:05<01:30,  3.03s/it]progress:  42%|[34m     [0m| 21/50 [01:05<01:27,  3.03s/it]                                                         Episode 22	 reward: -7.70	 makespan: 762.35	 Mean_loss: 0.05935022,  training time: 3.00
progress:  42%|[34m     [0m| 21/50 [01:08<01:27,  3.03s/it]progress:  44%|[34m     [0m| 22/50 [01:08<01:24,  3.02s/it]                                                         Episode 23	 reward: -7.68	 makespan: 760.55	 Mean_loss: 0.10313946,  training time: 3.03
progress:  44%|[34m     [0m| 22/50 [01:11<01:24,  3.02s/it]progress:  46%|[34m     [0m| 23/50 [01:11<01:21,  3.03s/it]                                                         Episode 24	 reward: -7.63	 makespan: 755.20	 Mean_loss: 0.07245494,  training time: 3.03
progress:  46%|[34m     [0m| 23/50 [01:14<01:21,  3.03s/it]progress:  48%|[34m     [0m| 24/50 [01:14<01:18,  3.03s/it]                                                         Episode 25	 reward: -7.90	 makespan: 782.55	 Mean_loss: 0.08342611,  training time: 3.03
progress:  48%|[34m     [0m| 24/50 [01:17<01:18,  3.03s/it]progress:  50%|[34m     [0m| 25/50 [01:17<01:15,  3.03s/it]                                                         Episode 26	 reward: -7.74	 makespan: 766.00	 Mean_loss: 0.07945877,  training time: 3.01
progress:  50%|[34m     [0m| 25/50 [01:20<01:15,  3.03s/it]progress:  52%|[34m    [0m| 26/50 [01:20<01:12,  3.03s/it]                                                         Episode 27	 reward: -7.58	 makespan: 750.85	 Mean_loss: 0.07226124,  training time: 3.04
progress:  52%|[34m    [0m| 26/50 [01:23<01:12,  3.03s/it]progress:  54%|[34m    [0m| 27/50 [01:23<01:09,  3.03s/it]                                                         Episode 28	 reward: -7.71	 makespan: 762.90	 Mean_loss: 0.07423754,  training time: 3.02
progress:  54%|[34m    [0m| 27/50 [01:26<01:09,  3.03s/it]progress:  56%|[34m    [0m| 28/50 [01:26<01:06,  3.03s/it]                                                         Episode 29	 reward: -7.70	 makespan: 762.20	 Mean_loss: 0.07983261,  training time: 2.98
progress:  56%|[34m    [0m| 28/50 [01:29<01:06,  3.03s/it]progress:  58%|[34m    [0m| 29/50 [01:29<01:03,  3.02s/it]                                                         Episode 30	 reward: -7.68	 makespan: 760.30	 Mean_loss: 0.07119213,  training time: 3.04
progress:  58%|[34m    [0m| 29/50 [01:32<01:03,  3.02s/it]progress:  60%|[34m    [0m| 30/50 [01:32<01:00,  3.03s/it]                                                         Episode 31	 reward: -7.82	 makespan: 774.25	 Mean_loss: 0.09623425,  training time: 3.01
progress:  60%|[34m    [0m| 30/50 [01:35<01:00,  3.03s/it]progress:  62%|[34m   [0m| 31/50 [01:35<00:57,  3.02s/it]                                                         Episode 32	 reward: -7.69	 makespan: 761.00	 Mean_loss: 0.09724265,  training time: 3.03
progress:  62%|[34m   [0m| 31/50 [01:38<00:57,  3.02s/it]progress:  64%|[34m   [0m| 32/50 [01:38<00:54,  3.03s/it]                                                         Episode 33	 reward: -7.68	 makespan: 760.05	 Mean_loss: 0.06980533,  training time: 3.02
progress:  64%|[34m   [0m| 32/50 [01:41<00:54,  3.03s/it]progress:  66%|[34m   [0m| 33/50 [01:41<00:51,  3.03s/it]                                                         Episode 34	 reward: -7.75	 makespan: 767.65	 Mean_loss: 0.08976021,  training time: 3.03
progress:  66%|[34m   [0m| 33/50 [01:44<00:51,  3.03s/it]progress:  68%|[34m   [0m| 34/50 [01:44<00:48,  3.03s/it]                                                         Episode 35	 reward: -7.88	 makespan: 780.15	 Mean_loss: 0.09573495,  training time: 3.01
progress:  68%|[34m   [0m| 34/50 [01:47<00:48,  3.03s/it]progress:  70%|[34m   [0m| 35/50 [01:47<00:45,  3.03s/it]                                                         Episode 36	 reward: -7.74	 makespan: 765.95	 Mean_loss: 0.07954807,  training time: 3.01
progress:  70%|[34m   [0m| 35/50 [01:50<00:45,  3.03s/it]progress:  72%|[34m  [0m| 36/50 [01:50<00:42,  3.03s/it]                                                         Episode 37	 reward: -7.71	 makespan: 763.05	 Mean_loss: 0.06498133,  training time: 3.02
progress:  72%|[34m  [0m| 36/50 [01:53<00:42,  3.03s/it]progress:  74%|[34m  [0m| 37/50 [01:53<00:39,  3.03s/it]                                                         Episode 38	 reward: -7.76	 makespan: 768.15	 Mean_loss: 0.07902128,  training time: 3.02
progress:  74%|[34m  [0m| 37/50 [01:56<00:39,  3.03s/it]progress:  76%|[34m  [0m| 38/50 [01:56<00:36,  3.03s/it]                                                         Episode 39	 reward: -7.75	 makespan: 766.90	 Mean_loss: 0.08773596,  training time: 3.01
progress:  76%|[34m  [0m| 38/50 [01:59<00:36,  3.03s/it]progress:  78%|[34m  [0m| 39/50 [01:59<00:33,  3.02s/it]                                                         Episode 40	 reward: -7.72	 makespan: 764.75	 Mean_loss: 0.08361115,  training time: 3.03
progress:  78%|[34m  [0m| 39/50 [02:02<00:33,  3.02s/it]progress:  80%|[34m  [0m| 40/50 [02:02<00:30,  3.03s/it]                                                         Episode 41	 reward: -7.69	 makespan: 761.25	 Mean_loss: 0.08228135,  training time: 3.18
progress:  80%|[34m  [0m| 40/50 [02:06<00:30,  3.03s/it]progress:  82%|[34m [0m| 41/50 [02:06<00:27,  3.07s/it]                                                         Episode 42	 reward: -7.61	 makespan: 753.60	 Mean_loss: 0.07334623,  training time: 3.07
progress:  82%|[34m [0m| 41/50 [02:09<00:27,  3.07s/it]progress:  84%|[34m [0m| 42/50 [02:09<00:24,  3.08s/it]                                                         Episode 43	 reward: -7.76	 makespan: 768.55	 Mean_loss: 0.08185109,  training time: 3.06
progress:  84%|[34m [0m| 42/50 [02:12<00:24,  3.08s/it]progress:  86%|[34m [0m| 43/50 [02:12<00:21,  3.08s/it]                                                         Episode 44	 reward: -7.71	 makespan: 763.35	 Mean_loss: 0.07070585,  training time: 3.04
progress:  86%|[34m [0m| 43/50 [02:15<00:21,  3.08s/it]progress:  88%|[34m [0m| 44/50 [02:15<00:18,  3.07s/it]                                                         Episode 45	 reward: -7.69	 makespan: 761.20	 Mean_loss: 0.08949948,  training time: 3.04
progress:  88%|[34m [0m| 44/50 [02:18<00:18,  3.07s/it]progress:  90%|[34m [0m| 45/50 [02:18<00:15,  3.06s/it]                                                         Episode 46	 reward: -7.63	 makespan: 754.90	 Mean_loss: 0.06805937,  training time: 3.04
progress:  90%|[34m [0m| 45/50 [02:21<00:15,  3.06s/it]progress:  92%|[34m[0m| 46/50 [02:21<00:12,  3.06s/it]                                                         Episode 47	 reward: -7.71	 makespan: 763.30	 Mean_loss: 0.08449298,  training time: 3.05
progress:  92%|[34m[0m| 46/50 [02:24<00:12,  3.06s/it]progress:  94%|[34m[0m| 47/50 [02:24<00:09,  3.06s/it]                                                         Episode 48	 reward: -7.84	 makespan: 776.15	 Mean_loss: 0.08313568,  training time: 3.04
progress:  94%|[34m[0m| 47/50 [02:27<00:09,  3.06s/it]progress:  96%|[34m[0m| 48/50 [02:27<00:06,  3.05s/it]                                                         Episode 49	 reward: -7.64	 makespan: 756.50	 Mean_loss: 0.08592547,  training time: 3.04
progress:  96%|[34m[0m| 48/50 [02:30<00:06,  3.05s/it]progress:  98%|[34m[0m| 49/50 [02:30<00:03,  3.05s/it]                                                         Episode 50	 reward: -7.79	 makespan: 771.10	 Mean_loss: 0.07723217,  training time: 3.02
progress:  98%|[34m[0m| 49/50 [02:33<00:03,  3.05s/it]progress: 100%|[34m[0m| 50/50 [02:33<00:00,  3.04s/it]progress: 100%|[34m[0m| 50/50 [02:33<00:00,  3.07s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x7_12 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 7 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x7+mix
save model name:  15x7+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x7+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -9.39	 makespan: 929.90	 Mean_loss: 0.25243142,  training time: 5.08
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:09,  5.09s/it]                                                        Episode 2	 reward: -9.47	 makespan: 937.35	 Mean_loss: 0.24703790,  training time: 3.89
progress:   2%|[34m         [0m| 1/50 [00:08<04:09,  5.09s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:30,  4.39s/it]                                                        Episode 3	 reward: -9.34	 makespan: 924.70	 Mean_loss: 0.19989635,  training time: 3.80
progress:   4%|[34m         [0m| 2/50 [00:12<03:30,  4.39s/it]progress:   6%|[34m         [0m| 3/50 [00:12<03:13,  4.12s/it]                                                        Episode 4	 reward: -9.44	 makespan: 934.65	 Mean_loss: 0.15637994,  training time: 3.90
progress:   6%|[34m         [0m| 3/50 [00:16<03:13,  4.12s/it]progress:   8%|[34m         [0m| 4/50 [00:16<03:05,  4.04s/it]                                                        Episode 5	 reward: -9.29	 makespan: 919.45	 Mean_loss: 0.16133240,  training time: 3.86
progress:   8%|[34m         [0m| 4/50 [00:20<03:05,  4.04s/it]progress:  10%|[34m         [0m| 5/50 [00:20<02:59,  3.98s/it]                                                        Episode 6	 reward: -9.37	 makespan: 927.65	 Mean_loss: 0.15810339,  training time: 3.78
progress:  10%|[34m         [0m| 5/50 [00:24<02:59,  3.98s/it]progress:  12%|[34m        [0m| 6/50 [00:24<02:52,  3.92s/it]                                                        Episode 7	 reward: -9.40	 makespan: 930.45	 Mean_loss: 0.14097354,  training time: 3.91
progress:  12%|[34m        [0m| 6/50 [00:28<02:52,  3.92s/it]progress:  14%|[34m        [0m| 7/50 [00:28<02:48,  3.92s/it]                                                        Episode 8	 reward: -9.41	 makespan: 931.20	 Mean_loss: 0.14627315,  training time: 3.81
progress:  14%|[34m        [0m| 7/50 [00:32<02:48,  3.92s/it]progress:  16%|[34m        [0m| 8/50 [00:32<02:43,  3.88s/it]                                                        Episode 9	 reward: -9.40	 makespan: 931.00	 Mean_loss: 0.11848902,  training time: 3.99
progress:  16%|[34m        [0m| 8/50 [00:36<02:43,  3.88s/it]progress:  18%|[34m        [0m| 9/50 [00:36<02:40,  3.92s/it]                                                        Episode 10	 reward: -9.54	 makespan: 944.10	 Mean_loss: 0.14999360,  training time: 3.88
progress:  18%|[34m        [0m| 9/50 [00:39<02:40,  3.92s/it]progress:  20%|[34m        [0m| 10/50 [00:39<02:36,  3.91s/it]                                                         Episode 11	 reward: -9.58	 makespan: 948.25	 Mean_loss: 0.13087994,  training time: 3.78
progress:  20%|[34m        [0m| 10/50 [00:43<02:36,  3.91s/it]progress:  22%|[34m       [0m| 11/50 [00:43<02:31,  3.88s/it]                                                         Episode 12	 reward: -9.42	 makespan: 932.25	 Mean_loss: 0.12929907,  training time: 3.80
progress:  22%|[34m       [0m| 11/50 [00:47<02:31,  3.88s/it]progress:  24%|[34m       [0m| 12/50 [00:47<02:26,  3.86s/it]                                                         Episode 13	 reward: -9.42	 makespan: 932.30	 Mean_loss: 0.10544847,  training time: 3.83
progress:  24%|[34m       [0m| 12/50 [00:51<02:26,  3.86s/it]progress:  26%|[34m       [0m| 13/50 [00:51<02:22,  3.85s/it]                                                         Episode 14	 reward: -9.33	 makespan: 923.40	 Mean_loss: 0.15608966,  training time: 3.84
progress:  26%|[34m       [0m| 13/50 [00:55<02:22,  3.85s/it]progress:  28%|[34m       [0m| 14/50 [00:55<02:18,  3.85s/it]                                                         Episode 15	 reward: -9.41	 makespan: 931.85	 Mean_loss: 0.12878740,  training time: 3.92
progress:  28%|[34m       [0m| 14/50 [00:59<02:18,  3.85s/it]progress:  30%|[34m       [0m| 15/50 [00:59<02:15,  3.88s/it]                                                         Episode 16	 reward: -9.46	 makespan: 936.55	 Mean_loss: 0.12809533,  training time: 3.83
progress:  30%|[34m       [0m| 15/50 [01:03<02:15,  3.88s/it]progress:  32%|[34m      [0m| 16/50 [01:03<02:11,  3.87s/it]                                                         Episode 17	 reward: -9.27	 makespan: 917.25	 Mean_loss: 0.09079248,  training time: 3.93
progress:  32%|[34m      [0m| 16/50 [01:07<02:11,  3.87s/it]progress:  34%|[34m      [0m| 17/50 [01:07<02:08,  3.89s/it]                                                         Episode 18	 reward: -9.53	 makespan: 943.75	 Mean_loss: 0.12751311,  training time: 4.09
progress:  34%|[34m      [0m| 17/50 [01:11<02:08,  3.89s/it]progress:  36%|[34m      [0m| 18/50 [01:11<02:06,  3.95s/it]                                                         Episode 19	 reward: -9.38	 makespan: 928.30	 Mean_loss: 0.08461871,  training time: 4.07
progress:  36%|[34m      [0m| 18/50 [01:15<02:06,  3.95s/it]progress:  38%|[34m      [0m| 19/50 [01:15<02:03,  3.99s/it]                                                         Episode 20	 reward: -9.27	 makespan: 917.35	 Mean_loss: 0.09693885,  training time: 3.96
progress:  38%|[34m      [0m| 19/50 [01:19<02:03,  3.99s/it]progress:  40%|[34m      [0m| 20/50 [01:19<01:59,  3.98s/it]                                                         Episode 21	 reward: -9.53	 makespan: 943.10	 Mean_loss: 0.13158791,  training time: 3.82
progress:  40%|[34m      [0m| 20/50 [01:22<01:59,  3.98s/it]progress:  42%|[34m     [0m| 21/50 [01:22<01:54,  3.93s/it]                                                         Episode 22	 reward: -9.58	 makespan: 948.30	 Mean_loss: 0.11829393,  training time: 3.86
progress:  42%|[34m     [0m| 21/50 [01:26<01:54,  3.93s/it]progress:  44%|[34m     [0m| 22/50 [01:26<01:49,  3.91s/it]                                                         Episode 23	 reward: -9.24	 makespan: 914.90	 Mean_loss: 0.11002161,  training time: 3.80
progress:  44%|[34m     [0m| 22/50 [01:30<01:49,  3.91s/it]progress:  46%|[34m     [0m| 23/50 [01:30<01:44,  3.88s/it]                                                         Episode 24	 reward: -9.32	 makespan: 922.95	 Mean_loss: 0.08727486,  training time: 3.80
progress:  46%|[34m     [0m| 23/50 [01:34<01:44,  3.88s/it]progress:  48%|[34m     [0m| 24/50 [01:34<01:40,  3.86s/it]                                                         Episode 25	 reward: -9.33	 makespan: 923.70	 Mean_loss: 0.08921089,  training time: 3.90
progress:  48%|[34m     [0m| 24/50 [01:38<01:40,  3.86s/it]progress:  50%|[34m     [0m| 25/50 [01:38<01:36,  3.87s/it]                                                         Episode 26	 reward: -9.42	 makespan: 932.35	 Mean_loss: 0.12698552,  training time: 3.84
progress:  50%|[34m     [0m| 25/50 [01:42<01:36,  3.87s/it]progress:  52%|[34m    [0m| 26/50 [01:42<01:32,  3.87s/it]                                                         Episode 27	 reward: -9.40	 makespan: 930.85	 Mean_loss: 0.09901170,  training time: 3.76
progress:  52%|[34m    [0m| 26/50 [01:45<01:32,  3.87s/it]progress:  54%|[34m    [0m| 27/50 [01:45<01:28,  3.84s/it]                                                         Episode 28	 reward: -9.25	 makespan: 915.80	 Mean_loss: 0.10143837,  training time: 3.77
progress:  54%|[34m    [0m| 27/50 [01:49<01:28,  3.84s/it]progress:  56%|[34m    [0m| 28/50 [01:49<01:24,  3.82s/it]                                                         Episode 29	 reward: -9.21	 makespan: 912.20	 Mean_loss: 0.10442404,  training time: 3.90
progress:  56%|[34m    [0m| 28/50 [01:53<01:24,  3.82s/it]progress:  58%|[34m    [0m| 29/50 [01:53<01:20,  3.85s/it]                                                         Episode 30	 reward: -9.26	 makespan: 916.75	 Mean_loss: 0.10966586,  training time: 4.01
progress:  58%|[34m    [0m| 29/50 [01:57<01:20,  3.85s/it]progress:  60%|[34m    [0m| 30/50 [01:57<01:17,  3.90s/it]                                                         Episode 31	 reward: -9.41	 makespan: 931.75	 Mean_loss: 0.10701274,  training time: 3.82
progress:  60%|[34m    [0m| 30/50 [02:01<01:17,  3.90s/it]progress:  62%|[34m   [0m| 31/50 [02:01<01:13,  3.88s/it]                                                         Episode 32	 reward: -9.32	 makespan: 922.20	 Mean_loss: 0.10718179,  training time: 3.83
progress:  62%|[34m   [0m| 31/50 [02:05<01:13,  3.88s/it]progress:  64%|[34m   [0m| 32/50 [02:05<01:09,  3.87s/it]                                                         Episode 33	 reward: -9.31	 makespan: 921.30	 Mean_loss: 0.10737646,  training time: 3.83
progress:  64%|[34m   [0m| 32/50 [02:09<01:09,  3.87s/it]progress:  66%|[34m   [0m| 33/50 [02:09<01:05,  3.86s/it]                                                         Episode 34	 reward: -9.38	 makespan: 928.95	 Mean_loss: 0.09546161,  training time: 3.83
progress:  66%|[34m   [0m| 33/50 [02:13<01:05,  3.86s/it]progress:  68%|[34m   [0m| 34/50 [02:13<01:01,  3.85s/it]                                                         Episode 35	 reward: -9.43	 makespan: 933.55	 Mean_loss: 0.15376133,  training time: 3.84
progress:  68%|[34m   [0m| 34/50 [02:16<01:01,  3.85s/it]progress:  70%|[34m   [0m| 35/50 [02:16<00:57,  3.85s/it]                                                         Episode 36	 reward: -9.28	 makespan: 918.60	 Mean_loss: 0.10971639,  training time: 3.87
progress:  70%|[34m   [0m| 35/50 [02:20<00:57,  3.85s/it]progress:  72%|[34m  [0m| 36/50 [02:20<00:54,  3.86s/it]                                                         Episode 37	 reward: -9.31	 makespan: 922.10	 Mean_loss: 0.14035934,  training time: 3.83
progress:  72%|[34m  [0m| 36/50 [02:24<00:54,  3.86s/it]progress:  74%|[34m  [0m| 37/50 [02:24<00:50,  3.85s/it]                                                         Episode 38	 reward: -9.21	 makespan: 912.20	 Mean_loss: 0.07150168,  training time: 3.83
progress:  74%|[34m  [0m| 37/50 [02:28<00:50,  3.85s/it]progress:  76%|[34m  [0m| 38/50 [02:28<00:46,  3.85s/it]                                                         Episode 39	 reward: -9.32	 makespan: 922.35	 Mean_loss: 0.09091473,  training time: 3.83
progress:  76%|[34m  [0m| 38/50 [02:32<00:46,  3.85s/it]progress:  78%|[34m  [0m| 39/50 [02:32<00:42,  3.84s/it]                                                         Episode 40	 reward: -9.26	 makespan: 916.30	 Mean_loss: 0.10243943,  training time: 3.82
progress:  78%|[34m  [0m| 39/50 [02:36<00:42,  3.84s/it]progress:  80%|[34m  [0m| 40/50 [02:36<00:38,  3.84s/it]                                                         Episode 41	 reward: -9.23	 makespan: 914.25	 Mean_loss: 0.13486183,  training time: 3.81
progress:  80%|[34m  [0m| 40/50 [02:39<00:38,  3.84s/it]progress:  82%|[34m [0m| 41/50 [02:39<00:34,  3.83s/it]                                                         Episode 42	 reward: -9.16	 makespan: 906.85	 Mean_loss: 0.08908336,  training time: 3.85
progress:  82%|[34m [0m| 41/50 [02:43<00:34,  3.83s/it]progress:  84%|[34m [0m| 42/50 [02:43<00:30,  3.84s/it]                                                         Episode 43	 reward: -9.51	 makespan: 941.90	 Mean_loss: 0.11065668,  training time: 3.84
progress:  84%|[34m [0m| 42/50 [02:47<00:30,  3.84s/it]progress:  86%|[34m [0m| 43/50 [02:47<00:26,  3.85s/it]                                                         Episode 44	 reward: -9.27	 makespan: 917.80	 Mean_loss: 0.10545953,  training time: 3.83
progress:  86%|[34m [0m| 43/50 [02:51<00:26,  3.85s/it]progress:  88%|[34m [0m| 44/50 [02:51<00:23,  3.84s/it]                                                         Episode 45	 reward: -9.16	 makespan: 906.60	 Mean_loss: 0.07149003,  training time: 3.84
progress:  88%|[34m [0m| 44/50 [02:55<00:23,  3.84s/it]progress:  90%|[34m [0m| 45/50 [02:55<00:19,  3.85s/it]                                                         Episode 46	 reward: -9.35	 makespan: 925.45	 Mean_loss: 0.10185133,  training time: 3.83
progress:  90%|[34m [0m| 45/50 [02:59<00:19,  3.85s/it]progress:  92%|[34m[0m| 46/50 [02:59<00:15,  3.84s/it]                                                         Episode 47	 reward: -9.38	 makespan: 928.70	 Mean_loss: 0.14385135,  training time: 3.86
progress:  92%|[34m[0m| 46/50 [03:03<00:15,  3.84s/it]progress:  94%|[34m[0m| 47/50 [03:03<00:11,  3.85s/it]                                                         Episode 48	 reward: -9.24	 makespan: 915.20	 Mean_loss: 0.12321752,  training time: 3.85
progress:  94%|[34m[0m| 47/50 [03:06<00:11,  3.85s/it]progress:  96%|[34m[0m| 48/50 [03:06<00:07,  3.86s/it]                                                         Episode 49	 reward: -9.35	 makespan: 925.90	 Mean_loss: 0.08996098,  training time: 4.03
progress:  96%|[34m[0m| 48/50 [03:10<00:07,  3.86s/it]progress:  98%|[34m[0m| 49/50 [03:10<00:03,  3.91s/it]                                                         Episode 50	 reward: -9.42	 makespan: 932.20	 Mean_loss: 0.11001407,  training time: 4.23
progress:  98%|[34m[0m| 49/50 [03:15<00:03,  3.91s/it]progress: 100%|[34m[0m| 50/50 [03:15<00:00,  4.01s/it]progress: 100%|[34m[0m| 50/50 [03:15<00:00,  3.90s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for n_m in '$n_m_options'
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x5_4 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 4
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -4.51	 makespan: 446.75	 Mean_loss: 0.35765290,  training time: 2.30
progress:   0%|[34m          [0m| 0/50 [00:02<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:02<01:53,  2.31s/it]                                                        Episode 2	 reward: -4.66	 makespan: 461.60	 Mean_loss: 0.24721463,  training time: 1.27
progress:   2%|[34m         [0m| 1/50 [00:03<01:53,  2.31s/it]progress:   4%|[34m         [0m| 2/50 [00:03<01:21,  1.70s/it]                                                        Episode 3	 reward: -4.65	 makespan: 460.50	 Mean_loss: 0.19262722,  training time: 1.28
progress:   4%|[34m         [0m| 2/50 [00:04<01:21,  1.70s/it]progress:   6%|[34m         [0m| 3/50 [00:04<01:10,  1.51s/it]                                                        Episode 4	 reward: -4.61	 makespan: 456.30	 Mean_loss: 0.13151671,  training time: 1.32
progress:   6%|[34m         [0m| 3/50 [00:06<01:10,  1.51s/it]progress:   8%|[34m         [0m| 4/50 [00:06<01:06,  1.44s/it]                                                        Episode 5	 reward: -4.64	 makespan: 459.25	 Mean_loss: 0.12728642,  training time: 1.29
progress:   8%|[34m         [0m| 4/50 [00:07<01:06,  1.44s/it]progress:  10%|[34m         [0m| 5/50 [00:07<01:02,  1.39s/it]                                                        Episode 6	 reward: -4.68	 makespan: 463.75	 Mean_loss: 0.12334606,  training time: 1.28
progress:  10%|[34m         [0m| 5/50 [00:08<01:02,  1.39s/it]progress:  12%|[34m        [0m| 6/50 [00:08<00:59,  1.35s/it]                                                        Episode 7	 reward: -4.65	 makespan: 460.60	 Mean_loss: 0.11850379,  training time: 1.28
progress:  12%|[34m        [0m| 6/50 [00:10<00:59,  1.35s/it]progress:  14%|[34m        [0m| 7/50 [00:10<00:57,  1.33s/it]                                                        Episode 8	 reward: -4.67	 makespan: 461.85	 Mean_loss: 0.11053409,  training time: 1.28
progress:  14%|[34m        [0m| 7/50 [00:11<00:57,  1.33s/it]progress:  16%|[34m        [0m| 8/50 [00:11<00:55,  1.32s/it]                                                        Episode 9	 reward: -4.57	 makespan: 452.35	 Mean_loss: 0.11036609,  training time: 1.22
progress:  16%|[34m        [0m| 8/50 [00:12<00:55,  1.32s/it]progress:  18%|[34m        [0m| 9/50 [00:12<00:52,  1.29s/it]                                                        Episode 10	 reward: -4.72	 makespan: 467.55	 Mean_loss: 0.08843119,  training time: 1.27
progress:  18%|[34m        [0m| 9/50 [00:13<00:52,  1.29s/it]progress:  20%|[34m        [0m| 10/50 [00:13<00:51,  1.28s/it]                                                         Episode 11	 reward: -4.66	 makespan: 460.95	 Mean_loss: 0.06572270,  training time: 1.27
progress:  20%|[34m        [0m| 10/50 [00:15<00:51,  1.28s/it]progress:  22%|[34m       [0m| 11/50 [00:15<00:50,  1.28s/it]                                                         Episode 12	 reward: -4.67	 makespan: 462.25	 Mean_loss: 0.10065325,  training time: 1.34
progress:  22%|[34m       [0m| 11/50 [00:16<00:50,  1.28s/it]progress:  24%|[34m       [0m| 12/50 [00:16<00:49,  1.30s/it]                                                         Episode 13	 reward: -4.64	 makespan: 459.50	 Mean_loss: 0.09759422,  training time: 1.28
progress:  24%|[34m       [0m| 12/50 [00:17<00:49,  1.30s/it]progress:  26%|[34m       [0m| 13/50 [00:17<00:47,  1.30s/it]                                                         Episode 14	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.12589559,  training time: 1.22
progress:  26%|[34m       [0m| 13/50 [00:18<00:47,  1.30s/it]progress:  28%|[34m       [0m| 14/50 [00:19<00:45,  1.28s/it]                                                         Episode 15	 reward: -4.68	 makespan: 463.10	 Mean_loss: 0.08998681,  training time: 1.34
progress:  28%|[34m       [0m| 14/50 [00:20<00:45,  1.28s/it]progress:  30%|[34m       [0m| 15/50 [00:20<00:45,  1.30s/it]                                                         Episode 16	 reward: -4.63	 makespan: 458.40	 Mean_loss: 0.04672468,  training time: 1.22
progress:  30%|[34m       [0m| 15/50 [00:21<00:45,  1.30s/it]progress:  32%|[34m      [0m| 16/50 [00:21<00:43,  1.28s/it]                                                         Episode 17	 reward: -4.70	 makespan: 465.25	 Mean_loss: 0.07789729,  training time: 1.26
progress:  32%|[34m      [0m| 16/50 [00:22<00:43,  1.28s/it]progress:  34%|[34m      [0m| 17/50 [00:22<00:41,  1.27s/it]                                                         Episode 18	 reward: -4.66	 makespan: 461.30	 Mean_loss: 0.05521515,  training time: 1.25
progress:  34%|[34m      [0m| 17/50 [00:24<00:41,  1.27s/it]progress:  36%|[34m      [0m| 18/50 [00:24<00:40,  1.27s/it]                                                         Episode 19	 reward: -4.68	 makespan: 463.30	 Mean_loss: 0.07501994,  training time: 1.19
progress:  36%|[34m      [0m| 18/50 [00:25<00:40,  1.27s/it]progress:  38%|[34m      [0m| 19/50 [00:25<00:38,  1.25s/it]                                                         Episode 20	 reward: -4.68	 makespan: 463.25	 Mean_loss: 0.10917375,  training time: 1.19
progress:  38%|[34m      [0m| 19/50 [00:26<00:38,  1.25s/it]progress:  40%|[34m      [0m| 20/50 [00:26<00:36,  1.23s/it]                                                         Episode 21	 reward: -4.71	 makespan: 466.30	 Mean_loss: 0.04064661,  training time: 1.22
progress:  40%|[34m      [0m| 20/50 [00:27<00:36,  1.23s/it]progress:  42%|[34m     [0m| 21/50 [00:27<00:35,  1.23s/it]                                                         Episode 22	 reward: -4.65	 makespan: 460.55	 Mean_loss: 0.06360018,  training time: 1.26
progress:  42%|[34m     [0m| 21/50 [00:28<00:35,  1.23s/it]progress:  44%|[34m     [0m| 22/50 [00:28<00:34,  1.24s/it]                                                         Episode 23	 reward: -4.88	 makespan: 483.45	 Mean_loss: 0.13005747,  training time: 1.19
progress:  44%|[34m     [0m| 22/50 [00:30<00:34,  1.24s/it]progress:  46%|[34m     [0m| 23/50 [00:30<00:33,  1.23s/it]                                                         Episode 24	 reward: -4.77	 makespan: 472.65	 Mean_loss: 0.10488677,  training time: 1.18
progress:  46%|[34m     [0m| 23/50 [00:31<00:33,  1.23s/it]progress:  48%|[34m     [0m| 24/50 [00:31<00:31,  1.21s/it]                                                         Episode 25	 reward: -4.60	 makespan: 455.75	 Mean_loss: 0.06369285,  training time: 1.18
progress:  48%|[34m     [0m| 24/50 [00:32<00:31,  1.21s/it]progress:  50%|[34m     [0m| 25/50 [00:32<00:30,  1.20s/it]                                                         Episode 26	 reward: -4.72	 makespan: 467.25	 Mean_loss: 0.12812306,  training time: 1.18
progress:  50%|[34m     [0m| 25/50 [00:33<00:30,  1.20s/it]progress:  52%|[34m    [0m| 26/50 [00:33<00:28,  1.20s/it]                                                         Episode 27	 reward: -4.68	 makespan: 463.10	 Mean_loss: 0.09579325,  training time: 1.18
progress:  52%|[34m    [0m| 26/50 [00:34<00:28,  1.20s/it]progress:  54%|[34m    [0m| 27/50 [00:34<00:27,  1.19s/it]                                                         Episode 28	 reward: -4.69	 makespan: 464.70	 Mean_loss: 0.10308985,  training time: 1.26
progress:  54%|[34m    [0m| 27/50 [00:36<00:27,  1.19s/it]progress:  56%|[34m    [0m| 28/50 [00:36<00:26,  1.22s/it]                                                         Episode 29	 reward: -4.62	 makespan: 457.45	 Mean_loss: 0.04928425,  training time: 1.28
progress:  56%|[34m    [0m| 28/50 [00:37<00:26,  1.22s/it]progress:  58%|[34m    [0m| 29/50 [00:37<00:25,  1.24s/it]                                                         Episode 30	 reward: -4.59	 makespan: 454.50	 Mean_loss: 0.07480618,  training time: 1.20
progress:  58%|[34m    [0m| 29/50 [00:38<00:25,  1.24s/it]progress:  60%|[34m    [0m| 30/50 [00:38<00:24,  1.23s/it]                                                         Episode 31	 reward: -4.83	 makespan: 477.85	 Mean_loss: 0.13284628,  training time: 1.27
progress:  60%|[34m    [0m| 30/50 [00:39<00:24,  1.23s/it]progress:  62%|[34m   [0m| 31/50 [00:39<00:23,  1.24s/it]                                                         Episode 32	 reward: -4.71	 makespan: 466.30	 Mean_loss: 0.07178481,  training time: 1.24
progress:  62%|[34m   [0m| 31/50 [00:41<00:23,  1.24s/it]progress:  64%|[34m   [0m| 32/50 [00:41<00:22,  1.24s/it]                                                         Episode 33	 reward: -4.66	 makespan: 461.65	 Mean_loss: 0.09231617,  training time: 1.19
progress:  64%|[34m   [0m| 32/50 [00:42<00:22,  1.24s/it]progress:  66%|[34m   [0m| 33/50 [00:42<00:20,  1.23s/it]                                                         Episode 34	 reward: -4.49	 makespan: 444.95	 Mean_loss: 0.10785797,  training time: 1.19
progress:  66%|[34m   [0m| 33/50 [00:43<00:20,  1.23s/it]progress:  68%|[34m   [0m| 34/50 [00:43<00:19,  1.22s/it]                                                         Episode 35	 reward: -4.71	 makespan: 466.55	 Mean_loss: 0.07537632,  training time: 1.20
progress:  68%|[34m   [0m| 34/50 [00:44<00:19,  1.22s/it]progress:  70%|[34m   [0m| 35/50 [00:44<00:18,  1.21s/it]                                                         Episode 36	 reward: -4.60	 makespan: 455.00	 Mean_loss: 0.04201390,  training time: 1.25
progress:  70%|[34m   [0m| 35/50 [00:46<00:18,  1.21s/it]progress:  72%|[34m  [0m| 36/50 [00:46<00:17,  1.23s/it]                                                         Episode 37	 reward: -4.60	 makespan: 455.20	 Mean_loss: 0.07677205,  training time: 1.26
progress:  72%|[34m  [0m| 36/50 [00:47<00:17,  1.23s/it]progress:  74%|[34m  [0m| 37/50 [00:47<00:16,  1.24s/it]                                                         Episode 38	 reward: -4.59	 makespan: 454.50	 Mean_loss: 0.10368758,  training time: 1.24
progress:  74%|[34m  [0m| 37/50 [00:48<00:16,  1.24s/it]progress:  76%|[34m  [0m| 38/50 [00:48<00:14,  1.24s/it]                                                         Episode 39	 reward: -4.58	 makespan: 453.00	 Mean_loss: 0.06959611,  training time: 1.18
progress:  76%|[34m  [0m| 38/50 [00:49<00:14,  1.24s/it]progress:  78%|[34m  [0m| 39/50 [00:49<00:13,  1.22s/it]                                                         Episode 40	 reward: -4.73	 makespan: 468.60	 Mean_loss: 0.10683110,  training time: 1.18
progress:  78%|[34m  [0m| 39/50 [00:50<00:13,  1.22s/it]progress:  80%|[34m  [0m| 40/50 [00:50<00:12,  1.21s/it]                                                         Episode 41	 reward: -4.55	 makespan: 450.40	 Mean_loss: 0.06626754,  training time: 1.23
progress:  80%|[34m  [0m| 40/50 [00:52<00:12,  1.21s/it]progress:  82%|[34m [0m| 41/50 [00:52<00:10,  1.22s/it]                                                         Episode 42	 reward: -4.66	 makespan: 460.85	 Mean_loss: 0.06889681,  training time: 1.26
progress:  82%|[34m [0m| 41/50 [00:53<00:10,  1.22s/it]progress:  84%|[34m [0m| 42/50 [00:53<00:09,  1.23s/it]                                                         Episode 43	 reward: -4.61	 makespan: 456.00	 Mean_loss: 0.05679358,  training time: 1.20
progress:  84%|[34m [0m| 42/50 [00:54<00:09,  1.23s/it]progress:  86%|[34m [0m| 43/50 [00:54<00:08,  1.23s/it]                                                         Episode 44	 reward: -4.61	 makespan: 456.75	 Mean_loss: 0.08564875,  training time: 1.21
progress:  86%|[34m [0m| 43/50 [00:55<00:08,  1.23s/it]progress:  88%|[34m [0m| 44/50 [00:55<00:07,  1.22s/it]                                                         Episode 45	 reward: -4.66	 makespan: 461.20	 Mean_loss: 0.07028832,  training time: 1.20
progress:  88%|[34m [0m| 44/50 [00:57<00:07,  1.22s/it]progress:  90%|[34m [0m| 45/50 [00:57<00:06,  1.22s/it]                                                         Episode 46	 reward: -4.56	 makespan: 451.15	 Mean_loss: 0.07362036,  training time: 1.26
progress:  90%|[34m [0m| 45/50 [00:58<00:06,  1.22s/it]progress:  92%|[34m[0m| 46/50 [00:58<00:04,  1.23s/it]                                                         Episode 47	 reward: -4.57	 makespan: 452.30	 Mean_loss: 0.07831695,  training time: 1.19
progress:  92%|[34m[0m| 46/50 [00:59<00:04,  1.23s/it]progress:  94%|[34m[0m| 47/50 [00:59<00:03,  1.22s/it]                                                         Episode 48	 reward: -4.53	 makespan: 448.80	 Mean_loss: 0.06968572,  training time: 1.26
progress:  94%|[34m[0m| 47/50 [01:00<00:03,  1.22s/it]progress:  96%|[34m[0m| 48/50 [01:00<00:02,  1.23s/it]                                                         Episode 49	 reward: -4.57	 makespan: 452.25	 Mean_loss: 0.08881551,  training time: 1.20
progress:  96%|[34m[0m| 48/50 [01:01<00:02,  1.23s/it]progress:  98%|[34m[0m| 49/50 [01:01<00:01,  1.23s/it]                                                         Episode 50	 reward: -4.68	 makespan: 463.60	 Mean_loss: 0.08325218,  training time: 1.21
progress:  98%|[34m[0m| 49/50 [01:03<00:01,  1.23s/it]progress: 100%|[34m[0m| 50/50 [01:03<00:00,  1.22s/it]progress: 100%|[34m[0m| 50/50 [01:03<00:00,  1.26s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x5_7 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 7
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -7.49	 makespan: 741.20	 Mean_loss: 0.29618490,  training time: 3.26
progress:   0%|[34m          [0m| 0/50 [00:03<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:03<02:40,  3.27s/it]                                                        Episode 2	 reward: -7.48	 makespan: 740.55	 Mean_loss: 0.00183265,  training time: 2.27
progress:   2%|[34m         [0m| 1/50 [00:05<02:40,  3.27s/it]progress:   4%|[34m         [0m| 2/50 [00:05<02:09,  2.69s/it]                                                        Episode 3	 reward: -7.57	 makespan: 748.95	 Mean_loss: 0.13926378,  training time: 2.22
progress:   4%|[34m         [0m| 2/50 [00:07<02:09,  2.69s/it]progress:   6%|[34m         [0m| 3/50 [00:07<01:56,  2.48s/it]                                                        Episode 4	 reward: -7.58	 makespan: 750.50	 Mean_loss: -0.11241181,  training time: 2.12
progress:   6%|[34m         [0m| 3/50 [00:09<01:56,  2.48s/it]progress:   8%|[34m         [0m| 4/50 [00:09<01:47,  2.34s/it]                                                        Episode 5	 reward: -7.60	 makespan: 752.05	 Mean_loss: 0.21359162,  training time: 2.14
progress:   8%|[34m         [0m| 4/50 [00:12<01:47,  2.34s/it]progress:  10%|[34m         [0m| 5/50 [00:12<01:42,  2.27s/it]                                                        Episode 6	 reward: -7.63	 makespan: 755.75	 Mean_loss: -0.34047613,  training time: 2.18
progress:  10%|[34m         [0m| 5/50 [00:14<01:42,  2.27s/it]progress:  12%|[34m        [0m| 6/50 [00:14<01:38,  2.24s/it]                                                        Episode 7	 reward: -7.56	 makespan: 748.25	 Mean_loss: -0.42919916,  training time: 2.16
progress:  12%|[34m        [0m| 6/50 [00:16<01:38,  2.24s/it]progress:  14%|[34m        [0m| 7/50 [00:16<01:35,  2.21s/it]                                                        Episode 8	 reward: -7.52	 makespan: 744.40	 Mean_loss: -0.21164706,  training time: 2.16
progress:  14%|[34m        [0m| 7/50 [00:18<01:35,  2.21s/it]progress:  16%|[34m        [0m| 8/50 [00:18<01:32,  2.20s/it]                                                        Episode 9	 reward: -7.59	 makespan: 751.40	 Mean_loss: -0.25476879,  training time: 2.17
progress:  16%|[34m        [0m| 8/50 [00:20<01:32,  2.20s/it]progress:  18%|[34m        [0m| 9/50 [00:20<01:29,  2.19s/it]                                                        Episode 10	 reward: -7.62	 makespan: 754.45	 Mean_loss: -0.02621763,  training time: 2.16
progress:  18%|[34m        [0m| 9/50 [00:22<01:29,  2.19s/it]progress:  20%|[34m        [0m| 10/50 [00:22<01:27,  2.18s/it]                                                         Episode 11	 reward: -7.58	 makespan: 750.05	 Mean_loss: -0.43059212,  training time: 2.17
progress:  20%|[34m        [0m| 10/50 [00:25<01:27,  2.18s/it]progress:  22%|[34m       [0m| 11/50 [00:25<01:25,  2.18s/it]                                                         Episode 12	 reward: -7.62	 makespan: 754.35	 Mean_loss: -0.11909743,  training time: 2.18
progress:  22%|[34m       [0m| 11/50 [00:27<01:25,  2.18s/it]progress:  24%|[34m       [0m| 12/50 [00:27<01:22,  2.18s/it]                                                         Episode 13	 reward: -7.62	 makespan: 754.60	 Mean_loss: -0.40613651,  training time: 2.31
progress:  24%|[34m       [0m| 12/50 [00:29<01:22,  2.18s/it]progress:  26%|[34m       [0m| 13/50 [00:29<01:22,  2.22s/it]                                                         Episode 14	 reward: -7.65	 makespan: 757.40	 Mean_loss: -0.05302506,  training time: 2.18
progress:  26%|[34m       [0m| 13/50 [00:31<01:22,  2.22s/it]progress:  28%|[34m       [0m| 14/50 [00:31<01:19,  2.21s/it]                                                         Episode 15	 reward: -7.52	 makespan: 744.55	 Mean_loss: -0.08376776,  training time: 2.17
progress:  28%|[34m       [0m| 14/50 [00:33<01:19,  2.21s/it]progress:  30%|[34m       [0m| 15/50 [00:33<01:17,  2.20s/it]                                                         Episode 16	 reward: -7.62	 makespan: 754.20	 Mean_loss: -0.19442838,  training time: 2.13
progress:  30%|[34m       [0m| 15/50 [00:36<01:17,  2.20s/it]progress:  32%|[34m      [0m| 16/50 [00:36<01:14,  2.18s/it]                                                         Episode 17	 reward: -7.55	 makespan: 747.85	 Mean_loss: -0.33205450,  training time: 2.16
progress:  32%|[34m      [0m| 16/50 [00:38<01:14,  2.18s/it]progress:  34%|[34m      [0m| 17/50 [00:38<01:11,  2.18s/it]                                                         Episode 18	 reward: -7.59	 makespan: 751.65	 Mean_loss: -0.01784579,  training time: 2.16
progress:  34%|[34m      [0m| 17/50 [00:40<01:11,  2.18s/it]progress:  36%|[34m      [0m| 18/50 [00:40<01:09,  2.18s/it]                                                         Episode 19	 reward: -7.54	 makespan: 746.40	 Mean_loss: -0.42349386,  training time: 2.10
progress:  36%|[34m      [0m| 18/50 [00:42<01:09,  2.18s/it]progress:  38%|[34m      [0m| 19/50 [00:42<01:06,  2.16s/it]                                                         Episode 20	 reward: -7.57	 makespan: 749.35	 Mean_loss: -0.42248803,  training time: 2.16
progress:  38%|[34m      [0m| 19/50 [00:44<01:06,  2.16s/it]progress:  40%|[34m      [0m| 20/50 [00:44<01:04,  2.16s/it]                                                         Episode 21	 reward: -7.53	 makespan: 745.85	 Mean_loss: -0.04196820,  training time: 2.14
progress:  40%|[34m      [0m| 20/50 [00:46<01:04,  2.16s/it]progress:  42%|[34m     [0m| 21/50 [00:46<01:02,  2.16s/it]                                                         Episode 22	 reward: -7.52	 makespan: 744.90	 Mean_loss: -0.27047884,  training time: 2.21
progress:  42%|[34m     [0m| 21/50 [00:49<01:02,  2.16s/it]progress:  44%|[34m     [0m| 22/50 [00:49<01:00,  2.18s/it]                                                         Episode 23	 reward: -7.50	 makespan: 742.45	 Mean_loss: -0.62274462,  training time: 2.20
progress:  44%|[34m     [0m| 22/50 [00:51<01:00,  2.18s/it]progress:  46%|[34m     [0m| 23/50 [00:51<00:59,  2.19s/it]                                                         Episode 24	 reward: -7.67	 makespan: 759.65	 Mean_loss: -0.52510983,  training time: 2.17
progress:  46%|[34m     [0m| 23/50 [00:53<00:59,  2.19s/it]progress:  48%|[34m     [0m| 24/50 [00:53<00:56,  2.18s/it]                                                         Episode 25	 reward: -7.57	 makespan: 749.35	 Mean_loss: -0.28487903,  training time: 2.17
progress:  48%|[34m     [0m| 24/50 [00:55<00:56,  2.18s/it]progress:  50%|[34m     [0m| 25/50 [00:55<00:54,  2.18s/it]                                                         Episode 26	 reward: -7.57	 makespan: 749.15	 Mean_loss: -0.57404840,  training time: 2.17
progress:  50%|[34m     [0m| 25/50 [00:57<00:54,  2.18s/it]progress:  52%|[34m    [0m| 26/50 [00:57<00:52,  2.18s/it]                                                         Episode 27	 reward: -7.51	 makespan: 743.15	 Mean_loss: -0.53228676,  training time: 2.11
progress:  52%|[34m    [0m| 26/50 [00:59<00:52,  2.18s/it]progress:  54%|[34m    [0m| 27/50 [00:59<00:49,  2.16s/it]                                                         Episode 28	 reward: -7.51	 makespan: 743.15	 Mean_loss: 0.02312772,  training time: 2.22
progress:  54%|[34m    [0m| 27/50 [01:02<00:49,  2.16s/it]progress:  56%|[34m    [0m| 28/50 [01:02<00:47,  2.18s/it]                                                         Episode 29	 reward: -7.58	 makespan: 750.90	 Mean_loss: 0.39970386,  training time: 2.18
progress:  56%|[34m    [0m| 28/50 [01:04<00:47,  2.18s/it]progress:  58%|[34m    [0m| 29/50 [01:04<00:45,  2.18s/it]                                                         Episode 30	 reward: -7.67	 makespan: 759.45	 Mean_loss: -0.60777730,  training time: 2.27
progress:  58%|[34m    [0m| 29/50 [01:06<00:45,  2.18s/it]progress:  60%|[34m    [0m| 30/50 [01:06<00:44,  2.21s/it]                                                         Episode 31	 reward: -7.56	 makespan: 748.00	 Mean_loss: -0.21579543,  training time: 2.18
progress:  60%|[34m    [0m| 30/50 [01:08<00:44,  2.21s/it]progress:  62%|[34m   [0m| 31/50 [01:08<00:41,  2.21s/it]                                                         Episode 32	 reward: -7.63	 makespan: 755.75	 Mean_loss: -0.32790738,  training time: 2.12
progress:  62%|[34m   [0m| 31/50 [01:10<00:41,  2.21s/it]progress:  64%|[34m   [0m| 32/50 [01:10<00:39,  2.18s/it]                                                         Episode 33	 reward: -7.59	 makespan: 751.30	 Mean_loss: -0.48963988,  training time: 2.12
progress:  64%|[34m   [0m| 32/50 [01:13<00:39,  2.18s/it]progress:  66%|[34m   [0m| 33/50 [01:13<00:36,  2.16s/it]                                                         Episode 34	 reward: -7.51	 makespan: 743.65	 Mean_loss: 0.48441446,  training time: 2.20
progress:  66%|[34m   [0m| 33/50 [01:15<00:36,  2.16s/it]progress:  68%|[34m   [0m| 34/50 [01:15<00:34,  2.18s/it]                                                         Episode 35	 reward: -7.73	 makespan: 765.55	 Mean_loss: -0.63950670,  training time: 2.18
progress:  68%|[34m   [0m| 34/50 [01:17<00:34,  2.18s/it]progress:  70%|[34m   [0m| 35/50 [01:17<00:32,  2.18s/it]                                                         Episode 36	 reward: -7.52	 makespan: 744.30	 Mean_loss: -0.07423145,  training time: 2.19
progress:  70%|[34m   [0m| 35/50 [01:19<00:32,  2.18s/it]progress:  72%|[34m  [0m| 36/50 [01:19<00:30,  2.18s/it]                                                         Episode 37	 reward: -7.61	 makespan: 753.85	 Mean_loss: 0.12185732,  training time: 2.16
progress:  72%|[34m  [0m| 36/50 [01:21<00:30,  2.18s/it]progress:  74%|[34m  [0m| 37/50 [01:21<00:28,  2.18s/it]                                                         Episode 38	 reward: -7.55	 makespan: 747.90	 Mean_loss: -0.63120115,  training time: 2.17
progress:  74%|[34m  [0m| 37/50 [01:23<00:28,  2.18s/it]progress:  76%|[34m  [0m| 38/50 [01:23<00:26,  2.18s/it]                                                         Episode 39	 reward: -7.53	 makespan: 745.75	 Mean_loss: 0.03652161,  training time: 2.17
progress:  76%|[34m  [0m| 38/50 [01:26<00:26,  2.18s/it]progress:  78%|[34m  [0m| 39/50 [01:26<00:23,  2.18s/it]                                                         Episode 40	 reward: -7.52	 makespan: 744.90	 Mean_loss: -0.38164830,  training time: 2.17
progress:  78%|[34m  [0m| 39/50 [01:28<00:23,  2.18s/it]progress:  80%|[34m  [0m| 40/50 [01:28<00:21,  2.18s/it]                                                         Episode 41	 reward: -7.54	 makespan: 746.60	 Mean_loss: 0.48332214,  training time: 2.29
progress:  80%|[34m  [0m| 40/50 [01:30<00:21,  2.18s/it]progress:  82%|[34m [0m| 41/50 [01:30<00:19,  2.21s/it]                                                         Episode 42	 reward: -7.66	 makespan: 757.85	 Mean_loss: -0.64184970,  training time: 2.20
progress:  82%|[34m [0m| 41/50 [01:32<00:19,  2.21s/it]progress:  84%|[34m [0m| 42/50 [01:32<00:17,  2.21s/it]                                                         Episode 43	 reward: -7.51	 makespan: 743.80	 Mean_loss: -0.53091133,  training time: 2.17
progress:  84%|[34m [0m| 42/50 [01:35<00:17,  2.21s/it]progress:  86%|[34m [0m| 43/50 [01:35<00:15,  2.20s/it]                                                         Episode 44	 reward: -7.63	 makespan: 755.45	 Mean_loss: 0.03939154,  training time: 2.17
progress:  86%|[34m [0m| 43/50 [01:37<00:15,  2.20s/it]progress:  88%|[34m [0m| 44/50 [01:37<00:13,  2.19s/it]                                                         Episode 45	 reward: -7.63	 makespan: 755.00	 Mean_loss: -0.13749886,  training time: 2.12
progress:  88%|[34m [0m| 44/50 [01:39<00:13,  2.19s/it]progress:  90%|[34m [0m| 45/50 [01:39<00:10,  2.17s/it]                                                         Episode 46	 reward: -7.61	 makespan: 753.75	 Mean_loss: -0.52572602,  training time: 2.18
progress:  90%|[34m [0m| 45/50 [01:41<00:10,  2.17s/it]progress:  92%|[34m[0m| 46/50 [01:41<00:08,  2.18s/it]                                                         Episode 47	 reward: -7.53	 makespan: 745.40	 Mean_loss: -0.51802582,  training time: 2.19
progress:  92%|[34m[0m| 46/50 [01:43<00:08,  2.18s/it]progress:  94%|[34m[0m| 47/50 [01:43<00:06,  2.18s/it]                                                         Episode 48	 reward: -7.43	 makespan: 735.40	 Mean_loss: -0.18764517,  training time: 2.17
progress:  94%|[34m[0m| 47/50 [01:45<00:06,  2.18s/it]progress:  96%|[34m[0m| 48/50 [01:45<00:04,  2.18s/it]                                                         Episode 49	 reward: -7.61	 makespan: 753.60	 Mean_loss: -0.15976253,  training time: 2.16
progress:  96%|[34m[0m| 48/50 [01:48<00:04,  2.18s/it]progress:  98%|[34m[0m| 49/50 [01:48<00:02,  2.18s/it]                                                         Episode 50	 reward: -7.76	 makespan: 767.80	 Mean_loss: -0.18857411,  training time: 2.22
progress:  98%|[34m[0m| 49/50 [01:50<00:02,  2.18s/it]progress: 100%|[34m[0m| 50/50 [01:50<00:00,  2.19s/it]progress: 100%|[34m[0m| 50/50 [01:50<00:00,  2.21s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x5_10 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 10
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -10.56	 makespan: 1045.25	 Mean_loss: 0.12168077,  training time: 4.09
progress:   0%|[34m          [0m| 0/50 [00:04<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:04<03:21,  4.11s/it]                                                        Episode 2	 reward: -10.48	 makespan: 1037.80	 Mean_loss: 0.12895536,  training time: 2.95
progress:   2%|[34m         [0m| 1/50 [00:07<03:21,  4.11s/it]progress:   4%|[34m         [0m| 2/50 [00:07<02:44,  3.43s/it]                                                        Episode 3	 reward: -10.58	 makespan: 1047.20	 Mean_loss: 0.09848701,  training time: 2.93
progress:   4%|[34m         [0m| 2/50 [00:09<02:44,  3.43s/it]progress:   6%|[34m         [0m| 3/50 [00:10<02:30,  3.21s/it]                                                        Episode 4	 reward: -10.57	 makespan: 1046.15	 Mean_loss: 0.09522513,  training time: 2.94
progress:   6%|[34m         [0m| 3/50 [00:12<02:30,  3.21s/it]progress:   8%|[34m         [0m| 4/50 [00:12<02:22,  3.10s/it]                                                        Episode 5	 reward: -10.58	 makespan: 1046.95	 Mean_loss: 0.08497141,  training time: 2.99
progress:   8%|[34m         [0m| 4/50 [00:15<02:22,  3.10s/it]progress:  10%|[34m         [0m| 5/50 [00:15<02:17,  3.07s/it]                                                        Episode 6	 reward: -10.44	 makespan: 1033.10	 Mean_loss: 0.10274952,  training time: 3.11
progress:  10%|[34m         [0m| 5/50 [00:19<02:17,  3.07s/it]progress:  12%|[34m        [0m| 6/50 [00:19<02:15,  3.08s/it]                                                        Episode 7	 reward: -10.49	 makespan: 1038.55	 Mean_loss: 0.09989379,  training time: 3.02
progress:  12%|[34m        [0m| 6/50 [00:22<02:15,  3.08s/it]progress:  14%|[34m        [0m| 7/50 [00:22<02:11,  3.06s/it]                                                        Episode 8	 reward: -10.47	 makespan: 1036.70	 Mean_loss: 0.07915545,  training time: 2.99
progress:  14%|[34m        [0m| 7/50 [00:25<02:11,  3.06s/it]progress:  16%|[34m        [0m| 8/50 [00:25<02:07,  3.04s/it]                                                        Episode 9	 reward: -10.47	 makespan: 1036.25	 Mean_loss: 0.08069377,  training time: 2.98
progress:  16%|[34m        [0m| 8/50 [00:28<02:07,  3.04s/it]progress:  18%|[34m        [0m| 9/50 [00:28<02:04,  3.03s/it]                                                        Episode 10	 reward: -10.51	 makespan: 1040.35	 Mean_loss: 0.07120894,  training time: 3.11
progress:  18%|[34m        [0m| 9/50 [00:31<02:04,  3.03s/it]progress:  20%|[34m        [0m| 10/50 [00:31<02:02,  3.05s/it]                                                         Episode 11	 reward: -10.45	 makespan: 1034.45	 Mean_loss: 0.08646084,  training time: 3.02
progress:  20%|[34m        [0m| 10/50 [00:34<02:02,  3.05s/it]progress:  22%|[34m       [0m| 11/50 [00:34<01:58,  3.04s/it]                                                         Episode 12	 reward: -10.57	 makespan: 1046.70	 Mean_loss: 0.09656263,  training time: 3.02
progress:  22%|[34m       [0m| 11/50 [00:37<01:58,  3.04s/it]progress:  24%|[34m       [0m| 12/50 [00:37<01:55,  3.04s/it]                                                         Episode 13	 reward: -10.45	 makespan: 1034.80	 Mean_loss: 0.07445333,  training time: 3.10
progress:  24%|[34m       [0m| 12/50 [00:40<01:55,  3.04s/it]progress:  26%|[34m       [0m| 13/50 [00:40<01:53,  3.06s/it]                                                         Episode 14	 reward: -10.51	 makespan: 1040.50	 Mean_loss: 0.09847591,  training time: 2.99
progress:  26%|[34m       [0m| 13/50 [00:43<01:53,  3.06s/it]progress:  28%|[34m       [0m| 14/50 [00:43<01:49,  3.04s/it]                                                         Episode 15	 reward: -10.45	 makespan: 1035.00	 Mean_loss: 0.09042230,  training time: 2.89
progress:  28%|[34m       [0m| 14/50 [00:46<01:49,  3.04s/it]progress:  30%|[34m       [0m| 15/50 [00:46<01:44,  3.00s/it]                                                         Episode 16	 reward: -10.57	 makespan: 1046.50	 Mean_loss: 0.08639860,  training time: 2.91
progress:  30%|[34m       [0m| 15/50 [00:49<01:44,  3.00s/it]progress:  32%|[34m      [0m| 16/50 [00:49<01:41,  2.98s/it]                                                         Episode 17	 reward: -10.44	 makespan: 1033.95	 Mean_loss: 0.07778950,  training time: 2.95
progress:  32%|[34m      [0m| 16/50 [00:52<01:41,  2.98s/it]progress:  34%|[34m      [0m| 17/50 [00:52<01:37,  2.97s/it]                                                         Episode 18	 reward: -10.38	 makespan: 1027.70	 Mean_loss: 0.09519442,  training time: 2.91
progress:  34%|[34m      [0m| 17/50 [00:55<01:37,  2.97s/it]progress:  36%|[34m      [0m| 18/50 [00:55<01:34,  2.95s/it]                                                         Episode 19	 reward: -10.40	 makespan: 1029.15	 Mean_loss: 0.07507282,  training time: 2.94
progress:  36%|[34m      [0m| 18/50 [00:57<01:34,  2.95s/it]progress:  38%|[34m      [0m| 19/50 [00:57<01:31,  2.95s/it]                                                         Episode 20	 reward: -10.54	 makespan: 1043.60	 Mean_loss: 0.08394521,  training time: 2.92
progress:  38%|[34m      [0m| 19/50 [01:00<01:31,  2.95s/it]progress:  40%|[34m      [0m| 20/50 [01:00<01:28,  2.95s/it]                                                         Episode 21	 reward: -10.46	 makespan: 1035.65	 Mean_loss: 0.09009402,  training time: 2.92
progress:  40%|[34m      [0m| 20/50 [01:03<01:28,  2.95s/it]progress:  42%|[34m     [0m| 21/50 [01:03<01:25,  2.94s/it]                                                         Episode 22	 reward: -10.54	 makespan: 1043.30	 Mean_loss: 0.08130111,  training time: 2.96
progress:  42%|[34m     [0m| 21/50 [01:06<01:25,  2.94s/it]progress:  44%|[34m     [0m| 22/50 [01:06<01:22,  2.95s/it]                                                         Episode 23	 reward: -10.64	 makespan: 1052.90	 Mean_loss: 0.08995590,  training time: 2.92
progress:  44%|[34m     [0m| 22/50 [01:09<01:22,  2.95s/it]progress:  46%|[34m     [0m| 23/50 [01:09<01:19,  2.95s/it]                                                         Episode 24	 reward: -10.41	 makespan: 1030.50	 Mean_loss: 0.06605826,  training time: 2.95
progress:  46%|[34m     [0m| 23/50 [01:12<01:19,  2.95s/it]progress:  48%|[34m     [0m| 24/50 [01:12<01:16,  2.95s/it]                                                         Episode 25	 reward: -10.34	 makespan: 1023.95	 Mean_loss: 0.08380011,  training time: 2.92
progress:  48%|[34m     [0m| 24/50 [01:15<01:16,  2.95s/it]progress:  50%|[34m     [0m| 25/50 [01:15<01:13,  2.94s/it]                                                         Episode 26	 reward: -10.53	 makespan: 1042.40	 Mean_loss: 0.09440686,  training time: 2.95
progress:  50%|[34m     [0m| 25/50 [01:18<01:13,  2.94s/it]progress:  52%|[34m    [0m| 26/50 [01:18<01:10,  2.95s/it]                                                         Episode 27	 reward: -10.52	 makespan: 1041.35	 Mean_loss: 0.05609769,  training time: 2.91
progress:  52%|[34m    [0m| 26/50 [01:21<01:10,  2.95s/it]progress:  54%|[34m    [0m| 27/50 [01:21<01:07,  2.94s/it]                                                         Episode 28	 reward: -10.49	 makespan: 1038.45	 Mean_loss: 0.08716476,  training time: 2.90
progress:  54%|[34m    [0m| 27/50 [01:24<01:07,  2.94s/it]progress:  56%|[34m    [0m| 28/50 [01:24<01:04,  2.93s/it]                                                         Episode 29	 reward: -10.42	 makespan: 1031.35	 Mean_loss: 0.09235352,  training time: 2.97
progress:  56%|[34m    [0m| 28/50 [01:27<01:04,  2.93s/it]progress:  58%|[34m    [0m| 29/50 [01:27<01:01,  2.95s/it]                                                         Episode 30	 reward: -10.51	 makespan: 1040.60	 Mean_loss: 0.08107430,  training time: 2.92
progress:  58%|[34m    [0m| 29/50 [01:30<01:01,  2.95s/it]progress:  60%|[34m    [0m| 30/50 [01:30<00:58,  2.94s/it]                                                         Episode 31	 reward: -10.43	 makespan: 1032.80	 Mean_loss: 0.06483207,  training time: 3.00
progress:  60%|[34m    [0m| 30/50 [01:33<00:58,  2.94s/it]progress:  62%|[34m   [0m| 31/50 [01:33<00:56,  2.96s/it]                                                         Episode 32	 reward: -10.44	 makespan: 1033.30	 Mean_loss: 0.08019158,  training time: 2.96
progress:  62%|[34m   [0m| 31/50 [01:36<00:56,  2.96s/it]progress:  64%|[34m   [0m| 32/50 [01:36<00:53,  2.96s/it]                                                         Episode 33	 reward: -10.47	 makespan: 1037.00	 Mean_loss: 0.07362580,  training time: 2.98
progress:  64%|[34m   [0m| 32/50 [01:39<00:53,  2.96s/it]progress:  66%|[34m   [0m| 33/50 [01:39<00:50,  2.97s/it]                                                         Episode 34	 reward: -10.44	 makespan: 1033.60	 Mean_loss: 0.05785697,  training time: 2.97
progress:  66%|[34m   [0m| 33/50 [01:42<00:50,  2.97s/it]progress:  68%|[34m   [0m| 34/50 [01:42<00:47,  2.97s/it]                                                         Episode 35	 reward: -10.46	 makespan: 1036.00	 Mean_loss: 0.06642693,  training time: 2.96
progress:  68%|[34m   [0m| 34/50 [01:45<00:47,  2.97s/it]progress:  70%|[34m   [0m| 35/50 [01:45<00:44,  2.97s/it]                                                         Episode 36	 reward: -10.54	 makespan: 1043.25	 Mean_loss: 0.08501329,  training time: 2.95
progress:  70%|[34m   [0m| 35/50 [01:48<00:44,  2.97s/it]progress:  72%|[34m  [0m| 36/50 [01:48<00:41,  2.97s/it]                                                         Episode 37	 reward: -10.50	 makespan: 1039.50	 Mean_loss: 0.07423546,  training time: 2.96
progress:  72%|[34m  [0m| 36/50 [01:51<00:41,  2.97s/it]progress:  74%|[34m  [0m| 37/50 [01:51<00:38,  2.97s/it]                                                         Episode 38	 reward: -10.63	 makespan: 1052.50	 Mean_loss: 0.07376046,  training time: 2.96
progress:  74%|[34m  [0m| 37/50 [01:54<00:38,  2.97s/it]progress:  76%|[34m  [0m| 38/50 [01:54<00:35,  2.97s/it]                                                         Episode 39	 reward: -10.59	 makespan: 1048.85	 Mean_loss: 0.07888436,  training time: 2.96
progress:  76%|[34m  [0m| 38/50 [01:57<00:35,  2.97s/it]progress:  78%|[34m  [0m| 39/50 [01:57<00:32,  2.97s/it]                                                         Episode 40	 reward: -10.48	 makespan: 1037.20	 Mean_loss: 0.08121296,  training time: 2.97
progress:  78%|[34m  [0m| 39/50 [02:00<00:32,  2.97s/it]progress:  80%|[34m  [0m| 40/50 [02:00<00:29,  2.97s/it]                                                         Episode 41	 reward: -10.40	 makespan: 1029.60	 Mean_loss: 0.08515264,  training time: 2.91
progress:  80%|[34m  [0m| 40/50 [02:03<00:29,  2.97s/it]progress:  82%|[34m [0m| 41/50 [02:03<00:26,  2.96s/it]                                                         Episode 42	 reward: -10.61	 makespan: 1050.25	 Mean_loss: 0.07352315,  training time: 2.98
progress:  82%|[34m [0m| 41/50 [02:06<00:26,  2.96s/it]progress:  84%|[34m [0m| 42/50 [02:06<00:23,  2.97s/it]                                                         Episode 43	 reward: -10.45	 makespan: 1034.80	 Mean_loss: 0.10891111,  training time: 2.96
progress:  84%|[34m [0m| 42/50 [02:08<00:23,  2.97s/it]progress:  86%|[34m [0m| 43/50 [02:08<00:20,  2.97s/it]                                                         Episode 44	 reward: -10.46	 makespan: 1035.25	 Mean_loss: 0.07999702,  training time: 2.89
progress:  86%|[34m [0m| 43/50 [02:11<00:20,  2.97s/it]progress:  88%|[34m [0m| 44/50 [02:11<00:17,  2.95s/it]                                                         Episode 45	 reward: -10.55	 makespan: 1044.25	 Mean_loss: 0.08169717,  training time: 2.93
progress:  88%|[34m [0m| 44/50 [02:14<00:17,  2.95s/it]progress:  90%|[34m [0m| 45/50 [02:14<00:14,  2.94s/it]                                                         Episode 46	 reward: -10.46	 makespan: 1035.25	 Mean_loss: 0.07174244,  training time: 2.89
progress:  90%|[34m [0m| 45/50 [02:17<00:14,  2.94s/it]progress:  92%|[34m[0m| 46/50 [02:17<00:11,  2.93s/it]                                                         Episode 47	 reward: -10.48	 makespan: 1037.65	 Mean_loss: 0.07227285,  training time: 2.90
progress:  92%|[34m[0m| 46/50 [02:20<00:11,  2.93s/it]progress:  94%|[34m[0m| 47/50 [02:20<00:08,  2.92s/it]                                                         Episode 48	 reward: -10.46	 makespan: 1035.05	 Mean_loss: 0.09991908,  training time: 2.95
progress:  94%|[34m[0m| 47/50 [02:23<00:08,  2.92s/it]progress:  96%|[34m[0m| 48/50 [02:23<00:05,  2.93s/it]                                                         Episode 49	 reward: -10.54	 makespan: 1043.10	 Mean_loss: 0.09535250,  training time: 2.90
progress:  96%|[34m[0m| 48/50 [02:26<00:05,  2.93s/it]progress:  98%|[34m[0m| 49/50 [02:26<00:02,  2.92s/it]                                                         Episode 50	 reward: -10.64	 makespan: 1053.70	 Mean_loss: 0.08262090,  training time: 2.91
progress:  98%|[34m[0m| 49/50 [02:29<00:02,  2.92s/it]progress: 100%|[34m[0m| 50/50 [02:29<00:00,  2.92s/it]progress: 100%|[34m[0m| 50/50 [02:29<00:00,  2.99s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
+ for op_per_job in '$op_per_job_options'
+ python train/DAN_finetuning.py --logdir ./runs/exp17_1/DAN/finetuning/15x5+mix+SD2_12/15x5_12 --model_suffix free --finetuning_model 15x5+mix+SD2_12 --max_updates 50 --n_j 15 --n_m 5 --op_per_job 12
/work/home/lxx_hzau/miniconda3/envs/RL-torch/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181202/work/torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
vali_data = ./data/data_train_vali/SD2/15x5+mix
save model name:  15x5+mix+free
./trained_network/SD2/15x5+mix+SD2_12.pth
-------------------------Training Setting-------------------------
source : SD2
model name :./trained_network/SD2/15x5+mix+SD2_12.pth
vali data :./data/data_train_vali/SD2/15x5+mix


progress:   0%|[34m          [0m| 0/50 [00:00<?, ?it/s]                                                Episode 1	 reward: -12.71	 makespan: 1258.10	 Mean_loss: 0.19814403,  training time: 5.05
progress:   0%|[34m          [0m| 0/50 [00:05<?, ?it/s]progress:   2%|[34m         [0m| 1/50 [00:05<04:07,  5.06s/it]                                                        Episode 2	 reward: -12.76	 makespan: 1262.80	 Mean_loss: 0.20043166,  training time: 3.75
progress:   2%|[34m         [0m| 1/50 [00:08<04:07,  5.06s/it]progress:   4%|[34m         [0m| 2/50 [00:08<03:26,  4.30s/it]                                                        Episode 3	 reward: -12.78	 makespan: 1264.75	 Mean_loss: 0.17865774,  training time: 3.82
progress:   4%|[34m         [0m| 2/50 [00:12<03:26,  4.30s/it]progress:   6%|[34m         [0m| 3/50 [00:12<03:11,  4.08s/it]                                                        Episode 4	 reward: -12.91	 makespan: 1277.60	 Mean_loss: 0.18951862,  training time: 3.82
progress:   6%|[34m         [0m| 3/50 [00:16<03:11,  4.08s/it]progress:   8%|[34m         [0m| 4/50 [00:16<03:03,  3.98s/it]                                                        Episode 5	 reward: -12.72	 makespan: 1259.30	 Mean_loss: 0.17808999,  training time: 3.90
progress:   8%|[34m         [0m| 4/50 [00:20<03:03,  3.98s/it]progress:  10%|[34m         [0m| 5/50 [00:20<02:58,  3.96s/it]                                                        Episode 6	 reward: -12.88	 makespan: 1275.00	 Mean_loss: 0.20746410,  training time: 3.80
progress:  10%|[34m         [0m| 5/50 [00:24<02:58,  3.96s/it]progress:  12%|[34m        [0m| 6/50 [00:24<02:51,  3.91s/it]                                                        Episode 7	 reward: -12.88	 makespan: 1274.80	 Mean_loss: 0.20611206,  training time: 3.82
progress:  12%|[34m        [0m| 6/50 [00:28<02:51,  3.91s/it]progress:  14%|[34m        [0m| 7/50 [00:28<02:46,  3.88s/it]                                                        Episode 8	 reward: -12.80	 makespan: 1267.20	 Mean_loss: 0.19660477,  training time: 3.73
progress:  14%|[34m        [0m| 7/50 [00:31<02:46,  3.88s/it]progress:  16%|[34m        [0m| 8/50 [00:31<02:41,  3.84s/it]                                                        Episode 9	 reward: -12.79	 makespan: 1266.30	 Mean_loss: 0.16664934,  training time: 3.72
progress:  16%|[34m        [0m| 8/50 [00:35<02:41,  3.84s/it]progress:  18%|[34m        [0m| 9/50 [00:35<02:35,  3.80s/it]                                                        Episode 10	 reward: -12.79	 makespan: 1266.30	 Mean_loss: 0.18618509,  training time: 4.00
progress:  18%|[34m        [0m| 9/50 [00:39<02:35,  3.80s/it]progress:  20%|[34m        [0m| 10/50 [00:39<02:34,  3.87s/it]                                                         Episode 11	 reward: -12.79	 makespan: 1266.40	 Mean_loss: 0.17641862,  training time: 3.88
progress:  20%|[34m        [0m| 10/50 [00:43<02:34,  3.87s/it]progress:  22%|[34m       [0m| 11/50 [00:43<02:31,  3.87s/it]                                                         Episode 12	 reward: -12.91	 makespan: 1278.05	 Mean_loss: 0.17041871,  training time: 3.90
progress:  22%|[34m       [0m| 11/50 [00:47<02:31,  3.87s/it]progress:  24%|[34m       [0m| 12/50 [00:47<02:27,  3.89s/it]                                                         Episode 13	 reward: -12.88	 makespan: 1275.40	 Mean_loss: 0.17766094,  training time: 3.85
progress:  24%|[34m       [0m| 12/50 [00:51<02:27,  3.89s/it]progress:  26%|[34m       [0m| 13/50 [00:51<02:23,  3.88s/it]                                                         Episode 14	 reward: -12.87	 makespan: 1274.50	 Mean_loss: 0.18490487,  training time: 3.78
progress:  26%|[34m       [0m| 13/50 [00:54<02:23,  3.88s/it]progress:  28%|[34m       [0m| 14/50 [00:54<02:18,  3.85s/it]                                                         Episode 15	 reward: -12.81	 makespan: 1268.20	 Mean_loss: 0.18407449,  training time: 3.77
progress:  28%|[34m       [0m| 14/50 [00:58<02:18,  3.85s/it]progress:  30%|[34m       [0m| 15/50 [00:58<02:14,  3.83s/it]                                                         Episode 16	 reward: -12.83	 makespan: 1269.85	 Mean_loss: 0.18993700,  training time: 3.81
progress:  30%|[34m       [0m| 15/50 [01:02<02:14,  3.83s/it]progress:  32%|[34m      [0m| 16/50 [01:02<02:10,  3.83s/it]                                                         Episode 17	 reward: -12.79	 makespan: 1265.95	 Mean_loss: 0.16989118,  training time: 3.76
progress:  32%|[34m      [0m| 16/50 [01:06<02:10,  3.83s/it]progress:  34%|[34m      [0m| 17/50 [01:06<02:05,  3.81s/it]                                                         Episode 18	 reward: -12.95	 makespan: 1282.40	 Mean_loss: 0.17248000,  training time: 3.76
progress:  34%|[34m      [0m| 17/50 [01:10<02:05,  3.81s/it]progress:  36%|[34m      [0m| 18/50 [01:10<02:01,  3.80s/it]                                                         Episode 19	 reward: -12.84	 makespan: 1271.30	 Mean_loss: 0.19322848,  training time: 3.76
progress:  36%|[34m      [0m| 18/50 [01:13<02:01,  3.80s/it]progress:  38%|[34m      [0m| 19/50 [01:13<01:57,  3.79s/it]                                                         Episode 20	 reward: -12.83	 makespan: 1270.35	 Mean_loss: 0.17266256,  training time: 3.78
progress:  38%|[34m      [0m| 19/50 [01:17<01:57,  3.79s/it]progress:  40%|[34m      [0m| 20/50 [01:17<01:53,  3.79s/it]                                                         Episode 21	 reward: -12.91	 makespan: 1278.40	 Mean_loss: 0.15371157,  training time: 3.83
progress:  40%|[34m      [0m| 20/50 [01:21<01:53,  3.79s/it]progress:  42%|[34m     [0m| 21/50 [01:21<01:50,  3.80s/it]                                                         Episode 22	 reward: -12.84	 makespan: 1271.45	 Mean_loss: 0.17103156,  training time: 3.77
progress:  42%|[34m     [0m| 21/50 [01:25<01:50,  3.80s/it]progress:  44%|[34m     [0m| 22/50 [01:25<01:46,  3.79s/it]                                                         Episode 23	 reward: -12.67	 makespan: 1254.55	 Mean_loss: 0.18137442,  training time: 3.76
progress:  44%|[34m     [0m| 22/50 [01:29<01:46,  3.79s/it]progress:  46%|[34m     [0m| 23/50 [01:29<01:42,  3.79s/it]                                                         Episode 24	 reward: -12.84	 makespan: 1271.45	 Mean_loss: 0.18479259,  training time: 3.77
progress:  46%|[34m     [0m| 23/50 [01:32<01:42,  3.79s/it]progress:  48%|[34m     [0m| 24/50 [01:32<01:38,  3.79s/it]                                                         Episode 25	 reward: -12.80	 makespan: 1266.75	 Mean_loss: 0.17712606,  training time: 3.76
progress:  48%|[34m     [0m| 24/50 [01:36<01:38,  3.79s/it]progress:  50%|[34m     [0m| 25/50 [01:36<01:34,  3.78s/it]                                                         Episode 26	 reward: -12.85	 makespan: 1272.40	 Mean_loss: 0.15730102,  training time: 3.77
progress:  50%|[34m     [0m| 25/50 [01:40<01:34,  3.78s/it]progress:  52%|[34m    [0m| 26/50 [01:40<01:30,  3.78s/it]                                                         Episode 27	 reward: -12.89	 makespan: 1276.40	 Mean_loss: 0.17181048,  training time: 3.76
progress:  52%|[34m    [0m| 26/50 [01:44<01:30,  3.78s/it]progress:  54%|[34m    [0m| 27/50 [01:44<01:26,  3.78s/it]                                                         Episode 28	 reward: -12.72	 makespan: 1259.75	 Mean_loss: 0.17427146,  training time: 3.74
progress:  54%|[34m    [0m| 27/50 [01:47<01:26,  3.78s/it]progress:  56%|[34m    [0m| 28/50 [01:47<01:22,  3.77s/it]                                                         Episode 29	 reward: -12.76	 makespan: 1263.60	 Mean_loss: 0.18572296,  training time: 4.07
progress:  56%|[34m    [0m| 28/50 [01:51<01:22,  3.77s/it]progress:  58%|[34m    [0m| 29/50 [01:51<01:21,  3.86s/it]                                                         Episode 30	 reward: -12.83	 makespan: 1270.35	 Mean_loss: 0.17424862,  training time: 3.93
progress:  58%|[34m    [0m| 29/50 [01:55<01:21,  3.86s/it]progress:  60%|[34m    [0m| 30/50 [01:55<01:17,  3.89s/it]                                                         Episode 31	 reward: -12.74	 makespan: 1260.85	 Mean_loss: 0.17037712,  training time: 3.90
progress:  60%|[34m    [0m| 30/50 [01:59<01:17,  3.89s/it]progress:  62%|[34m   [0m| 31/50 [01:59<01:14,  3.90s/it]                                                         Episode 32	 reward: -12.75	 makespan: 1262.55	 Mean_loss: 0.15064397,  training time: 3.76
progress:  62%|[34m   [0m| 31/50 [02:03<01:14,  3.90s/it]progress:  64%|[34m   [0m| 32/50 [02:03<01:09,  3.86s/it]                                                         Episode 33	 reward: -12.73	 makespan: 1260.25	 Mean_loss: 0.14612657,  training time: 3.76
progress:  64%|[34m   [0m| 32/50 [02:07<01:09,  3.86s/it]progress:  66%|[34m   [0m| 33/50 [02:07<01:05,  3.83s/it]                                                         Episode 34	 reward: -12.74	 makespan: 1261.60	 Mean_loss: 0.13912725,  training time: 3.77
progress:  66%|[34m   [0m| 33/50 [02:11<01:05,  3.83s/it]progress:  68%|[34m   [0m| 34/50 [02:11<01:01,  3.82s/it]                                                         Episode 35	 reward: -12.72	 makespan: 1259.15	 Mean_loss: 0.17313442,  training time: 3.79
progress:  68%|[34m   [0m| 34/50 [02:14<01:01,  3.82s/it]progress:  70%|[34m   [0m| 35/50 [02:14<00:57,  3.81s/it]                                                         Episode 36	 reward: -12.86	 makespan: 1272.95	 Mean_loss: 0.15894544,  training time: 3.75
progress:  70%|[34m   [0m| 35/50 [02:18<00:57,  3.81s/it]progress:  72%|[34m  [0m| 36/50 [02:18<00:53,  3.80s/it]                                                         Episode 37	 reward: -12.80	 makespan: 1267.45	 Mean_loss: 0.20613825,  training time: 3.75
progress:  72%|[34m  [0m| 36/50 [02:22<00:53,  3.80s/it]progress:  74%|[34m  [0m| 37/50 [02:22<00:49,  3.79s/it]                                                         Episode 38	 reward: -12.74	 makespan: 1260.80	 Mean_loss: 0.16562980,  training time: 3.80
progress:  74%|[34m  [0m| 37/50 [02:26<00:49,  3.79s/it]progress:  76%|[34m  [0m| 38/50 [02:26<00:45,  3.79s/it]                                                         Episode 39	 reward: -12.69	 makespan: 1256.60	 Mean_loss: 0.18507694,  training time: 3.73
progress:  76%|[34m  [0m| 38/50 [02:30<00:45,  3.79s/it]progress:  78%|[34m  [0m| 39/50 [02:30<00:41,  3.78s/it]                                                         Episode 40	 reward: -12.75	 makespan: 1262.40	 Mean_loss: 0.17406654,  training time: 3.70
progress:  78%|[34m  [0m| 39/50 [02:33<00:41,  3.78s/it]progress:  80%|[34m  [0m| 40/50 [02:33<00:37,  3.76s/it]                                                         Episode 41	 reward: -12.69	 makespan: 1256.30	 Mean_loss: 0.17392869,  training time: 3.73
progress:  80%|[34m  [0m| 40/50 [02:37<00:37,  3.76s/it]progress:  82%|[34m [0m| 41/50 [02:37<00:33,  3.75s/it]                                                         Episode 42	 reward: -12.77	 makespan: 1264.15	 Mean_loss: 0.15091982,  training time: 3.71
progress:  82%|[34m [0m| 41/50 [02:41<00:33,  3.75s/it]progress:  84%|[34m [0m| 42/50 [02:41<00:29,  3.74s/it]                                                         Episode 43	 reward: -12.82	 makespan: 1268.95	 Mean_loss: 0.16662210,  training time: 3.71
progress:  84%|[34m [0m| 42/50 [02:44<00:29,  3.74s/it]progress:  86%|[34m [0m| 43/50 [02:44<00:26,  3.73s/it]                                                         Episode 44	 reward: -12.84	 makespan: 1271.10	 Mean_loss: 0.16436318,  training time: 3.73
progress:  86%|[34m [0m| 43/50 [02:48<00:26,  3.73s/it]progress:  88%|[34m [0m| 44/50 [02:48<00:22,  3.73s/it]                                                         Episode 45	 reward: -12.81	 makespan: 1268.00	 Mean_loss: 0.15025133,  training time: 3.71
progress:  88%|[34m [0m| 44/50 [02:52<00:22,  3.73s/it]progress:  90%|[34m [0m| 45/50 [02:52<00:18,  3.73s/it]                                                         Episode 46	 reward: -12.62	 makespan: 1249.25	 Mean_loss: 0.16209255,  training time: 3.72
progress:  90%|[34m [0m| 45/50 [02:56<00:18,  3.73s/it]progress:  92%|[34m[0m| 46/50 [02:56<00:14,  3.73s/it]                                                         Episode 47	 reward: -12.67	 makespan: 1254.70	 Mean_loss: 0.17289236,  training time: 3.86
progress:  92%|[34m[0m| 46/50 [02:59<00:14,  3.73s/it]progress:  94%|[34m[0m| 47/50 [02:59<00:11,  3.77s/it]                                                         Episode 48	 reward: -12.69	 makespan: 1256.05	 Mean_loss: 0.15784258,  training time: 3.72
progress:  94%|[34m[0m| 47/50 [03:03<00:11,  3.77s/it]progress:  96%|[34m[0m| 48/50 [03:03<00:07,  3.76s/it]                                                         Episode 49	 reward: -12.69	 makespan: 1256.05	 Mean_loss: 0.16012660,  training time: 3.71
progress:  96%|[34m[0m| 48/50 [03:07<00:07,  3.76s/it]progress:  98%|[34m[0m| 49/50 [03:07<00:03,  3.75s/it]                                                         Episode 50	 reward: -12.67	 makespan: 1254.75	 Mean_loss: 0.16917354,  training time: 3.88
progress:  98%|[34m[0m| 49/50 [03:11<00:03,  3.75s/it]progress: 100%|[34m[0m| 50/50 [03:11<00:00,  3.81s/it]progress: 100%|[34m[0m| 50/50 [03:11<00:00,  3.83s/it]
+ --num_envs 4 --lr 0.003
+ local runcnf=1
+ local retval=127
+ [[ hxB =~ i ]]
+ runcnf=0
+ [[ ! -S /run/dbus/system_bus_socket ]]
+ [[ ! -x /usr/libexec/packagekitd ]]
+ [[ -n '' ]]
+ '[' 0 -eq 1 ']'
+ [[ -n 4.2.46(2)-release ]]
+ printf 'bash: %scommand not found\n' '--num_envs: '
bash: --num_envs: command not found
+ return 127
